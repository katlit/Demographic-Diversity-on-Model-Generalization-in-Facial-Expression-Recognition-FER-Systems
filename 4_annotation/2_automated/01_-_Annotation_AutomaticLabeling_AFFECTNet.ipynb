{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fabd9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# https://github.com/serengil/deepface\n",
    "from deepface import DeepFace\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d26056df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swith it to false to run the full version\n",
    "DEMO = True\n",
    "MAX_IMAGIES_TO_ANALYZE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8052d8e",
   "metadata": {},
   "source": [
    "### Annotate Affectnet\n",
    "\n",
    "(including angry, fear, neutral, sad, disgust, happy and surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8eb4bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image0000006.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:   0%|          | 0/4 [00:00<?, ?it/s]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image0000060.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image0000061.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to e:\\ITU-BOOK\\Data in Wild\\Project\\DataInWild\\SUBMISSION\\4_annotation\\3_annotation_results/face_analysis_results_affectnet_anger_demo.csv\n",
      "Analysis completed! Results saved to face_analysis_results_affectnet_anger_demo.csv\n",
      "Processing ffhq_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ffhq_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ffhq_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to e:\\ITU-BOOK\\Data in Wild\\Project\\DataInWild\\SUBMISSION\\4_annotation\\3_annotation_results/face_analysis_results_affectnet_disgust_demo.csv\n",
      "Analysis completed! Results saved to face_analysis_results_affectnet_disgust_demo.csv\n",
      "Processing image0000284.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image0000285.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image0000419.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to e:\\ITU-BOOK\\Data in Wild\\Project\\DataInWild\\SUBMISSION\\4_annotation\\3_annotation_results/face_analysis_results_affectnet_fear_demo.csv\n",
      "Analysis completed! Results saved to face_analysis_results_affectnet_fear_demo.csv\n",
      "Processing ffhq_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ffhq_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ffhq_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to e:\\ITU-BOOK\\Data in Wild\\Project\\DataInWild\\SUBMISSION\\4_annotation\\3_annotation_results/face_analysis_results_affectnet_happy_demo.csv\n",
      "Analysis completed! Results saved to face_analysis_results_affectnet_happy_demo.csv\n",
      "Processing ffhq_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ffhq_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ffhq_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to e:\\ITU-BOOK\\Data in Wild\\Project\\DataInWild\\SUBMISSION\\4_annotation\\3_annotation_results/face_analysis_results_affectnet_neutral_demo.csv\n",
      "Analysis completed! Results saved to face_analysis_results_affectnet_neutral_demo.csv\n",
      "Processing image0000013.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image0000027.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image0000028.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to e:\\ITU-BOOK\\Data in Wild\\Project\\DataInWild\\SUBMISSION\\4_annotation\\3_annotation_results/face_analysis_results_affectnet_sad_demo.csv\n",
      "Analysis completed! Results saved to face_analysis_results_affectnet_sad_demo.csv\n",
      "Processing ffhq_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ffhq_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ffhq_100.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to e:\\ITU-BOOK\\Data in Wild\\Project\\DataInWild\\SUBMISSION\\4_annotation\\3_annotation_results/face_analysis_results_affectnet_surprise_demo.csv\n",
      "Analysis completed! Results saved to face_analysis_results_affectnet_surprise_demo.csv\n",
      "Processing ffhq_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ffhq_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ffhq_100.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to e:\\ITU-BOOK\\Data in Wild\\Project\\DataInWild\\SUBMISSION\\4_annotation\\3_annotation_results/face_analysis_results_affectnet_contempt_demo.csv\n",
      "Analysis completed! Results saved to face_analysis_results_affectnet_contempt_demo.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_faces_in_directory(directory, emotion_folder, DEMO=True, MAX_IMAGIES_TO_ANALYZE=3):\n",
    "    # Create a DataFrame to store the analysis results\n",
    "    results_df = pd.DataFrame(columns=[\"Image\", \"Age\", \"Gender\", \"Race\", \"Emotion\"])\n",
    "    results = []\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    if DEMO:\n",
    "        END = MAX_IMAGIES_TO_ANALYZE\n",
    "    else:\n",
    "        END = len(os.listdir(directory))\n",
    "    for filename in os.listdir(directory)[:END]:\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Add more extensions if needed\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                # Analyze the face in the image with enforce_detection=False\n",
    "                print(f\"Processing {filename}\")\n",
    "                analysis = DeepFace.analyze(img_path=file_path, actions=['age', 'gender', 'race', 'emotion'], enforce_detection=False)\n",
    "\n",
    "                # DeepFace returns a list, so access the first dictionary in the list\n",
    "                analysis = analysis[0]\n",
    "\n",
    "                result_dict = {\n",
    "                    \"Image\": f\"{emotion_folder}_-_{filename}\",\n",
    "                    \"Age\": analysis.get('age', 'N/A'),\n",
    "                    \"Gender\": analysis.get('dominant_gender', 'N/A'),\n",
    "                    \"Race\": analysis.get('dominant_race', 'N/A'),\n",
    "                    \"Emotion\": analysis.get('dominant_emotion', 'N/A')\n",
    "                }\n",
    "                \n",
    "                results.append(result_dict)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Save results to CSV\n",
    "    if results:  # Check if we have any results\n",
    "        results_df = pd.DataFrame(results)\n",
    "        folder = \"../3_annotation_results/\"\n",
    "        if DEMO:\n",
    "            output_file = f'face_analysis_results_affectnet_{emotion_folder}_demo.csv'\n",
    "        else:\n",
    "            output_file = f'face_analysis_results_affectnet_{emotion_folder}.csv'\n",
    "        directory_path = os.path.abspath(f\"{folder}\")\n",
    "        print(f\"Saving to {directory_path}/{output_file}\")\n",
    "        results_df.to_csv(folder+output_file, index=False)\n",
    "        print(f\"Analysis completed! Results saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No results to save!\")\n",
    "\n",
    "\n",
    "\n",
    "directory_path = '../../3_image_datasets/affectnet/Test'\n",
    "emotion_folders = ['anger', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise', 'contempt']\n",
    "for e in emotion_folders:\n",
    "    analyze_faces_in_directory(directory=f\"{directory_path}/{e}\", \n",
    "                               emotion_folder = e,\n",
    "                               DEMO=DEMO,\n",
    "                               MAX_IMAGIES_TO_ANALYZE=MAX_IMAGIES_TO_ANALYZE\n",
    "                               )  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
