<html lang="en-US" class="Preview toolbar-stuck"><head>
      <meta name="citation_pii" content="S0169260722000062">
<meta name="citation_id" content="106621">
<meta name="citation_issn" content="0169-2607">
<meta name="citation_volume" content="215">
<meta name="citation_publisher" content="Elsevier">
<meta name="citation_firstpage" content="106621">
<meta name="citation_journal_title" content="Computer Methods and Programs in Biomedicine">
<meta name="citation_type" content="JOUR">
<meta name="citation_doi" content="10.1016/j.cmpb.2022.106621">
<meta name="dc.identifier" content="10.1016/j.cmpb.2022.106621">
<meta name="citation_article_type" content="Full-length article">
<meta property="og:description" content="Facial expression recognition technology will play an increasingly important role in our daily life. Autonomous driving, virtual reality and all kinds…">
<meta property="og:image" content="https://ars.els-cdn.com/content/image/1-s2.0-S0169260721X00181-cov150h.gif">
<meta name="citation_title" content="Facial expression recognition based on deep learning">
<meta property="og:title" content="Facial expression recognition based on deep learning">
<meta name="citation_publication_date" content="2022/03/01">
<meta name="citation_online_date" content="2022/01/06">
<meta name="robots" content="INDEX,FOLLOW,NOARCHIVE,NOCACHE,NOODP,NOYDIR">
      <title>Facial expression recognition based on deep learning - ScienceDirect</title>
      <link rel="canonical" href="https://www.sciencedirect.com/science/article/abs/pii/S0169260722000062">
      <meta name="tdm-reservation" content="1">
      <meta name="tdm-policy" content="https://www.elsevier.com/tdm/tdmrep-policy.json">
      <meta property="og:type" content="article">
      <meta name="viewport" content="initial-scale=1">
      <meta name="SDTech" content="Proudly brought to you by the SD Technology team">
      <script async="" src="https://cdn.pendo.io/agent/static/d6c1d995-bc7e-4e53-77f1-2ea4ecbb9565/pendo.js"></script><script type="text/javascript">(function newRelicBrowserProSPA() {
  ;
  window.NREUM || (NREUM = {});
  NREUM.init = {
    privacy: {
      cookies_enabled: false
    },
    ajax: {
      deny_list: ["bam-cell.nr-data.net"]
    }
  };
  ;
  NREUM.loader_config = {
    accountID: "2128461",
    trustKey: "2038175",
    agentID: "1118783207",
    licenseKey: "7ac4127487",
    applicationID: "814813181"
  };
  ;
  NREUM.info = {
    beacon: "bam.nr-data.net",
    errorBeacon: "bam.nr-data.net",
    licenseKey: "7ac4127487",
    applicationID: "814813181",
    sa: 1
  };
  ; /*! For license information please see nr-loader-spa-1.238.0.min.js.LICENSE.txt */
  (() => {
    "use strict";

    var e,
      t,
      r = {
        5763: (e, t, r) => {
          r.d(t, {
            P_: () => f,
            Mt: () => p,
            C5: () => s,
            DL: () => v,
            OP: () => T,
            lF: () => D,
            Yu: () => y,
            Dg: () => h,
            CX: () => c,
            GE: () => b,
            sU: () => _
          });
          var n = r(8632),
            i = r(9567);
          const o = {
              beacon: n.ce.beacon,
              errorBeacon: n.ce.errorBeacon,
              licenseKey: void 0,
              applicationID: void 0,
              sa: void 0,
              queueTime: void 0,
              applicationTime: void 0,
              ttGuid: void 0,
              user: void 0,
              account: void 0,
              product: void 0,
              extra: void 0,
              jsAttributes: {},
              userAttributes: void 0,
              atts: void 0,
              transactionName: void 0,
              tNamePlain: void 0
            },
            a = {};
          function s(e) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            if (!a[e]) throw new Error("Info for ".concat(e, " was never set"));
            return a[e];
          }
          function c(e, t) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            a[e] = (0, i.D)(t, o), (0, n.Qy)(e, a[e], "info");
          }
          var u = r(7056);
          const d = () => {
              const e = {
                blockSelector: "[data-nr-block]",
                maskInputOptions: {
                  password: !0
                }
              };
              return {
                allow_bfcache: !0,
                privacy: {
                  cookies_enabled: !0
                },
                ajax: {
                  deny_list: void 0,
                  block_internal: !0,
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                distributed_tracing: {
                  enabled: void 0,
                  exclude_newrelic_header: void 0,
                  cors_use_newrelic_header: void 0,
                  cors_use_tracecontext_headers: void 0,
                  allowed_origins: void 0
                },
                session: {
                  domain: void 0,
                  expiresMs: u.oD,
                  inactiveMs: u.Hb
                },
                ssl: void 0,
                obfuscate: void 0,
                jserrors: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                metrics: {
                  enabled: !0
                },
                page_action: {
                  enabled: !0,
                  harvestTimeSeconds: 30
                },
                page_view_event: {
                  enabled: !0
                },
                page_view_timing: {
                  enabled: !0,
                  harvestTimeSeconds: 30,
                  long_task: !1
                },
                session_trace: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                harvest: {
                  tooManyRequestsDelay: 60
                },
                session_replay: {
                  enabled: !1,
                  harvestTimeSeconds: 60,
                  sampleRate: .1,
                  errorSampleRate: .1,
                  maskTextSelector: "*",
                  maskAllInputs: !0,
                  get blockClass() {
                    return "nr-block";
                  },
                  get ignoreClass() {
                    return "nr-ignore";
                  },
                  get maskTextClass() {
                    return "nr-mask";
                  },
                  get blockSelector() {
                    return e.blockSelector;
                  },
                  set blockSelector(t) {
                    e.blockSelector += ",".concat(t);
                  },
                  get maskInputOptions() {
                    return e.maskInputOptions;
                  },
                  set maskInputOptions(t) {
                    e.maskInputOptions = {
                      ...t,
                      password: !0
                    };
                  }
                },
                spa: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                }
              };
            },
            l = {};
          function f(e) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            if (!l[e]) throw new Error("Configuration for ".concat(e, " was never set"));
            return l[e];
          }
          function h(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            l[e] = (0, i.D)(t, d()), (0, n.Qy)(e, l[e], "config");
          }
          function p(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            var r = f(e);
            if (r) {
              for (var n = t.split("."), i = 0; i < n.length - 1; i++) if ("object" != typeof (r = r[n[i]])) return;
              r = r[n[n.length - 1]];
            }
            return r;
          }
          const g = {
              accountID: void 0,
              trustKey: void 0,
              agentID: void 0,
              licenseKey: void 0,
              applicationID: void 0,
              xpid: void 0
            },
            m = {};
          function v(e) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            if (!m[e]) throw new Error("LoaderConfig for ".concat(e, " was never set"));
            return m[e];
          }
          function b(e, t) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            m[e] = (0, i.D)(t, g), (0, n.Qy)(e, m[e], "loader_config");
          }
          const y = (0, n.mF)().o;
          var w = r(385),
            A = r(6818);
          const x = {
              buildEnv: A.Re,
              bytesSent: {},
              queryBytesSent: {},
              customTransaction: void 0,
              disabled: !1,
              distMethod: A.gF,
              isolatedBacklog: !1,
              loaderType: void 0,
              maxBytes: 3e4,
              offset: Math.floor(w._A?.performance?.timeOrigin || w._A?.performance?.timing?.navigationStart || Date.now()),
              onerror: void 0,
              origin: "" + w._A.location,
              ptid: void 0,
              releaseIds: {},
              session: void 0,
              xhrWrappable: "function" == typeof w._A.XMLHttpRequest?.prototype?.addEventListener,
              version: A.q4,
              denyList: void 0
            },
            E = {};
          function T(e) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            if (!E[e]) throw new Error("Runtime for ".concat(e, " was never set"));
            return E[e];
          }
          function _(e, t) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            E[e] = (0, i.D)(t, x), (0, n.Qy)(e, E[e], "runtime");
          }
          function D(e) {
            return function (e) {
              try {
                const t = s(e);
                return !!t.licenseKey && !!t.errorBeacon && !!t.applicationID;
              } catch (e) {
                return !1;
              }
            }(e);
          }
        },
        9567: (e, t, r) => {
          r.d(t, {
            D: () => i
          });
          var n = r(50);
          function i(e, t) {
            try {
              if (!e || "object" != typeof e) return (0, n.Z)("Setting a Configurable requires an object as input");
              if (!t || "object" != typeof t) return (0, n.Z)("Setting a Configurable requires a model to set its initial properties");
              const r = Object.create(Object.getPrototypeOf(t), Object.getOwnPropertyDescriptors(t)),
                o = 0 === Object.keys(r).length ? e : r;
              for (let a in o) if (void 0 !== e[a]) try {
                "object" == typeof e[a] && "object" == typeof t[a] ? r[a] = i(e[a], t[a]) : r[a] = e[a];
              } catch (e) {
                (0, n.Z)("An error occurred while setting a property of a Configurable", e);
              }
              return r;
            } catch (e) {
              (0, n.Z)("An error occured while setting a Configurable", e);
            }
          }
        },
        6818: (e, t, r) => {
          r.d(t, {
            Re: () => i,
            gF: () => o,
            q4: () => n
          });
          const n = "1.238.0",
            i = "PROD",
            o = "CDN";
        },
        385: (e, t, r) => {
          r.d(t, {
            FN: () => a,
            IF: () => u,
            Nk: () => l,
            Tt: () => s,
            _A: () => o,
            il: () => n,
            pL: () => c,
            v6: () => i,
            w1: () => d
          });
          const n = "undefined" != typeof window && !!window.document,
            i = "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self.navigator instanceof WorkerNavigator || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis.navigator instanceof WorkerNavigator),
            o = n ? window : "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis),
            a = "" + o?.location,
            s = /iPad|iPhone|iPod/.test(navigator.userAgent),
            c = s && "undefined" == typeof SharedWorker,
            u = (() => {
              const e = navigator.userAgent.match(/Firefox[/\s](\d+\.\d+)/);
              return Array.isArray(e) && e.length >= 2 ? +e[1] : 0;
            })(),
            d = Boolean(n && window.document.documentMode),
            l = !!navigator.sendBeacon;
        },
        1117: (e, t, r) => {
          r.d(t, {
            w: () => o
          });
          var n = r(50);
          const i = {
            agentIdentifier: "",
            ee: void 0
          };
          class o {
            constructor(e) {
              try {
                if ("object" != typeof e) return (0, n.Z)("shared context requires an object as input");
                this.sharedContext = {}, Object.assign(this.sharedContext, i), Object.entries(e).forEach(e => {
                  let [t, r] = e;
                  Object.keys(i).includes(t) && (this.sharedContext[t] = r);
                });
              } catch (e) {
                (0, n.Z)("An error occured while setting SharedContext", e);
              }
            }
          }
        },
        8e3: (e, t, r) => {
          r.d(t, {
            L: () => d,
            R: () => c
          });
          var n = r(8325),
            i = r(1284),
            o = r(4322),
            a = r(3325);
          const s = {};
          function c(e, t) {
            const r = {
              staged: !1,
              priority: a.p[t] || 0
            };
            u(e), s[e].get(t) || s[e].set(t, r);
          }
          function u(e) {
            e && (s[e] || (s[e] = new Map()));
          }
          function d() {
            let e = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : "",
              t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : "feature";
            if (u(e), !e || !s[e].get(t)) return a(t);
            s[e].get(t).staged = !0;
            const r = [...s[e]];
            function a(t) {
              const r = e ? n.ee.get(e) : n.ee,
                a = o.X.handlers;
              if (r.backlog && a) {
                var s = r.backlog[t],
                  c = a[t];
                if (c) {
                  for (var u = 0; s && u < s.length; ++u) l(s[u], c);
                  (0, i.D)(c, function (e, t) {
                    (0, i.D)(t, function (t, r) {
                      r[0].on(e, r[1]);
                    });
                  });
                }
                delete a[t], r.backlog[t] = null, r.emit("drain-" + t, []);
              }
            }
            r.every(e => {
              let [t, r] = e;
              return r.staged;
            }) && (r.sort((e, t) => e[1].priority - t[1].priority), r.forEach(e => {
              let [t] = e;
              a(t);
            }));
          }
          function l(e, t) {
            var r = e[1];
            (0, i.D)(t[r], function (t, r) {
              var n = e[0];
              if (r[0] === n) {
                var i = r[1],
                  o = e[3],
                  a = e[2];
                i.apply(o, a);
              }
            });
          }
        },
        8325: (e, t, r) => {
          r.d(t, {
            A: () => c,
            ee: () => u
          });
          var n = r(8632),
            i = r(2210),
            o = r(5763);
          class a {
            constructor(e) {
              this.contextId = e;
            }
          }
          var s = r(3117);
          const c = "nr@context:".concat(s.a),
            u = function e(t, r) {
              var n = {},
                s = {},
                d = {},
                f = !1;
              try {
                f = 16 === r.length && (0, o.OP)(r).isolatedBacklog;
              } catch (e) {}
              var h = {
                on: g,
                addEventListener: g,
                removeEventListener: function (e, t) {
                  var r = n[e];
                  if (!r) return;
                  for (var i = 0; i < r.length; i++) r[i] === t && r.splice(i, 1);
                },
                emit: function (e, r, n, i, o) {
                  !1 !== o && (o = !0);
                  if (u.aborted && !i) return;
                  t && o && t.emit(e, r, n);
                  for (var a = p(n), c = m(e), d = c.length, l = 0; l < d; l++) c[l].apply(a, r);
                  var f = b()[s[e]];
                  f && f.push([h, e, r, a]);
                  return a;
                },
                get: v,
                listeners: m,
                context: p,
                buffer: function (e, t) {
                  const r = b();
                  if (t = t || "feature", h.aborted) return;
                  Object.entries(e || {}).forEach(e => {
                    let [n, i] = e;
                    s[i] = t, t in r || (r[t] = []);
                  });
                },
                abort: l,
                aborted: !1,
                isBuffering: function (e) {
                  return !!b()[s[e]];
                },
                debugId: r,
                backlog: f ? {} : t && "object" == typeof t.backlog ? t.backlog : {}
              };
              return h;
              function p(e) {
                return e && e instanceof a ? e : e ? (0, i.X)(e, c, () => new a(c)) : new a(c);
              }
              function g(e, t) {
                n[e] = m(e).concat(t);
              }
              function m(e) {
                return n[e] || [];
              }
              function v(t) {
                return d[t] = d[t] || e(h, t);
              }
              function b() {
                return h.backlog;
              }
            }(void 0, "globalEE"),
            d = (0, n.fP)();
          function l() {
            u.aborted = !0, u.backlog = {};
          }
          d.ee || (d.ee = u);
        },
        5546: (e, t, r) => {
          r.d(t, {
            E: () => n,
            p: () => i
          });
          var n = r(8325).ee.get("handle");
          function i(e, t, r, i, o) {
            o ? (o.buffer([e], i), o.emit(e, t, r)) : (n.buffer([e], i), n.emit(e, t, r));
          }
        },
        4322: (e, t, r) => {
          r.d(t, {
            X: () => o
          });
          var n = r(5546);
          o.on = a;
          var i = o.handlers = {};
          function o(e, t, r, o) {
            a(o || n.E, i, e, t, r);
          }
          function a(e, t, r, i, o) {
            o || (o = "feature"), e || (e = n.E);
            var a = t[o] = t[o] || {};
            (a[r] = a[r] || []).push([e, i]);
          }
        },
        3239: (e, t, r) => {
          r.d(t, {
            bP: () => s,
            iz: () => c,
            m$: () => a
          });
          var n = r(385);
          let i = !1,
            o = !1;
          try {
            const e = {
              get passive() {
                return i = !0, !1;
              },
              get signal() {
                return o = !0, !1;
              }
            };
            n._A.addEventListener("test", null, e), n._A.removeEventListener("test", null, e);
          } catch (e) {}
          function a(e, t) {
            return i || o ? {
              capture: !!e,
              passive: i,
              signal: t
            } : !!e;
          }
          function s(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            window.addEventListener(e, t, a(r, n));
          }
          function c(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            document.addEventListener(e, t, a(r, n));
          }
        },
        3117: (e, t, r) => {
          r.d(t, {
            a: () => n
          });
          const n = (0, r(4402).Rl)();
        },
        4402: (e, t, r) => {
          r.d(t, {
            Ht: () => u,
            M: () => c,
            Rl: () => a,
            ky: () => s
          });
          var n = r(385);
          const i = "xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx";
          function o(e, t) {
            return e ? 15 & e[t] : 16 * Math.random() | 0;
          }
          function a() {
            const e = n._A?.crypto || n._A?.msCrypto;
            let t,
              r = 0;
            return e && e.getRandomValues && (t = e.getRandomValues(new Uint8Array(31))), i.split("").map(e => "x" === e ? o(t, ++r).toString(16) : "y" === e ? (3 & o() | 8).toString(16) : e).join("");
          }
          function s(e) {
            const t = n._A?.crypto || n._A?.msCrypto;
            let r,
              i = 0;
            t && t.getRandomValues && (r = t.getRandomValues(new Uint8Array(31)));
            const a = [];
            for (var s = 0; s < e; s++) a.push(o(r, ++i).toString(16));
            return a.join("");
          }
          function c() {
            return s(16);
          }
          function u() {
            return s(32);
          }
        },
        7056: (e, t, r) => {
          r.d(t, {
            Bq: () => n,
            Hb: () => o,
            oD: () => i
          });
          const n = "NRBA",
            i = 144e5,
            o = 18e5;
        },
        7894: (e, t, r) => {
          function n() {
            return Math.round(performance.now());
          }
          r.d(t, {
            z: () => n
          });
        },
        7243: (e, t, r) => {
          r.d(t, {
            e: () => o
          });
          var n = r(385),
            i = {};
          function o(e) {
            if (e in i) return i[e];
            if (0 === (e || "").indexOf("data:")) return {
              protocol: "data"
            };
            let t;
            var r = n._A?.location,
              o = {};
            if (n.il) t = document.createElement("a"), t.href = e;else try {
              t = new URL(e, r.href);
            } catch (e) {
              return o;
            }
            o.port = t.port;
            var a = t.href.split("://");
            !o.port && a[1] && (o.port = a[1].split("/")[0].split("@").pop().split(":")[1]), o.port && "0" !== o.port || (o.port = "https" === a[0] ? "443" : "80"), o.hostname = t.hostname || r.hostname, o.pathname = t.pathname, o.protocol = a[0], "/" !== o.pathname.charAt(0) && (o.pathname = "/" + o.pathname);
            var s = !t.protocol || ":" === t.protocol || t.protocol === r.protocol,
              c = t.hostname === r.hostname && t.port === r.port;
            return o.sameOrigin = s && (!t.hostname || c), "/" === o.pathname && (i[e] = o), o;
          }
        },
        50: (e, t, r) => {
          function n(e, t) {
            "function" == typeof console.warn && (console.warn("New Relic: ".concat(e)), t && console.warn(t));
          }
          r.d(t, {
            Z: () => n
          });
        },
        2587: (e, t, r) => {
          r.d(t, {
            N: () => c,
            T: () => u
          });
          var n = r(8325),
            i = r(5546),
            o = r(8e3),
            a = r(3325);
          const s = {
            stn: [a.D.sessionTrace],
            err: [a.D.jserrors, a.D.metrics],
            ins: [a.D.pageAction],
            spa: [a.D.spa],
            sr: [a.D.sessionReplay, a.D.sessionTrace]
          };
          function c(e, t) {
            const r = n.ee.get(t);
            e && "object" == typeof e && (Object.entries(e).forEach(e => {
              let [t, n] = e;
              void 0 === u[t] && (s[t] ? s[t].forEach(e => {
                n ? (0, i.p)("feat-" + t, [], void 0, e, r) : (0, i.p)("block-" + t, [], void 0, e, r), (0, i.p)("rumresp-" + t, [Boolean(n)], void 0, e, r);
              }) : n && (0, i.p)("feat-" + t, [], void 0, void 0, r), u[t] = Boolean(n));
            }), Object.keys(s).forEach(e => {
              void 0 === u[e] && (s[e]?.forEach(t => (0, i.p)("rumresp-" + e, [!1], void 0, t, r)), u[e] = !1);
            }), (0, o.L)(t, a.D.pageViewEvent));
          }
          const u = {};
        },
        2210: (e, t, r) => {
          r.d(t, {
            X: () => i
          });
          var n = Object.prototype.hasOwnProperty;
          function i(e, t, r) {
            if (n.call(e, t)) return e[t];
            var i = r();
            if (Object.defineProperty && Object.keys) try {
              return Object.defineProperty(e, t, {
                value: i,
                writable: !0,
                enumerable: !1
              }), i;
            } catch (e) {}
            return e[t] = i, i;
          }
        },
        1284: (e, t, r) => {
          r.d(t, {
            D: () => n
          });
          const n = (e, t) => Object.entries(e || {}).map(e => {
            let [r, n] = e;
            return t(r, n);
          });
        },
        4351: (e, t, r) => {
          r.d(t, {
            P: () => o
          });
          var n = r(8325);
          const i = () => {
            const e = new WeakSet();
            return (t, r) => {
              if ("object" == typeof r && null !== r) {
                if (e.has(r)) return;
                e.add(r);
              }
              return r;
            };
          };
          function o(e) {
            try {
              return JSON.stringify(e, i());
            } catch (e) {
              try {
                n.ee.emit("internal-error", [e]);
              } catch (e) {}
            }
          }
        },
        3960: (e, t, r) => {
          r.d(t, {
            K: () => a,
            b: () => o
          });
          var n = r(3239);
          function i() {
            return "undefined" == typeof document || "complete" === document.readyState;
          }
          function o(e, t) {
            if (i()) return e();
            (0, n.bP)("load", e, t);
          }
          function a(e) {
            if (i()) return e();
            (0, n.iz)("DOMContentLoaded", e);
          }
        },
        8632: (e, t, r) => {
          r.d(t, {
            EZ: () => u,
            Qy: () => c,
            ce: () => o,
            fP: () => a,
            gG: () => d,
            mF: () => s
          });
          var n = r(7894),
            i = r(385);
          const o = {
            beacon: "bam.nr-data.net",
            errorBeacon: "bam.nr-data.net"
          };
          function a() {
            return i._A.NREUM || (i._A.NREUM = {}), void 0 === i._A.newrelic && (i._A.newrelic = i._A.NREUM), i._A.NREUM;
          }
          function s() {
            let e = a();
            return e.o || (e.o = {
              ST: i._A.setTimeout,
              SI: i._A.setImmediate,
              CT: i._A.clearTimeout,
              XHR: i._A.XMLHttpRequest,
              REQ: i._A.Request,
              EV: i._A.Event,
              PR: i._A.Promise,
              MO: i._A.MutationObserver,
              FETCH: i._A.fetch
            }), e;
          }
          function c(e, t, r) {
            let i = a();
            const o = i.initializedAgents || {},
              s = o[e] || {};
            return Object.keys(s).length || (s.initializedAt = {
              ms: (0, n.z)(),
              date: new Date()
            }), i.initializedAgents = {
              ...o,
              [e]: {
                ...s,
                [r]: t
              }
            }, i;
          }
          function u(e, t) {
            a()[e] = t;
          }
          function d() {
            return function () {
              let e = a();
              const t = e.info || {};
              e.info = {
                beacon: o.beacon,
                errorBeacon: o.errorBeacon,
                ...t
              };
            }(), function () {
              let e = a();
              const t = e.init || {};
              e.init = {
                ...t
              };
            }(), s(), function () {
              let e = a();
              const t = e.loader_config || {};
              e.loader_config = {
                ...t
              };
            }(), a();
          }
        },
        7956: (e, t, r) => {
          r.d(t, {
            N: () => i
          });
          var n = r(3239);
          function i(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] && arguments[1],
              r = arguments.length > 2 ? arguments[2] : void 0,
              i = arguments.length > 3 ? arguments[3] : void 0;
            return void (0, n.iz)("visibilitychange", function () {
              if (t) return void ("hidden" == document.visibilityState && e());
              e(document.visibilityState);
            }, r, i);
          }
        },
        1214: (e, t, r) => {
          r.d(t, {
            em: () => b,
            u5: () => j,
            QU: () => O,
            _L: () => I,
            Gm: () => H,
            Lg: () => L,
            BV: () => G,
            Kf: () => K
          });
          var n = r(8325),
            i = r(3117);
          const o = "nr@original:".concat(i.a);
          var a = Object.prototype.hasOwnProperty,
            s = !1;
          function c(e, t) {
            return e || (e = n.ee), r.inPlace = function (e, t, n, i, o) {
              n || (n = "");
              const a = "-" === n.charAt(0);
              for (let s = 0; s < t.length; s++) {
                const c = t[s],
                  u = e[c];
                d(u) || (e[c] = r(u, a ? c + n : n, i, c, o));
              }
            }, r.flag = o, r;
            function r(t, r, n, s, c) {
              return d(t) ? t : (r || (r = ""), nrWrapper[o] = t, function (e, t, r) {
                if (Object.defineProperty && Object.keys) try {
                  return Object.keys(e).forEach(function (r) {
                    Object.defineProperty(t, r, {
                      get: function () {
                        return e[r];
                      },
                      set: function (t) {
                        return e[r] = t, t;
                      }
                    });
                  }), t;
                } catch (e) {
                  u([e], r);
                }
                for (var n in e) a.call(e, n) && (t[n] = e[n]);
              }(t, nrWrapper, e), nrWrapper);
              function nrWrapper() {
                var o, a, d, l;
                try {
                  a = this, o = [...arguments], d = "function" == typeof n ? n(o, a) : n || {};
                } catch (t) {
                  u([t, "", [o, a, s], d], e);
                }
                i(r + "start", [o, a, s], d, c);
                try {
                  return l = t.apply(a, o);
                } catch (e) {
                  throw i(r + "err", [o, a, e], d, c), e;
                } finally {
                  i(r + "end", [o, a, l], d, c);
                }
              }
            }
            function i(r, n, i, o) {
              if (!s || t) {
                var a = s;
                s = !0;
                try {
                  e.emit(r, n, i, t, o);
                } catch (t) {
                  u([t, r, n, i], e);
                }
                s = a;
              }
            }
          }
          function u(e, t) {
            t || (t = n.ee);
            try {
              t.emit("internal-error", e);
            } catch (e) {}
          }
          function d(e) {
            return !(e && e instanceof Function && e.apply && !e[o]);
          }
          var l = r(2210),
            f = r(385);
          const h = {},
            p = f._A.XMLHttpRequest,
            g = "addEventListener",
            m = "removeEventListener",
            v = "nr@wrapped:".concat(n.A);
          function b(e) {
            var t = function (e) {
              return (e || n.ee).get("events");
            }(e);
            if (h[t.debugId]++) return t;
            h[t.debugId] = 1;
            var r = c(t, !0);
            function i(e) {
              r.inPlace(e, [g, m], "-", o);
            }
            function o(e, t) {
              return e[1];
            }
            return "getPrototypeOf" in Object && (f.il && y(document, i), y(f._A, i), y(p.prototype, i)), t.on(g + "-start", function (e, t) {
              var n = e[1];
              if (null !== n && ("function" == typeof n || "object" == typeof n)) {
                var i = (0, l.X)(n, v, function () {
                  var e = {
                    object: function () {
                      if ("function" != typeof n.handleEvent) return;
                      return n.handleEvent.apply(n, arguments);
                    },
                    function: n
                  }[typeof n];
                  return e ? r(e, "fn-", null, e.name || "anonymous") : n;
                });
                this.wrapped = e[1] = i;
              }
            }), t.on(m + "-start", function (e) {
              e[1] = this.wrapped || e[1];
            }), t;
          }
          function y(e, t) {
            let r = e;
            for (; "object" == typeof r && !Object.prototype.hasOwnProperty.call(r, g);) r = Object.getPrototypeOf(r);
            for (var n = arguments.length, i = new Array(n > 2 ? n - 2 : 0), o = 2; o < n; o++) i[o - 2] = arguments[o];
            r && t(r, ...i);
          }
          var w = "fetch-",
            A = w + "body-",
            x = ["arrayBuffer", "blob", "json", "text", "formData"],
            E = f._A.Request,
            T = f._A.Response,
            _ = "prototype";
          const D = {};
          function j(e) {
            const t = function (e) {
              return (e || n.ee).get("fetch");
            }(e);
            if (!(E && T && f._A.fetch)) return t;
            if (D[t.debugId]++) return t;
            function r(e, r, i) {
              var o = e[r];
              "function" == typeof o && (e[r] = function () {
                var e,
                  r = [...arguments],
                  a = {};
                t.emit(i + "before-start", [r], a), a[n.A] && a[n.A].dt && (e = a[n.A].dt);
                var s = o.apply(this, r);
                return t.emit(i + "start", [r, e], s), s.then(function (e) {
                  return t.emit(i + "end", [null, e], s), e;
                }, function (e) {
                  throw t.emit(i + "end", [e], s), e;
                });
              });
            }
            return D[t.debugId] = 1, x.forEach(e => {
              r(E[_], e, A), r(T[_], e, A);
            }), r(f._A, "fetch", w), t.on(w + "end", function (e, r) {
              var n = this;
              if (r) {
                var i = r.headers.get("content-length");
                null !== i && (n.rxSize = i), t.emit(w + "done", [null, r], n);
              } else t.emit(w + "done", [e], n);
            }), t;
          }
          const C = {},
            N = ["pushState", "replaceState"];
          function O(e) {
            const t = function (e) {
              return (e || n.ee).get("history");
            }(e);
            return !f.il || C[t.debugId]++ || (C[t.debugId] = 1, c(t).inPlace(window.history, N, "-")), t;
          }
          var S = r(3239);
          const P = {},
            R = ["appendChild", "insertBefore", "replaceChild"];
          function I(e) {
            const t = function (e) {
              return (e || n.ee).get("jsonp");
            }(e);
            if (!f.il || P[t.debugId]) return t;
            P[t.debugId] = !0;
            var r = c(t),
              i = /[?&](?:callback|cb)=([^&#]+)/,
              o = /(.*)\.([^.]+)/,
              a = /^(\w+)(\.|$)(.*)$/;
            function s(e, t) {
              if (!e) return t;
              const r = e.match(a),
                n = r[1];
              return s(r[3], t[n]);
            }
            return r.inPlace(Node.prototype, R, "dom-"), t.on("dom-start", function (e) {
              !function (e) {
                if (!e || "string" != typeof e.nodeName || "script" !== e.nodeName.toLowerCase()) return;
                if ("function" != typeof e.addEventListener) return;
                var n = (a = e.src, c = a.match(i), c ? c[1] : null);
                var a, c;
                if (!n) return;
                var u = function (e) {
                  var t = e.match(o);
                  if (t && t.length >= 3) return {
                    key: t[2],
                    parent: s(t[1], window)
                  };
                  return {
                    key: e,
                    parent: window
                  };
                }(n);
                if ("function" != typeof u.parent[u.key]) return;
                var d = {};
                function l() {
                  t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                function f() {
                  t.emit("jsonp-error", [], d), t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                r.inPlace(u.parent, [u.key], "cb-", d), e.addEventListener("load", l, (0, S.m$)(!1)), e.addEventListener("error", f, (0, S.m$)(!1)), t.emit("new-jsonp", [e.src], d);
              }(e[0]);
            }), t;
          }
          const k = {};
          function H(e) {
            const t = function (e) {
              return (e || n.ee).get("mutation");
            }(e);
            if (!f.il || k[t.debugId]) return t;
            k[t.debugId] = !0;
            var r = c(t),
              i = f._A.MutationObserver;
            return i && (window.MutationObserver = function (e) {
              return this instanceof i ? new i(r(e, "fn-")) : i.apply(this, arguments);
            }, MutationObserver.prototype = i.prototype), t;
          }
          const z = {};
          function L(e) {
            const t = function (e) {
              return (e || n.ee).get("promise");
            }(e);
            if (z[t.debugId]) return t;
            z[t.debugId] = !0;
            var r = t.context,
              i = c(t),
              a = f._A.Promise;
            return a && function () {
              function e(r) {
                var n = t.context(),
                  o = i(r, "executor-", n, null, !1);
                const s = Reflect.construct(a, [o], e);
                return t.context(s).getCtx = function () {
                  return n;
                }, s;
              }
              f._A.Promise = e, Object.defineProperty(e, "name", {
                value: "Promise"
              }), e.toString = function () {
                return a.toString();
              }, Object.setPrototypeOf(e, a), ["all", "race"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  let i = !1;
                  [...(e || [])].forEach(e => {
                    this.resolve(e).then(a("all" === r), a(!1));
                  });
                  const o = n.apply(this, arguments);
                  return o;
                  function a(e) {
                    return function () {
                      t.emit("propagate", [null, !i], o, !1, !1), i = i || !e;
                    };
                  }
                };
              }), ["resolve", "reject"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  const r = n.apply(this, arguments);
                  return e !== r && t.emit("propagate", [e, !0], r, !1, !1), r;
                };
              }), e.prototype = a.prototype;
              const n = a.prototype.then;
              a.prototype.then = function () {
                var e = this,
                  o = r(e);
                o.promise = e;
                for (var a = arguments.length, s = new Array(a), c = 0; c < a; c++) s[c] = arguments[c];
                s[0] = i(s[0], "cb-", o, null, !1), s[1] = i(s[1], "cb-", o, null, !1);
                const u = n.apply(this, s);
                return o.nextPromise = u, t.emit("propagate", [e, !0], u, !1, !1), u;
              }, a.prototype.then[o] = n, t.on("executor-start", function (e) {
                e[0] = i(e[0], "resolve-", this, null, !1), e[1] = i(e[1], "resolve-", this, null, !1);
              }), t.on("executor-err", function (e, t, r) {
                e[1](r);
              }), t.on("cb-end", function (e, r, n) {
                t.emit("propagate", [n, !0], this.nextPromise, !1, !1);
              }), t.on("propagate", function (e, r, n) {
                this.getCtx && !r || (this.getCtx = function () {
                  if (e instanceof Promise) var r = t.context(e);
                  return r && r.getCtx ? r.getCtx() : this;
                });
              });
            }(), t;
          }
          const M = {},
            B = "setTimeout",
            F = "setInterval",
            U = "clearTimeout",
            q = "-start",
            Z = "-",
            V = [B, "setImmediate", F, U, "clearImmediate"];
          function G(e) {
            const t = function (e) {
              return (e || n.ee).get("timer");
            }(e);
            if (M[t.debugId]++) return t;
            M[t.debugId] = 1;
            var r = c(t);
            return r.inPlace(f._A, V.slice(0, 2), B + Z), r.inPlace(f._A, V.slice(2, 3), F + Z), r.inPlace(f._A, V.slice(3), U + Z), t.on(F + q, function (e, t, n) {
              e[0] = r(e[0], "fn-", null, n);
            }), t.on(B + q, function (e, t, n) {
              this.method = n, this.timerDuration = isNaN(e[1]) ? 0 : +e[1], e[0] = r(e[0], "fn-", this, n);
            }), t;
          }
          var W = r(50);
          const X = {},
            Q = ["open", "send"];
          function K(e) {
            var t = e || n.ee;
            const r = function (e) {
              return (e || n.ee).get("xhr");
            }(t);
            if (X[r.debugId]++) return r;
            X[r.debugId] = 1, b(t);
            var i = c(r),
              o = f._A.XMLHttpRequest,
              a = f._A.MutationObserver,
              s = f._A.Promise,
              u = f._A.setInterval,
              d = "readystatechange",
              l = ["onload", "onerror", "onabort", "onloadstart", "onloadend", "onprogress", "ontimeout"],
              h = [],
              p = f._A.XMLHttpRequest = function (e) {
                const t = new o(e),
                  n = r.context(t);
                try {
                  r.emit("new-xhr", [t], n), t.addEventListener(d, (a = n, function () {
                    var e = this;
                    e.readyState > 3 && !a.resolved && (a.resolved = !0, r.emit("xhr-resolved", [], e)), i.inPlace(e, l, "fn-", A);
                  }), (0, S.m$)(!1));
                } catch (e) {
                  (0, W.Z)("An error occurred while intercepting XHR", e);
                  try {
                    r.emit("internal-error", [e]);
                  } catch (e) {}
                }
                var a;
                return t;
              };
            function g(e, t) {
              i.inPlace(t, ["onreadystatechange"], "fn-", A);
            }
            if (function (e, t) {
              for (var r in e) t[r] = e[r];
            }(o, p), p.prototype = o.prototype, i.inPlace(p.prototype, Q, "-xhr-", A), r.on("send-xhr-start", function (e, t) {
              g(e, t), function (e) {
                h.push(e), a && (m ? m.then(w) : u ? u(w) : (v = -v, y.data = v));
              }(t);
            }), r.on("open-xhr-start", g), a) {
              var m = s && s.resolve();
              if (!u && !s) {
                var v = 1,
                  y = document.createTextNode(v);
                new a(w).observe(y, {
                  characterData: !0
                });
              }
            } else t.on("fn-end", function (e) {
              e[0] && e[0].type === d || w();
            });
            function w() {
              for (var e = 0; e < h.length; e++) g(0, h[e]);
              h.length && (h = []);
            }
            function A(e, t) {
              return t;
            }
            return r;
          }
        },
        7825: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.ajax;
        },
        6660: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.jserrors;
        },
        3081: (e, t, r) => {
          r.d(t, {
            gF: () => o,
            mY: () => i,
            t9: () => n,
            vz: () => s,
            xS: () => a
          });
          const n = r(3325).D.metrics,
            i = "sm",
            o = "cm",
            a = "storeSupportabilityMetrics",
            s = "storeEventMetrics";
        },
        4649: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageAction;
        },
        7633: (e, t, r) => {
          r.d(t, {
            Dz: () => i,
            OJ: () => a,
            qw: () => o,
            t9: () => n
          });
          const n = r(3325).D.pageViewEvent,
            i = "firstbyte",
            o = "domcontent",
            a = "windowload";
        },
        9251: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageViewTiming;
        },
        3614: (e, t, r) => {
          r.d(t, {
            BST_RESOURCE: () => i,
            END: () => s,
            FEATURE_NAME: () => n,
            FN_END: () => u,
            FN_START: () => c,
            PUSH_STATE: () => d,
            RESOURCE: () => o,
            START: () => a
          });
          const n = r(3325).D.sessionTrace,
            i = "bstResource",
            o = "resource",
            a = "-start",
            s = "-end",
            c = "fn" + a,
            u = "fn" + s,
            d = "pushState";
        },
        7836: (e, t, r) => {
          r.d(t, {
            BODY: () => x,
            CB_END: () => E,
            CB_START: () => u,
            END: () => A,
            FEATURE_NAME: () => i,
            FETCH: () => _,
            FETCH_BODY: () => v,
            FETCH_DONE: () => m,
            FETCH_START: () => g,
            FN_END: () => c,
            FN_START: () => s,
            INTERACTION: () => f,
            INTERACTION_API: () => d,
            INTERACTION_EVENTS: () => o,
            JSONP_END: () => b,
            JSONP_NODE: () => p,
            JS_TIME: () => T,
            MAX_TIMER_BUDGET: () => a,
            REMAINING: () => l,
            SPA_NODE: () => h,
            START: () => w,
            originalSetTimeout: () => y
          });
          var n = r(5763);
          const i = r(3325).D.spa,
            o = ["click", "submit", "keypress", "keydown", "keyup", "change"],
            a = 999,
            s = "fn-start",
            c = "fn-end",
            u = "cb-start",
            d = "api-ixn-",
            l = "remaining",
            f = "interaction",
            h = "spaNode",
            p = "jsonpNode",
            g = "fetch-start",
            m = "fetch-done",
            v = "fetch-body-",
            b = "jsonp-end",
            y = n.Yu.ST,
            w = "-start",
            A = "-end",
            x = "-body",
            E = "cb" + A,
            T = "jsTime",
            _ = "fetch";
        },
        5938: (e, t, r) => {
          r.d(t, {
            W: () => o
          });
          var n = r(5763),
            i = r(8325);
          class o {
            constructor(e, t, r) {
              this.agentIdentifier = e, this.aggregator = t, this.ee = i.ee.get(e, (0, n.OP)(this.agentIdentifier).isolatedBacklog), this.featureName = r, this.blocked = !1;
            }
          }
        },
        9144: (e, t, r) => {
          r.d(t, {
            j: () => m
          });
          var n = r(3325),
            i = r(5763),
            o = r(5546),
            a = r(8325),
            s = r(7894),
            c = r(8e3),
            u = r(3960),
            d = r(385),
            l = r(50),
            f = r(3081),
            h = r(8632);
          function p() {
            const e = (0, h.gG)();
            ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease", "addPageAction", "setCurrentRouteName", "setPageViewName", "setCustomAttribute", "interaction", "noticeError", "setUserId", "setApplicationVersion"].forEach(t => {
              e[t] = function () {
                for (var r = arguments.length, n = new Array(r), i = 0; i < r; i++) n[i] = arguments[i];
                return function (t) {
                  for (var r = arguments.length, n = new Array(r > 1 ? r - 1 : 0), i = 1; i < r; i++) n[i - 1] = arguments[i];
                  let o = [];
                  return Object.values(e.initializedAgents).forEach(e => {
                    e.exposed && e.api[t] && o.push(e.api[t](...n));
                  }), o.length > 1 ? o : o[0];
                }(t, ...n);
              };
            });
          }
          var g = r(2587);
          function m(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : {},
              m = arguments.length > 2 ? arguments[2] : void 0,
              v = arguments.length > 3 ? arguments[3] : void 0,
              {
                init: b,
                info: y,
                loader_config: w,
                runtime: A = {
                  loaderType: m
                },
                exposed: x = !0
              } = t;
            const E = (0, h.gG)();
            y || (b = E.init, y = E.info, w = E.loader_config), (0, i.Dg)(e, b || {}), (0, i.GE)(e, w || {}), y.jsAttributes ??= {}, d.v6 && (y.jsAttributes.isWorker = !0), (0, i.CX)(e, y);
            const T = (0, i.P_)(e);
            A.denyList = [...(T.ajax?.deny_list || []), ...(T.ajax?.block_internal ? [y.beacon, y.errorBeacon] : [])], (0, i.sU)(e, A), p();
            const _ = function (e, t) {
              t || (0, c.R)(e, "api");
              const h = {};
              var p = a.ee.get(e),
                g = p.get("tracer"),
                m = "api-",
                v = m + "ixn-";
              function b(t, r, n, o) {
                const a = (0, i.C5)(e);
                return null === r ? delete a.jsAttributes[t] : (0, i.CX)(e, {
                  ...a,
                  jsAttributes: {
                    ...a.jsAttributes,
                    [t]: r
                  }
                }), A(m, n, !0, o || null === r ? "session" : void 0)(t, r);
              }
              function y() {}
              ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease"].forEach(e => h[e] = A(m, e, !0, "api")), h.addPageAction = A(m, "addPageAction", !0, n.D.pageAction), h.setCurrentRouteName = A(m, "routeName", !0, n.D.spa), h.setPageViewName = function (t, r) {
                if ("string" == typeof t) return "/" !== t.charAt(0) && (t = "/" + t), (0, i.OP)(e).customTransaction = (r || "http://custom.transaction") + t, A(m, "setPageViewName", !0)();
              }, h.setCustomAttribute = function (e, t) {
                let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2];
                if ("string" == typeof e) {
                  if (["string", "number"].includes(typeof t) || null === t) return b(e, t, "setCustomAttribute", r);
                  (0, l.Z)("Failed to execute setCustomAttribute.\nNon-null value must be a string or number type, but a type of <".concat(typeof t, "> was provided."));
                } else (0, l.Z)("Failed to execute setCustomAttribute.\nName must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setUserId = function (e) {
                if ("string" == typeof e || null === e) return b("enduser.id", e, "setUserId", !0);
                (0, l.Z)("Failed to execute setUserId.\nNon-null value must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setApplicationVersion = function (e) {
                if ("string" == typeof e || null === e) return b("application.version", e, "setApplicationVersion", !1);
                (0, l.Z)("Failed to execute setApplicationVersion. Expected <String | null>, but got <".concat(typeof e, ">."));
              }, h.interaction = function () {
                return new y().get();
              };
              var w = y.prototype = {
                createTracer: function (e, t) {
                  var r = {},
                    i = this,
                    a = "function" == typeof t;
                  return (0, o.p)(v + "tracer", [(0, s.z)(), e, r], i, n.D.spa, p), function () {
                    if (g.emit((a ? "" : "no-") + "fn-start", [(0, s.z)(), i, a], r), a) try {
                      return t.apply(this, arguments);
                    } catch (e) {
                      throw g.emit("fn-err", [arguments, this, e], r), e;
                    } finally {
                      g.emit("fn-end", [(0, s.z)()], r);
                    }
                  };
                }
              };
              function A(e, t, r, i) {
                return function () {
                  return (0, o.p)(f.xS, ["API/" + t + "/called"], void 0, n.D.metrics, p), i && (0, o.p)(e + t, [(0, s.z)(), ...arguments], r ? null : this, i, p), r ? void 0 : this;
                };
              }
              function x() {
                r.e(111).then(r.bind(r, 7438)).then(t => {
                  let {
                    setAPI: r
                  } = t;
                  r(e), (0, c.L)(e, "api");
                }).catch(() => (0, l.Z)("Downloading runtime APIs failed..."));
              }
              return ["actionText", "setName", "setAttribute", "save", "ignore", "onEnd", "getContext", "end", "get"].forEach(e => {
                w[e] = A(v, e, void 0, n.D.spa);
              }), h.noticeError = function (e, t) {
                "string" == typeof e && (e = new Error(e)), (0, o.p)(f.xS, ["API/noticeError/called"], void 0, n.D.metrics, p), (0, o.p)("err", [e, (0, s.z)(), !1, t], void 0, n.D.jserrors, p);
              }, d.il ? (0, u.b)(() => x(), !0) : x(), h;
            }(e, v);
            return (0, h.Qy)(e, _, "api"), (0, h.Qy)(e, x, "exposed"), (0, h.EZ)("activatedFeatures", g.T), _;
          }
        },
        3325: (e, t, r) => {
          r.d(t, {
            D: () => n,
            p: () => i
          });
          const n = {
              ajax: "ajax",
              jserrors: "jserrors",
              metrics: "metrics",
              pageAction: "page_action",
              pageViewEvent: "page_view_event",
              pageViewTiming: "page_view_timing",
              sessionReplay: "session_replay",
              sessionTrace: "session_trace",
              spa: "spa"
            },
            i = {
              [n.pageViewEvent]: 1,
              [n.pageViewTiming]: 2,
              [n.metrics]: 3,
              [n.jserrors]: 4,
              [n.ajax]: 5,
              [n.sessionTrace]: 6,
              [n.pageAction]: 7,
              [n.spa]: 8,
              [n.sessionReplay]: 9
            };
        }
      },
      n = {};
    function i(e) {
      var t = n[e];
      if (void 0 !== t) return t.exports;
      var o = n[e] = {
        exports: {}
      };
      return r[e](o, o.exports, i), o.exports;
    }
    i.m = r, i.d = (e, t) => {
      for (var r in t) i.o(t, r) && !i.o(e, r) && Object.defineProperty(e, r, {
        enumerable: !0,
        get: t[r]
      });
    }, i.f = {}, i.e = e => Promise.all(Object.keys(i.f).reduce((t, r) => (i.f[r](e, t), t), [])), i.u = e => "nr-spa.1097a448-1.238.0.min.js", i.o = (e, t) => Object.prototype.hasOwnProperty.call(e, t), e = {}, t = "NRBA-1.238.0.PROD:", i.l = (r, n, o, a) => {
      if (e[r]) e[r].push(n);else {
        var s, c;
        if (void 0 !== o) for (var u = document.getElementsByTagName("script"), d = 0; d < u.length; d++) {
          var l = u[d];
          if (l.getAttribute("src") == r || l.getAttribute("data-webpack") == t + o) {
            s = l;
            break;
          }
        }
        s || (c = !0, (s = document.createElement("script")).charset = "utf-8", s.timeout = 120, i.nc && s.setAttribute("nonce", i.nc), s.setAttribute("data-webpack", t + o), s.src = r), e[r] = [n];
        var f = (t, n) => {
            s.onerror = s.onload = null, clearTimeout(h);
            var i = e[r];
            if (delete e[r], s.parentNode && s.parentNode.removeChild(s), i && i.forEach(e => e(n)), t) return t(n);
          },
          h = setTimeout(f.bind(null, void 0, {
            type: "timeout",
            target: s
          }), 12e4);
        s.onerror = f.bind(null, s.onerror), s.onload = f.bind(null, s.onload), c && document.head.appendChild(s);
      }
    }, i.r = e => {
      "undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(e, Symbol.toStringTag, {
        value: "Module"
      }), Object.defineProperty(e, "__esModule", {
        value: !0
      });
    }, i.p = "https://js-agent.newrelic.com/", (() => {
      var e = {
        801: 0,
        92: 0
      };
      i.f.j = (t, r) => {
        var n = i.o(e, t) ? e[t] : void 0;
        if (0 !== n) if (n) r.push(n[2]);else {
          var o = new Promise((r, i) => n = e[t] = [r, i]);
          r.push(n[2] = o);
          var a = i.p + i.u(t),
            s = new Error();
          i.l(a, r => {
            if (i.o(e, t) && (0 !== (n = e[t]) && (e[t] = void 0), n)) {
              var o = r && ("load" === r.type ? "missing" : r.type),
                a = r && r.target && r.target.src;
              s.message = "Loading chunk " + t + " failed.\n(" + o + ": " + a + ")", s.name = "ChunkLoadError", s.type = o, s.request = a, n[1](s);
            }
          }, "chunk-" + t, t);
        }
      };
      var t = (t, r) => {
          var n,
            o,
            [a, s, c] = r,
            u = 0;
          if (a.some(t => 0 !== e[t])) {
            for (n in s) i.o(s, n) && (i.m[n] = s[n]);
            if (c) c(i);
          }
          for (t && t(r); u < a.length; u++) o = a[u], i.o(e, o) && e[o] && e[o][0](), e[o] = 0;
        },
        r = self["webpackChunk:NRBA-1.238.0.PROD"] = self["webpackChunk:NRBA-1.238.0.PROD"] || [];
      r.forEach(t.bind(null, 0)), r.push = t.bind(null, r.push.bind(r));
    })(), (() => {
      var e = i(50);
      class t {
        addPageAction(t, r) {
          (0, e.Z)("Call to agent api addPageAction failed. The session trace feature is not currently initialized.");
        }
        setPageViewName(t, r) {
          (0, e.Z)("Call to agent api setPageViewName failed. The page view feature is not currently initialized.");
        }
        setCustomAttribute(t, r, n) {
          (0, e.Z)("Call to agent api setCustomAttribute failed. The js errors feature is not currently initialized.");
        }
        noticeError(t, r) {
          (0, e.Z)("Call to agent api noticeError failed. The js errors feature is not currently initialized.");
        }
        setUserId(t) {
          (0, e.Z)("Call to agent api setUserId failed. The js errors feature is not currently initialized.");
        }
        setApplicationVersion(t) {
          (0, e.Z)("Call to agent api setApplicationVersion failed. The agent is not currently initialized.");
        }
        setErrorHandler(t) {
          (0, e.Z)("Call to agent api setErrorHandler failed. The js errors feature is not currently initialized.");
        }
        finished(t) {
          (0, e.Z)("Call to agent api finished failed. The page action feature is not currently initialized.");
        }
        addRelease(t, r) {
          (0, e.Z)("Call to agent api addRelease failed. The agent is not currently initialized.");
        }
      }
      var r = i(3325),
        n = i(5763);
      const o = Object.values(r.D);
      function a(e) {
        const t = {};
        return o.forEach(r => {
          t[r] = function (e, t) {
            return !1 !== (0, n.Mt)(t, "".concat(e, ".enabled"));
          }(r, e);
        }), t;
      }
      var s = i(9144);
      var c = i(5546),
        u = i(385),
        d = i(8e3),
        l = i(5938),
        f = i(3960);
      class h extends l.W {
        constructor(e, t, r) {
          let n = !(arguments.length > 3 && void 0 !== arguments[3]) || arguments[3];
          super(e, t, r), this.auto = n, this.abortHandler, this.featAggregate, this.onAggregateImported, n && (0, d.R)(e, r);
        }
        importAggregator() {
          let t = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : {};
          if (this.featAggregate || !this.auto) return;
          const r = u.il && !0 === (0, n.Mt)(this.agentIdentifier, "privacy.cookies_enabled");
          let o;
          this.onAggregateImported = new Promise(e => {
            o = e;
          });
          const a = async () => {
            let n;
            try {
              if (r) {
                const {
                  setupAgentSession: e
                } = await i.e(111).then(i.bind(i, 3228));
                n = e(this.agentIdentifier);
              }
            } catch (t) {
              (0, e.Z)("A problem occurred when starting up session manager. This page will not start or extend any session.", t);
            }
            try {
              if (!this.shouldImportAgg(this.featureName, n)) return (0, d.L)(this.agentIdentifier, this.featureName), void o(!1);
              const {
                  lazyFeatureLoader: e
                } = await i.e(111).then(i.bind(i, 8582)),
                {
                  Aggregate: r
                } = await e(this.featureName, "aggregate");
              this.featAggregate = new r(this.agentIdentifier, this.aggregator, t), o(!0);
            } catch (t) {
              (0, e.Z)("Downloading and initializing ".concat(this.featureName, " failed..."), t), this.abortHandler?.(), o(!1);
            }
          };
          u.il ? (0, f.b)(() => a(), !0) : a();
        }
        shouldImportAgg(e, t) {
          return e !== r.D.sessionReplay || !!n.Yu.MO && !1 !== (0, n.Mt)(this.agentIdentifier, "session_trace.enabled") && (!!t?.isNew || !!t?.state.sessionReplay);
        }
      }
      var p = i(7633),
        g = i(7894);
      class m extends h {
        static featureName = p.t9;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          if (super(e, t, p.t9, i), ("undefined" == typeof PerformanceNavigationTiming || u.Tt) && "undefined" != typeof PerformanceTiming) {
            const t = (0, n.OP)(e);
            t[p.Dz] = Math.max(Date.now() - t.offset, 0), (0, f.K)(() => t[p.qw] = Math.max((0, g.z)() - t[p.Dz], 0)), (0, f.b)(() => {
              const e = (0, g.z)();
              t[p.OJ] = Math.max(e - t[p.Dz], 0), (0, c.p)("timing", ["load", e], void 0, r.D.pageViewTiming, this.ee);
            });
          }
          this.importAggregator();
        }
      }
      var v = i(1117),
        b = i(1284);
      class y extends v.w {
        constructor(e) {
          super(e), this.aggregatedData = {};
        }
        store(e, t, r, n, i) {
          var o = this.getBucket(e, t, r, i);
          return o.metrics = function (e, t) {
            t || (t = {
              count: 0
            });
            return t.count += 1, (0, b.D)(e, function (e, r) {
              t[e] = w(r, t[e]);
            }), t;
          }(n, o.metrics), o;
        }
        merge(e, t, r, n, i) {
          var o = this.getBucket(e, t, n, i);
          if (o.metrics) {
            var a = o.metrics;
            a.count += r.count, (0, b.D)(r, function (e, t) {
              if ("count" !== e) {
                var n = a[e],
                  i = r[e];
                i && !i.c ? a[e] = w(i.t, n) : a[e] = function (e, t) {
                  if (!t) return e;
                  t.c || (t = A(t.t));
                  return t.min = Math.min(e.min, t.min), t.max = Math.max(e.max, t.max), t.t += e.t, t.sos += e.sos, t.c += e.c, t;
                }(i, a[e]);
              }
            });
          } else o.metrics = r;
        }
        storeMetric(e, t, r, n) {
          var i = this.getBucket(e, t, r);
          return i.stats = w(n, i.stats), i;
        }
        getBucket(e, t, r, n) {
          this.aggregatedData[e] || (this.aggregatedData[e] = {});
          var i = this.aggregatedData[e][t];
          return i || (i = this.aggregatedData[e][t] = {
            params: r || {}
          }, n && (i.custom = n)), i;
        }
        get(e, t) {
          return t ? this.aggregatedData[e] && this.aggregatedData[e][t] : this.aggregatedData[e];
        }
        take(e) {
          for (var t = {}, r = "", n = !1, i = 0; i < e.length; i++) t[r = e[i]] = x(this.aggregatedData[r]), t[r].length && (n = !0), delete this.aggregatedData[r];
          return n ? t : null;
        }
      }
      function w(e, t) {
        return null == e ? function (e) {
          e ? e.c++ : e = {
            c: 1
          };
          return e;
        }(t) : t ? (t.c || (t = A(t.t)), t.c += 1, t.t += e, t.sos += e * e, e > t.max && (t.max = e), e < t.min && (t.min = e), t) : {
          t: e
        };
      }
      function A(e) {
        return {
          t: e,
          min: e,
          max: e,
          sos: e * e,
          c: 1
        };
      }
      function x(e) {
        return "object" != typeof e ? [] : (0, b.D)(e, E);
      }
      function E(e, t) {
        return t;
      }
      var T = i(8632),
        _ = i(4402),
        D = i(4351);
      var j = i(7956),
        C = i(3239),
        N = i(9251);
      class O extends h {
        static featureName = N.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, N.t, r), u.il && ((0, n.OP)(e).initHidden = Boolean("hidden" === document.visibilityState), (0, j.N)(() => (0, c.p)("docHidden", [(0, g.z)()], void 0, N.t, this.ee), !0), (0, C.bP)("pagehide", () => (0, c.p)("winPagehide", [(0, g.z)()], void 0, N.t, this.ee)), this.importAggregator());
        }
      }
      var S = i(3081);
      class P extends h {
        static featureName = S.t9;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, S.t9, r), this.importAggregator();
        }
      }
      var R = i(6660);
      class I {
        constructor(e, t, r, n) {
          this.name = "UncaughtError", this.message = e, this.sourceURL = t, this.line = r, this.column = n;
        }
      }
      class k extends h {
        static featureName = R.t;
        #e = new Set();
        constructor(e, t) {
          let n = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, R.t, n);
          try {
            this.removeOnAbort = new AbortController();
          } catch (e) {}
          this.ee.on("fn-err", (e, t, n) => {
            this.abortHandler && !this.#e.has(n) && (this.#e.add(n), (0, c.p)("err", [this.#t(n), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }), this.ee.on("internal-error", e => {
            this.abortHandler && (0, c.p)("ierr", [this.#t(e), (0, g.z)(), !0], void 0, r.D.jserrors, this.ee);
          }), u._A.addEventListener("unhandledrejection", e => {
            this.abortHandler && (0, c.p)("err", [this.#r(e), (0, g.z)(), !1, {
              unhandledPromiseRejection: 1
            }], void 0, r.D.jserrors, this.ee);
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), u._A.addEventListener("error", e => {
            this.abortHandler && (this.#e.has(e.error) ? this.#e.delete(e.error) : (0, c.p)("err", [this.#n(e), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
        }
        #i() {
          this.removeOnAbort?.abort(), this.#e.clear(), this.abortHandler = void 0;
        }
        #t(e) {
          return e instanceof Error ? e : void 0 !== e?.message ? new I(e.message, e.filename || e.sourceURL, e.lineno || e.line, e.colno || e.col) : new I("string" == typeof e ? e : (0, D.P)(e));
        }
        #r(e) {
          let t = "Unhandled Promise Rejection: ";
          if (e?.reason instanceof Error) try {
            return e.reason.message = t + e.reason.message, e.reason;
          } catch (t) {
            return e.reason;
          }
          if (void 0 === e.reason) return new I(t);
          const r = this.#t(e.reason);
          return r.message = t + r.message, r;
        }
        #n(e) {
          return e.error instanceof Error ? e.error : new I(e.message, e.filename, e.lineno, e.colno);
        }
      }
      var H = i(2210);
      let z = 1;
      const L = "nr@id";
      function M(e) {
        const t = typeof e;
        return !e || "object" !== t && "function" !== t ? -1 : e === u._A ? 0 : (0, H.X)(e, L, function () {
          return z++;
        });
      }
      function B(e) {
        if ("string" == typeof e && e.length) return e.length;
        if ("object" == typeof e) {
          if ("undefined" != typeof ArrayBuffer && e instanceof ArrayBuffer && e.byteLength) return e.byteLength;
          if ("undefined" != typeof Blob && e instanceof Blob && e.size) return e.size;
          if (!("undefined" != typeof FormData && e instanceof FormData)) try {
            return (0, D.P)(e).length;
          } catch (e) {
            return;
          }
        }
      }
      var F = i(1214),
        U = i(7243);
      class q {
        constructor(e) {
          this.agentIdentifier = e;
        }
        generateTracePayload(e) {
          if (!this.shouldGenerateTrace(e)) return null;
          var t = (0, n.DL)(this.agentIdentifier);
          if (!t) return null;
          var r = (t.accountID || "").toString() || null,
            i = (t.agentID || "").toString() || null,
            o = (t.trustKey || "").toString() || null;
          if (!r || !i) return null;
          var a = (0, _.M)(),
            s = (0, _.Ht)(),
            c = Date.now(),
            u = {
              spanId: a,
              traceId: s,
              timestamp: c
            };
          return (e.sameOrigin || this.isAllowedOrigin(e) && this.useTraceContextHeadersForCors()) && (u.traceContextParentHeader = this.generateTraceContextParentHeader(a, s), u.traceContextStateHeader = this.generateTraceContextStateHeader(a, c, r, i, o)), (e.sameOrigin && !this.excludeNewrelicHeader() || !e.sameOrigin && this.isAllowedOrigin(e) && this.useNewrelicHeaderForCors()) && (u.newrelicHeader = this.generateTraceHeader(a, s, c, r, i, o)), u;
        }
        generateTraceContextParentHeader(e, t) {
          return "00-" + t + "-" + e + "-01";
        }
        generateTraceContextStateHeader(e, t, r, n, i) {
          return i + "@nr=0-1-" + r + "-" + n + "-" + e + "----" + t;
        }
        generateTraceHeader(e, t, r, n, i, o) {
          if (!("function" == typeof u._A?.btoa)) return null;
          var a = {
            v: [0, 1],
            d: {
              ty: "Browser",
              ac: n,
              ap: i,
              id: e,
              tr: t,
              ti: r
            }
          };
          return o && n !== o && (a.d.tk = o), btoa((0, D.P)(a));
        }
        shouldGenerateTrace(e) {
          return this.isDtEnabled() && this.isAllowedOrigin(e);
        }
        isAllowedOrigin(e) {
          var t = !1,
            r = {};
          if ((0, n.Mt)(this.agentIdentifier, "distributed_tracing") && (r = (0, n.P_)(this.agentIdentifier).distributed_tracing), e.sameOrigin) t = !0;else if (r.allowed_origins instanceof Array) for (var i = 0; i < r.allowed_origins.length; i++) {
            var o = (0, U.e)(r.allowed_origins[i]);
            if (e.hostname === o.hostname && e.protocol === o.protocol && e.port === o.port) {
              t = !0;
              break;
            }
          }
          return t;
        }
        isDtEnabled() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.enabled;
        }
        excludeNewrelicHeader() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.exclude_newrelic_header;
        }
        useNewrelicHeaderForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !1 !== e.cors_use_newrelic_header;
        }
        useTraceContextHeadersForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.cors_use_tracecontext_headers;
        }
      }
      var Z = i(7825),
        V = ["load", "error", "abort", "timeout"],
        G = V.length,
        W = n.Yu.REQ,
        X = n.Yu.XHR;
      class Q extends h {
        static featureName = Z.t;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, Z.t, i), (0, n.OP)(e).xhrWrappable && (this.dt = new q(e), this.handler = (e, t, r, n) => (0, c.p)(e, t, r, n, this.ee), (0, F.u5)(this.ee), (0, F.Kf)(this.ee), function (e, t, i, o) {
            function a(e) {
              var t = this;
              t.totalCbs = 0, t.called = 0, t.cbTime = 0, t.end = E, t.ended = !1, t.xhrGuids = {}, t.lastSize = null, t.loadCaptureCalled = !1, t.params = this.params || {}, t.metrics = this.metrics || {}, e.addEventListener("load", function (r) {
                _(t, e);
              }, (0, C.m$)(!1)), u.IF || e.addEventListener("progress", function (e) {
                t.lastSize = e.loaded;
              }, (0, C.m$)(!1));
            }
            function s(e) {
              this.params = {
                method: e[0]
              }, T(this, e[1]), this.metrics = {};
            }
            function c(t, r) {
              var i = (0, n.DL)(e);
              i.xpid && this.sameOrigin && r.setRequestHeader("X-NewRelic-ID", i.xpid);
              var a = o.generateTracePayload(this.parsedOrigin);
              if (a) {
                var s = !1;
                a.newrelicHeader && (r.setRequestHeader("newrelic", a.newrelicHeader), s = !0), a.traceContextParentHeader && (r.setRequestHeader("traceparent", a.traceContextParentHeader), a.traceContextStateHeader && r.setRequestHeader("tracestate", a.traceContextStateHeader), s = !0), s && (this.dt = a);
              }
            }
            function d(e, r) {
              var n = this.metrics,
                i = e[0],
                o = this;
              if (n && i) {
                var a = B(i);
                a && (n.txSize = a);
              }
              this.startTime = (0, g.z)(), this.listener = function (e) {
                try {
                  "abort" !== e.type || o.loadCaptureCalled || (o.params.aborted = !0), ("load" !== e.type || o.called === o.totalCbs && (o.onloadCalled || "function" != typeof r.onload) && "function" == typeof o.end) && o.end(r);
                } catch (e) {
                  try {
                    t.emit("internal-error", [e]);
                  } catch (e) {}
                }
              };
              for (var s = 0; s < G; s++) r.addEventListener(V[s], this.listener, (0, C.m$)(!1));
            }
            function l(e, t, r) {
              this.cbTime += e, t ? this.onloadCalled = !0 : this.called += 1, this.called !== this.totalCbs || !this.onloadCalled && "function" == typeof r.onload || "function" != typeof this.end || this.end(r);
            }
            function f(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && !this.xhrGuids[r] && (this.xhrGuids[r] = !0, this.totalCbs += 1);
            }
            function h(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && this.xhrGuids[r] && (delete this.xhrGuids[r], this.totalCbs -= 1);
            }
            function p() {
              this.endTime = (0, g.z)();
            }
            function m(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-added", [e[1], e[2]], r);
            }
            function v(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-removed", [e[1], e[2]], r);
            }
            function b(e, t, r) {
              t instanceof X && ("onload" === r && (this.onload = !0), ("load" === (e[0] && e[0].type) || this.onload) && (this.xhrCbStart = (0, g.z)()));
            }
            function y(e, r) {
              this.xhrCbStart && t.emit("xhr-cb-time", [(0, g.z)() - this.xhrCbStart, this.onload, r], r);
            }
            function w(e) {
              var t,
                r = e[1] || {};
              if ("string" == typeof e[0] ? 0 === (t = e[0]).length && u.il && (t = "" + u._A.location.href) : e[0] && e[0].url ? t = e[0].url : u._A?.URL && e[0] && e[0] instanceof URL ? t = e[0].href : "function" == typeof e[0].toString && (t = e[0].toString()), "string" == typeof t && 0 !== t.length) {
                t && (this.parsedOrigin = (0, U.e)(t), this.sameOrigin = this.parsedOrigin.sameOrigin);
                var n = o.generateTracePayload(this.parsedOrigin);
                if (n && (n.newrelicHeader || n.traceContextParentHeader)) if (e[0] && e[0].headers) s(e[0].headers, n) && (this.dt = n);else {
                  var i = {};
                  for (var a in r) i[a] = r[a];
                  i.headers = new Headers(r.headers || {}), s(i.headers, n) && (this.dt = n), e.length > 1 ? e[1] = i : e.push(i);
                }
              }
              function s(e, t) {
                var r = !1;
                return t.newrelicHeader && (e.set("newrelic", t.newrelicHeader), r = !0), t.traceContextParentHeader && (e.set("traceparent", t.traceContextParentHeader), t.traceContextStateHeader && e.set("tracestate", t.traceContextStateHeader), r = !0), r;
              }
            }
            function A(e, t) {
              this.params = {}, this.metrics = {}, this.startTime = (0, g.z)(), this.dt = t, e.length >= 1 && (this.target = e[0]), e.length >= 2 && (this.opts = e[1]);
              var r,
                n = this.opts || {},
                i = this.target;
              "string" == typeof i ? r = i : "object" == typeof i && i instanceof W ? r = i.url : u._A?.URL && "object" == typeof i && i instanceof URL && (r = i.href), T(this, r);
              var o = ("" + (i && i instanceof W && i.method || n.method || "GET")).toUpperCase();
              this.params.method = o, this.txSize = B(n.body) || 0;
            }
            function x(e, t) {
              var n;
              this.endTime = (0, g.z)(), this.params || (this.params = {}), this.params.status = t ? t.status : 0, "string" == typeof this.rxSize && this.rxSize.length > 0 && (n = +this.rxSize);
              var o = {
                txSize: this.txSize,
                rxSize: n,
                duration: (0, g.z)() - this.startTime
              };
              i("xhr", [this.params, o, this.startTime, this.endTime, "fetch"], this, r.D.ajax);
            }
            function E(e) {
              var t = this.params,
                n = this.metrics;
              if (!this.ended) {
                this.ended = !0;
                for (var o = 0; o < G; o++) e.removeEventListener(V[o], this.listener, !1);
                t.aborted || (n.duration = (0, g.z)() - this.startTime, this.loadCaptureCalled || 4 !== e.readyState ? null == t.status && (t.status = 0) : _(this, e), n.cbTime = this.cbTime, i("xhr", [t, n, this.startTime, this.endTime, "xhr"], this, r.D.ajax));
              }
            }
            function T(e, t) {
              var r = (0, U.e)(t),
                n = e.params;
              n.hostname = r.hostname, n.port = r.port, n.protocol = r.protocol, n.host = r.hostname + ":" + r.port, n.pathname = r.pathname, e.parsedOrigin = r, e.sameOrigin = r.sameOrigin;
            }
            function _(e, t) {
              e.params.status = t.status;
              var r = function (e, t) {
                var r = e.responseType;
                return "json" === r && null !== t ? t : "arraybuffer" === r || "blob" === r || "json" === r ? B(e.response) : "text" === r || "" === r || void 0 === r ? B(e.responseText) : void 0;
              }(t, e.lastSize);
              if (r && (e.metrics.rxSize = r), e.sameOrigin) {
                var n = t.getResponseHeader("X-NewRelic-App-Data");
                n && (e.params.cat = n.split(", ").pop());
              }
              e.loadCaptureCalled = !0;
            }
            t.on("new-xhr", a), t.on("open-xhr-start", s), t.on("open-xhr-end", c), t.on("send-xhr-start", d), t.on("xhr-cb-time", l), t.on("xhr-load-added", f), t.on("xhr-load-removed", h), t.on("xhr-resolved", p), t.on("addEventListener-end", m), t.on("removeEventListener-end", v), t.on("fn-end", y), t.on("fetch-before-start", w), t.on("fetch-start", A), t.on("fn-start", b), t.on("fetch-done", x);
          }(e, this.ee, this.handler, this.dt), this.importAggregator());
        }
      }
      var K = i(3614);
      const {
        BST_RESOURCE: Y,
        RESOURCE: J,
        START: ee,
        END: te,
        FEATURE_NAME: re,
        FN_END: ne,
        FN_START: ie,
        PUSH_STATE: oe
      } = K;
      var ae = i(7836);
      const {
        FEATURE_NAME: se,
        START: ce,
        END: ue,
        BODY: de,
        CB_END: le,
        JS_TIME: fe,
        FETCH: he,
        FN_START: pe,
        CB_START: ge,
        FN_END: me
      } = ae;
      var ve = i(4649);
      class be extends h {
        static featureName = ve.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, ve.t, r), this.importAggregator();
        }
      }
      new class extends t {
        constructor(t) {
          let r = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : (0, _.ky)(16);
          super(), u._A ? (this.agentIdentifier = r, this.sharedAggregator = new y({
            agentIdentifier: this.agentIdentifier
          }), this.features = {}, this.desiredFeatures = new Set(t.features || []), this.desiredFeatures.add(m), Object.assign(this, (0, s.j)(this.agentIdentifier, t, t.loaderType || "agent")), this.start()) : (0, e.Z)("Failed to initial the agent. Could not determine the runtime environment.");
        }
        get config() {
          return {
            info: (0, n.C5)(this.agentIdentifier),
            init: (0, n.P_)(this.agentIdentifier),
            loader_config: (0, n.DL)(this.agentIdentifier),
            runtime: (0, n.OP)(this.agentIdentifier)
          };
        }
        start() {
          const t = "features";
          try {
            const n = a(this.agentIdentifier),
              i = [...this.desiredFeatures];
            i.sort((e, t) => r.p[e.featureName] - r.p[t.featureName]), i.forEach(t => {
              if (n[t.featureName] || t.featureName === r.D.pageViewEvent) {
                const i = function (e) {
                  switch (e) {
                    case r.D.ajax:
                      return [r.D.jserrors];
                    case r.D.sessionTrace:
                      return [r.D.ajax, r.D.pageViewEvent];
                    case r.D.sessionReplay:
                      return [r.D.sessionTrace];
                    case r.D.pageViewTiming:
                      return [r.D.pageViewEvent];
                    default:
                      return [];
                  }
                }(t.featureName);
                i.every(e => n[e]) || (0, e.Z)("".concat(t.featureName, " is enabled but one or more dependent features has been disabled (").concat((0, D.P)(i), "). This may cause unintended consequences or missing data...")), this.features[t.featureName] = new t(this.agentIdentifier, this.sharedAggregator);
              }
            }), (0, T.Qy)(this.agentIdentifier, this.features, t);
          } catch (r) {
            (0, e.Z)("Failed to initialize all enabled instrument classes (agent aborted) -", r);
            for (const e in this.features) this.features[e].abortHandler?.();
            const n = (0, T.fP)();
            return delete n.initializedAgents[this.agentIdentifier]?.api, delete n.initializedAgents[this.agentIdentifier]?.[t], delete this.sharedAggregator, n.ee?.abort(), delete n.ee?.get(this.agentIdentifier), !1;
          }
        }
        addToTrace(t) {
          (0, e.Z)("Call to agent api addToTrace failed. The page action feature is not currently initialized.");
        }
        setCurrentRouteName(t) {
          (0, e.Z)("Call to agent api setCurrentRouteName failed. The spa feature is not currently initialized.");
        }
        interaction() {
          (0, e.Z)("Call to agent api interaction failed. The spa feature is not currently initialized.");
        }
      }({
        features: [Q, m, O, class extends h {
          static featureName = re;
          constructor(e, t) {
            if (super(e, t, re, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            const n = this.ee;
            let i;
            (0, F.QU)(n), this.eventsEE = (0, F.em)(n), this.eventsEE.on(ie, function (e, t) {
              this.bstStart = (0, g.z)();
            }), this.eventsEE.on(ne, function (e, t) {
              (0, c.p)("bst", [e[0], t, this.bstStart, (0, g.z)()], void 0, r.D.sessionTrace, n);
            }), n.on(oe + ee, function (e) {
              this.time = (0, g.z)(), this.startPath = location.pathname + location.hash;
            }), n.on(oe + te, function (e) {
              (0, c.p)("bstHist", [location.pathname + location.hash, this.startPath, this.time], void 0, r.D.sessionTrace, n);
            });
            try {
              i = new PerformanceObserver(e => {
                const t = e.getEntries();
                (0, c.p)(Y, [t], void 0, r.D.sessionTrace, n);
              }), i.observe({
                type: J,
                buffered: !0
              });
            } catch (e) {}
            this.importAggregator({
              resourceObserver: i
            });
          }
        }, P, be, k, class extends h {
          static featureName = se;
          constructor(e, t) {
            if (super(e, t, se, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            if (!(0, n.OP)(e).xhrWrappable) return;
            try {
              this.removeOnAbort = new AbortController();
            } catch (e) {}
            let r,
              i = 0;
            const o = this.ee.get("tracer"),
              a = (0, F._L)(this.ee),
              s = (0, F.Lg)(this.ee),
              c = (0, F.BV)(this.ee),
              d = (0, F.Kf)(this.ee),
              l = this.ee.get("events"),
              f = (0, F.u5)(this.ee),
              h = (0, F.QU)(this.ee),
              p = (0, F.Gm)(this.ee);
            function m(e, t) {
              h.emit("newURL", ["" + window.location, t]);
            }
            function v() {
              i++, r = window.location.hash, this[pe] = (0, g.z)();
            }
            function b() {
              i--, window.location.hash !== r && m(0, !0);
              var e = (0, g.z)();
              this[fe] = ~~this[fe] + e - this[pe], this[me] = e;
            }
            function y(e, t) {
              e.on(t, function () {
                this[t] = (0, g.z)();
              });
            }
            this.ee.on(pe, v), s.on(ge, v), a.on(ge, v), this.ee.on(me, b), s.on(le, b), a.on(le, b), this.ee.buffer([pe, me, "xhr-resolved"], this.featureName), l.buffer([pe], this.featureName), c.buffer(["setTimeout" + ue, "clearTimeout" + ce, pe], this.featureName), d.buffer([pe, "new-xhr", "send-xhr" + ce], this.featureName), f.buffer([he + ce, he + "-done", he + de + ce, he + de + ue], this.featureName), h.buffer(["newURL"], this.featureName), p.buffer([pe], this.featureName), s.buffer(["propagate", ge, le, "executor-err", "resolve" + ce], this.featureName), o.buffer([pe, "no-" + pe], this.featureName), a.buffer(["new-jsonp", "cb-start", "jsonp-error", "jsonp-end"], this.featureName), y(f, he + ce), y(f, he + "-done"), y(a, "new-jsonp"), y(a, "jsonp-end"), y(a, "cb-start"), h.on("pushState-end", m), h.on("replaceState-end", m), window.addEventListener("hashchange", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("load", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("popstate", function () {
              m(0, i > 1);
            }, (0, C.m$)(!0, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
          }
          #i() {
            this.removeOnAbort?.abort(), this.abortHandler = void 0;
          }
        }],
        loaderType: "spa"
      });
    })();
  })();
})()</script>
      <link rel="shortcut icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
      <link rel="icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
      <link rel="stylesheet" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1/arp.css">
      <link href="//cdn.pendo.io" rel="dns-prefetch">
      <link href="https://cdn.pendo.io" rel="preconnect" crossorigin="anonymous">
      <link rel="dns-prefetch" href="https://smetrics.elsevier.com">
      
      <script type="text/javascript">
        var targetServerState = JSON.stringify({"4D6368F454EC41940A4C98A6@AdobeOrg":{"sdid":{"supplementalDataIDCurrent":"54403CD652B195F1-00D1EC0BC1DC2DBF","supplementalDataIDCurrentConsumed":{"payload:target-global-mbox":true},"supplementalDataIDLastConsumed":{}}}});
        window.appData = window.appData || [];
        window.pageTargeting = {"region":"eu-west-1","platform":"sdtech","entitled":false,"crawler":"","journal":"Computer Methods and Programs in Biomedicine","auth":"AE"};
        window.arp = {
          config: {"adobeSuite":"elsevier-sd-prod","arsUrl":"https://ars.els-cdn.com","recommendationsFeedback":{"enabled":true,"url":"https://feedback.recs.d.elsevier.com/raw/events","timeout":60000},"googleMapsApiKey":"AIzaSyCBYU6I6lrbEU6wQXUEIte3NwGtm3jwHQc","mediaBaseUrl":"https://ars.els-cdn.com/content/image/","strictMode":false,"seamlessAccess":{"enableSeamlessAccess":true,"scriptUrl":"https://unpkg.com/@theidentityselector/thiss-ds@1.0.13/dist/thiss-ds.js","persistenceUrl":"https://service.seamlessaccess.org/ps/","persistenceContext":"seamlessaccess.org","scienceDirectUrl":"https://www.sciencedirect.com","shibAuthUrl":"https://auth.elsevier.com/ShibAuth/institutionLogin"},"reaxys":{"apiUrl":"https://reaxys-sdlc.reaxys.com","origin":"sciencedirect","queryBuilderHostPath":"https://www.reaxys.com/reaxys/secured/hopinto.do","url":"https://www.reaxys.com"},"oneTrustCookie":{"enabled":true},"ssrn":{"url":"https://papers.ssrn.com","path":"/sol3/papers.cfm"},"plumX":"https://api.plu.mx/widget/elsevier/artifact","assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1"},
          subscriptions: [],
          subscribe: function(cb) {
            var self = this;
            var i = this.subscriptions.push(cb) - 1;
            return function unsubscribe() {
              self.subscriptions.splice(i, 1);
            }
          },
        };
        window.addEventListener('beforeprint', () => pendo.onGuideDismissed());
      </script>
    <script data-cfasync="false" src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" data-domain-script="865ea198-88cc-4e41-8952-1df75d554d02"></script><meta http-equiv="origin-trial" content="AlK2UR5SkAlj8jjdEc9p3F3xuFYlF6LYjAML3EOqw1g26eCwWPjdmecULvBH5MVPoqKYrOfPhYVL71xAXI1IBQoAAAB8eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="Amm8/NmvvQfhwCib6I7ZsmUxiSCfOxWxHayJwyU1r3gRIItzr7bNQid6O8ZYaE1GSQTa69WwhPC9flq/oYkRBwsAAACCeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="A9wSqI5i0iwGdf6L1CERNdmsTPgVu44ewj8QxTBYgsv1LCPUVF7YmWOvTappqB1139jAymxUW/RO8zmMqo4zlAAAAACNeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MzY4MTI4MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A+d7vJfYtay4OUbdtRPZA3y7bKQLsxaMEPmxgfhBGqKXNrdkCQeJlUwqa6EBbSfjwFtJWTrWIioXeMW+y8bWAgQAAACTeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MzY4MTI4MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><script src="https://securepubads.g.doubleclick.net/pagead/managed/js/gpt/m202412090101/pubads_impl.js" async=""></script><link href="https://securepubads.g.doubleclick.net/pagead/managed/dict/m202412050101/gpt" rel="compression-dictionary"><script src="https://unpkg.com/@theidentityselector/thiss-ds@1.0.13/dist/thiss-ds.js" async=""></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
</style><script src="https://cdn.cookielaw.org/scripttemplates/202402.1.0/otBannerSdk.js" async="" type="text/javascript"></script><style id="onetrust-style">#onetrust-banner-sdk{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}#onetrust-banner-sdk .onetrust-vendors-list-handler{cursor:pointer;color:#1f96db;font-size:inherit;font-weight:bold;text-decoration:none;margin-left:5px}#onetrust-banner-sdk .onetrust-vendors-list-handler:hover{color:#1f96db}#onetrust-banner-sdk:focus{outline:2px solid #000;outline-offset:-2px}#onetrust-banner-sdk a:focus{outline:2px solid #000}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{outline-offset:1px}#onetrust-banner-sdk.ot-bnr-w-logo .ot-bnr-logo{height:64px;width:64px}#onetrust-banner-sdk .ot-tcf2-vendor-count.ot-text-bold{font-weight:bold}#onetrust-banner-sdk .ot-close-icon,#onetrust-pc-sdk .ot-close-icon,#ot-sync-ntfy .ot-close-icon{background-size:contain;background-repeat:no-repeat;background-position:center;height:12px;width:12px}#onetrust-banner-sdk .powered-by-logo,#onetrust-banner-sdk .ot-pc-footer-logo a,#onetrust-pc-sdk .powered-by-logo,#onetrust-pc-sdk .ot-pc-footer-logo a,#ot-sync-ntfy .powered-by-logo,#ot-sync-ntfy .ot-pc-footer-logo a{background-size:contain;background-repeat:no-repeat;background-position:center;height:25px;width:152px;display:block;text-decoration:none;font-size:.75em}#onetrust-banner-sdk .powered-by-logo:hover,#onetrust-banner-sdk .ot-pc-footer-logo a:hover,#onetrust-pc-sdk .powered-by-logo:hover,#onetrust-pc-sdk .ot-pc-footer-logo a:hover,#ot-sync-ntfy .powered-by-logo:hover,#ot-sync-ntfy .ot-pc-footer-logo a:hover{color:#565656}#onetrust-banner-sdk h3 *,#onetrust-banner-sdk h4 *,#onetrust-banner-sdk h6 *,#onetrust-banner-sdk button *,#onetrust-banner-sdk a[data-parent-id] *,#onetrust-pc-sdk h3 *,#onetrust-pc-sdk h4 *,#onetrust-pc-sdk h6 *,#onetrust-pc-sdk button *,#onetrust-pc-sdk a[data-parent-id] *,#ot-sync-ntfy h3 *,#ot-sync-ntfy h4 *,#ot-sync-ntfy h6 *,#ot-sync-ntfy button *,#ot-sync-ntfy a[data-parent-id] *{font-size:inherit;font-weight:inherit;color:inherit}#onetrust-banner-sdk .ot-hide,#onetrust-pc-sdk .ot-hide,#ot-sync-ntfy .ot-hide{display:none !important}#onetrust-banner-sdk button.ot-link-btn:hover,#onetrust-pc-sdk button.ot-link-btn:hover,#ot-sync-ntfy button.ot-link-btn:hover{text-decoration:underline;opacity:1}#onetrust-pc-sdk .ot-sdk-row .ot-sdk-column{padding:0}#onetrust-pc-sdk .ot-sdk-container{padding-right:0}#onetrust-pc-sdk .ot-sdk-row{flex-direction:initial;width:100%}#onetrust-pc-sdk [type=checkbox]:checked,#onetrust-pc-sdk [type=checkbox]:not(:checked){pointer-events:initial}#onetrust-pc-sdk [type=checkbox]:disabled+label::before,#onetrust-pc-sdk [type=checkbox]:disabled+label:after,#onetrust-pc-sdk [type=checkbox]:disabled+label{pointer-events:none;opacity:.7}#onetrust-pc-sdk #vendor-list-content{transform:translate3d(0, 0, 0)}#onetrust-pc-sdk li input[type=checkbox]{z-index:1}#onetrust-pc-sdk li .ot-checkbox label{z-index:2}#onetrust-pc-sdk li .ot-checkbox input[type=checkbox]{height:auto;width:auto}#onetrust-pc-sdk li .host-title a,#onetrust-pc-sdk li .ot-host-name a,#onetrust-pc-sdk li .accordion-text,#onetrust-pc-sdk li .ot-acc-txt{z-index:2;position:relative}#onetrust-pc-sdk input{margin:3px .1ex}#onetrust-pc-sdk .pc-logo,#onetrust-pc-sdk .ot-pc-logo{height:60px;width:180px;background-position:center;background-size:contain;background-repeat:no-repeat;display:inline-flex;justify-content:center;align-items:center}#onetrust-pc-sdk .pc-logo img,#onetrust-pc-sdk .ot-pc-logo img{max-height:100%;max-width:100%}#onetrust-pc-sdk .screen-reader-only,#onetrust-pc-sdk .ot-scrn-rdr,.ot-sdk-cookie-policy .screen-reader-only,.ot-sdk-cookie-policy .ot-scrn-rdr{border:0;clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}#onetrust-pc-sdk.ot-fade-in,.onetrust-pc-dark-filter.ot-fade-in,#onetrust-banner-sdk.ot-fade-in{animation-name:onetrust-fade-in;animation-duration:400ms;animation-timing-function:ease-in-out}#onetrust-pc-sdk.ot-hide{display:none !important}.onetrust-pc-dark-filter.ot-hide{display:none !important}#ot-sdk-btn.ot-sdk-show-settings,#ot-sdk-btn.optanon-show-settings{color:#68b631;border:1px solid #68b631;height:auto;white-space:normal;word-wrap:break-word;padding:.8em 2em;font-size:.8em;line-height:1.2;cursor:pointer;-moz-transition:.1s ease;-o-transition:.1s ease;-webkit-transition:1s ease;transition:.1s ease}#ot-sdk-btn.ot-sdk-show-settings:hover,#ot-sdk-btn.optanon-show-settings:hover{color:#fff;background-color:#68b631}.onetrust-pc-dark-filter{background:rgba(0,0,0,.5);z-index:2147483646;width:100%;height:100%;overflow:hidden;position:fixed;top:0;bottom:0;left:0}@keyframes onetrust-fade-in{0%{opacity:0}100%{opacity:1}}.ot-cookie-label{text-decoration:underline}@media only screen and (min-width: 426px)and (max-width: 896px)and (orientation: landscape){#onetrust-pc-sdk p{font-size:.75em}}#onetrust-banner-sdk .banner-option-input:focus+label{outline:1px solid #000;outline-style:auto}.category-vendors-list-handler+a:focus,.category-vendors-list-handler+a:focus-visible{outline:2px solid #000}#onetrust-pc-sdk .ot-userid-title{margin-top:10px}#onetrust-pc-sdk .ot-userid-title>span,#onetrust-pc-sdk .ot-userid-timestamp>span{font-weight:700}#onetrust-pc-sdk .ot-userid-desc{font-style:italic}#onetrust-pc-sdk .ot-host-desc a{pointer-events:initial}#onetrust-pc-sdk .ot-ven-hdr>p a{position:relative;z-index:2;pointer-events:initial}#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info a,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info a{margin-right:auto}#onetrust-pc-sdk .ot-pc-footer-logo img{width:136px;height:16px}#onetrust-pc-sdk .ot-pur-vdr-count{font-weight:400;font-size:.7rem;padding-top:3px;display:block}#onetrust-banner-sdk .ot-optout-signal,#onetrust-pc-sdk .ot-optout-signal{border:1px solid #32ae88;border-radius:3px;padding:5px;margin-bottom:10px;background-color:#f9fffa;font-size:.85rem;line-height:2}#onetrust-banner-sdk .ot-optout-signal .ot-optout-icon,#onetrust-pc-sdk .ot-optout-signal .ot-optout-icon{display:inline;margin-right:5px}#onetrust-banner-sdk .ot-optout-signal svg,#onetrust-pc-sdk .ot-optout-signal svg{height:20px;width:30px;transform:scale(0.5)}#onetrust-banner-sdk .ot-optout-signal svg path,#onetrust-pc-sdk .ot-optout-signal svg path{fill:#32ae88}#onetrust-banner-sdk,#onetrust-pc-sdk,#ot-sdk-cookie-policy,#ot-sync-ntfy{font-size:16px}#onetrust-banner-sdk *,#onetrust-banner-sdk ::after,#onetrust-banner-sdk ::before,#onetrust-pc-sdk *,#onetrust-pc-sdk ::after,#onetrust-pc-sdk ::before,#ot-sdk-cookie-policy *,#ot-sdk-cookie-policy ::after,#ot-sdk-cookie-policy ::before,#ot-sync-ntfy *,#ot-sync-ntfy ::after,#ot-sync-ntfy ::before{-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box}#onetrust-banner-sdk div,#onetrust-banner-sdk span,#onetrust-banner-sdk h1,#onetrust-banner-sdk h2,#onetrust-banner-sdk h3,#onetrust-banner-sdk h4,#onetrust-banner-sdk h5,#onetrust-banner-sdk h6,#onetrust-banner-sdk p,#onetrust-banner-sdk img,#onetrust-banner-sdk svg,#onetrust-banner-sdk button,#onetrust-banner-sdk section,#onetrust-banner-sdk a,#onetrust-banner-sdk label,#onetrust-banner-sdk input,#onetrust-banner-sdk ul,#onetrust-banner-sdk li,#onetrust-banner-sdk nav,#onetrust-banner-sdk table,#onetrust-banner-sdk thead,#onetrust-banner-sdk tr,#onetrust-banner-sdk td,#onetrust-banner-sdk tbody,#onetrust-banner-sdk .ot-main-content,#onetrust-banner-sdk .ot-toggle,#onetrust-banner-sdk #ot-content,#onetrust-banner-sdk #ot-pc-content,#onetrust-banner-sdk .checkbox,#onetrust-pc-sdk div,#onetrust-pc-sdk span,#onetrust-pc-sdk h1,#onetrust-pc-sdk h2,#onetrust-pc-sdk h3,#onetrust-pc-sdk h4,#onetrust-pc-sdk h5,#onetrust-pc-sdk h6,#onetrust-pc-sdk p,#onetrust-pc-sdk img,#onetrust-pc-sdk svg,#onetrust-pc-sdk button,#onetrust-pc-sdk section,#onetrust-pc-sdk a,#onetrust-pc-sdk label,#onetrust-pc-sdk input,#onetrust-pc-sdk ul,#onetrust-pc-sdk li,#onetrust-pc-sdk nav,#onetrust-pc-sdk table,#onetrust-pc-sdk thead,#onetrust-pc-sdk tr,#onetrust-pc-sdk td,#onetrust-pc-sdk tbody,#onetrust-pc-sdk .ot-main-content,#onetrust-pc-sdk .ot-toggle,#onetrust-pc-sdk #ot-content,#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk .checkbox,#ot-sdk-cookie-policy div,#ot-sdk-cookie-policy span,#ot-sdk-cookie-policy h1,#ot-sdk-cookie-policy h2,#ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy h5,#ot-sdk-cookie-policy h6,#ot-sdk-cookie-policy p,#ot-sdk-cookie-policy img,#ot-sdk-cookie-policy svg,#ot-sdk-cookie-policy button,#ot-sdk-cookie-policy section,#ot-sdk-cookie-policy a,#ot-sdk-cookie-policy label,#ot-sdk-cookie-policy input,#ot-sdk-cookie-policy ul,#ot-sdk-cookie-policy li,#ot-sdk-cookie-policy nav,#ot-sdk-cookie-policy table,#ot-sdk-cookie-policy thead,#ot-sdk-cookie-policy tr,#ot-sdk-cookie-policy td,#ot-sdk-cookie-policy tbody,#ot-sdk-cookie-policy .ot-main-content,#ot-sdk-cookie-policy .ot-toggle,#ot-sdk-cookie-policy #ot-content,#ot-sdk-cookie-policy #ot-pc-content,#ot-sdk-cookie-policy .checkbox,#ot-sync-ntfy div,#ot-sync-ntfy span,#ot-sync-ntfy h1,#ot-sync-ntfy h2,#ot-sync-ntfy h3,#ot-sync-ntfy h4,#ot-sync-ntfy h5,#ot-sync-ntfy h6,#ot-sync-ntfy p,#ot-sync-ntfy img,#ot-sync-ntfy svg,#ot-sync-ntfy button,#ot-sync-ntfy section,#ot-sync-ntfy a,#ot-sync-ntfy label,#ot-sync-ntfy input,#ot-sync-ntfy ul,#ot-sync-ntfy li,#ot-sync-ntfy nav,#ot-sync-ntfy table,#ot-sync-ntfy thead,#ot-sync-ntfy tr,#ot-sync-ntfy td,#ot-sync-ntfy tbody,#ot-sync-ntfy .ot-main-content,#ot-sync-ntfy .ot-toggle,#ot-sync-ntfy #ot-content,#ot-sync-ntfy #ot-pc-content,#ot-sync-ntfy .checkbox{font-family:inherit;font-weight:normal;-webkit-font-smoothing:auto;letter-spacing:normal;line-height:normal;padding:0;margin:0;height:auto;min-height:0;max-height:none;width:auto;min-width:0;max-width:none;border-radius:0;border:none;clear:none;float:none;position:static;bottom:auto;left:auto;right:auto;top:auto;text-align:left;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;white-space:normal;background:none;overflow:visible;vertical-align:baseline;visibility:visible;z-index:auto;box-shadow:none}#onetrust-banner-sdk label:before,#onetrust-banner-sdk label:after,#onetrust-banner-sdk .checkbox:after,#onetrust-banner-sdk .checkbox:before,#onetrust-pc-sdk label:before,#onetrust-pc-sdk label:after,#onetrust-pc-sdk .checkbox:after,#onetrust-pc-sdk .checkbox:before,#ot-sdk-cookie-policy label:before,#ot-sdk-cookie-policy label:after,#ot-sdk-cookie-policy .checkbox:after,#ot-sdk-cookie-policy .checkbox:before,#ot-sync-ntfy label:before,#ot-sync-ntfy label:after,#ot-sync-ntfy .checkbox:after,#ot-sync-ntfy .checkbox:before{content:"";content:none}#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{position:relative;width:100%;max-width:100%;margin:0 auto;padding:0 20px;box-sizing:border-box}#onetrust-banner-sdk .ot-sdk-column,#onetrust-banner-sdk .ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-column,#onetrust-pc-sdk .ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-column,#ot-sdk-cookie-policy .ot-sdk-columns{width:100%;float:left;box-sizing:border-box;padding:0;display:initial}@media(min-width: 400px){#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{width:90%;padding:0}}@media(min-width: 550px){#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{width:100%}#onetrust-banner-sdk .ot-sdk-column,#onetrust-banner-sdk .ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-column,#onetrust-pc-sdk .ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-column,#ot-sdk-cookie-policy .ot-sdk-columns{margin-left:4%}#onetrust-banner-sdk .ot-sdk-column:first-child,#onetrust-banner-sdk .ot-sdk-columns:first-child,#onetrust-pc-sdk .ot-sdk-column:first-child,#onetrust-pc-sdk .ot-sdk-columns:first-child,#ot-sdk-cookie-policy .ot-sdk-column:first-child,#ot-sdk-cookie-policy .ot-sdk-columns:first-child{margin-left:0}#onetrust-banner-sdk .ot-sdk-two.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-two.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-two.ot-sdk-columns{width:13.3333333333%}#onetrust-banner-sdk .ot-sdk-three.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-three.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-three.ot-sdk-columns{width:22%}#onetrust-banner-sdk .ot-sdk-four.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-four.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-four.ot-sdk-columns{width:30.6666666667%}#onetrust-banner-sdk .ot-sdk-eight.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-eight.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-eight.ot-sdk-columns{width:65.3333333333%}#onetrust-banner-sdk .ot-sdk-nine.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-nine.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-nine.ot-sdk-columns{width:74%}#onetrust-banner-sdk .ot-sdk-ten.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-ten.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-ten.ot-sdk-columns{width:82.6666666667%}#onetrust-banner-sdk .ot-sdk-eleven.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-eleven.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-eleven.ot-sdk-columns{width:91.3333333333%}#onetrust-banner-sdk .ot-sdk-twelve.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-twelve.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-twelve.ot-sdk-columns{width:100%;margin-left:0}}#onetrust-banner-sdk h1,#onetrust-banner-sdk h2,#onetrust-banner-sdk h3,#onetrust-banner-sdk h4,#onetrust-banner-sdk h5,#onetrust-banner-sdk h6,#onetrust-pc-sdk h1,#onetrust-pc-sdk h2,#onetrust-pc-sdk h3,#onetrust-pc-sdk h4,#onetrust-pc-sdk h5,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h1,#ot-sdk-cookie-policy h2,#ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy h5,#ot-sdk-cookie-policy h6{margin-top:0;font-weight:600;font-family:inherit}#onetrust-banner-sdk h1,#onetrust-pc-sdk h1,#ot-sdk-cookie-policy h1{font-size:1.5rem;line-height:1.2}#onetrust-banner-sdk h2,#onetrust-pc-sdk h2,#ot-sdk-cookie-policy h2{font-size:1.5rem;line-height:1.25}#onetrust-banner-sdk h3,#onetrust-pc-sdk h3,#ot-sdk-cookie-policy h3{font-size:1.5rem;line-height:1.3}#onetrust-banner-sdk h4,#onetrust-pc-sdk h4,#ot-sdk-cookie-policy h4{font-size:1.5rem;line-height:1.35}#onetrust-banner-sdk h5,#onetrust-pc-sdk h5,#ot-sdk-cookie-policy h5{font-size:1.5rem;line-height:1.5}#onetrust-banner-sdk h6,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h6{font-size:1.5rem;line-height:1.6}@media(min-width: 550px){#onetrust-banner-sdk h1,#onetrust-pc-sdk h1,#ot-sdk-cookie-policy h1{font-size:1.5rem}#onetrust-banner-sdk h2,#onetrust-pc-sdk h2,#ot-sdk-cookie-policy h2{font-size:1.5rem}#onetrust-banner-sdk h3,#onetrust-pc-sdk h3,#ot-sdk-cookie-policy h3{font-size:1.5rem}#onetrust-banner-sdk h4,#onetrust-pc-sdk h4,#ot-sdk-cookie-policy h4{font-size:1.5rem}#onetrust-banner-sdk h5,#onetrust-pc-sdk h5,#ot-sdk-cookie-policy h5{font-size:1.5rem}#onetrust-banner-sdk h6,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h6{font-size:1.5rem}}#onetrust-banner-sdk p,#onetrust-pc-sdk p,#ot-sdk-cookie-policy p{margin:0 0 1em 0;font-family:inherit;line-height:normal}#onetrust-banner-sdk a,#onetrust-pc-sdk a,#ot-sdk-cookie-policy a{color:#565656;text-decoration:underline}#onetrust-banner-sdk a:hover,#onetrust-pc-sdk a:hover,#ot-sdk-cookie-policy a:hover{color:#565656;text-decoration:none}#onetrust-banner-sdk .ot-sdk-button,#onetrust-banner-sdk button,#onetrust-pc-sdk .ot-sdk-button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy .ot-sdk-button,#ot-sdk-cookie-policy button{margin-bottom:1rem;font-family:inherit}#onetrust-banner-sdk .ot-sdk-button,#onetrust-banner-sdk button,#onetrust-pc-sdk .ot-sdk-button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy .ot-sdk-button,#ot-sdk-cookie-policy button{display:inline-block;height:38px;padding:0 30px;color:#555;text-align:center;font-size:.9em;font-weight:400;line-height:38px;letter-spacing:.01em;text-decoration:none;white-space:nowrap;background-color:rgba(0,0,0,0);border-radius:2px;border:1px solid #bbb;cursor:pointer;box-sizing:border-box}#onetrust-banner-sdk .ot-sdk-button:hover,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus,#onetrust-pc-sdk .ot-sdk-button:hover,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus,#ot-sdk-cookie-policy .ot-sdk-button:hover,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus{color:#333;border-color:#888;opacity:.7}#onetrust-banner-sdk .ot-sdk-button:focus,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:focus,#onetrust-pc-sdk .ot-sdk-button:focus,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:focus,#ot-sdk-cookie-policy .ot-sdk-button:focus,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:focus{outline:2px solid #000}#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary,#onetrust-banner-sdk button.ot-sdk-button-primary,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary,#onetrust-pc-sdk button.ot-sdk-button-primary,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary,#ot-sdk-cookie-policy button.ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary{color:#fff;background-color:#33c3f0;border-color:#33c3f0}#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary:hover,#onetrust-banner-sdk button.ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary:hover,#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary:focus,#onetrust-banner-sdk button.ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary:focus,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary:hover,#onetrust-pc-sdk button.ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary:hover,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary:focus,#onetrust-pc-sdk button.ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary:hover,#ot-sdk-cookie-policy button.ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary:focus,#ot-sdk-cookie-policy button.ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary:focus{color:#fff;background-color:#1eaedb;border-color:#1eaedb}#onetrust-banner-sdk input[type=text],#onetrust-pc-sdk input[type=text],#ot-sdk-cookie-policy input[type=text]{height:38px;padding:6px 10px;background-color:#fff;border:1px solid #d1d1d1;border-radius:4px;box-shadow:none;box-sizing:border-box}#onetrust-banner-sdk input[type=text],#onetrust-pc-sdk input[type=text],#ot-sdk-cookie-policy input[type=text]{-webkit-appearance:none;-moz-appearance:none;appearance:none}#onetrust-banner-sdk input[type=text]:focus,#onetrust-pc-sdk input[type=text]:focus,#ot-sdk-cookie-policy input[type=text]:focus{border:1px solid #000;outline:0}#onetrust-banner-sdk label,#onetrust-pc-sdk label,#ot-sdk-cookie-policy label{display:block;margin-bottom:.5rem;font-weight:600}#onetrust-banner-sdk input[type=checkbox],#onetrust-pc-sdk input[type=checkbox],#ot-sdk-cookie-policy input[type=checkbox]{display:inline}#onetrust-banner-sdk ul,#onetrust-pc-sdk ul,#ot-sdk-cookie-policy ul{list-style:circle inside}#onetrust-banner-sdk ul,#onetrust-pc-sdk ul,#ot-sdk-cookie-policy ul{padding-left:0;margin-top:0}#onetrust-banner-sdk ul ul,#onetrust-pc-sdk ul ul,#ot-sdk-cookie-policy ul ul{margin:1.5rem 0 1.5rem 3rem;font-size:90%}#onetrust-banner-sdk li,#onetrust-pc-sdk li,#ot-sdk-cookie-policy li{margin-bottom:1rem}#onetrust-banner-sdk th,#onetrust-banner-sdk td,#onetrust-pc-sdk th,#onetrust-pc-sdk td,#ot-sdk-cookie-policy th,#ot-sdk-cookie-policy td{padding:12px 15px;text-align:left;border-bottom:1px solid #e1e1e1}#onetrust-banner-sdk button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy button{margin-bottom:1rem;font-family:inherit}#onetrust-banner-sdk .ot-sdk-container:after,#onetrust-banner-sdk .ot-sdk-row:after,#onetrust-pc-sdk .ot-sdk-container:after,#onetrust-pc-sdk .ot-sdk-row:after,#ot-sdk-cookie-policy .ot-sdk-container:after,#ot-sdk-cookie-policy .ot-sdk-row:after{content:"";display:table;clear:both}#onetrust-banner-sdk .ot-sdk-row,#onetrust-pc-sdk .ot-sdk-row,#ot-sdk-cookie-policy .ot-sdk-row{margin:0;max-width:none;display:block}#onetrust-banner-sdk{box-shadow:0 0 18px rgba(0,0,0,.2)}#onetrust-banner-sdk.otFlat{position:fixed;z-index:2147483645;bottom:0;right:0;left:0;background-color:#fff;max-height:90%;overflow-x:hidden;overflow-y:auto}#onetrust-banner-sdk.otFlat.top{top:0px;bottom:auto}#onetrust-banner-sdk.otRelFont{font-size:1rem}#onetrust-banner-sdk>.ot-sdk-container{overflow:hidden}#onetrust-banner-sdk::-webkit-scrollbar{width:11px}#onetrust-banner-sdk::-webkit-scrollbar-thumb{border-radius:10px;background:#c1c1c1}#onetrust-banner-sdk{scrollbar-arrow-color:#c1c1c1;scrollbar-darkshadow-color:#c1c1c1;scrollbar-face-color:#c1c1c1;scrollbar-shadow-color:#c1c1c1}#onetrust-banner-sdk #onetrust-policy{margin:1.25em 0 .625em 2em;overflow:hidden}#onetrust-banner-sdk #onetrust-policy .ot-gv-list-handler{float:left;font-size:.82em;padding:0;margin-bottom:0;border:0;line-height:normal;height:auto;width:auto}#onetrust-banner-sdk #onetrust-policy-title{font-size:1.2em;line-height:1.3;margin-bottom:10px}#onetrust-banner-sdk #onetrust-policy-text{clear:both;text-align:left;font-size:.88em;line-height:1.4}#onetrust-banner-sdk #onetrust-policy-text *{font-size:inherit;line-height:inherit}#onetrust-banner-sdk #onetrust-policy-text a{font-weight:bold;margin-left:5px}#onetrust-banner-sdk #onetrust-policy-title,#onetrust-banner-sdk #onetrust-policy-text{color:dimgray;float:left}#onetrust-banner-sdk #onetrust-button-group-parent{min-height:1px;text-align:center}#onetrust-banner-sdk #onetrust-button-group{display:inline-block}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{background-color:#68b631;color:#fff;border-color:#68b631;margin-right:1em;min-width:125px;height:auto;white-space:normal;word-break:break-word;word-wrap:break-word;padding:12px 10px;line-height:1.2;font-size:.813em;font-weight:600}#onetrust-banner-sdk #onetrust-pc-btn-handler.cookie-setting-link{background-color:#fff;border:none;color:#68b631;text-decoration:underline;padding-left:0;padding-right:0}#onetrust-banner-sdk .onetrust-close-btn-ui{width:44px;height:44px;background-size:12px;border:none;position:relative;margin:auto;padding:0}#onetrust-banner-sdk .banner_logo{display:none}#onetrust-banner-sdk.ot-bnr-w-logo .ot-bnr-logo{position:absolute;top:50%;transform:translateY(-50%);left:0px}#onetrust-banner-sdk.ot-bnr-w-logo #onetrust-policy{margin-left:65px}#onetrust-banner-sdk .ot-b-addl-desc{clear:both;float:left;display:block}#onetrust-banner-sdk #banner-options{float:left;display:table;margin-right:0;margin-left:1em;width:calc(100% - 1em)}#onetrust-banner-sdk .banner-option-input{cursor:pointer;width:auto;height:auto;border:none;padding:0;padding-right:3px;margin:0 0 10px;font-size:.82em;line-height:1.4}#onetrust-banner-sdk .banner-option-input *{pointer-events:none;font-size:inherit;line-height:inherit}#onetrust-banner-sdk .banner-option-input[aria-expanded=true]~.banner-option-details{display:block;height:auto}#onetrust-banner-sdk .banner-option-input[aria-expanded=true] .ot-arrow-container{transform:rotate(90deg)}#onetrust-banner-sdk .banner-option{margin-bottom:12px;margin-left:0;border:none;float:left;padding:0}#onetrust-banner-sdk .banner-option:first-child{padding-left:2px}#onetrust-banner-sdk .banner-option:not(:first-child){padding:0;border:none}#onetrust-banner-sdk .banner-option-header{cursor:pointer;display:inline-block}#onetrust-banner-sdk .banner-option-header :first-child{color:dimgray;font-weight:bold;float:left}#onetrust-banner-sdk .banner-option-header .ot-arrow-container{display:inline-block;border-top:6px solid rgba(0,0,0,0);border-bottom:6px solid rgba(0,0,0,0);border-left:6px solid dimgray;margin-left:10px;vertical-align:middle}#onetrust-banner-sdk .banner-option-details{display:none;font-size:.83em;line-height:1.5;padding:10px 0px 5px 10px;margin-right:10px;height:0px}#onetrust-banner-sdk .banner-option-details *{font-size:inherit;line-height:inherit;color:dimgray}#onetrust-banner-sdk .ot-arrow-container,#onetrust-banner-sdk .banner-option-details{transition:all 300ms ease-in 0s;-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s}#onetrust-banner-sdk .ot-dpd-container{float:left}#onetrust-banner-sdk .ot-dpd-title{margin-bottom:10px}#onetrust-banner-sdk .ot-dpd-title,#onetrust-banner-sdk .ot-dpd-desc{font-size:.88em;line-height:1.4;color:dimgray}#onetrust-banner-sdk .ot-dpd-title *,#onetrust-banner-sdk .ot-dpd-desc *{font-size:inherit;line-height:inherit}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text *{margin-bottom:0}#onetrust-banner-sdk.ot-iab-2 .onetrust-vendors-list-handler{display:block;margin-left:0;margin-top:5px;clear:both;margin-bottom:0;padding:0;border:0;height:auto;width:auto}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group button{display:block}#onetrust-banner-sdk.ot-close-btn-link{padding-top:25px}#onetrust-banner-sdk.ot-close-btn-link #onetrust-close-btn-container{top:15px;transform:none;right:15px}#onetrust-banner-sdk.ot-close-btn-link #onetrust-close-btn-container button{padding:0;white-space:pre-wrap;border:none;height:auto;line-height:1.5;text-decoration:underline;font-size:.69em}#onetrust-banner-sdk #onetrust-policy-text,#onetrust-banner-sdk .ot-dpd-desc,#onetrust-banner-sdk .ot-b-addl-desc{font-size:.813em;line-height:1.5}#onetrust-banner-sdk .ot-dpd-desc{margin-bottom:10px}#onetrust-banner-sdk .ot-dpd-desc>.ot-b-addl-desc{margin-top:10px;margin-bottom:10px;font-size:1em}@media only screen and (max-width: 425px){#onetrust-banner-sdk #onetrust-close-btn-container{position:absolute;top:6px;right:2px}#onetrust-banner-sdk #onetrust-policy{margin-left:0;margin-top:3em}#onetrust-banner-sdk #onetrust-button-group{display:block}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{width:100%}#onetrust-banner-sdk .onetrust-close-btn-ui{top:auto;transform:none}#onetrust-banner-sdk #onetrust-policy-title{display:inline;float:none}#onetrust-banner-sdk #banner-options{margin:0;padding:0;width:100%}}@media only screen and (min-width: 426px)and (max-width: 896px){#onetrust-banner-sdk #onetrust-close-btn-container{position:absolute;top:0;right:0}#onetrust-banner-sdk #onetrust-policy{margin-left:1em;margin-right:1em}#onetrust-banner-sdk .onetrust-close-btn-ui{top:10px;right:10px}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:95%}#onetrust-banner-sdk.ot-iab-2 #onetrust-group-container{width:100%}#onetrust-banner-sdk.ot-bnr-w-logo #onetrust-button-group-parent{padding-left:50px}#onetrust-banner-sdk #onetrust-button-group-parent{width:100%;position:relative;margin-left:0}#onetrust-banner-sdk #onetrust-button-group button{display:inline-block}#onetrust-banner-sdk #onetrust-button-group{margin-right:0;text-align:center}#onetrust-banner-sdk .has-reject-all-button #onetrust-pc-btn-handler{float:left}#onetrust-banner-sdk .has-reject-all-button #onetrust-reject-all-handler,#onetrust-banner-sdk .has-reject-all-button #onetrust-accept-btn-handler{float:right}#onetrust-banner-sdk .has-reject-all-button #onetrust-button-group{width:calc(100% - 2em);margin-right:0}#onetrust-banner-sdk .has-reject-all-button #onetrust-pc-btn-handler.cookie-setting-link{padding-left:0px;text-align:left}#onetrust-banner-sdk.ot-buttons-fw .ot-sdk-three button{width:100%;text-align:center}#onetrust-banner-sdk.ot-buttons-fw #onetrust-button-group-parent button{float:none}#onetrust-banner-sdk.ot-buttons-fw #onetrust-pc-btn-handler.cookie-setting-link{text-align:center}}@media only screen and (min-width: 550px){#onetrust-banner-sdk .banner-option:not(:first-child){border-left:1px solid #d8d8d8;padding-left:25px}}@media only screen and (min-width: 425px)and (max-width: 550px){#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group,#onetrust-banner-sdk.ot-iab-2 #onetrust-policy,#onetrust-banner-sdk.ot-iab-2 .banner-option{width:100%}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-accept-btn-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-reject-all-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-pc-btn-handler{width:100%}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-accept-btn-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-reject-all-handler{float:left}}@media only screen and (min-width: 769px){#onetrust-banner-sdk #onetrust-button-group{margin-right:30%}#onetrust-banner-sdk #banner-options{margin-left:2em;margin-right:5em;margin-bottom:1.25em;width:calc(100% - 7em)}}@media only screen and (min-width: 897px)and (max-width: 1023px){#onetrust-banner-sdk.vertical-align-content #onetrust-button-group-parent{position:absolute;top:50%;left:75%;transform:translateY(-50%)}#onetrust-banner-sdk #onetrust-close-btn-container{top:50%;margin:auto;transform:translate(-50%, -50%);position:absolute;padding:0;right:0}#onetrust-banner-sdk #onetrust-close-btn-container button{position:relative;margin:0;right:-22px;top:2px}}@media only screen and (min-width: 1024px){#onetrust-banner-sdk #onetrust-close-btn-container{top:50%;margin:auto;transform:translate(-50%, -50%);position:absolute;right:0}#onetrust-banner-sdk #onetrust-close-btn-container button{right:-12px}#onetrust-banner-sdk #onetrust-policy{margin-left:2em}#onetrust-banner-sdk.vertical-align-content #onetrust-button-group-parent{position:absolute;top:50%;left:60%;transform:translateY(-50%)}#onetrust-banner-sdk .ot-optout-signal{width:50%}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-title{width:50%}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text,#onetrust-banner-sdk.ot-iab-2 :not(.ot-dpd-desc)>.ot-b-addl-desc{margin-bottom:1em;width:50%;border-right:1px solid #d8d8d8;padding-right:1rem}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text{margin-bottom:0;padding-bottom:1em}#onetrust-banner-sdk.ot-iab-2 :not(.ot-dpd-desc)>.ot-b-addl-desc{margin-bottom:0;padding-bottom:1em}#onetrust-banner-sdk.ot-iab-2 .ot-dpd-container{width:45%;padding-left:1rem;display:inline-block;float:none}#onetrust-banner-sdk.ot-iab-2 .ot-dpd-title{line-height:1.7}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group-parent{left:auto;right:4%;margin-left:0}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group button{display:block}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:auto;width:30%}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:60%}#onetrust-banner-sdk #onetrust-button-group{margin-right:auto}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{margin-top:1em}}@media only screen and (min-width: 890px){#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group-parent{padding-left:3%;padding-right:4%;margin-left:0}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{margin-right:0;margin-top:1.25em;width:100%}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button{width:100%;margin-bottom:5px;margin-top:5px}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type{margin-bottom:20px}}@media only screen and (min-width: 1280px){#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:55%}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{width:44%;padding-left:2%;padding-right:2%}#onetrust-banner-sdk:not(.ot-iab-2).vertical-align-content #onetrust-button-group-parent{position:absolute;left:55%}}
        #onetrust-consent-sdk #onetrust-banner-sdk {background-color: #FFF;}
            #onetrust-consent-sdk #onetrust-policy-title,
                    #onetrust-consent-sdk #onetrust-policy-text,
                    #onetrust-consent-sdk .ot-b-addl-desc,
                    #onetrust-consent-sdk .ot-dpd-desc,
                    #onetrust-consent-sdk .ot-dpd-title,
                    #onetrust-consent-sdk #onetrust-policy-text *:not(.onetrust-vendors-list-handler),
                    #onetrust-consent-sdk .ot-dpd-desc *:not(.onetrust-vendors-list-handler),
                    #onetrust-consent-sdk #onetrust-banner-sdk #banner-options *,
                    #onetrust-banner-sdk .ot-cat-header,
                    #onetrust-banner-sdk .ot-optout-signal
                    {
                        color: #2E2E2E;
                    }
            #onetrust-consent-sdk #onetrust-banner-sdk .banner-option-details {
                    background-color: #E9E9E9;}
             #onetrust-consent-sdk #onetrust-banner-sdk a[href],
                    #onetrust-consent-sdk #onetrust-banner-sdk a[href] font,
                    #onetrust-consent-sdk #onetrust-banner-sdk .ot-link-btn
                        {
                            color: #007398;
                        }#onetrust-consent-sdk #onetrust-accept-btn-handler,
                         #onetrust-banner-sdk #onetrust-reject-all-handler {
                            background-color: #007398;border-color: #007398;
                color: #FFF;
            }
            #onetrust-consent-sdk #onetrust-banner-sdk *:focus,
            #onetrust-consent-sdk #onetrust-banner-sdk:focus {
               outline-color: #000000;
               outline-width: 1px;
            }
            #onetrust-consent-sdk #onetrust-pc-btn-handler,
            #onetrust-consent-sdk #onetrust-pc-btn-handler.cookie-setting-link {
                color: #6CC04A; border-color: #6CC04A;
                background-color:
                #FFF;
            }/*! Extra code to blur out background */
.onetrust-pc-dark-filter{
background:rgba(0,0,0,.5);
z-index:2147483646;
width:100%;
height:100%;
overflow:hidden;
position:fixed;
top:0;
bottom:0;
left:0;
backdrop-filter: initial
}

/*! v6.12.0 2021-01-19 */
div#onetrust-consent-sdk #onetrust-banner-sdk{border-top:2px solid #eb6500!important;outline:1px solid transparent;box-shadow:none;padding:24px}div#onetrust-consent-sdk button{border-radius:0!important;box-shadow:none!important;box-sizing:border-box!important;font-size:20px!important;font-weight:400!important;letter-spacing:0!important;max-width:none!important;white-space:nowrap!important}div#onetrust-consent-sdk button:not(.ot-link-btn){background-color:#007398!important;border:2px solid #007398!important;color:#fff!important;height:48px!important;padding:0 1em!important;width:auto!important}div#onetrust-consent-sdk button:hover{background-color:#fff!important;border-color:#eb6500!important;color:#2e2e2e!important}div#onetrust-consent-sdk button.ot-link-btn{color:#007398!important;font-size:16px!important;text-decoration:underline}div#onetrust-consent-sdk button.ot-link-btn:hover{color: #2e2e2e!important;text-decoration-color:#eb6500!important}div#onetrust-consent-sdk a,div#onetrust-pc-sdk a{color:#007398!important;text-decoration:underline!important}div#onetrust-consent-sdk a,div#onetrust-consent-sdk button,div#onetrust-consent-sdk p:hover{opacity:1!important}div#onetrust-consent-sdk a:focus,div#onetrust-consent-sdk button:focus,div#onetrust-consent-sdk input:focus{outline:2px solid #eb6500!important;outline-offset:1px!important}div#onetrust-banner-sdk .ot-sdk-container{padding:0;width:auto}div#onetrust-banner-sdk .ot-sdk-row{align-items:flex-start;box-sizing:border-box;display:flex;flex-direction:column;justify-content:space-between;margin:auto;max-width:1152px}div#onetrust-banner-sdk .ot-sdk-row:after{display:none}div#onetrust-banner-sdk #onetrust-group-container,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-group-container,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{flex-grow:1;width:auto}div#onetrust-banner-sdk #onetrust-policy,div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy{margin:0;overflow:visible}div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy-text,div#onetrust-consent-sdk #onetrust-policy-text{font-size:16px;line-height:24px;max-width:44em;margin:0}div#onetrust-consent-sdk #onetrust-policy-text a[href]{font-weight:400;margin-left:8px}div#onetrust-banner-sdk #onetrust-button-group-parent{flex:0 0 auto;margin:32px 0 0;width:100%}div#onetrust-banner-sdk #onetrust-button-group{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;margin:-8px}div#onetrust-banner-sdk .banner-actions-container{display:flex;flex:1 0 auto}div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type,div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto;margin:8px;width:auto}div#onetrust-consent-sdk #onetrust-pc-btn-handler{background-color:#fff!important;color:#2e2e2e!important}div#onetrust-banner-sdk #onetrust-close-btn-container{display:none}@media only screen and (min-width:556px){div#onetrust-consent-sdk #onetrust-banner-sdk{padding:40px}div#onetrust-banner-sdk #onetrust-policy{margin:0 40px 0 0}div#onetrust-banner-sdk .ot-sdk-row{align-items:center;flex-direction:row}div#onetrust-banner-sdk #onetrust-button-group-parent,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-button-group-parent,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:0;padding:0;width:auto}div#onetrust-banner-sdk #onetrust-button-group,div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{align-items:stretch;flex-direction:column-reverse;margin:0}div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto}}@media only screen and (min-width:768px){div#onetrust-banner-sdk #onetrust-policy{margin:0 48px 0 0}div#onetrust-consent-sdk #onetrust-banner-sdk{padding:48px}}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-size:16px;line-height:24px}div#onetrust-consent-sdk #onetrust-pc-sdk p,div#onetrust-pc-sdk #ot-pc-desc,div#onetrust-pc-sdk .category-host-list-handler,div#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{font-size:16px;font-weight:400;line-height:24px}div#onetrust-consent-sdk a:hover,div#onetrust-pc-sdk a:hover{color:#2e2e2e!important;text-decoration-color:#eb6500!important}div#onetrust-pc-sdk{border-radius:0;bottom:0;height:auto;left:0;margin:auto;max-width:100%;overflow:hidden;right:0;top:0;width:512px;max-height:800px}div#onetrust-pc-sdk .ot-pc-header{display:none}div#onetrust-pc-sdk #ot-pc-content{overscroll-behavior:contain;padding:0 12px 0 24px;margin:16px 4px 0 0;top:0;right:16px;left:0;width:auto}div#onetrust-pc-sdk #ot-category-title,div#onetrust-pc-sdk #ot-pc-title{font-size:24px;font-weight:400;line-height:32px;margin:0 0 16px}div#onetrust-pc-sdk #ot-pc-desc{padding:0}div#onetrust-pc-sdk #ot-pc-desc a{display:inline}div#onetrust-pc-sdk #accept-recommended-btn-handler{display:none!important}div#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:2px solid #eb6500;outline-offset:-1px;transition:none}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{border-width:0 0 2px}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{border-width:2px 0}div#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding:8px 0;width:100%}div#onetrust-pc-sdk .ot-plus-minus{transform:translateY(2px)}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item>button{background:0 0!important;border:0!important;height:44px!important;max-width:none!important;width:calc(100% - 48px)!important}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-weight:700}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding:0}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item .ot-acc-grpdesc{padding:0;width:100%}div#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border:0;padding:0}div#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp{margin:0}div#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:calc(100% - 160px)}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{width:calc(100% - 88px)}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{color:#2e2e2e;font-size:12px;font-weight:400;line-height:1.5;padding-right:48px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:before{border-radius:12px;position:absolute;right:0;top:0;content:'';background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:after{border-radius:50%;position:absolute;right:5px;top:4px;content:'';background-color:#eb6500;height:12px;width:12px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active,div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl{right:2px}div#onetrust-pc-sdk .ot-switch{display:block;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob,div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob:before{background-color:#737373;height:8px;left:4px;top:4px;width:8px}div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{background-color:#eb6500;height:12px;left:0;top:2px;width:12px}div#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch .ot-switch-nob{box-shadow:0 0;outline:2px solid #eb6500!important;outline-offset:1px;transition:none}div#onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt{background-color:transparent;padding-left:3px}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr,div#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr{overflow:visible;width:100%}div#onetrust-pc-sdk .ot-pc-footer{border-top:0 solid}div#onetrust-pc-sdk .ot-btn-container{padding-top:24px;text-align:center}div#onetrust-pc-sdk .ot-pc-footer button{margin:8px 0;background-color:#fff}div#onetrust-pc-sdk .ot-pc-footer-logo{background-color:#fff}div#onetrust-pc-sdk #ot-lst-title span{font-size:24px;font-weight:400;line-height:32px}div#onetrust-pc-sdk #ot-host-lst .ot-host-desc,div#onetrust-pc-sdk #ot-host-lst .ot-host-expand,div#onetrust-pc-sdk #ot-host-lst .ot-host-name,div#onetrust-pc-sdk #ot-host-lst .ot-host-name a,div#onetrust-pc-sdk .back-btn-handler,div#onetrust-pc-sdk .ot-host-opt li>div div{font-size:16px;font-weight:400;line-height:24px}div#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{width:100%}div#onetrust-pc-sdk #ot-pc-lst{top:0}div#onetrust-pc-sdk .back-btn-handler{text-decoration:none!important}div#onetrust-pc-sdk #filter-btn-handler:hover svg{filter:invert(1)}div#onetrust-pc-sdk .back-btn-handler svg{width:16px;height:16px}div#onetrust-pc-sdk .ot-host-item>button{background:0 0!important;border:0!important;height:66px!important;max-width:none!important;width:calc(100% - 5px)!important;transform:translate(2px,2px)}div#onetrust-pc-sdk .ot-host-item{border-bottom:2px solid #b9b9b9;padding:0}div#onetrust-pc-sdk .ot-host-item .ot-acc-hdr{margin:0 0 -6px;padding:8px 0}div#onetrust-pc-sdk ul li:first-child{border-top:2px solid #b9b9b9}div#onetrust-pc-sdk .ot-host-item .ot-plus-minus{margin:0 8px 0 0}div#onetrust-pc-sdk .ot-search-cntr{width:calc(100% - 48px)}div#onetrust-pc-sdk .ot-host-opt .ot-host-info{background-color:transparent}div#onetrust-pc-sdk .ot-host-opt li>div div{padding:0}div#onetrust-pc-sdk #vendor-search-handler{border-radius:0;border-color:#939393;border-style:solid;border-width:2px 0 2px 2px;font-size:20px;height:48px;margin:0}div#onetrust-pc-sdk #ot-pc-hdr{margin-left:24px}div#onetrust-pc-sdk .ot-lst-subhdr{width:calc(100% - 24px)}div#onetrust-pc-sdk .ot-lst-subhdr svg{right:0;top:8px}div#onetrust-pc-sdk .ot-fltr-cntr{box-sizing:border-box;right:0;width:48px}div#onetrust-pc-sdk #filter-btn-handler{width:48px!important;padding:8px!important}div#onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,div#onetrust-pc-sdk button#filter-apply-handler,div#onetrust-pc-sdk button#filter-cancel-handler{height:2em!important;padding-left:14px!important;padding-right:14px!important}div#onetrust-pc-sdk #ot-fltr-cnt{box-shadow:0 0;border:1px solid #8e8e8e;border-radius:0}div#onetrust-pc-sdk .ot-fltr-scrlcnt{max-height:calc(100% - 80px)}div#onetrust-pc-sdk #ot-fltr-modal{max-height:400px}div#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:16px}div#onetrust-pc-sdk #ot-lst-cnt{margin-left:24px;width:calc(100% - 48px)}div#onetrust-pc-sdk #ot-anchor{display:none!important}

/* 2023-12-04  Fix for button order in mobile view*/
@media (max-width: 550px) {
  #onetrust-accept-btn-handler {order: 1;  }
  #onetrust-reject-all-handler { order: 2;  }
  #onetrust-pc-btn-handler { order: 3;  }
}


/*! Extra code to blur our background */
.onetrust-pc-dark-filter{
backdrop-filter: blur(3px)
}
#onetrust-pc-sdk.otPcCenter{overflow:hidden;position:fixed;margin:0 auto;top:5%;right:0;left:0;width:40%;max-width:575px;min-width:575px;border-radius:2.5px;z-index:2147483647;background-color:#fff;-webkit-box-shadow:0px 2px 10px -3px #999;-moz-box-shadow:0px 2px 10px -3px #999;box-shadow:0px 2px 10px -3px #999}#onetrust-pc-sdk.otPcCenter[dir=rtl]{right:0;left:0}#onetrust-pc-sdk.otRelFont{font-size:1rem}#onetrust-pc-sdk .ot-optout-signal{margin-top:.625rem}#onetrust-pc-sdk #ot-addtl-venlst .ot-arw-cntr,#onetrust-pc-sdk #ot-addtl-venlst .ot-plus-minus,#onetrust-pc-sdk .ot-hide-tgl{visibility:hidden}#onetrust-pc-sdk #ot-addtl-venlst .ot-arw-cntr *,#onetrust-pc-sdk #ot-addtl-venlst .ot-plus-minus *,#onetrust-pc-sdk .ot-hide-tgl *{visibility:hidden}#onetrust-pc-sdk #ot-gn-venlst .ot-ven-item .ot-acc-hdr{min-height:40px}#onetrust-pc-sdk .ot-pc-header{height:39px;padding:10px 0 10px 30px;border-bottom:1px solid #e9e9e9}#onetrust-pc-sdk #ot-pc-title,#onetrust-pc-sdk #ot-category-title,#onetrust-pc-sdk .ot-cat-header,#onetrust-pc-sdk #ot-lst-title,#onetrust-pc-sdk .ot-ven-hdr .ot-ven-name,#onetrust-pc-sdk .ot-always-active{font-weight:bold;color:dimgray}#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:55%;font-weight:700}#onetrust-pc-sdk .ot-cat-item p{clear:both;float:left;margin-top:10px;margin-bottom:5px;line-height:1.5;font-size:.812em;color:dimgray}#onetrust-pc-sdk .ot-close-icon{height:44px;width:44px;background-size:10px}#onetrust-pc-sdk #ot-pc-title{float:left;font-size:1em;line-height:1.5;margin-bottom:10px;margin-top:10px;width:100%}#onetrust-pc-sdk #accept-recommended-btn-handler{margin-right:10px;margin-bottom:25px;outline-offset:-1px}#onetrust-pc-sdk #ot-pc-desc{clear:both;width:100%;font-size:.812em;line-height:1.5;margin-bottom:25px}#onetrust-pc-sdk #ot-pc-desc a{margin-left:5px}#onetrust-pc-sdk #ot-pc-desc *{font-size:inherit;line-height:inherit}#onetrust-pc-sdk #ot-pc-desc ul li{padding:10px 0px}#onetrust-pc-sdk a{color:#656565;cursor:pointer}#onetrust-pc-sdk a:hover{color:#3860be}#onetrust-pc-sdk label{margin-bottom:0}#onetrust-pc-sdk #vdr-lst-dsc{font-size:.812em;line-height:1.5;padding:10px 15px 5px 15px}#onetrust-pc-sdk button{max-width:394px;padding:12px 30px;line-height:1;word-break:break-word;word-wrap:break-word;white-space:normal;font-weight:bold;height:auto}#onetrust-pc-sdk .ot-link-btn{padding:0;margin-bottom:0;border:0;font-weight:normal;line-height:normal;width:auto;height:auto}#onetrust-pc-sdk #ot-pc-content{position:absolute;overflow-y:scroll;padding-left:0px;padding-right:30px;top:60px;bottom:110px;margin:1px 3px 0 30px;width:calc(100% - 63px)}#onetrust-pc-sdk .ot-vs-list .ot-always-active,#onetrust-pc-sdk .ot-cat-grp .ot-always-active{float:right;clear:none;color:#3860be;margin:0;font-size:.813em;line-height:1.3}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar-track{margin-right:20px}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar{width:11px}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar-thumb{border-radius:10px;background:#d8d8d8}#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:#000 1px solid}#onetrust-pc-sdk .ot-pc-scrollbar{scrollbar-arrow-color:#d8d8d8;scrollbar-darkshadow-color:#d8d8d8;scrollbar-face-color:#d8d8d8;scrollbar-shadow-color:#d8d8d8}#onetrust-pc-sdk .save-preference-btn-handler{margin-right:20px}#onetrust-pc-sdk .ot-pc-refuse-all-handler{margin-right:10px}#onetrust-pc-sdk #ot-pc-desc .privacy-notice-link{margin-left:0;margin-right:8px}#onetrust-pc-sdk #ot-pc-desc .ot-imprint-handler{margin-left:0;margin-right:8px}#onetrust-pc-sdk .ot-subgrp-cntr{display:inline-block;clear:both;width:100%;padding-top:15px}#onetrust-pc-sdk .ot-switch+.ot-subgrp-cntr{padding-top:10px}#onetrust-pc-sdk ul.ot-subgrps{margin:0;font-size:initial}#onetrust-pc-sdk ul.ot-subgrps li p,#onetrust-pc-sdk ul.ot-subgrps li h5{font-size:.813em;line-height:1.4;color:dimgray}#onetrust-pc-sdk ul.ot-subgrps .ot-switch{min-height:auto}#onetrust-pc-sdk ul.ot-subgrps .ot-switch-nob{top:0}#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr{display:inline-block;width:100%}#onetrust-pc-sdk ul.ot-subgrps .ot-acc-txt{margin:0}#onetrust-pc-sdk ul.ot-subgrps li{padding:0;border:none}#onetrust-pc-sdk ul.ot-subgrps li h5{position:relative;top:5px;font-weight:bold;margin-bottom:0;float:left}#onetrust-pc-sdk li.ot-subgrp{margin-left:20px;overflow:auto}#onetrust-pc-sdk li.ot-subgrp>h5{width:calc(100% - 100px)}#onetrust-pc-sdk .ot-cat-item p>ul,#onetrust-pc-sdk li.ot-subgrp p>ul{margin:0px;list-style:disc;margin-left:15px;font-size:inherit}#onetrust-pc-sdk .ot-cat-item p>ul li,#onetrust-pc-sdk li.ot-subgrp p>ul li{font-size:inherit;padding-top:10px;padding-left:0px;padding-right:0px;border:none}#onetrust-pc-sdk .ot-cat-item p>ul li:last-child,#onetrust-pc-sdk li.ot-subgrp p>ul li:last-child{padding-bottom:10px}#onetrust-pc-sdk .ot-pc-logo{height:40px;width:120px}#onetrust-pc-sdk .ot-pc-footer{position:absolute;bottom:0px;width:100%;max-height:160px;border-top:1px solid #d8d8d8}#onetrust-pc-sdk.ot-ftr-stacked .ot-pc-refuse-all-handler{margin-bottom:0px}#onetrust-pc-sdk.ot-ftr-stacked #ot-pc-content{bottom:160px}#onetrust-pc-sdk.ot-ftr-stacked .ot-pc-footer button{width:100%;max-width:none}#onetrust-pc-sdk.ot-ftr-stacked .ot-btn-container{margin:0 30px;width:calc(100% - 60px);padding-right:0}#onetrust-pc-sdk .ot-pc-footer-logo{height:30px;width:100%;text-align:right;background:#f4f4f4}#onetrust-pc-sdk .ot-pc-footer-logo a{display:inline-block;margin-top:5px;margin-right:10px}#onetrust-pc-sdk[dir=rtl] .ot-pc-footer-logo{direction:rtl}#onetrust-pc-sdk[dir=rtl] .ot-pc-footer-logo a{margin-right:25px}#onetrust-pc-sdk .ot-tgl{float:right;position:relative;z-index:1}#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background-color:#468254;border:1px solid #fff}#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{-webkit-transform:translateX(20px);-ms-transform:translateX(20px);transform:translateX(20px);background-color:#fff;border-color:#fff}#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch{outline:#000 solid 1px}#onetrust-pc-sdk .ot-switch{position:relative;display:inline-block;width:45px;height:25px}#onetrust-pc-sdk .ot-switch-nob{position:absolute;cursor:pointer;top:0;left:0;right:0;bottom:0;background-color:#767676;border:1px solid #ddd;transition:all .2s ease-in 0s;-moz-transition:all .2s ease-in 0s;-o-transition:all .2s ease-in 0s;-webkit-transition:all .2s ease-in 0s;border-radius:20px}#onetrust-pc-sdk .ot-switch-nob:before{position:absolute;content:"";height:18px;width:18px;bottom:3px;left:3px;background-color:#fff;-webkit-transition:.4s;transition:.4s;border-radius:20px}#onetrust-pc-sdk .ot-chkbox input:checked~label::before{background-color:#3860be}#onetrust-pc-sdk .ot-chkbox input+label::after{content:none;color:#fff}#onetrust-pc-sdk .ot-chkbox input:checked+label::after{content:""}#onetrust-pc-sdk .ot-chkbox input:focus+label::before{outline-style:solid;outline-width:2px;outline-style:auto}#onetrust-pc-sdk .ot-chkbox label{position:relative;display:inline-block;padding-left:30px;cursor:pointer;font-weight:500}#onetrust-pc-sdk .ot-chkbox label::before,#onetrust-pc-sdk .ot-chkbox label::after{position:absolute;content:"";display:inline-block;border-radius:3px}#onetrust-pc-sdk .ot-chkbox label::before{height:18px;width:18px;border:1px solid #3860be;left:0px;top:auto}#onetrust-pc-sdk .ot-chkbox label::after{height:5px;width:9px;border-left:3px solid;border-bottom:3px solid;transform:rotate(-45deg);-o-transform:rotate(-45deg);-ms-transform:rotate(-45deg);-webkit-transform:rotate(-45deg);left:4px;top:5px}#onetrust-pc-sdk .ot-label-txt{display:none}#onetrust-pc-sdk .ot-chkbox input,#onetrust-pc-sdk .ot-tgl input{position:absolute;opacity:0;width:0;height:0}#onetrust-pc-sdk .ot-arw-cntr{float:right;position:relative;pointer-events:none}#onetrust-pc-sdk .ot-arw-cntr .ot-arw{width:16px;height:16px;margin-left:5px;color:dimgray;display:inline-block;vertical-align:middle;-webkit-transition:all 150ms ease-in 0s;-moz-transition:all 150ms ease-in 0s;-o-transition:all 150ms ease-in 0s;transition:all 150ms ease-in 0s}#onetrust-pc-sdk input:checked~.ot-acc-hdr .ot-arw,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-arw-cntr svg{transform:rotate(90deg);-o-transform:rotate(90deg);-ms-transform:rotate(90deg);-webkit-transform:rotate(90deg)}#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:#000 1px solid}#onetrust-pc-sdk .ot-tgl-cntr,#onetrust-pc-sdk .ot-arw-cntr{display:inline-block}#onetrust-pc-sdk .ot-tgl-cntr{width:45px;float:right;margin-top:2px}#onetrust-pc-sdk #ot-lst-cnt .ot-tgl-cntr{margin-top:10px}#onetrust-pc-sdk .ot-always-active-subgroup{width:auto;padding-left:0px !important;top:3px;position:relative}#onetrust-pc-sdk .ot-label-status{padding-left:5px;font-size:.75em;display:none}#onetrust-pc-sdk .ot-arw-cntr{margin-top:-1px}#onetrust-pc-sdk .ot-arw-cntr svg{-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s;transition:all 300ms ease-in 0s;height:10px;width:10px}#onetrust-pc-sdk input:checked~.ot-acc-hdr .ot-arw{transform:rotate(90deg);-o-transform:rotate(90deg);-ms-transform:rotate(90deg);-webkit-transform:rotate(90deg)}#onetrust-pc-sdk .ot-arw{width:10px;margin-left:15px;transition:all 300ms ease-in 0s;-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s}#onetrust-pc-sdk .ot-vlst-cntr{margin-bottom:0}#onetrust-pc-sdk .ot-hlst-cntr{margin-top:5px;display:inline-block;width:100%}#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a,#onetrust-pc-sdk .category-host-list-handler{clear:both;color:#3860be;margin-left:0;font-size:.813em;text-decoration:none;float:left;overflow:hidden}#onetrust-pc-sdk .category-vendors-list-handler:hover,#onetrust-pc-sdk .category-vendors-list-handler+a:hover,#onetrust-pc-sdk .category-host-list-handler:hover{text-decoration-line:underline}#onetrust-pc-sdk .category-vendors-list-handler+a{clear:none}#onetrust-pc-sdk .ot-vlst-cntr .ot-ext-lnk,#onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{display:inline-block;height:13px;width:13px;background-repeat:no-repeat;margin-left:1px;margin-top:6px;cursor:pointer}#onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{margin-bottom:-1px}#onetrust-pc-sdk .back-btn-handler{font-size:1em;text-decoration:none}#onetrust-pc-sdk .back-btn-handler:hover{opacity:.6}#onetrust-pc-sdk #ot-lst-title h3{display:inline-block;word-break:break-word;word-wrap:break-word;margin-bottom:0;color:#656565;font-size:1em;font-weight:bold;margin-left:15px}#onetrust-pc-sdk #ot-lst-title{margin:10px 0 10px 0px;font-size:1em;text-align:left}#onetrust-pc-sdk #ot-pc-hdr{margin:0 0 0 30px;height:auto;width:auto}#onetrust-pc-sdk #ot-pc-hdr input::placeholder{color:#d4d4d4;font-style:italic}#onetrust-pc-sdk #vendor-search-handler{height:31px;width:100%;border-radius:50px;font-size:.8em;padding-right:35px;padding-left:15px;float:left;margin-left:15px}#onetrust-pc-sdk .ot-ven-name{display:block;width:auto;padding-right:5px}#onetrust-pc-sdk #ot-lst-cnt{overflow-y:auto;margin-left:20px;margin-right:7px;width:calc(100% - 27px);max-height:calc(100% - 80px);height:100%;transform:translate3d(0, 0, 0)}#onetrust-pc-sdk #ot-pc-lst{width:100%;bottom:100px;position:absolute;top:60px}#onetrust-pc-sdk #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr .ot-arw-cntr,#onetrust-pc-sdk #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr .ot-arw-cntr *{visibility:hidden}#onetrust-pc-sdk #ot-pc-lst .ot-tgl-cntr{right:12px;position:absolute}#onetrust-pc-sdk #ot-pc-lst .ot-arw-cntr{float:right;position:relative}#onetrust-pc-sdk #ot-pc-lst .ot-arw{margin-left:10px}#onetrust-pc-sdk #ot-pc-lst .ot-acc-hdr{overflow:hidden;cursor:pointer}#onetrust-pc-sdk .ot-vlst-cntr{overflow:hidden}#onetrust-pc-sdk #ot-sel-blk{overflow:hidden;width:100%;position:sticky;position:-webkit-sticky;top:0;z-index:3}#onetrust-pc-sdk #ot-back-arw{height:12px;width:12px}#onetrust-pc-sdk .ot-lst-subhdr{width:100%;display:inline-block}#onetrust-pc-sdk .ot-search-cntr{float:left;width:78%;position:relative}#onetrust-pc-sdk .ot-search-cntr>svg{width:30px;height:30px;position:absolute;float:left;right:-15px}#onetrust-pc-sdk .ot-fltr-cntr{float:right;right:50px;position:relative}#onetrust-pc-sdk #filter-btn-handler{background-color:#3860be;border-radius:17px;display:inline-block;position:relative;width:32px;height:32px;-moz-transition:.1s ease;-o-transition:.1s ease;-webkit-transition:1s ease;transition:.1s ease;padding:0;margin:0}#onetrust-pc-sdk #filter-btn-handler:hover{background-color:#3860be}#onetrust-pc-sdk #filter-btn-handler svg{width:12px;height:12px;margin:3px 10px 0 10px;display:block;position:static;right:auto;top:auto}#onetrust-pc-sdk .ot-ven-link,#onetrust-pc-sdk .ot-ven-legclaim-link{color:#3860be;text-decoration:none;font-weight:100;display:inline-block;padding-top:10px;transform:translate(0, 1%);-o-transform:translate(0, 1%);-ms-transform:translate(0, 1%);-webkit-transform:translate(0, 1%);position:relative;z-index:2}#onetrust-pc-sdk .ot-ven-link *,#onetrust-pc-sdk .ot-ven-legclaim-link *{font-size:inherit}#onetrust-pc-sdk .ot-ven-link:hover,#onetrust-pc-sdk .ot-ven-legclaim-link:hover{text-decoration:underline}#onetrust-pc-sdk .ot-ven-hdr{width:calc(100% - 160px);height:auto;float:left;word-break:break-word;word-wrap:break-word;vertical-align:middle;padding-bottom:3px}#onetrust-pc-sdk .ot-ven-link,#onetrust-pc-sdk .ot-ven-legclaim-link{letter-spacing:.03em;font-size:.75em;font-weight:400}#onetrust-pc-sdk .ot-ven-dets{border-radius:2px;background-color:#f8f8f8}#onetrust-pc-sdk .ot-ven-dets li:first-child p:first-child{border-top:none}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:not(:first-child){border-top:1px solid #ddd !important}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p{display:inline-block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p:nth-of-type(odd){width:30%}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p:nth-of-type(even){width:50%;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p,#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc h4{padding-top:5px;padding-bottom:5px;display:block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc h4{display:inline-block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p:nth-last-child(-n+1){padding-bottom:10px}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p:nth-child(-n+2):not(.disc-pur){padding-top:10px}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur-cont{display:inline}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur{position:relative;width:50% !important;word-break:break-word;word-wrap:break-word;left:calc(30% + 17px)}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur:nth-child(-n+1){position:static}#onetrust-pc-sdk .ot-ven-dets p,#onetrust-pc-sdk .ot-ven-dets h4,#onetrust-pc-sdk .ot-ven-dets span{font-size:.69em;text-align:left;vertical-align:middle;word-break:break-word;word-wrap:break-word;margin:0;padding-bottom:10px;padding-left:15px;color:#2e3644}#onetrust-pc-sdk .ot-ven-dets h4{padding-top:5px}#onetrust-pc-sdk .ot-ven-dets span{color:dimgray;padding:0;vertical-align:baseline}#onetrust-pc-sdk .ot-ven-dets .ot-ven-pur h4{border-top:1px solid #e9e9e9;border-bottom:1px solid #e9e9e9;padding-bottom:5px;margin-bottom:5px;font-weight:bold}#onetrust-pc-sdk #ot-host-lst .ot-sel-all{float:right;position:relative;margin-right:42px;top:10px}#onetrust-pc-sdk #ot-host-lst .ot-sel-all input[type=checkbox]{width:auto;height:auto}#onetrust-pc-sdk #ot-host-lst .ot-sel-all label{height:20px;width:20px;padding-left:0px}#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{overflow:hidden;width:95%}#onetrust-pc-sdk .ot-host-hdr{position:relative;z-index:1;pointer-events:none;width:calc(100% - 125px);float:left}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-desc{display:inline-block;width:90%}#onetrust-pc-sdk .ot-host-name{pointer-events:none}#onetrust-pc-sdk .ot-host-hdr>a{text-decoration:underline;font-size:.82em;position:relative;z-index:2;float:left;margin-bottom:5px;pointer-events:initial}#onetrust-pc-sdk .ot-host-name+a{margin-top:5px}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-name a,#onetrust-pc-sdk .ot-host-desc,#onetrust-pc-sdk .ot-host-info{color:dimgray;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-name a{font-weight:bold;font-size:.82em;line-height:1.3}#onetrust-pc-sdk .ot-host-name a{font-size:1em}#onetrust-pc-sdk .ot-host-expand{margin-top:3px;margin-bottom:3px;clear:both;display:block;color:#3860be;font-size:.72em;font-weight:normal}#onetrust-pc-sdk .ot-host-expand *{font-size:inherit}#onetrust-pc-sdk .ot-host-desc,#onetrust-pc-sdk .ot-host-info{font-size:.688em;line-height:1.4;font-weight:normal}#onetrust-pc-sdk .ot-host-desc{margin-top:10px}#onetrust-pc-sdk .ot-host-opt{margin:0;font-size:inherit;display:inline-block;width:100%}#onetrust-pc-sdk .ot-host-opt li>div div{font-size:.8em;padding:5px 0}#onetrust-pc-sdk .ot-host-opt li>div div:nth-child(1){width:30%;float:left}#onetrust-pc-sdk .ot-host-opt li>div div:nth-child(2){width:70%;float:left;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-host-info{border:none;display:inline-block;width:calc(100% - 10px);padding:10px;margin-bottom:10px;background-color:#f8f8f8}#onetrust-pc-sdk .ot-host-info>div{overflow:auto}#onetrust-pc-sdk #no-results{text-align:center;margin-top:30px}#onetrust-pc-sdk #no-results p{font-size:1em;color:#2e3644;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk #no-results p span{font-weight:bold}#onetrust-pc-sdk #ot-fltr-modal{width:100%;height:auto;display:none;-moz-transition:.2s ease;-o-transition:.2s ease;-webkit-transition:2s ease;transition:.2s ease;overflow:hidden;opacity:1;right:0}#onetrust-pc-sdk #ot-fltr-modal .ot-label-txt{display:inline-block;font-size:.85em;color:dimgray}#onetrust-pc-sdk #ot-fltr-cnt{z-index:2147483646;background-color:#fff;position:absolute;height:90%;max-height:300px;width:325px;left:210px;margin-top:10px;margin-bottom:20px;padding-right:10px;border-radius:3px;-webkit-box-shadow:0px 0px 12px 2px #c7c5c7;-moz-box-shadow:0px 0px 12px 2px #c7c5c7;box-shadow:0px 0px 12px 2px #c7c5c7}#onetrust-pc-sdk .ot-fltr-scrlcnt{overflow-y:auto;overflow-x:hidden;clear:both;max-height:calc(100% - 60px)}#onetrust-pc-sdk #ot-anchor{border:12px solid rgba(0,0,0,0);display:none;position:absolute;z-index:2147483647;right:55px;top:75px;transform:rotate(45deg);-o-transform:rotate(45deg);-ms-transform:rotate(45deg);-webkit-transform:rotate(45deg);background-color:#fff;-webkit-box-shadow:-3px -3px 5px -2px #c7c5c7;-moz-box-shadow:-3px -3px 5px -2px #c7c5c7;box-shadow:-3px -3px 5px -2px #c7c5c7}#onetrust-pc-sdk .ot-fltr-btns{margin-left:15px}#onetrust-pc-sdk #filter-apply-handler{margin-right:15px}#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:25px;margin-left:15px;width:75%;position:relative}#onetrust-pc-sdk .ot-fltr-opt p{display:inline-block;margin:0;font-size:.9em;color:#2e3644}#onetrust-pc-sdk .ot-chkbox label span{font-size:.85em;color:dimgray}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]+label::after{content:none;color:#fff}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]:checked+label::after{content:""}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]:focus+label::before{outline-style:solid;outline-width:2px;outline-style:auto}#onetrust-pc-sdk #ot-selall-vencntr,#onetrust-pc-sdk #ot-selall-adtlvencntr,#onetrust-pc-sdk #ot-selall-hostcntr,#onetrust-pc-sdk #ot-selall-licntr,#onetrust-pc-sdk #ot-selall-gnvencntr{right:15px;position:relative;width:20px;height:20px;float:right}#onetrust-pc-sdk #ot-selall-vencntr label,#onetrust-pc-sdk #ot-selall-adtlvencntr label,#onetrust-pc-sdk #ot-selall-hostcntr label,#onetrust-pc-sdk #ot-selall-licntr label,#onetrust-pc-sdk #ot-selall-gnvencntr label{float:left;padding-left:0}#onetrust-pc-sdk #ot-ven-lst:first-child{border-top:1px solid #e2e2e2}#onetrust-pc-sdk ul{list-style:none;padding:0}#onetrust-pc-sdk ul li{position:relative;margin:0;padding:15px 15px 15px 10px;border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk ul li h3{font-size:.75em;color:#656565;margin:0;display:inline-block;width:70%;height:auto;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk ul li p{margin:0;font-size:.7em}#onetrust-pc-sdk ul li input[type=checkbox]{position:absolute;cursor:pointer;width:100%;height:100%;opacity:0;margin:0;top:0;left:0}#onetrust-pc-sdk .ot-cat-item>button:focus,#onetrust-pc-sdk .ot-acc-cntr>button:focus,#onetrust-pc-sdk li>button:focus{outline:#000 solid 2px}#onetrust-pc-sdk .ot-cat-item>button,#onetrust-pc-sdk .ot-acc-cntr>button,#onetrust-pc-sdk li>button{position:absolute;cursor:pointer;width:100%;height:100%;margin:0;top:0;left:0;z-index:1;max-width:none;border:none}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=false]~.ot-acc-txt,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=false]~.ot-acc-txt,#onetrust-pc-sdk li>button[aria-expanded=false]~.ot-acc-txt{margin-top:0;max-height:0;opacity:0;overflow:hidden;width:100%;transition:.25s ease-out;display:none}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=true]~.ot-acc-txt,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=true]~.ot-acc-txt,#onetrust-pc-sdk li>button[aria-expanded=true]~.ot-acc-txt{transition:.1s ease-in;margin-top:10px;width:100%;overflow:auto;display:block}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=true]~.ot-acc-grpcntr,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=true]~.ot-acc-grpcntr,#onetrust-pc-sdk li>button[aria-expanded=true]~.ot-acc-grpcntr{width:auto;margin-top:0px;padding-bottom:10px}#onetrust-pc-sdk .ot-host-item>button:focus,#onetrust-pc-sdk .ot-ven-item>button:focus{outline:0;border:2px solid #000}#onetrust-pc-sdk .ot-hide-acc>button{pointer-events:none}#onetrust-pc-sdk .ot-hide-acc .ot-plus-minus>*,#onetrust-pc-sdk .ot-hide-acc .ot-arw-cntr>*{visibility:hidden}#onetrust-pc-sdk .ot-hide-acc .ot-acc-hdr{min-height:30px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt){padding-right:10px;width:calc(100% - 37px);margin-top:10px;max-height:calc(100% - 90px)}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk{background-color:#f9f9fc;border:1px solid #e2e2e2;width:calc(100% - 2px);padding-bottom:5px;padding-top:5px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt{border:unset;background-color:unset}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all-hdr{display:none}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all{padding-right:.5rem}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all .ot-chkbox{right:0}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-sel-all{padding-right:34px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-sel-all-chkbox{width:auto}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) ul li{border:1px solid #e2e2e2;margin-bottom:10px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-acc-cntr>.ot-acc-hdr{padding:10px 0 10px 15px}#onetrust-pc-sdk.ot-addtl-vendors .ot-sel-all-chkbox{float:right}#onetrust-pc-sdk.ot-addtl-vendors .ot-plus-minus~.ot-sel-all-chkbox{right:34px}#onetrust-pc-sdk.ot-addtl-vendors #ot-ven-lst:first-child{border-top:none}#onetrust-pc-sdk .ot-acc-cntr{position:relative;border-left:1px solid #e2e2e2;border-right:1px solid #e2e2e2;border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk .ot-acc-cntr input{z-index:1}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr{background-color:#f9f9fc;padding:5px 0 5px 15px;width:auto}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr .ot-plus-minus{vertical-align:middle;top:auto}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr .ot-arw-cntr{right:10px}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr input{z-index:2}#onetrust-pc-sdk .ot-acc-cntr.ot-add-tech .ot-acc-hdr{padding:10px 0 10px 15px}#onetrust-pc-sdk .ot-acc-cntr>input[type=checkbox]:checked~.ot-acc-hdr{border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-txt{padding-left:10px;padding-right:10px}#onetrust-pc-sdk .ot-acc-cntr button[aria-expanded=true]~.ot-acc-txt{width:auto}#onetrust-pc-sdk .ot-acc-cntr .ot-addtl-venbox{display:none}#onetrust-pc-sdk .ot-vlst-cntr{margin-bottom:0;width:100%}#onetrust-pc-sdk .ot-vensec-title{font-size:.813em;vertical-align:middle;display:inline-block}#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a{margin-left:0;margin-top:10px}#onetrust-pc-sdk #ot-selall-vencntr.line-through label::after,#onetrust-pc-sdk #ot-selall-adtlvencntr.line-through label::after,#onetrust-pc-sdk #ot-selall-licntr.line-through label::after,#onetrust-pc-sdk #ot-selall-hostcntr.line-through label::after,#onetrust-pc-sdk #ot-selall-gnvencntr.line-through label::after{height:auto;border-left:0;transform:none;-o-transform:none;-ms-transform:none;-webkit-transform:none;left:5px;top:9px}#onetrust-pc-sdk #ot-category-title{float:left;padding-bottom:10px;font-size:1em;width:100%}#onetrust-pc-sdk .ot-cat-grp{margin-top:10px}#onetrust-pc-sdk .ot-cat-item{line-height:1.1;margin-top:10px;display:inline-block;width:100%}#onetrust-pc-sdk .ot-btn-container{text-align:right}#onetrust-pc-sdk .ot-btn-container button{display:inline-block;font-size:.75em;letter-spacing:.08em;margin-top:19px}#onetrust-pc-sdk #close-pc-btn-handler.ot-close-icon{position:absolute;top:10px;right:0;z-index:1;padding:0;background-color:rgba(0,0,0,0);border:none}#onetrust-pc-sdk #close-pc-btn-handler.ot-close-icon svg{display:block;height:10px;width:10px}#onetrust-pc-sdk #clear-filters-handler{margin-top:20px;margin-bottom:10px;float:right;max-width:200px;text-decoration:none;color:#3860be;font-size:.9em;font-weight:bold;background-color:rgba(0,0,0,0);border-color:rgba(0,0,0,0);padding:1px}#onetrust-pc-sdk #clear-filters-handler:hover{color:#2285f7}#onetrust-pc-sdk #clear-filters-handler:focus{outline:#000 solid 1px}#onetrust-pc-sdk .ot-enbl-chr h4~.ot-tgl,#onetrust-pc-sdk .ot-enbl-chr h4~.ot-always-active{right:45px}#onetrust-pc-sdk .ot-enbl-chr h4~.ot-tgl+.ot-tgl{right:120px}#onetrust-pc-sdk .ot-enbl-chr .ot-pli-hdr.ot-leg-border-color span:first-child{width:90px}#onetrust-pc-sdk .ot-enbl-chr li.ot-subgrp>h5+.ot-tgl-cntr{padding-right:25px}#onetrust-pc-sdk .ot-plus-minus{width:20px;height:20px;font-size:1.5em;position:relative;display:inline-block;margin-right:5px;top:3px}#onetrust-pc-sdk .ot-plus-minus span{position:absolute;background:#27455c;border-radius:1px}#onetrust-pc-sdk .ot-plus-minus span:first-of-type{top:25%;bottom:25%;width:10%;left:45%}#onetrust-pc-sdk .ot-plus-minus span:last-of-type{left:25%;right:25%;height:10%;top:45%}#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-arw,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:first-of-type,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:last-of-type{transform:rotate(90deg)}#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:last-of-type{left:50%;right:50%}#onetrust-pc-sdk #ot-selall-vencntr label,#onetrust-pc-sdk #ot-selall-adtlvencntr label,#onetrust-pc-sdk #ot-selall-hostcntr label,#onetrust-pc-sdk #ot-selall-licntr label{position:relative;display:inline-block;width:20px;height:20px}#onetrust-pc-sdk .ot-host-item .ot-plus-minus,#onetrust-pc-sdk .ot-ven-item .ot-plus-minus{float:left;margin-right:8px;top:10px}#onetrust-pc-sdk .ot-ven-item ul{list-style:none inside;font-size:100%;margin:0}#onetrust-pc-sdk .ot-ven-item ul li{margin:0 !important;padding:0;border:none !important}#onetrust-pc-sdk .ot-pli-hdr{color:#77808e;overflow:hidden;padding-top:7.5px;padding-bottom:7.5px;width:calc(100% - 2px);border-top-left-radius:3px;border-top-right-radius:3px}#onetrust-pc-sdk .ot-pli-hdr span:first-child{top:50%;transform:translateY(50%);max-width:90px}#onetrust-pc-sdk .ot-pli-hdr span:last-child{padding-right:10px;max-width:95px;text-align:center}#onetrust-pc-sdk .ot-li-title{float:right;font-size:.813em}#onetrust-pc-sdk .ot-pli-hdr.ot-leg-border-color{background-color:#f4f4f4;border:1px solid #d8d8d8}#onetrust-pc-sdk .ot-pli-hdr.ot-leg-border-color span:first-child{text-align:left;width:70px}#onetrust-pc-sdk li.ot-subgrp>h5,#onetrust-pc-sdk .ot-cat-header{width:calc(100% - 130px)}#onetrust-pc-sdk li.ot-subgrp>h5+.ot-tgl-cntr{padding-left:13px}#onetrust-pc-sdk .ot-acc-grpcntr .ot-acc-grpdesc{margin-bottom:5px}#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border-top:1px solid #d8d8d8}#onetrust-pc-sdk .ot-acc-grpcntr .ot-vlst-cntr+.ot-subgrp-cntr{border-top:none}#onetrust-pc-sdk .ot-acc-hdr .ot-arw-cntr+.ot-tgl-cntr,#onetrust-pc-sdk .ot-acc-txt h4+.ot-tgl-cntr{padding-left:13px}#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-subgrp>h5,#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-cat-header{width:calc(100% - 145px)}#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item h5+.ot-tgl-cntr,#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-cat-header+.ot-tgl{padding-left:28px}#onetrust-pc-sdk .ot-sel-all-hdr,#onetrust-pc-sdk .ot-sel-all-chkbox{display:inline-block;width:100%;position:relative}#onetrust-pc-sdk .ot-sel-all-chkbox{z-index:1}#onetrust-pc-sdk .ot-sel-all{margin:0;position:relative;padding-right:23px;float:right}#onetrust-pc-sdk .ot-consent-hdr,#onetrust-pc-sdk .ot-li-hdr{float:right;font-size:.812em;line-height:normal;text-align:center;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-li-hdr{max-width:100px;padding-right:10px}#onetrust-pc-sdk .ot-consent-hdr{max-width:55px}#onetrust-pc-sdk #ot-selall-licntr{display:block;width:21px;height:auto;float:right;position:relative;right:80px}#onetrust-pc-sdk #ot-selall-licntr label{position:absolute}#onetrust-pc-sdk .ot-ven-ctgl{margin-left:66px}#onetrust-pc-sdk .ot-ven-litgl+.ot-arw-cntr{margin-left:81px}#onetrust-pc-sdk .ot-enbl-chr .ot-host-cnt .ot-tgl-cntr{width:auto}#onetrust-pc-sdk #ot-lst-cnt:not(.ot-host-cnt) .ot-tgl-cntr{width:auto;top:auto;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-chkbox{position:relative;display:inline-block;width:20px;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-chkbox label{position:absolute;padding:0;width:20px;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 2rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk .ot-acc-grpdesc+.ot-leg-btn-container{padding-left:20px;padding-right:20px;width:calc(100% - 40px);margin-bottom:5px}#onetrust-pc-sdk .ot-subgrp .ot-leg-btn-container{margin-bottom:5px}#onetrust-pc-sdk #ot-ven-lst .ot-leg-btn-container{margin-top:10px}#onetrust-pc-sdk .ot-leg-btn-container{display:inline-block;width:100%;margin-bottom:10px}#onetrust-pc-sdk .ot-leg-btn-container button{height:auto;padding:6.5px 8px;margin-bottom:0;letter-spacing:0;font-size:.75em;line-height:normal}#onetrust-pc-sdk .ot-leg-btn-container svg{display:none;height:14px;width:14px;padding-right:5px;vertical-align:sub}#onetrust-pc-sdk .ot-active-leg-btn{cursor:default;pointer-events:none}#onetrust-pc-sdk .ot-active-leg-btn svg{display:inline-block}#onetrust-pc-sdk .ot-remove-objection-handler{text-decoration:underline;padding:0;font-size:.75em;font-weight:600;line-height:1;padding-left:10px}#onetrust-pc-sdk .ot-obj-leg-btn-handler span{font-weight:bold;text-align:center;font-size:inherit;line-height:1.5}#onetrust-pc-sdk.ot-close-btn-link #close-pc-btn-handler{border:none;height:auto;line-height:1.5;text-decoration:underline;font-size:.69em;background:none;right:15px;top:15px;width:auto;font-weight:normal}#onetrust-pc-sdk .ot-pgph-link{font-size:.813em !important;margin-top:5px;position:relative}#onetrust-pc-sdk .ot-pgph-link.ot-pgph-link-subgroup{margin-bottom:1rem}#onetrust-pc-sdk .ot-pgph-contr{margin:0 2.5rem}#onetrust-pc-sdk .ot-pgph-title{font-size:1.18rem;margin-bottom:2rem}#onetrust-pc-sdk .ot-pgph-desc{font-size:1rem;font-weight:400;margin-bottom:2rem;line-height:1.5rem}#onetrust-pc-sdk .ot-pgph-desc:not(:last-child):after{content:"";width:96%;display:block;margin:0 auto;padding-bottom:2rem;border-bottom:1px solid #e9e9e9}#onetrust-pc-sdk .ot-cat-header{float:left;font-weight:600;font-size:.875em;line-height:1.5;max-width:90%;vertical-align:middle}#onetrust-pc-sdk .ot-vnd-item>button:focus{outline:#000 solid 2px}#onetrust-pc-sdk .ot-vnd-item>button{position:absolute;cursor:pointer;width:100%;height:100%;margin:0;top:0;left:0;z-index:1;max-width:none;border:none}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=false]~.ot-acc-txt{margin-top:0;max-height:0;opacity:0;overflow:hidden;width:100%;transition:.25s ease-out;display:none}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=true]~.ot-acc-txt{transition:.1s ease-in;margin-top:10px;width:100%;overflow:auto;display:block}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=true]~.ot-acc-grpcntr{width:auto;margin-top:0px;padding-bottom:10px}#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{position:relative;border-radius:2px;margin:0;padding:0;border:1px solid #d8d8d8;border-top:none;width:calc(100% - 2px);float:left}#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{margin-top:10px;border-top:1px solid #d8d8d8}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc{padding-left:20px;padding-right:20px;width:calc(100% - 40px);font-size:.812em;margin-bottom:10px;margin-top:15px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc>ul{padding-top:10px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc>ul li{padding-top:0;line-height:1.5;padding-bottom:10px}#onetrust-pc-sdk .ot-accordion-layout div+.ot-acc-grpdesc{margin-top:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr:first-child{margin-top:10px}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr:last-child,#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr:last-child{margin-bottom:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding-top:11.5px;padding-bottom:11.5px;padding-left:20px;padding-right:20px;width:calc(100% - 40px);display:inline-block}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-txt{width:100%;padding:0}#onetrust-pc-sdk .ot-accordion-layout .ot-subgrp-cntr{padding-left:20px;padding-right:15px;padding-bottom:0;width:calc(100% - 35px)}#onetrust-pc-sdk .ot-accordion-layout .ot-subgrp{padding-right:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpcntr{z-index:1;position:relative}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header+.ot-arw-cntr{position:absolute;top:50%;transform:translateY(-50%);right:20px;margin-top:-2px}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header+.ot-arw-cntr .ot-arw{width:15px;height:20px;margin-left:5px;color:dimgray}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{float:none;color:#2e3644;margin:0;display:inline-block;height:auto;word-wrap:break-word;min-height:inherit}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr,#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding-left:20px;width:calc(100% - 20px);display:inline-block;margin-top:0;padding-bottom:2px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{position:relative;min-height:25px}#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl,#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{position:absolute;top:50%;transform:translateY(-50%);right:20px}#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl+.ot-tgl{right:95px}#onetrust-pc-sdk .ot-accordion-layout .category-vendors-list-handler,#onetrust-pc-sdk .ot-accordion-layout .category-vendors-list-handler+a{margin-top:5px}#onetrust-pc-sdk #ot-lst-cnt{margin-top:1rem;max-height:calc(100% - 96px)}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 2rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info{margin-bottom:1rem;padding-left:.75rem;padding-right:.75rem;display:flex;flex-direction:column}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info[data-vnd-info-key*=DPOEmail]{border-top:1px solid #d8d8d8;padding-top:1rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info[data-vnd-info-key*=DPOLink]{border-bottom:1px solid #d8d8d8;padding-bottom:1rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info .ot-vnd-lbl{font-weight:bold;font-size:.85em;margin-bottom:.5rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info .ot-vnd-cnt{margin-left:.5rem;font-weight:500;font-size:.85rem}#onetrust-pc-sdk .ot-vs-list,#onetrust-pc-sdk .ot-vnd-serv{width:auto;padding:1rem 1.25rem;padding-bottom:0}#onetrust-pc-sdk .ot-vs-list .ot-vnd-serv-hdr-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-serv-hdr-cntr{padding-bottom:.75rem;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-vs-list .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-weight:600;font-size:.95em;line-height:2;margin-left:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item{border:none;margin:0;padding:0}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item button,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item button{outline:none;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item button[aria-expanded=true],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item button[aria-expanded=true]{border-bottom:none}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:first-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:first-child{margin-top:.25rem;border-top:unset}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:last-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:last-child{margin-bottom:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:last-child button,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:last-child button{border-bottom:none}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 1.75rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info{margin-bottom:1rem;padding-left:.75rem;padding-right:.75rem;display:flex;flex-direction:column}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOEmail],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOEmail]{border-top:1px solid #d8d8d8;padding-top:1rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOLink],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOLink]{border-bottom:1px solid #d8d8d8;padding-bottom:1rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info .ot-vnd-lbl,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info .ot-vnd-lbl{font-weight:bold;font-size:.85em;margin-bottom:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info .ot-vnd-cnt,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info .ot-vnd-cnt{margin-left:.5rem;font-weight:500;font-size:.85rem}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt{padding-left:40px}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-size:.8em}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt .ot-cat-header,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt .ot-cat-header{font-size:.8em}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv{margin-bottom:1rem;padding:1rem .95rem}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv .ot-vnd-serv-hdr-cntr{padding-bottom:.75rem;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-weight:700;font-size:.8em;line-height:20px;margin-left:.82rem}#onetrust-pc-sdk .ot-subgrp-cntr .ot-cat-header{font-weight:700;font-size:.8em;line-height:20px}#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-vnd-serv .ot-vnd-lst-cont .ot-accordion-layout .ot-acc-hdr div.ot-chkbox{margin-left:.82rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr{padding:.7rem 0;margin:0;display:flex;width:100%;align-items:center;justify-content:space-between}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr div:first-child,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr div:first-child{margin-left:.5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr div:last-child,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr div:last-child{margin-right:.5rem;margin-left:.5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-always-active{position:relative;right:unset;top:unset;transform:unset}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-plus-minus{top:0}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-arw-cntr{float:none;top:unset;right:unset;transform:unset;margin-top:-2px;position:relative}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-cat-header{flex:1;margin:0 .5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-tgl{position:relative;transform:none;right:0;top:0;float:none}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox{position:relative;margin:0 .5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox label{padding:0}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox label::before{position:relative}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox input{position:absolute;cursor:pointer;width:100%;height:100%;opacity:0;margin:0;top:0;left:0;z-index:1}#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp .ot-acc-hdr h5.ot-cat-header,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp .ot-acc-hdr h4.ot-cat-header{margin:0}#onetrust-pc-sdk .ot-vs-config .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp h5{top:0;line-height:20px}#onetrust-pc-sdk .ot-vs-list{display:flex;flex-direction:column;padding:0;margin:.5rem 4px}#onetrust-pc-sdk .ot-vs-selc-all{display:flex;padding:0;float:unset;align-items:center;justify-content:flex-start}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf{justify-content:flex-end}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf.ot-caret-conf .ot-sel-all-chkbox{margin-right:48px}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf .ot-sel-all-chkbox{margin:0;padding:0;margin-right:14px;justify-content:flex-end}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr.ot-chkbox,#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr.ot-tgl{display:inline-block;right:unset;width:auto;height:auto;float:none}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr label{width:45px;height:25px}#onetrust-pc-sdk .ot-vs-selc-all .ot-sel-all-chkbox{margin-right:11px;margin-left:.75rem;display:flex;align-items:center}#onetrust-pc-sdk .ot-vs-selc-all .sel-all-hdr{margin:0 1.25rem;font-size:.812em;line-height:normal;text-align:center;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-vnd-list-cnt #ot-selall-vencntr.ot-chkbox{float:unset;right:0}#onetrust-pc-sdk[dir=rtl] #ot-back-arw,#onetrust-pc-sdk[dir=rtl] input~.ot-acc-hdr .ot-arw{transform:rotate(180deg);-o-transform:rotate(180deg);-ms-transform:rotate(180deg);-webkit-transform:rotate(180deg)}#onetrust-pc-sdk[dir=rtl] input:checked~.ot-acc-hdr .ot-arw{transform:rotate(270deg);-o-transform:rotate(270deg);-ms-transform:rotate(270deg);-webkit-transform:rotate(270deg)}#onetrust-pc-sdk[dir=rtl] .ot-chkbox label::after{transform:rotate(45deg);-webkit-transform:rotate(45deg);-o-transform:rotate(45deg);-ms-transform:rotate(45deg);border-left:0;border-right:3px solid}#onetrust-pc-sdk[dir=rtl] .ot-search-cntr>svg{right:0}@media only screen and (max-width: 600px){#onetrust-pc-sdk.otPcCenter{left:0;min-width:100%;height:100%;top:0;border-radius:0}#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk.ot-ftr-stacked .ot-btn-container{margin:1px 3px 0 10px;padding-right:10px;width:calc(100% - 23px)}#onetrust-pc-sdk .ot-btn-container button{max-width:none;letter-spacing:.01em}#onetrust-pc-sdk #close-pc-btn-handler{top:10px;right:17px}#onetrust-pc-sdk p{font-size:.7em}#onetrust-pc-sdk #ot-pc-hdr{margin:10px 10px 0 5px;width:calc(100% - 15px)}#onetrust-pc-sdk .vendor-search-handler{font-size:1em}#onetrust-pc-sdk #ot-back-arw{margin-left:12px}#onetrust-pc-sdk #ot-lst-cnt{margin:0;padding:0 5px 0 10px;min-width:95%}#onetrust-pc-sdk .switch+p{max-width:80%}#onetrust-pc-sdk .ot-ftr-stacked button{width:100%}#onetrust-pc-sdk #ot-fltr-cnt{max-width:320px;width:90%;border-top-right-radius:0;border-bottom-right-radius:0;margin:0;margin-left:15px;left:auto;right:40px;top:85px}#onetrust-pc-sdk .ot-fltr-opt{margin-left:25px;margin-bottom:10px}#onetrust-pc-sdk .ot-pc-refuse-all-handler{margin-bottom:0}#onetrust-pc-sdk #ot-fltr-cnt{right:40px}}@media only screen and (max-width: 476px){#onetrust-pc-sdk .ot-fltr-cntr,#onetrust-pc-sdk #ot-fltr-cnt{right:10px}#onetrust-pc-sdk #ot-anchor{right:25px}#onetrust-pc-sdk button{width:100%}#onetrust-pc-sdk:not(.ot-addtl-vendors) #ot-pc-lst:not(.ot-enbl-chr) .ot-sel-all{padding-right:9px}#onetrust-pc-sdk:not(.ot-addtl-vendors) #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr{right:0}}@media only screen and (max-width: 896px)and (max-height: 425px)and (orientation: landscape){#onetrust-pc-sdk.otPcCenter{left:0;top:0;min-width:100%;height:100%;border-radius:0}#onetrust-pc-sdk .ot-pc-header{height:auto;min-height:20px}#onetrust-pc-sdk .ot-pc-header .ot-pc-logo{max-height:30px}#onetrust-pc-sdk .ot-pc-footer{max-height:60px;overflow-y:auto}#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk #ot-pc-lst{bottom:70px}#onetrust-pc-sdk.ot-ftr-stacked #ot-pc-content{bottom:70px}#onetrust-pc-sdk #ot-anchor{left:initial;right:50px}#onetrust-pc-sdk #ot-lst-title{margin-top:12px}#onetrust-pc-sdk #ot-lst-title *{font-size:inherit}#onetrust-pc-sdk #ot-pc-hdr input{margin-right:0;padding-right:45px}#onetrust-pc-sdk .switch+p{max-width:85%}#onetrust-pc-sdk #ot-sel-blk{position:static}#onetrust-pc-sdk #ot-pc-lst{overflow:auto}#onetrust-pc-sdk #ot-lst-cnt{max-height:none;overflow:initial}#onetrust-pc-sdk #ot-lst-cnt.no-results{height:auto}#onetrust-pc-sdk input{font-size:1em !important}#onetrust-pc-sdk p{font-size:.6em}#onetrust-pc-sdk #ot-fltr-modal{width:100%;top:0}#onetrust-pc-sdk ul li p,#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a,#onetrust-pc-sdk .category-host-list-handler{font-size:.6em}#onetrust-pc-sdk.ot-shw-fltr #ot-anchor{display:none !important}#onetrust-pc-sdk.ot-shw-fltr #ot-pc-lst{height:100% !important;overflow:hidden;top:0px}#onetrust-pc-sdk.ot-shw-fltr #ot-fltr-cnt{margin:0;height:100%;max-height:none;padding:10px;top:0;width:calc(100% - 20px);position:absolute;right:0;left:0;max-width:none}#onetrust-pc-sdk.ot-shw-fltr .ot-fltr-scrlcnt{max-height:calc(100% - 65px)}}
            #onetrust-consent-sdk #onetrust-pc-sdk,
                #onetrust-consent-sdk #ot-search-cntr,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-switch.ot-toggle,
                #onetrust-consent-sdk #onetrust-pc-sdk ot-grp-hdr1 .checkbox,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-title:after
                ,#onetrust-consent-sdk #onetrust-pc-sdk #ot-sel-blk,
                        #onetrust-consent-sdk #onetrust-pc-sdk #ot-fltr-cnt,
                        #onetrust-consent-sdk #onetrust-pc-sdk #ot-anchor {
                    background-color: #FFF;
                }
               
            #onetrust-consent-sdk #onetrust-pc-sdk h3,
                #onetrust-consent-sdk #onetrust-pc-sdk h4,
                #onetrust-consent-sdk #onetrust-pc-sdk h5,
                #onetrust-consent-sdk #onetrust-pc-sdk h6,
                #onetrust-consent-sdk #onetrust-pc-sdk p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-ven-lst .ot-ven-opts p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-desc,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-title,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-li-title,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-sel-all-hdr span,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-fltr-modal #modal-header,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-checkbox label span,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-sel-blk p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-lst-title h3,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst .back-btn-handler p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst .ot-ven-name,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-ven-lst .consent-category,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-inactive-leg-btn,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-label-status,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-chkbox label span,
                #onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-optout-signal
                {
                    color: #2E2E2E;
                }
             #onetrust-consent-sdk #onetrust-pc-sdk .privacy-notice-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-pgph-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler + a,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-host-list-handler,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-ven-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-ven-legclaim-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-name a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-acc-hdr .ot-host-expand,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-content #ot-pc-desc .ot-link-btn,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info a
                    {
                        color: #007398;
                    }
            #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler:hover { text-decoration: underline;}
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt,
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-txt .ot-subgrp-tgl .ot-switch.ot-toggle
             {
                background-color: #F8F8F8;
            }
             #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-txt .ot-ven-dets
                            {
                                background-color: #F8F8F8;
                            }
        #onetrust-consent-sdk #onetrust-pc-sdk
            button:not(#clear-filters-handler):not(.ot-close-icon):not(#filter-btn-handler):not(.ot-remove-objection-handler):not(.ot-obj-leg-btn-handler):not([aria-expanded]):not(.ot-link-btn),
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-active-leg-btn {
                background-color: #007398;border-color: #007398;
                color: #FFF;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-active-menu {
                border-color: #007398;
            }
            
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-remove-objection-handler{
                background-color: transparent;
                border: 1px solid transparent;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-inactive-leg-btn {
                background-color: #FFFFFF;
                color: #78808E; border-color: #78808E;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-tgl input:focus + .ot-switch, .ot-switch .ot-switch-nob, .ot-switch .ot-switch-nob:before,
            #onetrust-pc-sdk .ot-checkbox input[type="checkbox"]:focus + label::before,
            #onetrust-pc-sdk .ot-chkbox input[type="checkbox"]:focus + label::before {
                outline-color: #000000;
                outline-width: 1px;
            }
            #onetrust-pc-sdk .ot-host-item > button:focus, #onetrust-pc-sdk .ot-ven-item > button:focus {
                border: 1px solid #000000;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk *:focus,
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-vlst-cntr > a:focus {
               outline: 1px solid #000000;
            }#onetrust-pc-sdk .ot-vlst-cntr .ot-ext-lnk,  #onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{
                    background-image: url('https://cdn.cookielaw.org/logos/static/ot_external_link.svg');
                }
            /*! Extra code to blur out background */
.onetrust-pc-dark-filter{
background:rgba(0,0,0,.5);
z-index:2147483646;
width:100%;
height:100%;
overflow:hidden;
position:fixed;
top:0;
bottom:0;
left:0;
backdrop-filter: initial
}

/*! v6.12.0 2021-01-19 */
div#onetrust-consent-sdk #onetrust-banner-sdk{border-top:2px solid #eb6500!important;outline:1px solid transparent;box-shadow:none;padding:24px}div#onetrust-consent-sdk button{border-radius:0!important;box-shadow:none!important;box-sizing:border-box!important;font-size:20px!important;font-weight:400!important;letter-spacing:0!important;max-width:none!important;white-space:nowrap!important}div#onetrust-consent-sdk button:not(.ot-link-btn){background-color:#007398!important;border:2px solid #007398!important;color:#fff!important;height:48px!important;padding:0 1em!important;width:auto!important}div#onetrust-consent-sdk button:hover{background-color:#fff!important;border-color:#eb6500!important;color:#2e2e2e!important}div#onetrust-consent-sdk button.ot-link-btn{color:#007398!important;font-size:16px!important;text-decoration:underline}div#onetrust-consent-sdk button.ot-link-btn:hover{color: #2e2e2e!important;text-decoration-color:#eb6500!important}div#onetrust-consent-sdk a,div#onetrust-pc-sdk a{color:#007398!important;text-decoration:underline!important}div#onetrust-consent-sdk a,div#onetrust-consent-sdk button,div#onetrust-consent-sdk p:hover{opacity:1!important}div#onetrust-consent-sdk a:focus,div#onetrust-consent-sdk button:focus,div#onetrust-consent-sdk input:focus{outline:2px solid #eb6500!important;outline-offset:1px!important}div#onetrust-banner-sdk .ot-sdk-container{padding:0;width:auto}div#onetrust-banner-sdk .ot-sdk-row{align-items:flex-start;box-sizing:border-box;display:flex;flex-direction:column;justify-content:space-between;margin:auto;max-width:1152px}div#onetrust-banner-sdk .ot-sdk-row:after{display:none}div#onetrust-banner-sdk #onetrust-group-container,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-group-container,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{flex-grow:1;width:auto}div#onetrust-banner-sdk #onetrust-policy,div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy{margin:0;overflow:visible}div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy-text,div#onetrust-consent-sdk #onetrust-policy-text{font-size:16px;line-height:24px;max-width:44em;margin:0}div#onetrust-consent-sdk #onetrust-policy-text a[href]{font-weight:400;margin-left:8px}div#onetrust-banner-sdk #onetrust-button-group-parent{flex:0 0 auto;margin:32px 0 0;width:100%}div#onetrust-banner-sdk #onetrust-button-group{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;margin:-8px}div#onetrust-banner-sdk .banner-actions-container{display:flex;flex:1 0 auto}div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type,div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto;margin:8px;width:auto}div#onetrust-consent-sdk #onetrust-pc-btn-handler{background-color:#fff!important;color:#2e2e2e!important}div#onetrust-banner-sdk #onetrust-close-btn-container{display:none}@media only screen and (min-width:556px){div#onetrust-consent-sdk #onetrust-banner-sdk{padding:40px}div#onetrust-banner-sdk #onetrust-policy{margin:0 40px 0 0}div#onetrust-banner-sdk .ot-sdk-row{align-items:center;flex-direction:row}div#onetrust-banner-sdk #onetrust-button-group-parent,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-button-group-parent,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:0;padding:0;width:auto}div#onetrust-banner-sdk #onetrust-button-group,div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{align-items:stretch;flex-direction:column-reverse;margin:0}div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto}}@media only screen and (min-width:768px){div#onetrust-banner-sdk #onetrust-policy{margin:0 48px 0 0}div#onetrust-consent-sdk #onetrust-banner-sdk{padding:48px}}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-size:16px;line-height:24px}div#onetrust-consent-sdk #onetrust-pc-sdk p,div#onetrust-pc-sdk #ot-pc-desc,div#onetrust-pc-sdk .category-host-list-handler,div#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{font-size:16px;font-weight:400;line-height:24px}div#onetrust-consent-sdk a:hover,div#onetrust-pc-sdk a:hover{color:#2e2e2e!important;text-decoration-color:#eb6500!important}div#onetrust-pc-sdk{border-radius:0;bottom:0;height:auto;left:0;margin:auto;max-width:100%;overflow:hidden;right:0;top:0;width:512px;max-height:800px}div#onetrust-pc-sdk .ot-pc-header{display:none}div#onetrust-pc-sdk #ot-pc-content{overscroll-behavior:contain;padding:0 12px 0 24px;margin:16px 4px 0 0;top:0;right:16px;left:0;width:auto}div#onetrust-pc-sdk #ot-category-title,div#onetrust-pc-sdk #ot-pc-title{font-size:24px;font-weight:400;line-height:32px;margin:0 0 16px}div#onetrust-pc-sdk #ot-pc-desc{padding:0}div#onetrust-pc-sdk #ot-pc-desc a{display:inline}div#onetrust-pc-sdk #accept-recommended-btn-handler{display:none!important}div#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:2px solid #eb6500;outline-offset:-1px;transition:none}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{border-width:0 0 2px}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{border-width:2px 0}div#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding:8px 0;width:100%}div#onetrust-pc-sdk .ot-plus-minus{transform:translateY(2px)}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item>button{background:0 0!important;border:0!important;height:44px!important;max-width:none!important;width:calc(100% - 48px)!important}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-weight:700}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding:0}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item .ot-acc-grpdesc{padding:0;width:100%}div#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border:0;padding:0}div#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp{margin:0}div#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:calc(100% - 160px)}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{width:calc(100% - 88px)}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{color:#2e2e2e;font-size:12px;font-weight:400;line-height:1.5;padding-right:48px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:before{border-radius:12px;position:absolute;right:0;top:0;content:'';background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:after{border-radius:50%;position:absolute;right:5px;top:4px;content:'';background-color:#eb6500;height:12px;width:12px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active,div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl{right:2px}div#onetrust-pc-sdk .ot-switch{display:block;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob,div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob:before{background-color:#737373;height:8px;left:4px;top:4px;width:8px}div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{background-color:#eb6500;height:12px;left:0;top:2px;width:12px}div#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch .ot-switch-nob{box-shadow:0 0;outline:2px solid #eb6500!important;outline-offset:1px;transition:none}div#onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt{background-color:transparent;padding-left:3px}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr,div#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr{overflow:visible;width:100%}div#onetrust-pc-sdk .ot-pc-footer{border-top:0 solid}div#onetrust-pc-sdk .ot-btn-container{padding-top:24px;text-align:center}div#onetrust-pc-sdk .ot-pc-footer button{margin:8px 0;background-color:#fff}div#onetrust-pc-sdk .ot-pc-footer-logo{background-color:#fff}div#onetrust-pc-sdk #ot-lst-title span{font-size:24px;font-weight:400;line-height:32px}div#onetrust-pc-sdk #ot-host-lst .ot-host-desc,div#onetrust-pc-sdk #ot-host-lst .ot-host-expand,div#onetrust-pc-sdk #ot-host-lst .ot-host-name,div#onetrust-pc-sdk #ot-host-lst .ot-host-name a,div#onetrust-pc-sdk .back-btn-handler,div#onetrust-pc-sdk .ot-host-opt li>div div{font-size:16px;font-weight:400;line-height:24px}div#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{width:100%}div#onetrust-pc-sdk #ot-pc-lst{top:0}div#onetrust-pc-sdk .back-btn-handler{text-decoration:none!important}div#onetrust-pc-sdk #filter-btn-handler:hover svg{filter:invert(1)}div#onetrust-pc-sdk .back-btn-handler svg{width:16px;height:16px}div#onetrust-pc-sdk .ot-host-item>button{background:0 0!important;border:0!important;height:66px!important;max-width:none!important;width:calc(100% - 5px)!important;transform:translate(2px,2px)}div#onetrust-pc-sdk .ot-host-item{border-bottom:2px solid #b9b9b9;padding:0}div#onetrust-pc-sdk .ot-host-item .ot-acc-hdr{margin:0 0 -6px;padding:8px 0}div#onetrust-pc-sdk ul li:first-child{border-top:2px solid #b9b9b9}div#onetrust-pc-sdk .ot-host-item .ot-plus-minus{margin:0 8px 0 0}div#onetrust-pc-sdk .ot-search-cntr{width:calc(100% - 48px)}div#onetrust-pc-sdk .ot-host-opt .ot-host-info{background-color:transparent}div#onetrust-pc-sdk .ot-host-opt li>div div{padding:0}div#onetrust-pc-sdk #vendor-search-handler{border-radius:0;border-color:#939393;border-style:solid;border-width:2px 0 2px 2px;font-size:20px;height:48px;margin:0}div#onetrust-pc-sdk #ot-pc-hdr{margin-left:24px}div#onetrust-pc-sdk .ot-lst-subhdr{width:calc(100% - 24px)}div#onetrust-pc-sdk .ot-lst-subhdr svg{right:0;top:8px}div#onetrust-pc-sdk .ot-fltr-cntr{box-sizing:border-box;right:0;width:48px}div#onetrust-pc-sdk #filter-btn-handler{width:48px!important;padding:8px!important}div#onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,div#onetrust-pc-sdk button#filter-apply-handler,div#onetrust-pc-sdk button#filter-cancel-handler{height:2em!important;padding-left:14px!important;padding-right:14px!important}div#onetrust-pc-sdk #ot-fltr-cnt{box-shadow:0 0;border:1px solid #8e8e8e;border-radius:0}div#onetrust-pc-sdk .ot-fltr-scrlcnt{max-height:calc(100% - 80px)}div#onetrust-pc-sdk #ot-fltr-modal{max-height:400px}div#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:16px}div#onetrust-pc-sdk #ot-lst-cnt{margin-left:24px;width:calc(100% - 48px)}div#onetrust-pc-sdk #ot-anchor{display:none!important}

/* 2023-12-04  Fix for button order in mobile view*/
@media (max-width: 550px) {
  #onetrust-accept-btn-handler {order: 1;  }
  #onetrust-reject-all-handler { order: 2;  }
  #onetrust-pc-btn-handler { order: 3;  }
}


/*! Extra code to blur our background */
.onetrust-pc-dark-filter{
backdrop-filter: blur(3px)
}
.ot-sdk-cookie-policy{font-family:inherit;font-size:16px}.ot-sdk-cookie-policy.otRelFont{font-size:1rem}.ot-sdk-cookie-policy h3,.ot-sdk-cookie-policy h4,.ot-sdk-cookie-policy h6,.ot-sdk-cookie-policy p,.ot-sdk-cookie-policy li,.ot-sdk-cookie-policy a,.ot-sdk-cookie-policy th,.ot-sdk-cookie-policy #cookie-policy-description,.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group,.ot-sdk-cookie-policy #cookie-policy-title{color:dimgray}.ot-sdk-cookie-policy #cookie-policy-description{margin-bottom:1em}.ot-sdk-cookie-policy h4{font-size:1.2em}.ot-sdk-cookie-policy h6{font-size:1em;margin-top:2em}.ot-sdk-cookie-policy th{min-width:75px}.ot-sdk-cookie-policy a,.ot-sdk-cookie-policy a:hover{background:#fff}.ot-sdk-cookie-policy thead{background-color:#f6f6f4;font-weight:bold}.ot-sdk-cookie-policy .ot-mobile-border{display:none}.ot-sdk-cookie-policy section{margin-bottom:2em}.ot-sdk-cookie-policy table{border-collapse:inherit}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy{font-family:inherit;font-size:1rem}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h6,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy p,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-title{color:dimgray}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description{margin-bottom:1em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup{margin-left:1.5em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group-desc,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-table-header,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy span,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td{font-size:.9em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td span,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td a{font-size:inherit}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group{font-size:1em;margin-bottom:.6em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-title{margin-bottom:1.2em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy>section{margin-bottom:1em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th{min-width:75px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a:hover{background:#fff}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead{background-color:#f6f6f4;font-weight:bold}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-mobile-border{display:none}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy section{margin-bottom:2em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup ul li{list-style:disc;margin-left:1.5em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup ul li h4{display:inline-block}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table{border-collapse:inherit;margin:auto;border:1px solid #d7d7d7;border-radius:5px;border-spacing:initial;width:100%;overflow:hidden}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table td{border-bottom:1px solid #d7d7d7;border-right:1px solid #d7d7d7}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td{border-bottom:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr th:last-child,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr td:last-child{border-right:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-host,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-cookies-type{width:25%}.ot-sdk-cookie-policy[dir=rtl]{text-align:left}#ot-sdk-cookie-policy h3{font-size:1.5em}@media only screen and (max-width: 530px){.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) table,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) thead,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tbody,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) th,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr{display:block}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) thead tr{position:absolute;top:-9999px;left:-9999px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr{margin:0 0 1em 0}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr:nth-child(odd),.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr:nth-child(odd) a{background:#f6f6f4}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td{border:none;border-bottom:1px solid #eee;position:relative;padding-left:50%}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td:before{position:absolute;height:100%;left:6px;width:40%;padding-right:10px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) .ot-mobile-border{display:inline-block;background-color:#e4e4e4;position:absolute;height:100%;top:0;left:45%;width:2px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td:before{content:attr(data-label);font-weight:bold}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) li{word-break:break-word;word-wrap:break-word}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table{overflow:hidden}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table td{border:none;border-bottom:1px solid #d7d7d7}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tbody,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tr{display:block}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-host,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-cookies-type{width:auto}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tr{margin:0 0 1em 0}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td:before{height:100%;width:40%;padding-right:10px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td:before{content:attr(data-label);font-weight:bold}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li{word-break:break-word;word-wrap:break-word}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead tr{position:absolute;top:-9999px;left:-9999px;z-index:-9999}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td{border-bottom:1px solid #d7d7d7;border-right:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td:last-child{border-bottom:0px}}
                
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h5,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h6,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy p,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy span,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description {
                        color: #696969;
                    }
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th {
                        color: #696969;
                    }
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group {
                        color: #696969;
                    }
                    
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-title {
                            color: #696969;
                        }
                    
            
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table th {
                            background-color: #F8F8F8;
                        }
                    
            .ot-floating-button__front{background-image:url('https://cdn.cookielaw.org/logos/static/ot_persistent_cookie_icon.png')}</style></head>
    <body data-sd-ui-layer-boundary="true"><div id="MathJax_Message" style="display: none;"></div>
      <script type="text/javascript">
        window.__PRELOADED_STATE__ = {"abstracts":{"content":[{"$$":[{"$":{"id":"cesectitle0001"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0001"},"#name":"para","$$":[{"#name":"topic-link","_":"Autonomous driving","$":{"href":"/topics/computer-science/autonomous-driving","term":"Autonomous driving"}},{"#name":"__text__","_":", virtual reality and all kinds of robots integrated into our life rely on facial expression recognition technology."}]}],"$":{"id":"celistitem0001"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0002"},"#name":"para","$$":[{"#name":"text","$$":[{"#name":"text","$$":[{"#name":"__text__","_":"Facial expression recognition and "},{"#name":"topic-link","_":"computer vision","$":{"href":"/topics/engineering/computervision","term":"computer vision"}},{"#name":"__text__","_":" is based on "}]},{"#name":"topic-link","_":"deep learning","$":{"href":"/topics/engineering/deep-learning","term":"deep learning"}},{"#name":"__text__","_":" technology and "}]},{"#name":"topic-link","_":"convolutional neural network","$":{"href":"/topics/computer-science/convolutional-neural-network","term":"convolutional neural network"}},{"#name":"__text__","_":"."}]}],"$":{"id":"celistitem0002"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0003"},"#name":"para","_":"Whether it is two-stage target detection or single-stage target detection, performance of algorithm is measured by detection speed and accuracy."}],"$":{"id":"celistitem0003"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0004"},"#name":"para","$$":[{"#name":"__text__","_":"Large variety of "},{"#name":"topic-link","_":"training data","$":{"href":"/topics/computer-science/training-data","term":"training data"}},{"#name":"__text__","_":" with accurate expression tags can fundamentally improve expression recognition rate."}]}],"$":{"id":"celistitem0004"},"#name":"list-item"}],"$":{"id":"celist0001"},"#name":"list"}],"$":{"view":"all","id":"spara010"},"#name":"simple-para"}],"$":{"view":"all","id":"abss0001"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0001","class":"author-highlights"},"#name":"abstract"},{"$$":[{"$":{"id":"cesectitle0002"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"id":"cesectitle0003"},"#name":"section-title","_":"Background and objective"},{"$":{"view":"all","id":"spara011"},"#name":"simple-para","$$":[{"#name":"__text__","_":"Facial expression recognition technology will play an increasingly important role in our daily life. Autonomous driving, virtual reality and all kinds of robots integrated into our life depend on the development of facial expression recognition technology. Many tasks in the field of computer vision are based on "},{"#name":"topic-link","_":"deep learning","$":{"href":"/topics/computer-science/deep-learning","term":"deep learning"}},{"#name":"text","$$":[{"#name":"__text__","_":" technology and "},{"#name":"topic-link","_":"convolutional neural network","$":{"href":"/topics/engineering/convolutional-neural-network","term":"convolutional neural network"}},{"#name":"__text__","_":". The paper proposes an occluded expression recognition model based on the generated countermeasure network. The model is divided into two modules, namely, occluded face image restoration and face recognition."}]}]}],"$":{"view":"all","role":"background","id":"abss0003"},"#name":"abstract-sec"},{"$$":[{"$":{"id":"cesectitle0004"},"#name":"section-title","_":"Methods"},{"$":{"view":"all","id":"spara012"},"#name":"simple-para","_":"Firstly, this paper summarizes the research status of deep facial expression recognition methods in recent ten years and the development of related facial expression database. Then, the current facial expression recognition methods based on deep learning are divided into two categories: Static facial expression recognition and dynamic facial expression recognition. The two methodswill be introduced and summarized respectively. Aiming at the advanced deep expression recognition algorithms in the field, the performance of these algorithms on common expression databases is compared, and the strengths and weaknesses of these algorithms are analyzed in detail."}],"$":{"view":"all","role":"materials-methods","id":"abss0004"},"#name":"abstract-sec"},{"$$":[{"$":{"id":"cesectitle0005"},"#name":"section-title","_":"Discussion and results"},{"$":{"view":"all","id":"spara013"},"#name":"simple-para","_":"As the task of facial expression recognition is gradually transferred from the controlled laboratory environment to the challenging real-world environment, with the rapid development of deep learning technology, deep neural network can learn discriminative features, and is gradually applied to automatic facial expression recognition task. The current deep facial expression recognition system is committed to solve the following two problems: (1) Overfitting due to lack of sufficient training data; (2) In the real world environment, other variables that have nothing to do with expression bring interference problems."}],"$":{"view":"all","role":"results","id":"abss0005"},"#name":"abstract-sec"},{"$$":[{"$":{"id":"cesectitle0006"},"#name":"section-title","_":"Conclusion"},{"$":{"view":"all","id":"spara014"},"#name":"simple-para","_":"From the perspective of algorithm, combining other expression models, such as facial action unit model and pleasure arousal dimension model, as well as other multimodal models, such as audio mode, 3D face depth information and human physiological information, can make expression recognition more practical."}],"$":{"view":"all","role":"conclusion","id":"abss0006"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0002","class":"author"},"#name":"abstract"}],"floats":[],"footnotes":[],"attachments":[]},"accessbarConfig":{"fallback":false,"id":"accessbar","version":"0.0.1","analytics":{"location":"accessbar","eventName":"ctaImpression"},"ariaLabel":{"accessbar":"Download options and search","componentsList":"PDF Options"},"banners":[{"id":"BannerSsrn"}],"components":[{"analytics":[{"ids":["accessbar:clinicalkeycta:inst-known:sdcust-unknown:ent-no:ra-no:source-linkinghub:method-ip"],"eventName":"ctaClick"}],"label":"Access through&nbsp;**ClinicalKey**","id":"ClinicalKey"},{"ariaLabel":"Access through your organization","institutionLogoAltText":"Seamless access","analytics":[{"ids":["accessbar:accesscta:inst-unknown:sdcust-unknown:ent-unknown:ra-yes:source-seamlessaccess:method-shib"],"eventName":"ctaClick"}],"labelPrefix":"Access through","defaultLabelSuffix":"your organization","href":"/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0169260722000062","id":"RemoteAccess"},{"analytics":[{"ids":["accessbar:purchase-pdf"],"eventName":"ctaClick"}],"label":"Purchase PDF","href":"/getaccess/pii/S0169260722000062/purchase","rel":"noreferrer noopener","target":"_blank","id":"PurchasePDF"},{"analytics":[{"ids":["accessbar:patient-access"],"eventName":"ctaClick"}],"label":"Patient Access","href":"https://www.elsevier.com/open-science/science-and-society/access-for-healthcare-and-patients","rel":"noreferrer noopener","target":"_blank","id":"PatientAccess"},{"analytics":[{"ids":["accessbar:another-institution"],"eventName":"ctaClick"}],"label":"Access through another organization","href":"/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0169260722000062","id":"RemoteAccessOther"}],"search":{"inputPlaceHolder":"Search ScienceDirect","ariaLabel":{"input":"Search ScienceDirect","submit":"Submit search"},"formAction":"/search#submit","analytics":[{"ids":["accessbar:search"],"eventName":"searchStart"}],"id":"QuickSearch"}},"adobeTarget":{"sd:genai-question-and-answer":{}},"article":{"accessOptions":{},"analyticsMetadata":{"accountId":"228598","accountName":"ScienceDirect Guests","loginStatus":"anonymous","userId":"12975512","isLoggedIn":false},"article-number":"106621","cid":"271322","content-family":"serial","copyright-line":"© 2022 Elsevier B.V. All rights reserved.","cover-date-years":["2022"],"cover-date-start":"2022-03-01","cover-date-text":"March 2022","document-subtype":"fla","document-type":"article","eid":"1-s2.0-S0169260722000062","doi":"10.1016/j.cmpb.2022.106621","first-fp":"106621","hub-eid":"1-s2.0-S0169260721X00181","issuePii":"S0169260721X00181","item-weight":"FULL-TEXT","language":"en","last-author":{"#name":"last-author","$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"$$":[{"#name":"author","$":{"id":"au0005","author-id":"S0169260722000062-ea6ce9ccbe2ae1bd2269ea5d9ed20599"},"$$":[{"#name":"given-name","_":"Xuedong"},{"#name":"surname","_":"Wu"}]}]},"normalized-first-auth-initial":"H","normalized-first-auth-surname":"GE","open-research":{"#name":"open-research","$":{"xmlns:xocs":true},"$$":[{"#name":"or-embargo-opening-date","_":"2023-02-07T00:00:00.000Z"}]},"pages":[{"first-page":"106621"}],"pii":"S0169260722000062","self-archiving":{"#name":"self-archiving","$":{"xmlns:xocs":true},"$$":[{"#name":"sa-start-date","_":"2023-02-07T00:00:00.000Z"},{"#name":"sa-user-license","_":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}]},"srctitle":"Computer Methods and Programs in Biomedicine","suppl":"C","timestamp":"2022-12-12T14:18:56.962043Z","title":{"content":[{"#name":"title","$":{"id":"tte0002"},"_":"Facial expression recognition based on deep learning"}],"floats":[],"footnotes":[],"attachments":[]},"vol-first":"215","vol-iss-suppl-text":"Volume 215","userSettings":{"forceAbstract":false,"creditCardPurchaseAllowed":true,"blockFullTextForAnonymousAccess":false,"disableWholeIssueDownload":false,"preventTransactionalAccess":false,"preventDocumentDelivery":true},"contentType":"JL","crossmark":true,"document-references":38,"freeHtmlGiven":false,"ssoUrls":["//acw.clinicalkey.com/SSOCore/update?acw=8aee8e3a2a2ca74c189bc600c4438ca55e60gxrqb%7C%24%7C37F16F5FD7A5B27227E5435E49EB17DB92CB7C15F18BC959B5732B0DCC4C6F27E4DEC7F9AFEEDCE80AB2CB2ED6A8B9342ECCB0E1EAF272AC0E9169905BBD791CB0469A67597464825D387A21AFA2E514&utt=35642ad5a4fe391addb3ef4669a228792f21ad6-J","//acw.scopus.com/SSOCore/update?acw=8aee8e3a2a2ca74c189bc600c4438ca55e60gxrqb%7C%24%7C37F16F5FD7A5B27227E5435E49EB17DB92CB7C15F18BC959B5732B0DCC4C6F27E4DEC7F9AFEEDCE80AB2CB2ED6A8B9342ECCB0E1EAF272AC0E9169905BBD791CB0469A67597464825D387A21AFA2E514&utt=35642ad5a4fe391addb3ef4669a228792f21ad6-J","//acw.sciencedirect.com/SSOCore/update?acw=8aee8e3a2a2ca74c189bc600c4438ca55e60gxrqb%7C%24%7C37F16F5FD7A5B27227E5435E49EB17DB92CB7C15F18BC959B5732B0DCC4C6F27E4DEC7F9AFEEDCE80AB2CB2ED6A8B9342ECCB0E1EAF272AC0E9169905BBD791CB0469A67597464825D387A21AFA2E514&utt=35642ad5a4fe391addb3ef4669a228792f21ad6-J","//acw.elsevier.com/SSOCore/update?acw=8aee8e3a2a2ca74c189bc600c4438ca55e60gxrqb%7C%24%7C37F16F5FD7A5B27227E5435E49EB17DB92CB7C15F18BC959B5732B0DCC4C6F27E4DEC7F9AFEEDCE80AB2CB2ED6A8B9342ECCB0E1EAF272AC0E9169905BBD791CB0469A67597464825D387A21AFA2E514&utt=35642ad5a4fe391addb3ef4669a228792f21ad6-J"],"userProfile":{"departmentName":"ScienceDirect Guests","accessType":"GUEST","accountId":"228598","webUserId":"12975512","accountName":"ScienceDirect Guests","departmentId":"291352","userType":"NORMAL","hasMultipleOrganizations":false,"accountNumber":"C000228598"},"access":{"openAccess":false,"openArchive":false},"aipType":"none","articleEntitlement":{"entitled":false,"isCasaUser":false,"usageInfo":"(12975512,U|291352,D|228598,A|3,P|2,PL)(SDFE,CON|8aee8e3a2a2ca74c189bc600c4438ca55e60gxrqb,SSO|ANON_GUEST,ACCESS_TYPE)","entitledByAccount":false},"crawlerInformation":{"canCrawlPDFContent":false,"isCrawler":false},"dates":{"Available online":"6 January 2022","Received":"17 September 2021","Revised":["22 December 2021"],"Accepted":"3 January 2022","Publication date":"1 March 2022","Version of Record":"7 February 2022"},"downloadFullIssue":false,"entitlementReason":"unsubscribed","features":["aamAttachments","keywords","references","preview"],"hasBody":true,"has-large-authors":false,"hasScholarlyAbstract":true,"headerConfig":{"contactUrl":"https://service.elsevier.com/app/contact/supporthub/sciencedirect/","userName":"","userEmail":"","orgName":"ScienceDirect Guests","webUserId":"12975512","libraryBanner":null,"shib_regUrl":"","tick_regUrl":"","recentInstitutions":[],"canActivatePersonalization":false,"hasInstitutionalAssociation":false,"hasMultiOrg":false,"userType":"GUEST","userAnonymity":"ANON_GUEST","allowCart":true,"environment":"prod","cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com"},"isCorpReq":false,"isPdfFullText":false,"issn":"01692607","issn-primary-formatted":"0169-2607","issRange":"","isThirdParty":false,"pageCount":9,"publication-content":{"noElsevierLogo":false,"imprintPublisher":{"displayName":"Elsevier","id":"47"},"isSpecialIssue":false,"isSampleIssue":false,"transactionsBlocked":false,"publicationOpenAccess":{"oaStatus":"","oaArticleCount":644,"openArchiveStatus":false,"openArchiveArticleCount":18,"openAccessStartDate":"","oaAllowsAuthorPaid":true},"issue-cover":{"attachment":[{"attachment-eid":"1-s2.0-S0169260721X00181-cov200h.gif","file-basename":"cov200h","extension":"gif","filename":"cov200h.gif","ucs-locator":["https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260721X00181/cover/DOWNSAMPLED200/image/gif/9979246d6636ee7e9586962c0340358c/cov200h.gif"],"attachment-type":"IMAGE-COVER-H200","filesize":"10952","pixel-height":"200","pixel-width":"150"},{"attachment-eid":"1-s2.0-S0169260721X00181-cov150h.gif","file-basename":"cov150h","extension":"gif","filename":"cov150h.gif","ucs-locator":["https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0169260721X00181/cover/DOWNSAMPLED/image/gif/32a5721acee557d09ac20c570408b079/cov150h.gif"],"attachment-type":"IMAGE-COVER-H150","filesize":"7135","pixel-height":"150","pixel-width":"113"}]},"smallCoverUrl":"https://ars.els-cdn.com/content/image/S01692607.gif","title":"computer-methods-and-programs-in-biomedicine","contentTypeCode":"JL","images":{"coverImage":"https://ars.els-cdn.com/content/image/1-s2.0-S0169260721X00181-cov150h.gif","logo":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1/image/elsevier-non-solus.png","logoAltText":"Elsevier"},"publicationCoverImageUrl":"https://ars.els-cdn.com/content/image/1-s2.0-S0169260721X00181-cov150h.gif"},"volRange":"215","titleString":"Facial expression recognition based on deep learning","ssrn":{},"renderingMode":"Preview","isAbstract":true,"isContentVisible":false,"ajaxLinks":{"referredToBy":true,"authorMetadata":true,"substances":true},"pdfEmbed":false,"displayViewFullText":false},"authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","author-id":"S0169260722000062-5050632bc63a34d5be74bf089bd181b7"},"$$":[{"#name":"given-name","_":"Huilin"},{"#name":"surname","_":"Ge"}]},{"#name":"author","$":{"id":"au0002","author-id":"S0169260722000062-8a8bcbcb0ea5654c97ba5252b22085e6"},"$$":[{"#name":"given-name","_":"Zhiyu"},{"#name":"surname","_":"Zhu"},{"#name":"cross-ref","$":{"id":"crf0001","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIyaWQlMjIlM0ElMjJlYWQwMDAxJTIyJTJDJTIydHlwZSUyMiUzQSUyMmVtYWlsJTIyJTJDJTIyaHJlZiUyMiUzQSUyMm1haWx0byUzQXpodXp5JTQwanVzdC5lZHUuY24lMjIlN0QlMkMlMjJfJTIyJTNBJTIyemh1enklNDBqdXN0LmVkdS5jbiUyMiU3RA=="}]},{"#name":"author","$":{"id":"au0003","author-id":"S0169260722000062-12d28a2de825ffda4e82a01d9e3d17ec"},"$$":[{"#name":"given-name","_":"Yuewei"},{"#name":"surname","_":"Dai"},{"#name":"cross-ref","$":{"id":"crf0002","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIyaWQlMjIlM0ElMjJlYWQwMDAyJTIyJTJDJTIydHlwZSUyMiUzQSUyMmVtYWlsJTIyJTJDJTIyaHJlZiUyMiUzQSUyMm1haWx0byUzQWR5d2p1c3QlNDAxNjMuY29tJTIyJTdEJTJDJTIyXyUyMiUzQSUyMmR5d2p1c3QlNDAxNjMuY29tJTIyJTdE"}]},{"#name":"author","$":{"id":"au0004","author-id":"S0169260722000062-e6cd93a93519723405afc5ee008f8aef"},"$$":[{"#name":"given-name","_":"Biao"},{"#name":"surname","_":"Wang"}]},{"#name":"author","$":{"id":"au0005","author-id":"S0169260722000062-ea6ce9ccbe2ae1bd2269ea5d9ed20599"},"$$":[{"#name":"given-name","_":"Xuedong"},{"#name":"surname","_":"Wu"}]},{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0169260722000062-39ba2978f4c20dd9f31e5ec27a048f60"},"$$":[{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"School of Electronic Information, Jiangsu University of Science and Technology, Zhenjiang 212003, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Electronic Information"},{"#name":"organization","_":"Jiangsu University of Science and Technology"},{"#name":"city","_":"Zhenjiang"},{"#name":"postal-code","_":"212003"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"staff0001"},"_":"School of Electronic Information, Jiangsu University of Science and Technology, Zhenjiang 212003, China"}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cetext0001"},"_":"Corresponding authors."}]}]}],"floats":[],"footnotes":[],"affiliations":{"aff0001":{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0169260722000062-39ba2978f4c20dd9f31e5ec27a048f60"},"$$":[{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"School of Electronic Information, Jiangsu University of Science and Technology, Zhenjiang 212003, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Electronic Information"},{"#name":"organization","_":"Jiangsu University of Science and Technology"},{"#name":"city","_":"Zhenjiang"},{"#name":"postal-code","_":"212003"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"staff0001"},"_":"School of Electronic Information, Jiangsu University of Science and Technology, Zhenjiang 212003, China"}]}},"correspondences":{"cor0001":{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cetext0001"},"_":"Corresponding authors."}]}},"attachments":[],"scopusAuthorIds":{},"articles":{}},"authorMetadata":[],"banner":{"expanded":false},"biographies":{},"body":{},"chapters":{"toc":[],"isLoading":false},"changeViewLinks":{"showFullTextLink":true,"showAbstractLink":false},"citingArticles":{"hitCount":86,"viewMoreUrl":"http://www.scopus.com/scopus/inward/citedby.url?partnerID=10&rel=3.0.0&eid=2-s2.0-85124002209&md5=efc6284d60efc47572e3d858a84bf2b","articles":[{"articleTitle":"Deep neural network technique for automated detection of ADHD and CD using ECG signal","authors":"Bibi N., Ooi C.P., Fung D.S.S.","doi":"10.1016/j.cmpb.2023.107775","externalArticle":false,"issn":"01692607","openAccess":1,"pii":"S0169260723004418","publicationDate":"2023-11-01","publicationTitle":"Computer Methods and Programs in Biomedicine","publicationYear":"2023","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85169001367&md5=93cc98696b30c8331c8601e9240f638","scopusEid":"2-s2.0-85169001367","snippets":["In this study, the ECG segments were classified into three categories: CD, ADHD + CD, and CD using 1-Dimensional (1D) Convolutional Neural Network (CNN) models. The CNN model is well-known for its ability to classify images, and as a result, it has been used in applications like face and object identification [26,27], satellite forecasting [28,29] and analysis of medical images such as MRI, CT, X-RAY, and PET [30,31]. Besides 2-dimensional images, CNN models have also been applied to 1-dimensional biosignals, such as ECG to identify arrhythmias [32,33]."],"thirdParty":false,"volume":"Volume 241","abstract":{"$$":[{"$$":[{"$":{"id":"cesectitle0001"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0001"},"#name":"para","_":"This study proposed the first deep learning system to differentiate individuals with ADHD, ADHD+CD, and CD using EEG signals."}],"$":{"id":"celistitem0001"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0002"},"#name":"para","_":"The workflow process of our deep learning system is simple and does not require complicated signal processing procedures."}],"$":{"id":"celistitem0002"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0003"},"#name":"para","_":"Grad-CAM was also employed to pinpoint crucial ECG characteristics at particular time points that influence the outcome of the prediction."}],"$":{"id":"celistitem0003"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0004"},"#name":"para","_":"The proposed deep learning system achieved high performance result with 96.04% accuracy, 95.99% sensitivity, 96.26.% precision, and 96.11% F1-score."}],"$":{"id":"celistitem0004"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0005"},"#name":"para","_":"The proposed deep learning system can identify significant ECG features and time-localize them, which may be used as an objective biomarker for more precise diagnosis."}],"$":{"id":"celistitem0005"},"#name":"list-item"}],"$":{"id":"celist0001"},"#name":"list"}],"$":{"view":"all","id":"spara010"},"#name":"simple-para"}],"$":{"view":"all","id":"abss0001"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0001","class":"author-highlights"},"#name":"abstract"},{"$$":[{"$":{"id":"cesectitle0002"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"id":"cesectitle0003"},"#name":"section-title","_":"Background and objective"},{"$":{"view":"all","id":"spara011"},"#name":"simple-para","_":"Attention Deficit Hyperactivity problem (ADHD) is a common neurodevelopment problem in children and adolescents that can lead to long-term challenges in life outcomes if left untreated. Also, ADHD is frequently associated with Conduct Disorder (CD), and multiple research have found similarities in clinical signs and behavioral symptoms between both diseases, making differentiation between ADHD, ADHD comorbid with CD (ADHD+CD), and CD a subjective diagnosis. Therefore, the goal of this pilot study is to create the first explainable deep learning (DL) model for objective ECG-based ADHD/CD diagnosis as having an objective biomarker may improve diagnostic accuracy."}],"$":{"view":"all","role":"background","id":"abss0002"},"#name":"abstract-sec"},{"$$":[{"$":{"id":"cesectitle0004"},"#name":"section-title","_":"Methods"},{"$":{"view":"all","id":"spara012"},"#name":"simple-para","_":"The dataset used in this study consist of ECG data collected from 45 ADHD, 62 ADHD+CD, and 16 CD patients at the Child Guidance Clinic in Singapore. The ECG data were segmented into 2 s epochs and directly used to train our 1-dimensional (1D) convolutional neural network (CNN) model."}],"$":{"view":"all","role":"materials-methods","id":"abss0003"},"#name":"abstract-sec"},{"$$":[{"$":{"id":"cesectitle0005"},"#name":"section-title","_":"Results"},{"$":{"view":"all","id":"spara013"},"#name":"simple-para","_":"The proposed model yielded 96.04% classification accuracy, 96.26% precision, 95.99% sensitivity, and 96.11% F1-score. The Gradient-weighted class activation mapping (Grad-CAM) function was also used to highlight the important ECG characteristics at specific time points that most impact the classification score."}],"$":{"view":"all","role":"results","id":"abss0004"},"#name":"abstract-sec"},{"$$":[{"$":{"id":"cesectitle0006"},"#name":"section-title","_":"Conclusion"},{"$":{"view":"all","id":"spara014"},"#name":"simple-para","_":"In addition to achieving model performance results with our suggested DL method, Grad-CAM's implementation also offers vital temporal data that clinicians and other mental healthcare professionals can use to make wise medical judgments. We hope that by conducting this pilot study, we will be able to encourage larger-scale research with a larger biosignal dataset. Hence allowing biosignal-based computer-aided diagnostic (CAD) tools to be implemented in healthcare and ambulatory settings, as ECG can be easily obtained via wearable devices such as smartwatches."}],"$":{"view":"all","role":"conclusion","id":"abss0005"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0002","class":"author"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"}},{"articleTitle":"Deep learning and computer vision based occupancy CO<inf>2</inf> level prediction for demand-controlled ventilation (DCV)","authors":"Wei S., Tien P.W., Kaiser Calautit J.K.S.","doi":"10.1016/j.jobe.2022.104715","externalArticle":false,"issn":"23527102","openAccess":1,"pii":"S2352710222007288","publicationDate":"2022-09-15","publicationTitle":"Journal of Building Engineering","publicationYear":"2022","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85131948306&md5=e049624499ec1ff8f10ff91b87bad5e","scopusEid":"2-s2.0-85131948306","thirdParty":false,"volume":"Volume 56","abstract":{"$$":[{"$$":[{"$$":[{"#name":"attachment-eid","_":"1-s2.0-S2352710222007288-ga1.jpg"},{"#name":"ucs-locator","_":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710222007288/ga1/DOWNSAMPLED/image/jpeg/432fece5d524c0f0e366a80e2731843d/ga1.jpg"},{"#name":"file-basename","_":"ga1"},{"#name":"abstract-attachment","_":"true"},{"#name":"filename","_":"ga1.jpg"},{"#name":"extension","_":"jpg"},{"#name":"filesize","_":"111800"},{"#name":"pixel-height","_":"200"},{"#name":"pixel-width","_":"379"},{"#name":"attachment-type","_":"IMAGE-DOWNSAMPLED"}],"$":{"xmlns:xocs":true},"#name":"attachment"},{"$$":[{"#name":"attachment-eid","_":"1-s2.0-S2352710222007288-ga1.sml"},{"#name":"ucs-locator","_":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710222007288/ga1/THUMBNAIL/image/gif/5951b44c6f474cb00741b1e80e5161ba/ga1.sml"},{"#name":"file-basename","_":"ga1"},{"#name":"abstract-attachment","_":"true"},{"#name":"filename","_":"ga1.sml"},{"#name":"extension","_":"sml"},{"#name":"filesize","_":"83949"},{"#name":"pixel-height","_":"115"},{"#name":"pixel-width","_":"219"},{"#name":"attachment-type","_":"IMAGE-THUMBNAIL"}],"$":{"xmlns:xocs":true},"#name":"attachment"},{"$$":[{"#name":"attachment-eid","_":"1-s2.0-S2352710222007288-ga1_lrg.jpg"},{"#name":"ucs-locator","_":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2352710222007288/ga1/HIGHRES/image/jpeg/9c91469b9fc3d4b4d9132c90f5e734a6/ga1_lrg.jpg"},{"#name":"file-basename","_":"ga1"},{"#name":"abstract-attachment","_":"true"},{"#name":"filename","_":"ga1_lrg.jpg"},{"#name":"extension","_":"jpg"},{"#name":"filesize","_":"383956"},{"#name":"pixel-height","_":"886"},{"#name":"pixel-width","_":"1680"},{"#name":"attachment-type","_":"IMAGE-HIGH-RES"}],"$":{"xmlns:xocs":true},"#name":"attachment"}],"#name":"attachments"},{"$$":[{"$":{"id":"sectitle0010"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"abspara0010"},"#name":"simple-para","_":"The present study investigated the potential of the application of a live occupancy detection approach to assist the operations of demand-controlled ventilation (DCV) systems to ensure that sufficient interior thermal conditions and air quality were attained while reducing unnecessary building energy loads to improve building energy performance. Faster region-based convolutional neural network (RCNN) models were trained to detect the number of people and occupancy activities respectively, and deployed to an artificial intelligence (AI)-powered camera. Experimental tests were carried out within a case study room to assess the performance of this approach. Due to the less complexity of people counting model, it achieved an average intersection over union (IoU) detection accuracy of about 98.9%, which was higher than activity detection model of about 88.5%. During the detection, the count-based occupancy profiles were produced according to the real-time information about the number of people and their activities. To estimate the effect of this approach on indoor air quality and energy demand, scenario-based modelling of the case study building under four ventilation scenarios was carried out via building energy simulation (BES). Results showed that the proposed approach could provide demand-driven ventilation controls data on the dynamic changes of occupancy to improve the indoor air quality (IAQ) and address the problem of under- or over-estimation of the ventilation demand when using the static or fixed profiles."}],"$":{"view":"all","id":"abssec0010"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0010","lang":"en","class":"author"},"#name":"abstract"},{"$$":[{"$":{"id":"sectitle0015"},"#name":"section-title","_":"Graphical abstract"},{"$$":[{"$$":[{"$$":[{"$$":[{"$":{"role":"short","id":"alttext0010"},"#name":"alt-text","_":"Image 1"},{"$":{"role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","xmlns:xlink":true,"href":"pii:S2352710222007288/ga1","id":"aep-link-id18","type":"simple","locator":"ga1"},"#name":"link"}],"$":{"id":"undfig1"},"#name":"figure"}],"#name":"display"}],"$":{"view":"all","id":"abspara0015"},"#name":"simple-para"}],"$":{"view":"all","id":"abssec0015"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0015","class":"graphical"},"#name":"abstract"},{"$$":[{"$":{"id":"sectitle0020"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"p0010"},"#name":"para","_":"A CNN-based model was developed to perform occupancy counting and activity detection."}],"$":{"id":"u0010"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"p0015"},"#name":"para","_":"The occupancy information was detected for indoor air quality and building ventilation energy demand estimation."}],"$":{"id":"u0015"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"p0020"},"#name":"para","_":"Building energy modelling was carried out under different ventilation scenarios."}],"$":{"id":"u0020"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"p0025"},"#name":"para","_":"Live occupancy detection can assist HVAC operations to provide demand-driven ventilation controls."}],"$":{"id":"u0025"},"#name":"list-item"}],"$":{"id":"ulist0010"},"#name":"list"}],"$":{"view":"all","id":"abspara0020"},"#name":"simple-para"}],"$":{"view":"all","id":"abssec0020"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0020","lang":"en","class":"author-highlights"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"}},{"articleTitle":"SMD-YOLO: An efficient and lightweight detection method for mask wearing status during the COVID-19 pandemic","authors":"Han Z., Huang H., Chen X.","doi":"10.1016/j.cmpb.2022.106888","externalArticle":false,"issn":"01692607","openAccess":0,"pii":"S016926072200270X","publicationDate":"2022-06-01","publicationTitle":"Computer Methods and Programs in Biomedicine","publicationYear":"2022","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85130789269&md5=37c1c4f7b6cf9cdfcdaeaf41ca483c15","scopusEid":"2-s2.0-85130789269","snippets":["Therefore, it is of great practical significance to realize the detection for mask wearing status in public places (such as hospitals, campuses etc.). In recent years, a large number of studies have used deep learning to complete object detection and are widely used in biomedicine [6–8], lesions detection [9–11], face detection [12–14] and other fields [15–18]. The existing machine learning and deep learning methods have achieved some results in the task of face mask detection [19—22], however, there are still limitations in the complicated environments."],"thirdParty":false,"volume":"Volume 221","abstract":{"$$":[{"$$":[{"$":{"id":"cesectitle0001"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0001"},"#name":"para","_":"A face mask detection and monitoring system is developed by using an improved variant of YOLOv4-tiny."}],"$":{"id":"celistitem0001"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0002"},"#name":"para","_":"A novel detector is proposed for mask wearing status in a complicated environment during the COVID-19 pandemic."}],"$":{"id":"celistitem0002"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0003"},"#name":"para","_":"Anchor boxes of K-means++ clustering algorithm increase the detection accuracy."}],"$":{"id":"celistitem0003"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0004"},"#name":"para","_":"Network structure optimization of the original YOLOv4-tiny is to improve detection accuracy and reduce parameter number."}],"$":{"id":"celistitem0004"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0005"},"#name":"para","_":"he overall performance of proposed detector surpasses other CNN models in face mask detection."}],"$":{"id":"celistitem0005"},"#name":"list-item"}],"$":{"id":"celist0001"},"#name":"list"}],"$":{"view":"all","id":"spara026"},"#name":"simple-para"}],"$":{"view":"all","id":"abss0001"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0001","class":"author-highlights"},"#name":"abstract"},{"$$":[{"$":{"id":"cesectitle0002"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"id":"cesectitle0003"},"#name":"section-title","_":"Background and Objective"},{"$":{"view":"all","id":"spara027"},"#name":"simple-para","_":"At present, the COVID-19 epidemic is still spreading worldwide and wearing a mask in public areas is an effective way to prevent the spread of the respiratory virus. Although there are many deep learning methods used for detecting the face masks, there are few lightweight detectors having a good effect on small or medium-size face masks detection in the complicated environments."}],"$":{"view":"all","role":"background","id":"abss0003"},"#name":"abstract-sec"},{"$$":[{"$":{"id":"cesectitle0004"},"#name":"section-title","_":"Methods"},{"$":{"view":"all","id":"spara028"},"#name":"simple-para","_":"In this work we propose an efficient and lightweight detection method based on YOLOv4-tiny, and a face mask detection and monitoring system for mask wearing status. Two feasible improvement strategies, network structure optimization and K-means++ clustering algorithm, are utilized for improving the detection accuracy on the premise of ensuring the real-time face masks recognition. Particularly, the improved residual module and cross fusion module are designed to aim at extracting the features of small or medium-size targets effectively. Moreover, the enhanced dual attention mechanism and the improved spatial pyramid pooling module are employed for merging sufficiently the deep and shallow semantic information and expanding the receptive field. Afterwards, the detection accuracy is compensated through the combination of activation functions. Finally, the depthwise separable convolution module is used to reduce the quantity of parameters and improve the detection efficiency. Our proposed detector is evaluated on a public face mask dataset, and an ablation experiment is also provided to verify the effectiveness of our proposed model, which is compared with the state-of-the-art (SOTA) models as well."}],"$":{"view":"all","role":"materials-methods","id":"abss0004"},"#name":"abstract-sec"},{"$$":[{"$":{"id":"cesectitle0005"},"#name":"section-title","_":"Results"},{"$":{"view":"all","id":"spara029"},"#name":"simple-para","_":"Our proposed detector increases the AP (average precision) values in each category of the public face mask dataset compared with the original YOLOv4-tiny. The mAP (mean average precision) is improved by 4.56% and the speed reaches 92.81 FPS. Meanwhile, the quantity of parameters and the FLOPs (floating-point operations) are reduced by 1/3, 16.48%, respectively."}],"$":{"view":"all","role":"results","id":"abss0005"},"#name":"abstract-sec"},{"$$":[{"$":{"id":"cesectitle0006"},"#name":"section-title","_":"Conclusions"},{"$":{"view":"all","id":"spara030"},"#name":"simple-para","_":"The proposed detector achieves better overall detection performance compared with other SOTA detectors for real-time mask detection, demonstrated the superiority with both theoretical value and practical significance. The developed system also brings greater flexibility to the application of face mask detection in hospitals, campuses, communities, etc."}],"$":{"view":"all","role":"conclusion","id":"abss0006"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0002","class":"author"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"}},{"articleTitle":"A comprehensive review of facial expression recognition techniques","authors":"Rashmi Adyapady R., Annappa B.","doi":"10.1007/s00530-022-00984-w","externalArticle":true,"openAccess":0,"page":"73-103","publicationDate":"February 2023","publicationTitle":"Multimedia Systems","publicationYear":"2023","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85135257001&md5=2415e04dacc41d98f9d3bfaafa04f48","scopusEid":"2-s2.0-85135257001","thirdParty":false,"volume":"Volume 29","abstract":{}},{"articleTitle":"Face Detection & Recognition from Images & Videos Based on CNN & Raspberry Pi","authors":"Zamir M.F., Ali N., Attia E.A.","doi":"10.3390/computation10090148","externalArticle":true,"openAccess":0,"publicationDate":"September 2022","publicationTitle":"Computation","publicationYear":"2022","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85138711986&md5=df543c77392061c649c92ffeafdb8d42","scopusEid":"2-s2.0-85138711986","thirdParty":false,"volume":"Volume 10","abstract":{}},{"articleTitle":"Intelligent Sign Language Recognition System for E-Learning Context","authors":"Hussain M.J., Shaoor A., Park J.","doi":"10.32604/cmc.2022.025953","externalArticle":true,"openAccess":0,"page":"5327-5343","publicationDate":"2022","publicationTitle":"Computers, Materials and Continua","publicationYear":"2022","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85128686483&md5=99af44c83b4b745ae198387a2bf3e2b","scopusEid":"2-s2.0-85128686483","thirdParty":false,"volume":"Volume 72","abstract":{}}]},"combinedContentItems":{"content":[{"#name":"keywords","$$":[{"#name":"keywords","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:xoe":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"keys0001","view":"all","class":"keyword"},"$$":[{"#name":"section-title","$":{"id":"cesectitle0007"},"_":"Keywords"},{"#name":"keyword","$":{"id":"key0001"},"$$":[{"#name":"text","$":{"id":"cetext0002"},"_":"3D face depth information"}]},{"#name":"keyword","$":{"id":"key0002"},"$$":[{"#name":"text","$":{"id":"cetext0003"},"_":"Deep learning"}]},{"#name":"keyword","$":{"id":"key0003"},"$$":[{"#name":"text","$":{"id":"cetext0004"},"_":"Facial expression recognition"}]},{"#name":"keyword","$":{"id":"key0004"},"$$":[{"#name":"text","$":{"id":"cetext0005"},"_":"Target detection"}]},{"#name":"keyword","$":{"id":"key0005"},"$$":[{"#name":"text","$":{"id":"cetext0006"},"_":"Convolutional neural network"}]}]}]}],"floats":[],"footnotes":[],"attachments":[]},"crossMark":{"isOpen":false},"domainConfig":{"cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1"},"downloadIssue":{"openOnPageLoad":false,"isOpen":false,"downloadCapOpen":false,"articles":[],"selected":[]},"enrichedContent":{"tableOfContents":false,"researchData":{"hasResearchData":false,"dataProfile":{},"openData":{},"mendeleyData":{},"databaseLinking":{}},"geospatialData":{"attachments":[]},"interactiveCaseInsights":{},"virtualMicroscope":{}},"entitledRecommendations":{"openOnPageLoad":false,"isOpen":false,"articles":[],"selected":[],"currentPage":1,"totalPages":1},"exam":{},"helpText":{"keyDates":{"html":"<div class=\"key-dates-help\"><h3 class=\"u-margin-s-bottom u-h4\">Publication milestones</h3><p class=\"u-margin-m-bottom\">The dates displayed for an article provide information on when various publication milestones were reached at the journal that has published the article. Where applicable, activities on preceding journals at which the article was previously under consideration are not shown (for instance submission, revisions, rejection).</p><p class=\"u-margin-xs-bottom\">The publication milestones include:</p><ul class=\"key-dates-help-list u-margin-m-bottom u-padding-s-left\"><li><span class=\"u-text-italic\">Received</span>: The date the article was originally submitted to the journal.</li><li><span class=\"u-text-italic\">Revised</span>: The date the most recent revision of the article was submitted to the journal. Dates corresponding to intermediate revisions are not shown.</li><li><span class=\"u-text-italic\">Accepted</span>: The date the article was accepted for publication in the journal.</li><li><span class=\"u-text-italic\">Available online</span>: The date a version of the article was made available online in the journal.</li><li><span class=\"u-text-italic\">Version of Record</span>: The date the finalized version of the article was made available in the journal.</li></ul><p>More information on publishing policies can be found on the <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://www.elsevier.com/about/policies-and-standards/publishing-ethics\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">Publishing Ethics Policies</span></span></a> page. View our <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://www.elsevier.com/researcher/author/submit-your-paper\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">Publishing with Elsevier: step-by-step</span></span></a> page to learn more about the publishing process. For any questions on your own submission or other questions related to publishing an article, <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://service.elsevier.com/app/phone/supporthub/publishing\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">contact our Researcher support team.</span></span></a></p></div>","title":"What do these dates mean?"}},"glossary":{},"issueNavigation":{"previous":{},"next":{}},"linkingHubLinks":{},"metrics":{"metricGroup":{"citations":[],"captures":[],"mentions":[],"socialMedia":[]},"isLoading":false,"error":false},"preview":{"content":[{"#name":"introduction","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"sec0001","role":"introduction","view":"all"},"$$":[{"#name":"label","_":"1"},{"#name":"section-title","$":{"id":"cesectitle0008"},"_":"Introduction"},{"#name":"para","$":{"id":"para0009","view":"all"},"_":"Image recognition is a technology that uses computer to process, analyze and understand images to identify different patterns of targets and objects. It is a main research direction in the field of computer vision and plays an important role in intelligent data acquisition and processing based on image. Image recognition technology can efficiently complete the detection and recognition of specific target objects (such as handwritten characters, products or faces), image classification and marking, and subjective image quality evaluation. At present, image recognition technology has a broad commercial market and optimistic application prospects in Internet application products such as image retrieval, commodity recommendation, user behavior analysis and face recognition. Moreover, it has long-term development potential in high-tech industries such as UAV, autonomous driving and intelligent robot, as well as many fields such as geology, medicine and biology. Early image recognition systems mainly used directional gradient histogram [1] and scale invariant feature transformation [2], and then input the extracted features into the classifier for classification and recognition. These functions are basically manually designed. For different recognition problems, the extracted features will directly affect the performance of the system. Therefore, researchers need to further study the unsolved problem areas in order to design better adaptive features to improve the performance of the system. The image recognition system in this period is often for a specific recognition task, and the data scale is small, the generalization ability is poor, so it is not easy to achieve the ideal recognition effect in daily application."},{"#name":"para","$":{"id":"para0010","view":"all"},"_":"Deep learning is a branch of representation learning based on data of artificial neural network. Deep learning includes supervised learning, semi-supervised learning and unsupervised learning. In deep learning, deep neural network, deep belief network and recurrent neural network have been widely used in speech recognition, computer vision, audio recognition, unmanned driving and natural language processing. Rina dechter first introduced deep learning in 1986. In addition, Igor aizenberg introduced the concept of artificial neural network in 2000. In fact, Alexey ivakhnenko and Lapa proposed supervised feedforward learning network as early as 1965. In 1986, Geoffrey Hinton proposed the back-propagation algorithm of multilayer perceptron (MLS), and used the SIGMOD activation function for nonlinear transformation, so as to solve the problems of nonlinear learning and classification. In 2006, Geoffrey Hinton et al. Pointed out that the pre-training weight should be used to initialize the model and fine tune the model according to the supervised training. With the further development of deep learning, the proposal of lenet [3] in 1998 marked the emergence of convolutional neural network (CNN)."},{"#name":"para","$":{"id":"para0011","view":"all"},"_":"However, due to the backward hardware at that time, convolutional neural network is not in an advantage compared with other machine learning methods (such as SVM [4]). With the further development of computing devices, the Alex net that is proposed by Hinton et al. has made significant achievements in the computer vision competition ILSVRC 2012. Convolutional neural networks have made rapid progress in recent decades."}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"sec0002","view":"all"},"$$":[{"#name":"label","_":"2"},{"#name":"section-title","$":{"id":"cesectitle0009"},"_":"Related research"},{"#name":"section","$":{"id":"sec0003","view":"all"},"$$":[{"#name":"label","_":"2.1"},{"#name":"section-title","$":{"id":"cesectitle0010"},"_":"Review of face recognition technology"},{"#name":"para","$":{"id":"para0012","view":"all"},"_":"Face recognition has the characteristics of easy access, easy operation and diversified features. In the last century, many scholars studied face recognition. However, due to the underdeveloped network, limited resources of face images and poor quality of photos, many scholars mostly studied it from the perspective of algorithm, but the recognition accuracy is low, far from the human eye recognition effect. With the gradual maturity of machine learning technology, there are many powerful"}]}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"sec0005","role":"materials-methods","view":"all"},"$$":[{"#name":"label","_":"3"},{"#name":"section-title","$":{"id":"cesectitle0012"},"_":"Methods"},{"#name":"section","$":{"id":"sec0006","view":"all"},"$$":[{"#name":"label","_":"3.1"},{"#name":"section-title","$":{"id":"cesectitle0013"},"_":"Depth target detection algorithm"},{"#name":"para","$":{"id":"para0020","view":"all"},"_":"In the realm of computer vision, object recognition technology is an algorithm that can detect sample objects in videos and photos. Recent target recognition algorithms mostly rely on high-performance GPU chips based on multilayer neural network and deep learning software framework and built-in thousands of stream processors. Therefore, it is also known as deep object detection (Deep OD). Object detection has always been a vital issue in the realm of computer vision. Before deep learning is"}]}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"sec0009","role":"results","view":"all"},"$$":[{"#name":"label","_":"4"},{"#name":"section-title","$":{"id":"cesectitle0016"},"_":"Results"},{"#name":"section","$":{"id":"sec0010","view":"all"},"$$":[{"#name":"label","_":"4.1"},{"#name":"section-title","$":{"id":"cesectitle0017"},"_":"Deep facial expression recognition based on static image"},{"#name":"para","$":{"id":"para0039","view":"all"},"_":"Due to the convenience and availability of network static data processing, a large number of researches are based on static images without considering time information for expression recognition. Direct training of deep network on relatively small facial expression databases will inevitably result in overfitting problem. In order to solve this problem, many related researches use additional auxiliary data to pre-train and build their own network, or directly fine tune based on an effective"}]}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"sec0013","role":"discussion","view":"all"},"$$":[{"#name":"label","_":"5"},{"#name":"section-title","$":{"id":"cesectitle0020"},"_":"Discussion"},{"#name":"para","$":{"id":"para0045","view":"all"},"_":"This paper firstly recommends the background knowledge of facial expression recognition, and summarizes the evolution and development of database and algorithm in the field of facial expression recognition. It points out that deep learning has become the mainstream framework in this field. Then, the expression recognition algorithms based on deep learning are divided into two categories (static expression recognition network and dynamic expression recognition network). By comparing the"}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"sec0014","role":"conclusion","view":"all"},"$$":[{"#name":"label","_":"6"},{"#name":"section-title","$":{"id":"cesectitle0021"},"_":"Conclusions"},{"#name":"para","$":{"id":"para0047","view":"all"},"_":"In the field of computer vision, based on the research status at home and abroad, facial expression recognition technology has made great progress and development. However, there are still many challenges and difficulties waiting for researchers to solve. For example, the research on facial expression recognition in real scenes, and there is a certain confusion between different expressions. The expression of facial emotion may vary with region, culture, and environment. There are differences"}]}]},{"#name":"section","$$":[{"#name":"conflict-of-interest","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"coi0001","view":"all"},"$$":[{"#name":"section-title","$":{"id":"cesectitle0022"},"_":"Declaration of Competing Interest"},{"#name":"para","$":{"id":"para0048","view":"all"},"_":"The authors declare that there is no conflict of interest in this paper."}]}]},{"#name":"section","$$":[{"#name":"acknowledgment","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"ack0001","view":"all"},"$$":[{"#name":"section-title","$":{"id":"cesectitle0023"},"_":"Acknowledgment"},{"#name":"para","$":{"id":"para0049","view":"all"},"$$":[{"#name":"__text__","_":"This work is supported by the "},{"#name":"grant-sponsor","$":{"id":"gs0001","type":"simple","role":"http://www.elsevier.com/xml/linking-roles/grant-sponsor"},"_":"National Natural Science Foundation of China"},{"#name":"__text__","_":" (No. "},{"#name":"grant-number","$":{"refid":"gs0001","id":"gn0001"},"_":"62006102"},{"#name":"__text__","_":")."}]}]}]}],"floats":[],"footnotes":[],"attachments":[]},"rawtext":"","recommendations":{"articles":[{"pii":"S1568494619307008","doi":"10.1016/j.asoc.2019.105919","journalTitle":"Applied Soft Computing","publicationYear":"2020","publicationDate":"2020-01-01","volumeSupText":"Volume 86","articleNumber":"105919","pageRange":"105919","trace-token":"AAAAQGl9010qzIZ6fYtHMxBNaZAm66IIhyXW-9UVB-J3nyHnVRy4FgY4FE1raf2fItlsnzIRWVPzqh3cMwAaK5Lsgmq9ozGYkI4Vr49-kA6VQZ9lK19NZA","authors":{"content":[{"#name":"author-group","$":{"id":"d1e700"},"$$":[{"#name":"author","$":{"id":"au000001","author-id":"S1568494619307008-e880833c1f27997c7ce26fbb3cb7c893"},"$$":[{"#name":"given-name","_":"Yuanhang"},{"#name":"surname","_":"Chen"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea1","type":"email","href":"mailto:cyh.wne@gmail.com"},"_":"cyh.wne@gmail.com"}]},{"#name":"author","$":{"id":"au000002","author-id":"S1568494619307008-867e09acf237c4f53681fdaa1e525aef","orcid":"0000-0002-0911-830X"},"$$":[{"#name":"given-name","_":"Gaoliang"},{"#name":"surname","_":"Peng"},{"#name":"cross-ref","$":{"refid":"cor1","id":"d1e713"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea2","type":"email","href":"mailto:pgl7782@hit.edu.cn"},"_":"pgl7782@hit.edu.cn"}]},{"#name":"author","$":{"id":"au000003","author-id":"S1568494619307008-8a8bcbcb0ea5654c97ba5252b22085e6"},"$$":[{"#name":"given-name","_":"Zhiyu"},{"#name":"surname","_":"Zhu"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea3","type":"email","href":"mailto:zbzhzhy@gmail.com"},"_":"zbzhzhy@gmail.com"}]},{"#name":"author","$":{"id":"au000004","author-id":"S1568494619307008-71f2da4b4c2562294f17387e0715f191"},"$$":[{"#name":"given-name","_":"Sijue"},{"#name":"surname","_":"Li"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea4","type":"email","href":"mailto:lisijue@hit.edu.cn"},"_":"lisijue@hit.edu.cn"}]},{"#name":"affiliation","$":{"affiliation-id":"S1568494619307008-eada8f77ca611705c5cc22be88802548","id":"aff1"},"$$":[{"#name":"textfn","_":"State Key Laboratory of Robotics and System, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin 150001, Heilongjiang Province, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"State Key Laboratory of Robotics and System, Harbin Institute of Technology"},{"#name":"address-line","_":"No. 92 Xidazhi Street, Harbin 150001, Heilongjiang Province"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"afs46"},"_":"State Key Laboratory of Robotics and System, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin 150001, Heilongjiang Province, China"}]},{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au000004","author-id":"S1568494619307008-71f2da4b4c2562294f17387e0715f191"},"$$":[{"#name":"given-name","_":"Sijue"},{"#name":"surname","_":"Li"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea4","type":"email","href":"mailto:lisijue@hit.edu.cn"},"_":"lisijue@hit.edu.cn"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"d1e697"},"_":"A novel deep learning method based on attention mechanism for bearing remaining useful life prediction"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"86","isThirdParty":false,"language":"en","issn-primary-unformatted":"15684946","issn-primary-formatted":"1568-4946"},{"pii":"S0925231220301193","doi":"10.1016/j.neucom.2020.01.067","journalTitle":"Neurocomputing","publicationYear":"2020","publicationDate":"2020-06-07","volumeSupText":"Volume 392","articleNumber":"","pageRange":"38-49","trace-token":"AAAAQGl9010qzIZ6fYtHMxBNaZAyQNbxEhJ0Chzm5uf3tsxRoaf3zT9DwL_ToUSTRp9Dc2Dy-IYFtHUMcAZxKVIUnCgWjgHQurYT4aELFuwpMWMOMZsP_w","authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"author-id":"S0925231220301193-489ee205bae003a1d0319ae407d3477a","biographyid":"auth1Bio1","id":"au0001"},"$$":[{"#name":"given-name","_":"Feng"},{"#name":"surname","_":"Zhou"},{"#name":"cross-ref","$":{"id":"crf0001","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0007a","refid":"fn1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"1"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0001","type":"email","href":"mailto:fezhou@umich.edu"},"_":"fezhou@umich.edu"}]},{"#name":"author","$":{"author-id":"S0925231220301193-361492603c7e144755495e1241c199f0","biographyid":"auth2Bio2","id":"au0002","orcid":"0000-0002-1362-5937"},"$$":[{"#name":"given-name","_":"Shu"},{"#name":"surname","_":"Kong"},{"#name":"cross-ref","$":{"id":"crf0002","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"cross-ref","$":{"id":"crf0002a","refid":"aff0006"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"f"}]},{"#name":"cross-ref","$":{"id":"crf0007b","refid":"fn1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"1"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0002","type":"email","href":"mailto:skong2@ics.uci.edu"},"_":"skong2@ics.uci.edu"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0002q","type":"email","href":"mailto:Kongshuk@andrew.cmu.edu"},"_":"Kongshuk@andrew.cmu.edu"}]},{"#name":"author","$":{"author-id":"S0925231220301193-d6edb59af27486add4fe67ed37fd26c6","biographyid":"auth3Bio3","id":"au0003"},"$$":[{"#name":"given-name","_":"Charless C."},{"#name":"surname","_":"Fowlkes"},{"#name":"cross-ref","$":{"id":"crf0003","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0003","type":"email","href":"mailto:fowlkes@ics.uci.edu"},"_":"fowlkes@ics.uci.edu"}]},{"#name":"author","$":{"author-id":"S0925231220301193-66e63eb933a3755864195a09dcdbad61","biographyid":"auth4Bio4","id":"au0004"},"$$":[{"#name":"given-name","_":"Tao"},{"#name":"surname","_":"Chen"},{"#name":"cross-ref","$":{"id":"crf0004","refid":"aff0003"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"c"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0004","type":"email","href":"mailto:eetchen@fudan.edu.cn"},"_":"eetchen@fudan.edu.cn"}]},{"#name":"author","$":{"author-id":"S0925231220301193-7c614d9e97d5a023bb0e0dbe8d551e73","biographyid":"auth5Bio5","id":"au0005"},"$$":[{"#name":"given-name","_":"Baiying"},{"#name":"surname","_":"Lei"},{"#name":"cross-ref","$":{"id":"crf0005","refid":"aff0004"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"d"}]},{"#name":"cross-ref","$":{"id":"crf0006","refid":"aff0005"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"e"}]},{"#name":"cross-ref","$":{"id":"crf0007","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0005","type":"email","href":"mailto:leiby@szu.edu.cn"},"_":"leiby@szu.edu.cn"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0006","type":"email","href":"mailto:leib0001@e.ntu.edu.sg"},"_":"leib0001@e.ntu.edu.sg"}]},{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0925231220301193-7d9ce8b0aa2c475a8d199bdb7149cfda"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"Department of Industrial and Manufacturing Systems Engineering, University of Michigan, Dearborn 48128, USA"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Industrial and Manufacturing Systems Engineering"},{"#name":"organization","_":"University of Michigan"},{"#name":"city","_":"Dearborn"},{"#name":"postal-code","_":"48128"},{"#name":"country","_":"USA"}]},{"#name":"source-text","$":{"id":"staff0001"},"_":"aDepartment of Industrial and Manufacturing Systems Engineering, University of Michigan, Dearborn 48128, USA"}]},{"#name":"affiliation","$":{"id":"aff0002","affiliation-id":"S0925231220301193-b5a09b8b76dc29f9afd628723643745c"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","$":{"id":"cetextfn0002"},"_":"Department of Computer Science, University of California, Irvine 92697, USA"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Computer Science"},{"#name":"organization","_":"University of California"},{"#name":"city","_":"Irvine"},{"#name":"postal-code","_":"92697"},{"#name":"country","_":"USA"}]},{"#name":"source-text","$":{"id":"staff0002"},"_":"bDepartment of Computer Science, University of California, Irvine 92697, USA"}]},{"#name":"affiliation","$":{"id":"aff0003","affiliation-id":"S0925231220301193-35b0b3e7a8af1d9a3f5c953c6e4607cd"},"$$":[{"#name":"label","_":"c"},{"#name":"textfn","$":{"id":"cetextfn0003"},"_":"School of Information Science and Engineering, Fudan University, Shanghai 20043, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Information Science and Engineering"},{"#name":"organization","_":"Fudan University"},{"#name":"city","_":"Shanghai"},{"#name":"postal-code","_":"20043"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"staff0003"},"_":"cSchool of Information Science and Engineering, Fudan University, Shanghai 20043, China"}]},{"#name":"affiliation","$":{"id":"aff0004","affiliation-id":"S0925231220301193-f4efaae32044a87552cc83d4cfdf1fd9"},"$$":[{"#name":"label","_":"d"},{"#name":"textfn","$":{"id":"cetextfn0004"},"_":"National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"National-Regional Key Technology Engineering Laboratory for Medical Ultrasound"},{"#name":"organization","_":"Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"staff0004"},"_":"dNational-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, China"}]},{"#name":"affiliation","$":{"id":"aff0005","affiliation-id":"S0925231220301193-3467a42cd7403705739f81833c3236d4"},"$$":[{"#name":"label","_":"e"},{"#name":"textfn","$":{"id":"cetextfn0005"},"_":"School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen 518060, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Biomedical Engineering"},{"#name":"organization","_":"Health Science Center"},{"#name":"organization","_":"Shenzhen University"},{"#name":"city","_":"Shenzhen"},{"#name":"postal-code","_":"518060"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"staff0005"},"_":"eSchool of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen 518060, China"}]},{"#name":"affiliation","$":{"id":"aff0006","affiliation-id":"S0925231220301193-8ee10dec51a1f39e90850102ecab1e08"},"$$":[{"#name":"label","_":"f"},{"#name":"textfn","$":{"id":"cetextfn0002a"},"_":"Robotics Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA, 15213, USA"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Robotics Institute"},{"#name":"organization","_":"Carnegie Mellon University"},{"#name":"address-line","_":"5000 Forbes Ave"},{"#name":"city","_":"Pittsburgh"},{"#name":"state","_":"PA"},{"#name":"postal-code","_":"15213"},{"#name":"country","_":"USA"}]},{"#name":"source-text","$":{"id":"staff0002a"},"_":"fRobotics Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA, 15213, USA"}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cetext0001"},"_":"Corresponding author at: School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen 518060, China."},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Biomedical Engineering"},{"#name":"organization","_":"Health Science Center"},{"#name":"organization","_":"Shenzhen University"},{"#name":"city","_":"Shenzhen"},{"#name":"postal-code","_":"518060"},{"#name":"country","_":"China"}]}]},{"#name":"footnote","$":{"id":"fn1"},"$$":[{"#name":"label","_":"1"},{"#name":"note-para","$":{"id":"notep0001a","view":"all"},"_":"The first author and the second author has equal contribution."}]}]}],"floats":[],"footnotes":[{"#name":"footnote","$":{"id":"fn1"},"$$":[{"#name":"label","_":"1"},{"#name":"note-para","$":{"id":"notep0001a","view":"all"},"_":"The first author and the second author has equal contribution."}]}],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"author-id":"S0925231220301193-7c614d9e97d5a023bb0e0dbe8d551e73","biographyid":"auth5Bio5","id":"au0005"},"$$":[{"#name":"given-name","_":"Baiying"},{"#name":"surname","_":"Lei"},{"#name":"cross-ref","$":{"id":"crf0005","refid":"aff0004"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"d"}]},{"#name":"cross-ref","$":{"id":"crf0006","refid":"aff0005"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"e"}]},{"#name":"cross-ref","$":{"id":"crf0007","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0005","type":"email","href":"mailto:leiby@szu.edu.cn"},"_":"leiby@szu.edu.cn"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0006","type":"email","href":"mailto:leib0001@e.ntu.edu.sg"},"_":"leib0001@e.ntu.edu.sg"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"tte0002"},"_":"Fine-grained facial expression analysis using dimensional emotion model"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"392","isThirdParty":false,"language":"en","issn-primary-unformatted":"09252312","issn-primary-formatted":"0925-2312"},{"pii":"S1746809423006560","doi":"10.1016/j.bspc.2023.105223","journalTitle":"Biomedical Signal Processing and Control","publicationYear":"2023","publicationDate":"2023-09-01","volumeSupText":"Volume 86, Part B","articleNumber":"105223","pageRange":"105223","trace-token":"AAAAQGl9010qzIZ6fYtHMxBNaZCJAz-cjSf9AlpVp-GqABSfLrMjuPY_TgKWkiW65Djreq7hMWDU7p-JvPHwVGXVGpeHInvR7vNCy_BESwPj0PzM3VGf0Q","authors":{"content":[{"#name":"author-group","$":{"id":"d1e954"},"$$":[{"#name":"author","$":{"author-id":"S1746809423006560-90c55994e6db4ad3527637c72d8b51eb","id":"au000001","orcid":"0000-0002-9235-9429"},"$$":[{"#name":"given-name","_":"Wei"},{"#name":"surname","_":"Li"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/software"},"_":"Software"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/validation"},"_":"Validation"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/formal-analysis"},"_":"Formal analysis"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/investigation"},"_":"Investigation"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/resources"},"_":"Resources"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/data-curation"},"_":"Data curation"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/writing-original-draft"},"_":"Writing – original draft"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/writing-review-editing"},"_":"Writing – review & editing"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/visualization"},"_":"Visualization"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/supervision"},"_":"Supervision"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/project-administration"},"_":"Project administration"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/funding-acquisition"},"_":"Funding acquisition"},{"#name":"cross-ref","$":{"id":"d1e989","refid":"aff1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"d1e992","refid":"cor1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea1","type":"email","href":"mailto:li-wei@seu.edu.cn"},"_":"li-wei@seu.edu.cn"}]},{"#name":"author","$":{"author-id":"S1746809423006560-21164af385681b4dca24b3168dc14b2f","id":"au000002","orcid":"0000-0002-3226-0371"},"$$":[{"#name":"given-name","_":"Ye"},{"#name":"surname","_":"Tian"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/software"},"_":"Software"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/validation"},"_":"Validation"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/formal-analysis"},"_":"Formal analysis"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/investigation"},"_":"Investigation"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/resources"},"_":"Resources"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/data-curation"},"_":"Data curation"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/writing-original-draft"},"_":"Writing – original draft"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/writing-review-editing"},"_":"Writing – review & editing"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/visualization"},"_":"Visualization"},{"#name":"cross-ref","$":{"id":"d1e1023","refid":"aff2"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]},{"#name":"author","$":{"author-id":"S1746809423006560-f2ec486305e74b37ec991955268af563","id":"au000003","orcid":"0000-0001-8226-8139"},"$$":[{"#name":"given-name","_":"Bowen"},{"#name":"surname","_":"Hou"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/software"},"_":"Software"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/formal-analysis"},"_":"Formal analysis"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/investigation"},"_":"Investigation"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/resources"},"_":"Resources"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/data-curation"},"_":"Data curation"},{"#name":"cross-ref","$":{"id":"d1e1043","refid":"aff1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"author-id":"S1746809423006560-65d00c4c461353fe9a708358a4832963","id":"au000004","orcid":"0000-0002-6484-4363"},"$$":[{"#name":"given-name","_":"Jianzhang"},{"#name":"surname","_":"Dong"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/formal-analysis"},"_":"Formal analysis"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/investigation"},"_":"Investigation"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/writing-review-editing"},"_":"Writing – review & editing"},{"#name":"cross-ref","$":{"id":"d1e1057","refid":"aff2"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]},{"#name":"author","$":{"author-id":"S1746809423006560-8a059b259621ad020f44d35d45932b56","id":"au000005","orcid":"0000-0003-4689-6140"},"$$":[{"#name":"given-name","_":"Shitong"},{"#name":"surname","_":"Shao"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/formal-analysis"},"_":"Formal analysis"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/writing-review-editing"},"_":"Writing – review & editing"},{"#name":"cross-ref","$":{"id":"d1e1069","refid":"aff1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"author-id":"S1746809423006560-ce24ebb93f91942d5c5dd5d211e3c0f8","id":"au000006","orcid":"0000-0002-1982-6780"},"$$":[{"#name":"given-name","_":"Aiguo"},{"#name":"surname","_":"Song"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/project-administration"},"_":"Project administration"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/funding-acquisition"},"_":"Funding acquisition"},{"#name":"cross-ref","$":{"id":"d1e1081","refid":"aff1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"affiliation","$":{"affiliation-id":"S1746809423006560-6a9fb0f5e0905608955bdb27273d578a","id":"aff1"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","_":"School of Instrument Science and Engineering, Southeast University, Nanjing, Jiangsu 210096, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Instrument Science and Engineering, Southeast University"},{"#name":"city","_":"Nanjing"},{"#name":"state","_":"Jiangsu"},{"#name":"postal-code","_":"210096"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"afs49"},"_":"School of Instrument Science and Engineering, Southeast University, Nanjing, Jiangsu 210096, China"}]},{"#name":"affiliation","$":{"affiliation-id":"S1746809423006560-822a1da0cd88409b4d0ac7a69db5904b","id":"aff2"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","_":"College of Software Engineering, Southeast University, Suzhou, Jiangsu 215123, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"College of Software Engineering, Southeast University"},{"#name":"city","_":"Suzhou"},{"#name":"state","_":"Jiangsu"},{"#name":"postal-code","_":"215123"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"afs50"},"_":"College of Software Engineering, Southeast University, Suzhou, Jiangsu 215123, China"}]},{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"author-id":"S1746809423006560-ce24ebb93f91942d5c5dd5d211e3c0f8","id":"au000006","orcid":"0000-0002-1982-6780"},"$$":[{"#name":"given-name","_":"Aiguo"},{"#name":"surname","_":"Song"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/project-administration"},"_":"Project administration"},{"#name":"contributor-role","$":{"role":"http://credit.niso.org/contributor-roles/funding-acquisition"},"_":"Funding acquisition"},{"#name":"cross-ref","$":{"id":"d1e1081","refid":"aff1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"d1e951"},"_":"A Bi-Stream hybrid model with MLPBlocks and self-attention mechanism for EEG-based emotion recognition"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"86","isThirdParty":false,"language":"en","issn-primary-unformatted":"17468094","issn-primary-formatted":"1746-8094"},{"pii":"S0167865517302313","doi":"10.1016/j.patrec.2017.06.025","journalTitle":"Pattern Recognition Letters","publicationYear":"2020","publicationDate":"2020-11-01","volumeSupText":"Volume 139","articleNumber":"","pageRange":"157-165","trace-token":"AAAAQGl9010qzIZ6fYtHMxBNaZDU8_YZNr1X1FtGfovFlSF6UySPHvfyyn3-H8M56HXfhiDkk0fpn_Qdeol1zvBzcKfN3-RZ3pI8JABvlmAu4RkrqpxrZw","authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","author-id":"S0167865517302313-74923edf7f30e22f60bbdfaf0919af91"},"$$":[{"#name":"given-name","_":"Deepak Kumar"},{"#name":"surname","_":"Jain"},{"#name":"cross-ref","$":{"id":"crf0007","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0507","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"e-address","$":{"type":"email","id":"ead0001"},"_":"deepak.juet@cripac.ia.ac.cn"},{"#name":"e-address","$":{"type":"email","id":"ead0001a"},"_":"deepak.jain.juet@gmail.com"}]},{"#name":"author","$":{"id":"au0002","author-id":"S0167865517302313-d891010f04cbf5dbc029becbf187493f"},"$$":[{"#name":"given-name","_":"Zhang"},{"#name":"surname","_":"Zhang"},{"#name":"cross-ref","$":{"id":"crf0097","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0517","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"e-address","$":{"type":"email","id":"ead0002"},"_":"zzhang@nlpr.ia.ac.cn"}]},{"#name":"author","$":{"id":"au0003","author-id":"S0167865517302313-445cf01ddeb1319bac6cc9ad6a05cc27"},"$$":[{"#name":"given-name","_":"Kaiqi"},{"#name":"surname","_":"Huang"},{"#name":"cross-ref","$":{"id":"crf0087","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0527","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"cross-ref","$":{"id":"crf0551","refid":"cor0021"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"type":"email","id":"ead0003"},"_":"kaiqi.huang@nlpr.ia.ac.cn"}]},{"#name":"affiliation","$":{"id":"aff0001"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"CRIPAC & NLPR, CASIA, PR China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"CRIPAC & NLPR, CASIA"},{"#name":"country","_":"PR China"}]}]},{"#name":"affiliation","$":{"id":"aff0002"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","$":{"id":"cetextfn0091"},"_":"University of Chinese Academy of Sciences, PR China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"University of Chinese Academy of Sciences"},{"#name":"country","_":"PR China"}]}]},{"#name":"correspondence","$":{"id":"cor0021"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cor1"},"_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au0003","author-id":"S0167865517302313-445cf01ddeb1319bac6cc9ad6a05cc27"},"$$":[{"#name":"given-name","_":"Kaiqi"},{"#name":"surname","_":"Huang"},{"#name":"cross-ref","$":{"id":"crf0087","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0527","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"cross-ref","$":{"id":"crf0551","refid":"cor0021"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"type":"email","id":"ead0003"},"_":"kaiqi.huang@nlpr.ia.ac.cn"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"ct0001"},"_":"Multi angle optimal pattern-based deep learning for automatic facial expression recognition"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"sco","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"139","isThirdParty":false,"language":"en","issn-primary-unformatted":"01678655","issn-primary-formatted":"0167-8655"},{"pii":"S135044952100195X","doi":"10.1016/j.infrared.2021.103823","journalTitle":"Infrared Physics & Technology","publicationYear":"2021","publicationDate":"2021-09-01","volumeSupText":"Volume 117","articleNumber":"103823","pageRange":"103823","trace-token":"AAAAQGl9010qzIZ6fYtHMxBNaZCXlbbbZxgn2R00NPL34Sxel2lLMa-Mj9HloZVHKId4bLjr6eIocwTxpkF0V212ja9W0QYHEjA0zGQSUB_VT7CufzIr1A","authors":{"content":[{"#name":"author-group","$":{"id":"ag005"},"$$":[{"#name":"author","$":{"id":"au005","author-id":"S135044952100195X-cf90afa1eb7777ce3dca10f342007ee9"},"$$":[{"#name":"given-name","_":"Haixia"},{"#name":"surname","_":"Xiao"},{"#name":"e-address","$":{"xmlns:xlink":true,"href":"mailto:32557372@qq.com","id":"em903","type":"email"},"_":"32557372@qq.com"}]},{"#name":"author","$":{"id":"au010","author-id":"S135044952100195X-cdb49612b436dc701772904d1fbefdca"},"$$":[{"#name":"given-name","_":"Zhengfa"},{"#name":"surname","_":"Hu"},{"#name":"cross-ref","$":{"refid":"cor1","id":"c9001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"href":"mailto:hzf_725@163.com","id":"em900","type":"email"},"_":"hzf_725@163.com"}]},{"#name":"affiliation","$":{"id":"af005","affiliation-id":"S135044952100195X-739ef2b11ef71c1e3c1e4f1c0ec10a9c"},"$$":[{"#name":"textfn","_":"School of Mathematics, Physics and Optoelectronic Engineering, Hubei University of Automotive Technology, Shiyan, Hubei 442002, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Mathematics, Physics and Optoelectronic Engineering"},{"#name":"organization","_":"Hubei University of Automotive Technology"},{"#name":"city","_":"Shiyan"},{"#name":"state","_":"Hubei"},{"#name":"postal-code","_":"442002"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"stx005"},"_":"School of Mathematics, Physics and Optoelectronic Engineering, Hubei University of Automotive Technology, Shiyan, Hubei 442002, China"}]},{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au010","author-id":"S135044952100195X-cdb49612b436dc701772904d1fbefdca"},"$$":[{"#name":"given-name","_":"Zhengfa"},{"#name":"surname","_":"Hu"},{"#name":"cross-ref","$":{"refid":"cor1","id":"c9001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"href":"mailto:hzf_725@163.com","id":"em900","type":"email"},"_":"hzf_725@163.com"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"tm005"},"_":"Feature-similarity network via soft-label training for infrared facial emotional classification in human-robot interaction"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"117","isThirdParty":false,"language":"en","issn-primary-unformatted":"13504495","issn-primary-formatted":"1350-4495"},{"pii":"S0925231218311238","doi":"10.1016/j.neucom.2018.09.050","journalTitle":"Neurocomputing","publicationYear":"2019","publicationDate":"2019-01-05","volumeSupText":"Volume 323","articleNumber":"","pageRange":"62-75","trace-token":"AAAAQGl9010qzIZ6fYtHMxBNaZBJEYAIaRpdopLbiN6JLEE94r_yBLXKfaWkqTHJAr4zgRtAjytmS7kHeGtyNgjMCmcXvphIFKVM5PBeuFBEYYLcTr78QQ","authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","biographyid":"auth1Bio1","author-id":"S0925231218311238-8a8bcbcb0ea5654c97ba5252b22085e6"},"$$":[{"#name":"surname","_":"Zhu"},{"#name":"given-name","_":"Zhiyu"},{"#name":"cross-ref","$":{"id":"crf0001","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"id":"au0002","biographyid":"auth2Bio2","author-id":"S0925231218311238-867e09acf237c4f53681fdaa1e525aef","orcid":"0000-0002-0911-830X"},"$$":[{"#name":"surname","_":"Peng"},{"#name":"given-name","_":"Gaoliang"},{"#name":"cross-ref","$":{"id":"crf0001p","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0012a","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]}]},{"#name":"author","$":{"id":"au0003","biographyid":"auth3Bio3","author-id":"S0925231218311238-e880833c1f27997c7ce26fbb3cb7c893"},"$$":[{"#name":"surname","_":"Chen"},{"#name":"given-name","_":"Yuanhang"},{"#name":"cross-ref","$":{"id":"crf0003","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"id":"au0004","biographyid":"auth4Bio4","author-id":"S0925231218311238-c24cfa9bf4e61c7c96af7488899b4501"},"$$":[{"#name":"surname","_":"Gao"},{"#name":"given-name","_":"Huijun"},{"#name":"cross-ref","$":{"id":"crf0004","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0005","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:pgl7782@hit.edu.cn","id":"ead0001a"},"_":"pgl7782@hit.edu.cn"}]},{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0925231218311238-eada8f77ca611705c5cc22be88802548"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"State Key Laboratory of Robotics and System, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin 150001, Heilongjiang Province, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"State Key Laboratory of Robotics and System"},{"#name":"organization","_":"Harbin Institute of Technology"},{"#name":"address-line","_":"No. 92 Xidazhi Street"},{"#name":"city","_":"Harbin"},{"#name":"state","_":"Heilongjiang Province"},{"#name":"postal-code","_":"150001"},{"#name":"country","_":"China"}]}]},{"#name":"affiliation","$":{"id":"aff0002","affiliation-id":"S0925231218311238-068aefb22ec39db384c23605c823787c"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","$":{"id":"cetextfn0002"},"_":"Research Institute of Intelligent Control and Systems, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin 150001, Heilongjiang Province, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Research Institute of Intelligent Control and Systems, Harbin Institute of Technology"},{"#name":"address-line","_":"No. 92 Xidazhi Street"},{"#name":"city","_":"Harbin"},{"#name":"state","_":"Heilongjiang Province"},{"#name":"postal-code","_":"150001"},{"#name":"country","_":"China"}]}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cetext0001"},"_":"Corresponding author at: State Key Laboratory of Robotics and System, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin 150001, Heilongjiang Province, China."},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"State Key Laboratory of Robotics and System"},{"#name":"organization","_":"Harbin Institute of Technology"},{"#name":"address-line","_":"No. 92 Xidazhi Street"},{"#name":"city","_":"Harbin"},{"#name":"state","_":"Heilongjiang Province"},{"#name":"postal-code","_":"150001"},{"#name":"country","_":"China"}]}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au0004","biographyid":"auth4Bio4","author-id":"S0925231218311238-c24cfa9bf4e61c7c96af7488899b4501"},"$$":[{"#name":"surname","_":"Gao"},{"#name":"given-name","_":"Huijun"},{"#name":"cross-ref","$":{"id":"crf0004","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0005","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:pgl7782@hit.edu.cn","id":"ead0001a"},"_":"pgl7782@hit.edu.cn"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"ct0001"},"_":"A convolutional neural network based on a capsule network with strong generalization for bearing fault diagnosis"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"323","isThirdParty":false,"language":"en","issn-primary-unformatted":"09252312","issn-primary-formatted":"0925-2312"}]},"references":{"content":[{"#name":"bibliography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"cebibl1","view":"all"},"$$":[{"#name":"section-title","$":{"id":"cesectitle0024"},"_":"References"},{"#name":"bibliography-sec","$":{"id":"cebibsec1","view":"all"},"$$":[{"#name":"bib-reference","$":{"id":"bib0001"},"$$":[{"#name":"label","_":"[1]"},{"#name":"reference","$":{"id":"sbref0001","refId":"1"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"He"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Overview of face recognition technology"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Intell. Comput. Appl."}]},{"#name":"volume-nr","_":"6"}]},{"#name":"issue-nr","_":"5"},{"#name":"date","_":"2016"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"112"},{"#name":"last-page","_":"114"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0001"},"_":"He C.Overview of face recognition technology. Intell. Comput. Appl., 2016,6 (5): 112–114."}]},{"#name":"bib-reference","$":{"id":"bib0002"},"$$":[{"#name":"label","_":"[2]"},{"#name":"reference","$":{"id":"sbref0002","refId":"2"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M.H."},{"#name":"surname","_":"Zhu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"S.T."},{"#name":"surname","_":"Li"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Hua"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Facial expression recognition method based on sparse representation"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Pattern Recognit. Artif. Intell."}]},{"#name":"volume-nr","_":"27"}]},{"#name":"issue-nr","_":"8"},{"#name":"date","_":"2014"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"708"},{"#name":"last-page","_":"712"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0002"},"_":"Zhu M.H., Li S.T., Hua Y.. Facial expression recognition method based on sparse representation. Pattern Recognit. Artif. Intell., 2014, 27(8): 708–712."}]},{"#name":"bib-reference","$":{"id":"bib0003"},"$$":[{"#name":"label","_":"[3]"},{"#name":"reference","$":{"id":"sbref0003","refId":"3"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Y.L."},{"#name":"surname","_":"Xue"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Mao"}]},{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Catalin-Daniel"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Robust facial expression recognition method under occlusion conditions"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Beijing Univ. Aeronaut. Astronaut."}]},{"#name":"volume-nr","_":"36"}]},{"#name":"issue-nr","_":"4"},{"#name":"date","_":"2010"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"429"},{"#name":"last-page","_":"433"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0003"},"_":"Xue Y.L., Mao X., Catalin-Daniel C., etc. Robust facial expression recognition method under occlusion conditions. J. Beijing Univ. Aeronaut. Astronaut., 2010, 36 (4): 429–433."}]},{"#name":"bib-reference","$":{"id":"bib0004"},"$$":[{"#name":"label","_":"[4]"},{"#name":"reference","$":{"id":"sbref0004","refId":"4"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Chenglin"}]},{"#name":"author","$$":[{"#name":"given-name","_":"P."},{"#name":"surname","_":"Hailong"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Face recognition framework based on effective computing and adversarial neural network and its implementation in machine vision for social robots"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Comput. Electr. Eng."}]},{"#name":"volume-nr","_":"92"}]},{"#name":"date","_":"2021"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"92"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0004"},"_":"Chenglin Y. and Hailong P.. Face recognition framework based on effective computing and adversarial neural network and its implementation in machine vision for social robots. Comput. Electr. Eng., 2021, 92."}]},{"#name":"bib-reference","$":{"id":"bib0005"},"$$":[{"#name":"label","_":"[5]"},{"#name":"reference","$":{"id":"sbref0005","refId":"5"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Sun"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Wang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Tang"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Deep learning face representation from predicting 10,000 classes"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"}]},{"#name":"date","_":"2014"},{"#name":"publisher","$$":[{"#name":"name","_":"Honolulu"},{"#name":"location","_":"HI"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1891"},{"#name":"last-page","_":"1898"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0005"},"_":"Sun Y., Wang X., Tang X.Deep learning face representation from predicting 10,000 classes. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Honolulu, HI, 2014: 1891–1898."}]},{"#name":"bib-reference","$":{"id":"bib0006"},"$$":[{"#name":"label","_":"[6]"},{"#name":"reference","$":{"id":"sbref0006","refId":"6"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Sun"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Chen"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Wang"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Deep learning face representation by joint identification verification"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings of the Advances in Neural Information Processing Systems"}]},{"#name":"date","_":"2014"},{"#name":"publisher","$$":[{"#name":"name","_":"Barcelona"},{"#name":"location","_":"SPAIN"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1988"},{"#name":"last-page","_":"1996"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0006"},"_":"Sun Y., Chen Y., Wang X., et al. Deep learning face representation by joint identification verificationProceedings of the Advances in Neural Information Processing Systems, Barcelona, SPAIN2014: 1988–1996."}]},{"#name":"bib-reference","$":{"id":"bib0007"},"$$":[{"#name":"label","_":"[7]"},{"#name":"reference","$":{"id":"sbref0007","refId":"7"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Sun"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Wang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Tang"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Deeply learned face representations are sparse, selective, and robust"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"}]},{"#name":"date","_":"2015"},{"#name":"publisher","$$":[{"#name":"name","_":"Honolulu"},{"#name":"location","_":"HI"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"2892"},{"#name":"last-page","_":"2900"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0007"},"_":"Sun Y., Wang X., Tang X.Deeply learned face representations are sparse, selective, and robust. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Honolulu, HI, 2015: 2892–2900."}]},{"#name":"bib-reference","$":{"id":"bib0008"},"$$":[{"#name":"label","_":"[8]"},{"#name":"reference","$":{"id":"sbref0008","refId":"8"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Schroff"}]},{"#name":"author","$$":[{"#name":"given-name","_":"D."},{"#name":"surname","_":"Kalenichenko"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Philbin"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Facenet: a unified embedding for face recognition and clustering"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"}]},{"#name":"date","_":"2015"},{"#name":"publisher","$$":[{"#name":"name","_":"Honolulu"},{"#name":"location","_":"HI"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"815"},{"#name":"last-page","_":"823"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0008"},"_":"Schroff F., Kalenichenko D., Philbin J.Facenet: a unified embedding for face recognition and clustering. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Honolulu, HI, 2015: 815–823."}]},{"#name":"bib-reference","$":{"id":"bib0009"},"$$":[{"#name":"label","_":"[9]"},{"#name":"reference","$":{"id":"sbref0009","refId":"9"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Taigman"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Yang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M.A."},{"#name":"surname","_":"Ranzato"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Deepface: closing the gap to human-level performance in face verification"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"}]},{"#name":"date","_":"2014"},{"#name":"publisher","$$":[{"#name":"name","_":"Honolulu"},{"#name":"location","_":"HI"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1701"},{"#name":"last-page","_":"1708"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0009"},"_":"Taigman Y., Yang M., Ranzato M.A., et al. Deepface: closing the gap to human-level performance in face verification. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, 2014: 1701–1708."}]},{"#name":"bib-reference","$":{"id":"bib0010"},"$$":[{"#name":"label","_":"[10]"},{"#name":"reference","$":{"id":"sbref0010","refId":"10"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Wen"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Zhang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Z."},{"#name":"surname","_":"Li"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A discriminative feature learning approach for deep face recognition"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"European Conference on Computer Vision"}]},{"#name":"date","_":"2016"},{"#name":"publisher","$$":[{"#name":"name","_":"Springer, Cham"},{"#name":"location","_":"Berlin"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"499"},{"#name":"last-page","_":"515"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0010"},"_":"Wen Y., Zhang K., Li Z., et al. A discriminative feature learning approach for deep face recognition. European Conference on Computer Vision. Springer, Cham, Berlin,2016: 499–515."}]},{"#name":"bib-reference","$":{"id":"bib0011"},"$$":[{"#name":"label","_":"[11]"},{"#name":"reference","$":{"id":"sbref0011","refId":"11"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"W."},{"#name":"surname","_":"Liu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Wen"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Z."},{"#name":"surname","_":"Yu"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Large-margin softmax loss for convolutional neural networks"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings of the International Conference on Machine Learning"}]},{"#name":"book-series","$$":[{"#name":"series","$$":[{"#name":"volume-nr","_":"2"}]}]},{"#name":"date","_":"2016"},{"#name":"publisher","$$":[{"#name":"name","_":"ICML"},{"#name":"location","_":"Stockholm."}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"7"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0011"},"_":"Liu W., Wen Y., Yu Z., et al. Large-margin softmax loss for convolutional neural networks. Proceedings of the International Conference on Machine Learning (ICML), Stockholm.2016, 2(3): 7."}]},{"#name":"bib-reference","$":{"id":"bib0012"},"$$":[{"#name":"label","_":"[12]"},{"#name":"reference","$":{"id":"sbref0012","refId":"12"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Wang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Cheng"}]},{"#name":"author","$$":[{"#name":"given-name","_":"W."},{"#name":"surname","_":"Liu"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Additive margin softmax for face verification"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"book-series","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IEEE Signal Processing Letters"}]},{"#name":"volume-nr","_":"25"}]}]},{"#name":"date","_":"2018"},{"#name":"publisher","$$":[{"#name":"name","_":"PISCATAWAY"},{"#name":"location","_":"USA"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"926"},{"#name":"last-page","_":"930"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0012"},"_":"Wang F., Cheng J., Liu W., et al. Additive margin softmax for face verification. IEEE Signal Processing Letters, PISCATAWAY, USA, 2018, 25(7): 926–930."}]},{"#name":"bib-reference","$":{"id":"bib0013"},"$$":[{"#name":"label","_":"[13]"},{"#name":"reference","$":{"id":"sbref0013","refId":"13"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Wang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Wang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Z."},{"#name":"surname","_":"Zhou"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"CosFace: large margin cosine loss for deep face recognition"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"}]},{"#name":"date","_":"2018"},{"#name":"publisher","$$":[{"#name":"name","_":"Honolulu"},{"#name":"location","_":"HI"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"5265"},{"#name":"last-page","_":"5274"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0013"},"_":"Wang H., Wang Y., Zhou Z., et al. CosFace: large margin cosine loss for deep face recognition. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, 2018: 5265–5274."}]},{"#name":"bib-reference","$":{"id":"bib0014"},"$$":[{"#name":"label","_":"[14]"},{"#name":"reference","$":{"id":"sbref0014","refId":"14"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Chen"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Liu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Gao"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"MobileFaceNets: efficient CNNs for accurate real-time face verification on mobile devices"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Chinese Conference on Biometric Recognition"}]},{"#name":"date","_":"2018"},{"#name":"publisher","$$":[{"#name":"name","_":"Springer, Cham"},{"#name":"location","_":"Berlin"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"428"},{"#name":"last-page","_":"438"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0014"},"_":"Chen S., Liu Y., Gao X., et al. MobileFaceNets: efficient CNNs for accurate real-time face verification on mobile devices. Chinese Conference on Biometric Recognition. Springer, Cham, Berlin, 2018: 428–438."}]},{"#name":"bib-reference","$":{"id":"bib0015"},"$$":[{"#name":"label","_":"[15]"},{"#name":"reference","$":{"id":"sbref0015","refId":"15"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Sandler"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Howard"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Zhu"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"MobileNetV2: inverted residuals and linear bottlenecks"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"}]},{"#name":"date","_":"2018"},{"#name":"publisher","$$":[{"#name":"name","_":"Honolulu"},{"#name":"location","_":"HI"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"4510"},{"#name":"last-page","_":"4520"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0015"},"_":"Sandler M., Howard A., Zhu M., et al. MobileNetV2: inverted residuals and linear bottlenecks. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, 2018: 4510–4520."}]},{"#name":"bib-reference","$":{"id":"bib0016"},"$$":[{"#name":"label","_":"[16]"},{"#name":"reference","$":{"id":"sbref0016","refId":"16"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Girshick"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Donahue"}]},{"#name":"author","$$":[{"#name":"given-name","_":"T."},{"#name":"surname","_":"Darrell"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"R-CNN for object detection"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings of the IEEE Conference"}]},{"#name":"date","_":"2014"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0016"},"_":"Girshick R., Donahue J., Darrell T., et al. R-CNN for object detection. Proceedings of the IEEE Conference. 2014."}]},{"#name":"bib-reference","$":{"id":"bib0017"},"$$":[{"#name":"label","_":"[17]"},{"#name":"other-ref","$":{"id":"sbref0017","refId":"17"},"$$":[{"#name":"textref","_":"Zhu G., Porikli F., Li H. Tracking randomly moving objects on edge box proposals. arXiv preprint arXiv: 1507.08085, 2015."}]}]},{"#name":"bib-reference","$":{"id":"bib0018"},"$$":[{"#name":"label","_":"[18]"},{"#name":"reference","$":{"id":"sbref0018","refId":"18"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"J.R.R."},{"#name":"surname","_":"Uijlings"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K.E.A."},{"#name":"surname","_":"Van De Sande"}]},{"#name":"author","$$":[{"#name":"given-name","_":"T."},{"#name":"surname","_":"Gevers"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Selective search for object recognition"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Int. J. Comput. Vis."}]},{"#name":"volume-nr","_":"104"}]},{"#name":"issue-nr","_":"2"},{"#name":"date","_":"2013"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"154"},{"#name":"last-page","_":"171"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0018"},"_":"Uijlings J.R.R., Van De Sande K.E.A., Gevers T., et al. Selective search for object recognition. Int. J. Comput. Vis., 2013, 104(2): 154–171."}]},{"#name":"bib-reference","$":{"id":"bib0019"},"$$":[{"#name":"label","_":"[19]"},{"#name":"reference","$":{"id":"sbref0019","refId":"19"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Lee"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J.H."},{"#name":"surname","_":"Kim"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K.W."},{"#name":"surname","_":"Oh"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Comparison of faster R-CNN models for object detection[C]//2016 16th international conference on control"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Automation and systems (iccas)"}]},{"#name":"date","_":"2016"},{"#name":"publisher","$$":[{"#name":"name","_":"IEEE"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"107"},{"#name":"last-page","_":"110"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0019"},"_":"Girshick R.Fast R-CNN. Proceedings of the IEEE International Conference on Computer Vision. 2015: 1440–1448."}]},{"#name":"bib-reference","$":{"id":"bib0020"},"$$":[{"#name":"label","_":"[20]"},{"#name":"reference","$":{"id":"sbref0020","refId":"20"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Ren"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"He"}]},{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Girshick"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Faster R-CNN: towards real-time object detection with region proposal networks"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IEEE transactions on pattern analysis and machine intelligence"}]},{"#name":"volume-nr","_":"39"}]},{"#name":"issue-nr","_":"6"},{"#name":"date","_":"2016"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1137"},{"#name":"last-page","_":"1149"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0020"},"_":"Ren S., He K., Girshick R., et al. Faster R-CNN: towards real-time object detection with region proposal networks. Adv. Neural Inf. Process. Syst., 2015, 28: 91–99."}]},{"#name":"bib-reference","$":{"id":"bib0025"},"$$":[{"#name":"label","_":"[21]"},{"#name":"reference","$":{"id":"sbref0025","refId":"21"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"X.X."},{"#name":"surname","_":"Zhang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Zhu"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Moving vehicle detection in aerial infrared image sequences via fast image registration and improved YOLOv3 network"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Int. J. Remote Sens."}]},{"#name":"volume-nr","_":"41"}]},{"#name":"issue-nr","_":"11"},{"#name":"date","_":"2020"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"4312"},{"#name":"last-page","_":"4335"}]}]}]},{"#name":"source-text","$":{"id":"srctxt0025"},"_":"Zhang X.X., Zhu X.Moving vehicle detection in aerial infrared image sequences via fast image registration and improved YOLOv3 network. Int. J. Remote Sens., 2020, 41(11): 4312–4335."}]},{"#name":"bib-reference","$":{"id":"bib0031"},"$$":[{"#name":"label","_":"[22]"},{"#name":"other-ref","$":{"id":"sbref0031","refId":"22"},"$$":[{"#name":"textref","_":"Nguyen H.T. Contributions to facial feature extraction for face recognition. université de grenoble, 2014."}]}]},{"#name":"bib-reference","$":{"id":"bib0032"},"$$":[{"#name":"label","_":"[23]"},{"#name":"reference","$":{"id":"sbref0032","refId":"23"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Z."},{"#name":"surname","_":"Tang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"G."},{"#name":"surname","_":"Zhao"}]},{"#name":"author","$$":[{"#name":"given-name","_":"T."},{"#name":"surname","_":"Ouyang"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Two-phase deep learning model for short-term wind direction forecasting"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Renew. Energy"}]},{"#name":"volume-nr","_":"173"}]},{"#name":"date","_":"2021"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1005"},{"#name":"last-page","_":"1016"}]},{"#name":"doi","_":"10.1016/j.renene.2021.04.041"}]}]},{"#name":"source-text","$":{"id":"srctxt0032"},"_":"Tang Z., Zhao G., Ouyang T., Two-phase deep learning model for short-term wind direction forecasting, Renew. Energy, 173 (2021) 1005–1016. 10.1016/j.renene.2021.04.041"}]},{"#name":"bib-reference","$":{"id":"bib0033"},"$$":[{"#name":"label","_":"[24]"},{"#name":"reference","$":{"id":"sbref0033","refId":"24"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Lunerti"}]},{"#name":"author","$$":[{"#name":"given-name","_":"R.M."},{"#name":"surname","_":"Guest"}]},{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Blanco-Gonzalo"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Environmental effects on face recognition in smartphones"}]}]},{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings of the 51st IEEE International Carnahan Conference on Security Technology"}]},{"#name":"date","_":"2017"},{"#name":"publisher","$$":[{"#name":"name","_":"IEEE"}]}]}]}]},{"#name":"source-text","$":{"id":"srctxt0033"},"_":"Lunerti C., Guest R.M., Blanco-Gonzalo R., et al. Environmental effects on face recognition in smartphones. Proceedings of the 51st IEEE International Carnahan Conference on Security Technology. IEEE, 2017."}]},{"#name":"bib-reference","$":{"id":"bib0034"},"$$":[{"#name":"label","_":"[25]"},{"#name":"reference","$":{"id":"sbref0034","refId":"25"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Z.H."},{"#name":"surname","_":"Tang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y.Y."},{"#name":"surname","_":"Li"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X.Y."},{"#name":"surname","_":"Chai"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H.Y."},{"#name":"surname","_":"Zhang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"S.X."},{"#name":"surname","_":"Cao"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Adaptive nonlinear model predictive control of NOx emissions under load constraints in power plant boilers"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Chem. Eng. Jpn."}]},{"#name":"volume-nr","_":"53"}]},{"#name":"issue-nr","_":"1"},{"#name":"date","_":"2020"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"36"},{"#name":"last-page","_":"44"}]},{"#name":"doi","_":"10.1252/jcej.19we142"}]}]},{"#name":"source-text","$":{"id":"srctxt0034"},"_":"Tang Z.H., Li Y.Y., Chai X.Y., Zhang H.Y., Cao S.X.Adaptive nonlinear model predictive control of NOx emissions under load constraints in power plant boilers. J. Chem. Eng. Jpn., vol. 53, no. 1, pp. 36–44, 2020. DOI: 10.1252/jcej.19we142."}]},{"#name":"bib-reference","$":{"id":"bib35"},"$$":[{"#name":"label","_":"[26]"},{"#name":"reference","$":{"id":"opt7bwxPMRLvV","refId":"26"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"L.C."},{"#name":"surname","_":"Yan"}]},{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"Yoshua"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Geoffrey"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Deep learning"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Nature"}]},{"#name":"volume-nr","_":"521"}]},{"#name":"issue-nr","_":"7553"},{"#name":"date","_":"2015"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"436"},{"#name":"last-page","_":"444"}]}]}]},{"#name":"source-text","$":{"id":"srctbib35"},"_":"L. C. Yan, B. Yoshua, H. Geoffrey, Deep learning, Nature 521 (7553) (2015) 436–444."}]},{"#name":"bib-reference","$":{"id":"bib36"},"$$":[{"#name":"label","_":"[27]"},{"#name":"other-ref","$":{"id":"tboref0001","refId":"27"},"$$":[{"#name":"textref","_":"Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014."}]}]},{"#name":"bib-reference","$":{"id":"bib42"},"$$":[{"#name":"label","_":"[28]"},{"#name":"other-ref","$":{"id":"tboref0005","refId":"28"},"$$":[{"#name":"textref","_":"Knyazev B., Shvetsov R., Efremova N., et al. Convolutional neural networks pretrained on large face recognition datasets for emotion classification from video. arXiv preprint arXiv:1711.04598, 2017."}]}]},{"#name":"bib-reference","$":{"id":"bib43"},"$$":[{"#name":"label","_":"[29]"},{"#name":"other-ref","$":{"id":"tboref0006","refId":"29"},"$$":[{"#name":"textref","_":"Yue-Hei Ng J, Hausknecht M, Vijayanarasimhan S, et al. Beyond short snippets: Deep networks for video classification[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2015: 4694-4702."}]}]},{"#name":"bib-reference","$":{"id":"bib45"},"$$":[{"#name":"label","_":"[30]"},{"#name":"other-ref","$":{"id":"tboref0007","refId":"30"},"$$":[{"#name":"textref","_":"Gabrielsson S. A moral endeavour in a demoralizing context: Psychiatric inpatient care from the perspective of professional caregivers[D]. Luleå tekniska universitet, 2015."}]}]},{"#name":"bib-reference","$":{"id":"bib46"},"$$":[{"#name":"label","_":"[31]"},{"#name":"other-ref","$":{"id":"tboref0008","refId":"31"},"$$":[{"#name":"textref","_":"Nazir D, Hashmi KA, Pagani A, et al. Title. Preprints 2021, 1, 0[C]//Conference on Document Analysis and Recognition (ICDAR). IEEE. s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affil-iations. 1 Department of Computer Science, Technical University of Kaiserslautern, 67663 Kaiserslautern, Germany; dn8034@gmail. com (DN); khurram_azeem. hashmi@ dfki. de (KAH); muhammad_zeshan. afzal@ dfki. de (MZA); alain. pagani@ dfki. de (AP); didier. stricker@ dfki. de (DS); 2 Mindgarage, Technical University of Kaiserslautern, 67663 Kaiserslautern, Germany 3 German Research Institute for Artificial Intelligence (DFKI), 67663 Kaiserslautern, Germany, 4 Department of Computer Science, Luleå University of Technology, 971 87 Luleå, Sweden; marcus. liwicki@ ltu. se (ML);, 2017, 1: 1417-1422."}]}]},{"#name":"bib-reference","$":{"id":"bib47"},"$$":[{"#name":"label","_":"[32]"},{"#name":"reference","$":{"id":"optUU6uwujjWH","refId":"32"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"W."},{"#name":"surname","_":"Chen"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Fang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y.H."},{"#name":"surname","_":"Liu"}]},{"#name":"et-al"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Monocular semantic SLAM in dynamic street scene based on multiple object tracking[C]//2017"}]},{"#name":"date","_":"2017"},{"#name":"publisher","$$":[{"#name":"name","_":"IEEE"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"599"},{"#name":"last-page","_":"604"}]}]}]},{"#name":"source-text","$":{"id":"srctbib47"},"_":"Chen W., Fang M., Liu Y.H., et al. Monocular semantic SLAM in dynamic street scene based on multiple object tracking[C]//2017 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM). IEEE, 2017: 599-604."}]},{"#name":"bib-reference","$":{"id":"bib48"},"$$":[{"#name":"label","_":"[33]"},{"#name":"other-ref","$":{"id":"tboref0009","refId":"33"},"$$":[{"#name":"textref","_":"Xu X., Dou P., Le H.A., et al. When 3D-Aided 2D Face Recognition Meets Deep Learning: An extended UR2D for Pose-Invariant Face Recognition[J]. arXiv preprint arXiv:1709.06532, 2017."}]}]},{"#name":"bib-reference","$":{"id":"bib49"},"$$":[{"#name":"label","_":"[34]"},{"#name":"reference","$":{"id":"optYUOl9VjEWD","refId":"34"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Wang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Ding"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Guo"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Mask OBB: A semantic attention-based mask oriented bounding box representation for multi-category object detection in aerial images[J]"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Remote Sensing"}]},{"#name":"volume-nr","_":"11"}]},{"#name":"issue-nr","_":"24"},{"#name":"date","_":"2019"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"2930"}]}]}]},{"#name":"source-text","$":{"id":"srctbib49"},"_":"J. Wang, J. Ding, H. Guo, et al., Mask OBB: A semantic attention-based mask oriented bounding box representation for multi-category object detection in aerial images[J], Remote Sensing 11 (24) (2019) 2930."}]},{"#name":"bib-reference","$":{"id":"bib50"},"$$":[{"#name":"label","_":"[35]"},{"#name":"other-ref","$":{"id":"tboref0010","refId":"35"},"$$":[{"#name":"textref","_":"Felsberg M., Five years after the Deep Learning revolution of computer vision: State of the art methods for online image and video analysis[J]. 2017."}]}]},{"#name":"bib-reference","$":{"id":"bib51"},"$$":[{"#name":"label","_":"[36]"},{"#name":"other-ref","$":{"id":"tboref0011","refId":"36"},"$$":[{"#name":"textref","_":"Rezaei M, Azarmi M. Deepsocial: Social distancing monitoring and infection risk assessment in covid-19 pandemic[J]. Applied Sciences, 2020, 10(21): 7514."}]}]},{"#name":"bib-reference","$":{"id":"bib52"},"$$":[{"#name":"label","_":"[37]"},{"#name":"reference","$":{"id":"optmlLMqrTk2L","refId":"37"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Paul"}]},{"#name":"author","$$":[{"#name":"given-name","_":"L."},{"#name":"surname","_":"Singh"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A review on advances in deep learning[C]//2015 IEEE Workshop on Computational Intelligence: Theories, Applications and Future Directions (WCI)"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IEEE"}]}]},{"#name":"date","_":"2015"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"6"}]}]}]},{"#name":"source-text","$":{"id":"srctbib52"},"_":"S. Paul, L. Singh, A review on advances in deep learning[C]//2015 IEEE Workshop on Computational Intelligence: Theories, Applications and Future Directions (WCI), IEEE (2015) 1–6."}]},{"#name":"bib-reference","$":{"id":"bib53"},"$$":[{"#name":"label","_":"[38]"},{"#name":"reference","$":{"id":"optC6qbkHLwtK","refId":"38"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"H"},{"#name":"surname","_":"Ge"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y"},{"#name":"surname","_":"Dai"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Z"},{"#name":"surname","_":"Zhu"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A Robust Face Recognition Algorithm Based on an Improved Generative Confrontation Network[J]"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Applied Sciences"}]},{"#name":"volume-nr","_":"11"}]},{"#name":"issue-nr","_":"24"},{"#name":"date","_":"2021"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"11588"}]}]}]},{"#name":"source-text","$":{"id":"srctbib53"},"_":"H Ge, Y Dai, Z Zhu, et al., A Robust Face Recognition Algorithm Based on an Improved Generative Confrontation Network[J], Applied Sciences 11 (24) (2021) 11588."}]}]}]}],"floats":[],"footnotes":[],"attachments":[],"sourceTextMap":{"1":"He C.Overview of face recognition technology. Intell. Comput. Appl., 2016,6 (5): 112–114.","2":"Zhu M.H., Li S.T., Hua Y.. Facial expression recognition method based on sparse representation. Pattern Recognit. Artif. Intell., 2014, 27(8): 708–712.","3":"Xue Y.L., Mao X., Catalin-Daniel C., etc. Robust facial expression recognition method under occlusion conditions. J. Beijing Univ. Aeronaut. Astronaut., 2010, 36 (4): 429–433.","4":"Chenglin Y. and Hailong P.. Face recognition framework based on effective computing and adversarial neural network and its implementation in machine vision for social robots. Comput. Electr. Eng., 2021, 92.","5":"Sun Y., Wang X., Tang X.Deep learning face representation from predicting 10,000 classes. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Honolulu, HI, 2014: 1891–1898.","6":"Sun Y., Chen Y., Wang X., et al. Deep learning face representation by joint identification verificationProceedings of the Advances in Neural Information Processing Systems, Barcelona, SPAIN2014: 1988–1996.","7":"Sun Y., Wang X., Tang X.Deeply learned face representations are sparse, selective, and robust. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Honolulu, HI, 2015: 2892–2900.","8":"Schroff F., Kalenichenko D., Philbin J.Facenet: a unified embedding for face recognition and clustering. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Honolulu, HI, 2015: 815–823.","9":"Taigman Y., Yang M., Ranzato M.A., et al. Deepface: closing the gap to human-level performance in face verification. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, 2014: 1701–1708.","10":"Wen Y., Zhang K., Li Z., et al. A discriminative feature learning approach for deep face recognition. European Conference on Computer Vision. Springer, Cham, Berlin,2016: 499–515.","11":"Liu W., Wen Y., Yu Z., et al. Large-margin softmax loss for convolutional neural networks. Proceedings of the International Conference on Machine Learning (ICML), Stockholm.2016, 2(3): 7.","12":"Wang F., Cheng J., Liu W., et al. Additive margin softmax for face verification. IEEE Signal Processing Letters, PISCATAWAY, USA, 2018, 25(7): 926–930.","13":"Wang H., Wang Y., Zhou Z., et al. CosFace: large margin cosine loss for deep face recognition. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, 2018: 5265–5274.","14":"Chen S., Liu Y., Gao X., et al. MobileFaceNets: efficient CNNs for accurate real-time face verification on mobile devices. Chinese Conference on Biometric Recognition. Springer, Cham, Berlin, 2018: 428–438.","15":"Sandler M., Howard A., Zhu M., et al. MobileNetV2: inverted residuals and linear bottlenecks. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, 2018: 4510–4520.","16":"Girshick R., Donahue J., Darrell T., et al. R-CNN for object detection. Proceedings of the IEEE Conference. 2014.","18":"Uijlings J.R.R., Van De Sande K.E.A., Gevers T., et al. Selective search for object recognition. Int. J. Comput. Vis., 2013, 104(2): 154–171.","19":"Girshick R.Fast R-CNN. Proceedings of the IEEE International Conference on Computer Vision. 2015: 1440–1448.","20":"Ren S., He K., Girshick R., et al. Faster R-CNN: towards real-time object detection with region proposal networks. Adv. Neural Inf. Process. Syst., 2015, 28: 91–99.","21":"Zhang X.X., Zhu X.Moving vehicle detection in aerial infrared image sequences via fast image registration and improved YOLOv3 network. Int. J. Remote Sens., 2020, 41(11): 4312–4335.","23":"Tang Z., Zhao G., Ouyang T., Two-phase deep learning model for short-term wind direction forecasting, Renew. Energy, 173 (2021) 1005–1016. 10.1016/j.renene.2021.04.041","24":"Lunerti C., Guest R.M., Blanco-Gonzalo R., et al. Environmental effects on face recognition in smartphones. Proceedings of the 51st IEEE International Carnahan Conference on Security Technology. IEEE, 2017.","25":"Tang Z.H., Li Y.Y., Chai X.Y., Zhang H.Y., Cao S.X.Adaptive nonlinear model predictive control of NOx emissions under load constraints in power plant boilers. J. Chem. Eng. Jpn., vol. 53, no. 1, pp. 36–44, 2020. DOI: 10.1252/jcej.19we142.","26":"L. C. Yan, B. Yoshua, H. Geoffrey, Deep learning, Nature 521 (7553) (2015) 436–444.","32":"Chen W., Fang M., Liu Y.H., et al. Monocular semantic SLAM in dynamic street scene based on multiple object tracking[C]//2017 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM). IEEE, 2017: 599-604.","34":"J. Wang, J. Ding, H. Guo, et al., Mask OBB: A semantic attention-based mask oriented bounding box representation for multi-category object detection in aerial images[J], Remote Sensing 11 (24) (2019) 2930.","37":"S. Paul, L. Singh, A review on advances in deep learning[C]//2015 IEEE Workshop on Computational Intelligence: Theories, Applications and Future Directions (WCI), IEEE (2015) 1–6.","38":"H Ge, Y Dai, Z Zhu, et al., A Robust Face Recognition Algorithm Based on an Improved Generative Confrontation Network[J], Applied Sciences 11 (24) (2021) 11588."}},"referenceLinks":{"external":[{"refId":1,"crossRefDoi":"10.5539/mas.v10n5p112"},{"refId":2,"scopusHubEid":"2-s2.0-84907253480"},{"refId":3,"scopusHubEid":"2-s2.0-77953111023"},{"refId":5,"scopusHubEid":"2-s2.0-84911126535"},{"refId":6,"scopusHubEid":"2-s2.0-84937852544"},{"refId":7,"scopusHubEid":"2-s2.0-84946769681","crossRefDoi":"10.1109/CVPR.2015.7298907"},{"refId":8,"crossRefDoi":"10.1109/CVPR.2015.7298682"},{"refId":10,"scopusHubEid":"2-s2.0-84990032583","crossRefDoi":"10.1007/978-3-319-46478-7_31"},{"refId":12,"scopusHubEid":"2-s2.0-85047850608","crossRefDoi":"10.1109/lsp.2018.2822810"},{"refId":13,"scopusHubEid":"2-s2.0-85062873611","crossRefDoi":"10.1109/cvpr.2018.00552"},{"refId":14,"scopusHubEid":"2-s2.0-85051949375","crossRefDoi":"10.1007/978-3-319-97909-0_46"},{"refId":15,"scopusHubEid":"2-s2.0-85062799511","crossRefDoi":"10.1109/cvpr.2018.00474"},{"refId":18,"scopusHubEid":"2-s2.0-84881160857","crossRefDoi":"10.1007/s11263-013-0620-5"},{"refId":19,"scopusHubEid":"2-s2.0-85014025184"},{"refId":20,"scopusHubEid":"2-s2.0-85043768094","crossRefDoi":"10.1007/s10600-016-1887-x"},{"refId":21,"scopusHubEid":"2-s2.0-85079236695","crossRefDoi":"10.1080/01431161.2020.1717666"},{"refId":23,"scopusHubEid":"2-s2.0-85104604549"},{"refId":25,"scopusHubEid":"2-s2.0-85094621226","crossRefDoi":"10.1252/jcej.19we142"},{"refId":26,"scopusHubEid":"2-s2.0-84926420864","crossRefDoi":"10.1080/09205071.2014.992552"},{"refId":32,"scopusHubEid":"2-s2.0-85049090117","crossRefDoi":"10.1109/ICCIS.2017.8274845"},{"refId":34,"scopusHubEid":"2-s2.0-85077897231","crossRefDoi":"10.3390/rs11242930"},{"refId":37,"scopusHubEid":"2-s2.0-85049415611"},{"refId":38,"scopusHubEid":"2-s2.0-85120815534","crossRefDoi":"10.3390/app112411588"}],"internal":[{"refId":23,"pii":"S0960148121005590","filesize":"3MB","pdf":{"urlType":"download","url":"/science/article/pii/S0960148121005590/pdfft?md5=851a7124ab11b820ccf17f5c0017ffbd&pid=1-s2.0-S0960148121005590-main.pdf"}}]},"refersTo":{},"referredToBy":{},"relatedContent":{"isModal":false,"isOpenSpecialIssueArticles":false,"isOpenVirtualSpecialIssueLink":false,"isOpenRecommendations":true,"isOpenSubstances":true,"citingArticles":[false,false,false,false,false,false],"recommendations":[false,false,false,false,false,false]},"seamlessAccess":{},"specialIssueArticles":{},"substances":{},"supplementaryFilesData":[],"tableOfContents":{"outlineTitle":"Outline","outline":[{"#name":"entry","$":{"id":"abs0001","type":"abstract","class":"author-highlights","depth":"1"},"$$":[{"#name":"title","$":{"id":"cesectitle0001"},"_":"Highlights"}]},{"#name":"entry","$":{"id":"abs0002","type":"abstract","class":"author","depth":"1"},"$$":[{"#name":"title","$":{"id":"cesectitle0002"},"_":"Abstract"},{"#name":"entry","$":{"id":"abss0003","depth":"2"},"$$":[{"#name":"title","$":{"id":"cesectitle0003"},"_":"Background and objective"}]},{"#name":"entry","$":{"id":"abss0004","depth":"2"},"$$":[{"#name":"title","$":{"id":"cesectitle0004"},"_":"Methods"}]},{"#name":"entry","$":{"id":"abss0005","depth":"2"},"$$":[{"#name":"title","$":{"id":"cesectitle0005"},"_":"Discussion and results"}]},{"#name":"entry","$":{"id":"abss0006","depth":"2"},"$$":[{"#name":"title","$":{"id":"cesectitle0006"},"_":"Conclusion"}]}]},{"#name":"entry","$":{"id":"keys0001","type":"keywords","class":"keyword","depth":"1"},"$$":[{"#name":"title","$":{"id":"cesectitle0007"},"_":"Keywords"}]},{"#name":"entry","$":{"id":"sec0001","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"1"},{"#name":"title","$":{"id":"cesectitle0008"},"_":"Introduction"}]},{"#name":"entry","$":{"id":"sec0002","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"2"},{"#name":"title","$":{"id":"cesectitle0009"},"_":"Related research"},{"#name":"entry","$":{"id":"sec0003","depth":"2"},"$$":[{"#name":"label","_":"2.1"},{"#name":"title","$":{"id":"cesectitle0010"},"_":"Review of face recognition technology"}]},{"#name":"entry","$":{"id":"sec0004","depth":"2"},"$$":[{"#name":"label","_":"2.2"},{"#name":"title","$":{"id":"cesectitle0011"},"_":"Research status of target detection at home and abroad"}]}]},{"#name":"entry","$":{"id":"sec0005","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"3"},{"#name":"title","$":{"id":"cesectitle0012"},"_":"Methods"},{"#name":"entry","$":{"id":"sec0006","depth":"2"},"$$":[{"#name":"label","_":"3.1"},{"#name":"title","$":{"id":"cesectitle0013"},"_":"Depth target detection algorithm"}]},{"#name":"entry","$":{"id":"sec0007","depth":"2"},"$$":[{"#name":"label","_":"3.2"},{"#name":"title","$":{"id":"cesectitle0014"},"_":"Joint optimization method"}]},{"#name":"entry","$":{"id":"sec0008","depth":"2"},"$$":[{"#name":"label","_":"3.3"},{"#name":"title","$":{"id":"cesectitle0015"},"_":"Occluded face recognition model based on dual discrimination countermeasure network"}]}]},{"#name":"entry","$":{"id":"sec0009","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"4"},{"#name":"title","$":{"id":"cesectitle0016"},"_":"Results"},{"#name":"entry","$":{"id":"sec0010","depth":"2"},"$$":[{"#name":"label","_":"4.1"},{"#name":"title","$":{"id":"cesectitle0017"},"_":"Deep facial expression recognition based on static image"}]},{"#name":"entry","$":{"id":"sec0011","depth":"2"},"$$":[{"#name":"label","_":"4.2"},{"#name":"title","$":{"id":"cesectitle0018"},"_":"Deep facial expression recognition network based on dynamic image sequence"}]},{"#name":"entry","$":{"id":"sec0012","depth":"2"},"$$":[{"#name":"label","_":"4.3"},{"#name":"title","$":{"id":"cesectitle0019"},"_":"Summary of target detection based on deep learning"}]}]},{"#name":"entry","$":{"id":"sec0013","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"5"},{"#name":"title","$":{"id":"cesectitle0020"},"_":"Discussion"}]},{"#name":"entry","$":{"id":"sec0014","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"6"},{"#name":"title","$":{"id":"cesectitle0021"},"_":"Conclusions"}]},{"#name":"entry","$":{"id":"coi0001","type":"conflict-of-interest","depth":"1"},"$$":[{"#name":"title","$":{"id":"cesectitle0022"},"_":"Declaration of Competing Interest"}]},{"#name":"entry","$":{"id":"ack0001","type":"acknowledgment","depth":"1"},"$$":[{"#name":"title","$":{"id":"cesectitle0023"},"_":"Acknowledgment"}]},{"#name":"entry","$":{"id":"cebibl1","type":"bibliography","depth":"1"},"$$":[{"#name":"title","$":{"id":"cesectitle0024"},"_":"References"}]}],"figures":[],"tables":[{"#name":"entry","$":{"id":"tbl0001","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 1"},{"#name":"caption","$":{"truncated":"false"},"_":"Comparison results between the proposed algorithm and other algorithms."}]}],"extras":[],"attachments":[],"showEntitledTocLinks":false},"tail":{},"transientError":{"isOpen":false},"sidePanel":{"openState":1},"viewConfig":{"articleFeature":{"rightsAndContentLink":true,"sdAnswersButton":false},"pathPrefix":""},"virtualSpecialIssue":{"showVirtualSpecialIssueLink":false},"usageProps":{"itemStage":"S300","isAip":false,"tombAip":"0","sample":false},"userCookiePreferences":{"STRICTLY_NECESSARY":true,"PERFORMANCE":false,"FUNCTIONAL":false,"TARGETING":false}};
      </script>
      <noscript>
      JavaScript is disabled on your browser.
      Please enable JavaScript to use all the features on this page.
      <img src=https://smetrics.elsevier.com/b/ss/elsevier-sd-prod/1/G.4--NS/1734890140997?pageName=sd%3Aproduct%3Ajournal%3Aarticle&c16=els%3Arp%3Ast&c2=sd&v185=img&v33=ae%3AANON_GUEST&c1=ae%3A228598&c12=ae%3A12975512 />
    </noscript>
      <div id="elementForFocusReset" tabindex="-1"></div><a class="anchor sr-only sr-only-focusable u-display-inline anchor-primary" href="#screen-reader-main-content"><span class="anchor-text-container"><span class="anchor-text">Skip to main content</span></span></a><a class="anchor sr-only sr-only-focusable u-display-inline anchor-primary" href="#screen-reader-main-title"><span class="anchor-text-container"><span class="anchor-text">Skip to article</span></span></a>
      <div id="root"><div class="App" id="app" data-aa-name="root"><div class="page"><div class="sd-flex-container"><div class="sd-flex-content"><header id="gh-cnt"><div id="gh-main-cnt" class="u-flex-center-ver u-position-relative u-padding-s-hor u-padding-l-hor-from-xl"><a id="gh-branding" class="u-flex-center-ver" href="/" aria-label="ScienceDirect home page" data-aa-region="header" data-aa-name="ScienceDirect"><img class="gh-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/24/images/elsevier-non-solus-new-grey.svg" alt="Elsevier logo" height="48" width="54"><svg xmlns="http://www.w3.org/2000/svg" version="1.1" height="15" viewBox="0 0 190 23" role="img" class="gh-wordmark u-margin-s-left" aria-labelledby="gh-wm-science-direct" focusable="false" aria-hidden="true" alt="ScienceDirect Wordmark"><title id="gh-wm-science-direct">ScienceDirect</title><g><path fill="#EB6500" d="M3.81 6.9c0-1.48 0.86-3.04 3.7-3.04 1.42 0 3.1 0.43 4.65 1.32l0.13-2.64c-1.42-0.63-2.97-0.96-4.78-0.96 -4.62 0-6.6 2.44-6.6 5.45 0 5.61 8.78 6.14 8.78 9.93 0 1.48-1.15 3.04-3.86 3.04 -1.72 0-3.4-0.56-4.72-1.39l-0.36 2.64c1.55 0.76 3.57 1.06 5.15 1.06 4.26 0 6.7-2.48 6.7-5.51C12.59 11.49 3.81 10.76 3.81 6.9M20.27 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.14 0-4.55-1.71-4.55-5.91C17.93 10.2 20.01 9.18 20.27 9.01"></path><rect x="29.42" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M30.67 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.68-0.96 1.68-1.88C32.35 1.55 31.56 0.7 30.67 0.7M48.06 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H48.06M39.91 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C38.56 10.27 39.71 9.37 39.91 9.18zM58.82 6.57c-2.24 0-3.63 1.12-4.85 2.61l-0.4-2.21h-2.34l0.13 1.19c0.1 0.76 0.13 1.78 0.13 2.97v10.79h2.54V11.88c0.69-0.96 2.15-2.48 2.48-2.64 0.23-0.13 1.29-0.4 2.08-0.4 2.28 0 2.48 1.15 2.54 3.43 0.03 1.19 0.03 3.17 0.03 3.17 0.03 3-0.1 6.47-0.1 6.47h2.54c0 0 0.07-4.49 0.07-6.96 0-1.48 0.03-2.97-0.1-4.46C63.31 7.43 61.49 6.57 58.82 6.57M72.12 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C69.77 10.2 71.85 9.18 72.12 9.01M92.74 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H92.74M84.59 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C83.24 10.27 84.39 9.37 84.59 9.18zM103.9 1.98h-7.13v19.93h6.83c7.26 0 9.77-5.68 9.77-10.03C113.37 7.33 110.93 1.98 103.9 1.98M103.14 19.8h-3.76V4.1h4.09c5.38 0 6.96 4.39 6.96 7.79C110.43 16.87 108.19 19.8 103.14 19.8zM118.38 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.69-0.96 1.69-1.88C120.07 1.55 119.28 0.7 118.38 0.7"></path><rect x="117.13" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M130.2 6.6c-1.62 0-2.87 1.45-3.4 2.74l-0.43-2.37h-2.34l0.13 1.19c0.1 0.76 0.13 1.75 0.13 2.9v10.86h2.54v-9.51c0.53-1.29 1.72-3.7 3.17-3.7 0.96 0 1.06 0.99 1.06 1.22l2.08-0.6V9.18c0-0.03-0.03-0.17-0.06-0.4C132.8 7.36 131.91 6.6 130.2 6.6M145.87 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.89-1.95-4.89-5.51v-0.49H145.87M137.72 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C136.37 10.27 137.52 9.37 137.72 9.18zM153.23 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.14-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.69 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C150.89 10.2 152.97 9.18 153.23 9.01M170 19.44c-0.92 0.36-1.72 0.69-2.51 0.69 -1.16 0-1.58-0.66-1.58-2.34V8.95h3.93V6.97h-3.93V2.97h-2.48v3.99h-2.71v1.98h2.71v9.67c0 2.64 1.39 3.73 3.33 3.73 1.15 0 2.54-0.39 3.43-0.79L170 19.44M173.68 5.96c-1.09 0-2-0.87-2-1.97 0-1.1 0.91-1.97 2-1.97s1.98 0.88 1.98 1.98C175.66 5.09 174.77 5.96 173.68 5.96zM173.67 2.46c-0.85 0-1.54 0.67-1.54 1.52 0 0.85 0.69 1.54 1.54 1.54 0.85 0 1.54-0.69 1.54-1.54C175.21 3.13 174.52 2.46 173.67 2.46zM174.17 5.05c-0.09-0.09-0.17-0.19-0.25-0.3l-0.41-0.56h-0.16v0.87h-0.39V2.92c0.22-0.01 0.47-0.03 0.66-0.03 0.41 0 0.82 0.16 0.82 0.64 0 0.29-0.21 0.55-0.49 0.63 0.23 0.32 0.45 0.62 0.73 0.91H174.17zM173.56 3.22l-0.22 0.01v0.63h0.22c0.26 0 0.43-0.05 0.43-0.34C174 3.28 173.83 3.21 173.56 3.22z"></path></g></svg></a><div class="gh-nav-cnt u-hide-from-print"><div class="gh-nav-links-container gh-nav-links-container-h u-hide-from-print gh-nav-content-container"><nav aria-label="links" class="gh-nav gh-nav-links gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-item gh-move-to-spine"><a class="anchor gh-nav-action text-s anchor-secondary anchor-medium" href="/browse/journals-and-books" id="gh-journals-books-link" data-aa-region="header" data-aa-name="Journals &amp; Books"><span class="anchor-text-container"><span class="anchor-text">Journals &amp; Books</span></span></a></li></ul></nav><nav aria-label="utilities" class="gh-nav gh-nav-utilities gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-help text-s u-flex-center-ver u-gap-6 gh-nav-action"><div class="gh-move-to-spine gh-help-button gh-help-icon gh-nav-item"><div class="popover" id="gh-help-icon-popover"><div id="popover-trigger-gh-help-icon-popover"><input type="hidden"><button class="button-link button-link-secondary gh-icon-btn button-link-medium button-link-icon-left" title="Help" aria-expanded="false" type="button"><svg focusable="false" viewBox="0 0 114 128" height="20" width="20" class="icon icon-help gh-icon"><path d="M57 8C35.69 7.69 15.11 21.17 6.68 40.71c-8.81 19.38-4.91 43.67 9.63 59.25 13.81 15.59 36.85 21.93 56.71 15.68 21.49-6.26 37.84-26.81 38.88-49.21 1.59-21.15-10.47-42.41-29.29-52.1C74.76 10.17 65.88 7.99 57 8zm0 10c20.38-.37 39.57 14.94 43.85 34.85 4.59 18.53-4.25 39.23-20.76 48.79-17.05 10.59-40.96 7.62-54.9-6.83-14.45-13.94-17.42-37.85-6.83-54.9C26.28 26.5 41.39 17.83 57 18zm-.14 14C45.31 32.26 40 40.43 40 50v2h10v-2c0-4.22 2.22-9.66 8-9.24 5.5.4 6.32 5.14 5.78 8.14C62.68 55.06 52 58.4 52 69.4V76h10v-5.56c0-8.16 11.22-11.52 12-21.7.74-9.86-5.56-16.52-16-16.74-.39-.01-.76-.01-1.14 0zM52 82v10h10V82H52z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Help</span></span></button></div></div></div></li><li class="gh-nav-search text-s u-flex-center-ver u-gap-6 gh-nav-action"><div class="gh-search-toggle gh-nav-item search-button-link"><a class="anchor button-link-secondary anchor-secondary u-margin-l-left gh-nav-action gh-icon-btn anchor-medium anchor-icon-left anchor-with-icon" href="/search" id="gh-search-link" title="Search" data-aa-button="search-in-header-opened-from-article" role="button"><svg focusable="false" viewBox="0 0 100 128" height="20" class="icon icon-search gh-icon"><path d="M19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6L73.23 80.19c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96S19.9 18.47 12.19 26.18C4.47 33.89.22 44.15.22 55.06s4.25 21.17 11.97 28.88C19.9 91.65 30.16 95.9 41.07 95.9c9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg><span class="anchor-text-container"><span class="anchor-text">Search</span></span></a></div></li></ul></nav></div></div><div class="gh-profile-container gh-move-to-spine u-hide-from-print"><a class="anchor text-s u-clr-grey8 u-margin-l-left gh-icon-btn anchor-primary anchor-medium anchor-icon-left anchor-with-icon" href="/user/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0169260722000062&amp;from=globalheader" id="gh-myaccount-btn" data-aa-region="header" data-aa-name="personalsignin"><svg focusable="false" viewBox="0 0 106 128" height="20" aria-hidden="true" class="icon icon-person gh-cta-btn-icon"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><span class="anchor-text-container"><span class="anchor-text">My account</span></span></a></div><a class="anchor text-s u-clr-grey8 gh-move-to-spine u-hide-from-print u-margin-l-left anchor-secondary gh-icon-btn anchor-medium anchor-icon-left anchor-with-icon" href="/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0169260722000062" id="gh-institutionalsignin-btn" data-aa-region="header" data-aa-name="institutionalsignin"><svg focusable="false" viewBox="0 0 106 128" height="20" aria-hidden="true" class="icon icon-institution gh-cta-btn-icon"><path d="M84 98h10v10H12V98h10V52h14v46h10V52h14v46h10V52h14v46zM12 36.86l41-20.84 41 20.84V42H12v-5.14zM104 52V30.74L53 4.8 2 30.74V52h10v36H2v30h102V88H94V52h10z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Sign in</span></span></a><div id="gh-mobile-menu" class="mobile-menu u-hide-from-print"><div class="gh-hamburger u-fill-grey7"><button class="button-link u-flex-center-ver button-link-primary button-link-icon-left" aria-label="Toggle mobile menu" aria-expanded="false" type="button"><svg class="gh-hamburger-svg-el gh-hamburger-closed" role="img" aria-hidden="true" height="20" width="20"><path d="M0 14h40v2H0zm0-7h40v2H0zm0-7h40v2H0z"></path></svg></button></div><div id="gh-overlay" class="mobile-menu-overlay u-overlay u-display-none" role="button" tabindex="-1"></div><div id="gh-drawer" aria-label="Mobile menu" class="" role="navigation"></div></div></div></header><div class="Article Preview" id="mathjax-container" role="main"><div class="accessbar-sticky"><div id="screen-reader-main-content"></div><div role="region" aria-label="Download options and search"><div class="accessbar"><div class="accessbar-label"></div><ul aria-label="PDF Options"><li class="accessbar-item-show-from-initial accessbar-item-show-from-xs accessbar-item-show-from-md RemoteAccess"><a class="link-button RemoteAccessButton accessbar-utility-component accessbar-utility-link link-button-primary link-button-icon-left" href="/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0169260722000062" aria-label="Access through your organization"><svg focusable="false" viewBox="0 0 106 128" height="20" aria-label="Seamless access" role="img" class="icon icon-institution"><path d="M84 98h10v10H12V98h10V52h14v46h10V52h14v46h10V52h14v46zM12 36.86l41-20.84 41 20.84V42H12v-5.14zM104 52V30.74L53 4.8 2 30.74V52h10v36H2v30h102V88H94V52h10z"></path></svg><span class="link-button-text-container"><span class="link-button-text"><span>Access through&nbsp;<strong>your organization</strong></span></span></span></a></li><li class="accessbar-item-hide-from-initial accessbar-item-hide-from-xs accessbar-item-show-from-md PurchasePDF"><a class="anchor accessbar-utility-component accessbar-utility-link anchor-primary" href="/getaccess/pii/S0169260722000062/purchase" target="_blank" aria-label="Purchase PDF" rel="noreferrer noopener"><span class="anchor-text-container"><span class="anchor-text"><span>Purchase PDF</span></span></span></a></li><li class="accessbar-item-hide-from-initial accessbar-item-hide-from-xs accessbar-item-show-from-md Divider"><span class="accessbar-divider"></span></li><li class="accessbar-item-hide-from-initial accessbar-item-hide-from-xs accessbar-item-show-from-md PatientAccess"><a class="anchor accessbar-utility-component accessbar-utility-link anchor-primary" href="https://www.elsevier.com/open-science/science-and-society/access-for-healthcare-and-patients" target="_blank" aria-label="Patient Access" rel="noreferrer noopener"><span class="anchor-text-container"><span class="anchor-text"><span>Patient Access</span></span></span></a></li><li class="accessbar-item-show-from-initial accessbar-item-show-from-xs accessbar-item-hide-from-md OverflowPopover"><div class="popover accessbar-overflow-popover" id="OverflowPopoverAnchor"><div id="popover-trigger-OverflowPopoverAnchor"><button class="button-link accessbar-utility-component button-link-primary button-link-icon-right" aria-label="Other access options" type="button"><span class="button-link-text-container"><span class="button-link-text"><span>Other access options</span></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div></div></li></ul><form class="QuickSearch" action="/search#submit" method="get" aria-label="form"><div class="search-input"><div class="search-input-container search-input-container-no-label"><label class="search-input-label u-hide-visually" for="article-quick-search">Search ScienceDirect</label><input type="text" id="article-quick-search" name="qs" class="search-input-field" aria-describedby="article-quick-search-description-message" aria-invalid="false" aria-label="Search ScienceDirect" placeholder="Search ScienceDirect" value=""></div><div class="search-input-message-container"><div class="search-input-validation-error" aria-live="polite"></div><div id="article-quick-search-description-message"></div></div></div><button type="submit" class="button u-margin-xs-left button-primary small button-icon-only" aria-disabled="false" aria-label="Submit search"><svg focusable="false" viewBox="0 0 100 128" height="20" class="icon icon-search"><path d="M19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6L73.23 80.19c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96S19.9 18.47 12.19 26.18C4.47 33.89.22 44.15.22 55.06s4.25 21.17 11.97 28.88C19.9 91.65 30.16 95.9 41.07 95.9c9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></button><input type="hidden" name="origin" value="article"><input type="hidden" name="zone" value="qSearch"></form></div></div></div><div class="article-wrapper u-padding-s-top grid row"><div role="navigation" aria-label="Table of Contents" class="preview-sidebar u-display-block-from-lg col-lg-6"><div class="PreviewTableOfContents"><h2 class="u-h4 preview-table-of-contents-title">Article preview</h2><ul class="preview-table-of-contents-list"><li id="preview-section-abstract-item" class=""><a class="anchor anchor-primary" href="#preview-section-abstract"><span class="anchor-text-container"><span class="anchor-text">Abstract</span></span></a></li><li id="preview-section-introduction-item" class=""><a class="anchor anchor-primary" href="#preview-section-introduction"><span class="anchor-text-container"><span class="anchor-text">Introduction</span></span></a></li><li id="preview-section-snippets-item" class=""><a class="anchor anchor-primary" href="#preview-section-snippets"><span class="anchor-text-container"><span class="anchor-text">Section snippets</span></span></a></li><li id="preview-section-references-item" class=""><a class="anchor anchor-primary" href="#preview-section-references"><span class="anchor-text-container"><span class="anchor-text">References (38)</span></span></a></li><li id="preview-section-cited-by-item" class=""><a class="anchor anchor-primary" href="#preview-section-cited-by"><span class="anchor-text-container"><span class="anchor-text">Cited by (86)</span></span></a></li></ul></div></div><article class="col-lg-12 col-md-16 pad-left pad-right" lang="en"><div class="Publication" id="publication"><div class="publication-brand u-display-block-from-sm"><a class="anchor u-display-flex anchor-primary" href="/journal/computer-methods-and-programs-in-biomedicine" title="Go to Computer Methods and Programs in Biomedicine on ScienceDirect"><span class="anchor-text-container"><span class="anchor-text"><img class="publication-brand-image" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1/image/elsevier-non-solus.png" alt="Elsevier"></span></span></a></div><div class="publication-volume u-text-center"><h2 class="publication-title u-h3" id="publication-title"><a class="anchor anchor-secondary publication-title-link" href="/journal/computer-methods-and-programs-in-biomedicine" title="Go to Computer Methods and Programs in Biomedicine on ScienceDirect"><span class="anchor-text-container"><span class="anchor-text">Computer Methods and Programs in Biomedicine</span></span></a></h2><div class="text-xs"><a class="anchor anchor-primary" href="/journal/computer-methods-and-programs-in-biomedicine/vol/215/suppl/C" title="Go to table of contents for this volume/issue"><span class="anchor-text-container"><span class="anchor-text">Volume 215</span></span></a>, <!-- -->March 2022<!-- -->, 106621</div></div><div class="publication-cover u-display-block-from-sm"><a class="anchor u-display-flex anchor-primary" href="/journal/computer-methods-and-programs-in-biomedicine/vol/215/suppl/C"><span class="anchor-text-container"><span class="anchor-text"><img class="publication-cover-image" src="https://ars.els-cdn.com/content/image/1-s2.0-S0169260721X00181-cov150h.gif" alt="Computer Methods and Programs in Biomedicine"></span></span></a></div></div><div class="PageDivider"></div><h1 id="screen-reader-main-title" class="Head u-font-serif u-h2 u-margin-s-ver"><span class="title-text">Facial expression recognition based on deep learning</span></h1><div class="Banner" id="banner"><div class="wrapper truncated"><div aria-live="polite"></div><div class="AuthorGroups"><div class="author-group" id="author-group"><span class="sr-only">Author links open overlay panel</span><button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au0001" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Huilin</span> <span class="text surname">Ge</span></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au0002" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Zhiyu</span> <span class="text surname">Zhu</span></span><svg focusable="false" viewBox="0 0 106 128" height="20" title="Correspondence author icon" class="icon icon-person react-xocs-author-icon u-fill-grey8"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><svg focusable="false" viewBox="0 0 102 128" height="20" title="Author email or social media contact details icon" class="icon icon-envelope react-xocs-author-icon u-fill-grey8"><path d="M55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0L17.58 34h69.54L55.8 57.19zM0 32.42l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-.98 9.42-2.93L102 34.34V24H0zM92 88.9L73.94 66.16l-8.04 5.95L83.28 94H18.74l18.38-23.12-8.04-5.96L10 88.94V51.36L0 42.9V104h102V44.82l-10 8.46V88.9"></path></svg></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au0003" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Yuewei</span> <span class="text surname">Dai</span></span><svg focusable="false" viewBox="0 0 106 128" height="20" title="Correspondence author icon" class="icon icon-person react-xocs-author-icon u-fill-grey8"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><svg focusable="false" viewBox="0 0 102 128" height="20" title="Author email or social media contact details icon" class="icon icon-envelope react-xocs-author-icon u-fill-grey8"><path d="M55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0L17.58 34h69.54L55.8 57.19zM0 32.42l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-.98 9.42-2.93L102 34.34V24H0zM92 88.9L73.94 66.16l-8.04 5.95L83.28 94H18.74l18.38-23.12-8.04-5.96L10 88.94V51.36L0 42.9V104h102V44.82l-10 8.46V88.9"></path></svg></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au0004" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Biao</span> <span class="text surname">Wang</span></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au0005" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Xuedong</span> <span class="text surname">Wu</span></span></span></span></button></div></div></div><button class="button-link u-margin-s-ver button-link-primary button-link-icon-right" id="show-more-btn" type="button" data-aa-button="icon-expand"><span class="button-link-text-container"><span class="button-link-text">Show more</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="banner-options u-padding-xs-bottom"><button class="button-link AddToMendeley button-link-secondary u-margin-s-right u-display-inline-flex-from-md button-link-icon-left button-link-has-colored-icon" type="button"><svg focusable="false" viewBox="0 0 86 128" height="20" class="icon icon-plus"><path d="M48 58V20H38v38H0v10h38v38h10V68h38V58z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Add to Mendeley</span></span></button><div class="Social u-display-inline-block" id="social"><div class="popover social-popover" id="social-popover"><div id="popover-trigger-social-popover"><button class="button-link button-link-secondary u-margin-s-right button-link-icon-left button-link-has-colored-icon" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 114 128" height="20" class="icon icon-share"><path d="M90 112c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zM24 76c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zm66-60c6.62 0 12 5.38 12 12s-5.38 12-12 12-12-5.38-12-12 5.38-12 12-12zm0 62c-6.56 0-12.44 2.9-16.48 7.48L45.1 70.2c.58-1.98.9-4.04.9-6.2s-.32-4.22-.9-6.2l28.42-15.28C77.56 47.1 83.44 50 90 50c12.14 0 22-9.86 22-22S102.14 6 90 6s-22 9.86-22 22c0 1.98.28 3.9.78 5.72L40.14 49.1C36.12 44.76 30.38 42 24 42 11.86 42 2 51.86 2 64s9.86 22 22 22c6.38 0 12.12-2.76 16.14-7.12l28.64 15.38c-.5 1.84-.78 3.76-.78 5.74 0 12.14 9.86 22 22 22s22-9.86 22-22-9.86-22-22-22z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Share</span></span></button></div></div></div><div class="ExportCitation u-display-inline-block" id="export-citation"><div class="popover export-citation-popover" id="export-citation-popover"><div id="popover-trigger-export-citation-popover"><button class="button-link button-link-secondary button-link-icon-left button-link-has-colored-icon" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 104 128" height="20" class="icon icon-cited-by-66"><path d="M2 58.78V106h44V64H12v-5.22C12 40.28 29.08 32 46 32V22C20.1 22 2 37.12 2 58.78zM102 32V22c-25.9 0-44 15.12-44 36.78V106h44V64H68v-5.22C68 40.28 85.08 32 102 32z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Cite</span></span></button></div></div></div></div></div><div class="ArticleIdentifierLinks u-margin-xs-bottom text-xs" id="article-identifier-links"><a class="anchor doi anchor-primary" href="https://doi.org/10.1016/j.cmpb.2022.106621" target="_blank" rel="noreferrer noopener" aria-label="Persistent link using digital object identifier" title="Persistent link using digital object identifier"><span class="anchor-text-container"><span class="anchor-text">https://doi.org/10.1016/j.cmpb.2022.106621</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor rights-and-content anchor-primary" href="https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S0169260722000062&amp;orderBeanReset=true" target="_blank" rel="noreferrer noopener"><span class="anchor-text-container"><span class="anchor-text">Get rights and content</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><section class="ReferencedArticles"></section><section class="ReferencedArticles"></section><div id="preview-section-abstract"><div class="PageDivider"></div><div class="Abstracts u-font-serif" id="abstracts"><div class="abstract author-highlights" id="abs0001"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Highlights</h2><div id="abss0001"><div class="u-margin-s-bottom" id="spara010"><ul class="list"><li class="react-xocs-list-item"><span class="list-label">•</span><span><div class="u-margin-s-bottom" id="para0001"><a href="/topics/computer-science/autonomous-driving" title="Learn more about Autonomous driving from ScienceDirect's AI-generated Topic Pages" class="topic-link">Autonomous driving</a>, virtual reality and all kinds of robots integrated into our life rely on facial expression recognition technology.</div></span></li><li class="react-xocs-list-item"><span class="list-label">•</span><span><div class="u-margin-s-bottom" id="para0002"><span><span>Facial expression recognition and <a href="/topics/engineering/computervision" title="Learn more about computer vision from ScienceDirect's AI-generated Topic Pages" class="topic-link">computer vision</a> is based on </span><a href="/topics/engineering/deep-learning" title="Learn more about deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning</a> technology and </span><a href="/topics/computer-science/convolutional-neural-network" title="Learn more about convolutional neural network from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional neural network</a>.</div></span></li><li class="react-xocs-list-item"><span class="list-label">•</span><span><div class="u-margin-s-bottom" id="para0003">Whether it is two-stage target detection or single-stage target detection, performance of algorithm is measured by detection speed and accuracy.</div></span></li><li class="react-xocs-list-item"><span class="list-label">•</span><span><div class="u-margin-s-bottom" id="para0004">Large variety of <a href="/topics/computer-science/training-data" title="Learn more about training data from ScienceDirect's AI-generated Topic Pages" class="topic-link">training data</a> with accurate expression tags can fundamentally improve expression recognition rate.</div></span></li></ul></div></div></div><div class="abstract author" id="abs0002"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Abstract</h2><div id="abss0003"><h3 class="u-h4 u-margin-m-top u-margin-xs-bottom" id="cesectitle0003">Background and objective</h3><div class="u-margin-s-bottom" id="spara011"><span><span>Facial expression recognition technology will play an increasingly important role in our daily life. <a href="/topics/computer-science/autonomous-driving" title="Learn more about Autonomous driving from ScienceDirect's AI-generated Topic Pages" class="topic-link">Autonomous driving</a>, virtual reality and all kinds of robots integrated into our life depend on the development of facial expression recognition technology. Many tasks in the field of </span><a href="/topics/engineering/computervision" title="Learn more about computer vision from ScienceDirect's AI-generated Topic Pages" class="topic-link">computer vision</a> are based on </span><a href="/topics/computer-science/deep-learning" title="Learn more about deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning</a><span> technology and <a href="/topics/engineering/convolutional-neural-network" title="Learn more about convolutional neural network from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional neural network</a>. The paper proposes an occluded expression recognition model based on the generated countermeasure network. The model is divided into two modules, namely, occluded face image restoration and face recognition.</span></div></div><div id="abss0004"><h3 class="u-h4 u-margin-m-top u-margin-xs-bottom" id="cesectitle0004">Methods</h3><div class="u-margin-s-bottom" id="spara012">Firstly, this paper summarizes the research status of deep facial expression recognition methods in recent ten years and the development of related facial expression database. Then, the current facial expression recognition methods based on <a href="/topics/engineering/deep-learning" title="Learn more about deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning</a> are divided into two categories: Static facial expression recognition and dynamic facial expression recognition. The two methodswill be introduced and summarized respectively. Aiming at the advanced deep expression recognition algorithms in the field, the performance of these algorithms on common expression databases is compared, and the strengths and weaknesses of these algorithms are analyzed in detail.</div></div><div id="abss0005"><h3 class="u-h4 u-margin-m-top u-margin-xs-bottom" id="cesectitle0005">Discussion and results</h3><div class="u-margin-s-bottom" id="spara013">As the task of facial expression recognition is gradually transferred from the controlled laboratory environment to the challenging real-world environment, with the rapid development of <a href="/topics/computer-science/deep-learning" title="Learn more about deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning</a><span> technology, deep neural network can learn discriminative features, and is gradually applied to automatic facial expression recognition task. The current deep facial expression recognition system is committed to solve the following two problems: (1) Overfitting due to lack of sufficient <a href="/topics/computer-science/training-data" title="Learn more about training data from ScienceDirect's AI-generated Topic Pages" class="topic-link">training data</a>; (2) In the real world environment, other variables that have nothing to do with expression bring interference problems.</span></div></div><div id="abss0006"><h3 class="u-h4 u-margin-m-top u-margin-xs-bottom" id="cesectitle0006">Conclusion</h3><div class="u-margin-s-bottom" id="spara014">From the perspective of algorithm, combining other expression models, such as facial action unit model and pleasure arousal dimension model, as well as other multimodal models, such as audio mode, 3D face depth information and human physiological information, can make expression recognition more practical.</div></div></div></div></div><div id="preview-section-introduction"><div class="PageDivider"></div><div class="Introduction u-font-serif u-margin-l-ver"><h2 class="u-h4 u-margin-s-bottom">Introduction</h2><section id="sec0001"><div class="u-margin-s-bottom" id="para0009">Image recognition is a technology that uses computer to process, analyze and understand images to identify different patterns of targets and objects. It is a main research direction in the field of computer vision and plays an important role in intelligent data acquisition and processing based on image. Image recognition technology can efficiently complete the detection and recognition of specific target objects (such as handwritten characters, products or faces), image classification and marking, and subjective image quality evaluation. At present, image recognition technology has a broad commercial market and optimistic application prospects in Internet application products such as image retrieval, commodity recommendation, user behavior analysis and face recognition. Moreover, it has long-term development potential in high-tech industries such as UAV, autonomous driving and intelligent robot, as well as many fields such as geology, medicine and biology. Early image recognition systems mainly used directional gradient histogram [1] and scale invariant feature transformation [2], and then input the extracted features into the classifier for classification and recognition. These functions are basically manually designed. For different recognition problems, the extracted features will directly affect the performance of the system. Therefore, researchers need to further study the unsolved problem areas in order to design better adaptive features to improve the performance of the system. The image recognition system in this period is often for a specific recognition task, and the data scale is small, the generalization ability is poor, so it is not easy to achieve the ideal recognition effect in daily application.</div><div class="u-margin-s-bottom" id="para0010">Deep learning is a branch of representation learning based on data of artificial neural network. Deep learning includes supervised learning, semi-supervised learning and unsupervised learning. In deep learning, deep neural network, deep belief network and recurrent neural network have been widely used in speech recognition, computer vision, audio recognition, unmanned driving and natural language processing. Rina dechter first introduced deep learning in 1986. In addition, Igor aizenberg introduced the concept of artificial neural network in 2000. In fact, Alexey ivakhnenko and Lapa proposed supervised feedforward learning network as early as 1965. In 1986, Geoffrey Hinton proposed the back-propagation algorithm of multilayer perceptron (MLS), and used the SIGMOD activation function for nonlinear transformation, so as to solve the problems of nonlinear learning and classification. In 2006, Geoffrey Hinton et&nbsp;al. Pointed out that the pre-training weight should be used to initialize the model and fine tune the model according to the supervised training. With the further development of deep learning, the proposal of lenet [3] in 1998 marked the emergence of convolutional neural network (CNN).</div><div class="u-margin-s-bottom" id="para0011">However, due to the backward hardware at that time, convolutional neural network is not in an advantage compared with other machine learning methods (such as SVM [4]). With the further development of computing devices, the Alex net that is proposed by Hinton et&nbsp;al. has made significant achievements in the computer vision competition ILSVRC 2012. Convolutional neural networks have made rapid progress in recent decades.</div></section></div></div><div id="preview-section-snippets"><div class="PageDivider"></div><div class="Snippets u-font-serif"><h2 class="u-h4 u-margin-l-ver">Section snippets</h2><section><section id="sec0002"><section id="sec0003"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Review of face recognition technology</h2><div class="u-margin-s-bottom" id="para0012">Face recognition has the characteristics of easy access, easy operation and diversified features. In the last century, many scholars studied face recognition. However, due to the underdeveloped network, limited resources of face images and poor quality of photos, many scholars mostly studied it from the perspective of algorithm, but the recognition accuracy is low, far from the human eye recognition effect. With the gradual maturity of machine learning technology, there are many powerful</div></section></section></section><section><section id="sec0005"><section id="sec0006"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Depth target detection algorithm</h2><div class="u-margin-s-bottom" id="para0020">In the realm of computer vision, object recognition technology is an algorithm that can detect sample objects in videos and photos. Recent target recognition algorithms mostly rely on high-performance GPU chips based on multilayer neural network and deep learning software framework and built-in thousands of stream processors. Therefore, it is also known as deep object detection (Deep OD). Object detection has always been a vital issue in the realm of computer vision. Before deep learning is</div></section></section></section><section><section id="sec0009"><section id="sec0010"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Deep facial expression recognition based on static image</h2><div class="u-margin-s-bottom" id="para0039">Due to the convenience and availability of network static data processing, a large number of researches are based on static images without considering time information for expression recognition. Direct training of deep network on relatively small facial expression databases will inevitably result in overfitting problem. In order to solve this problem, many related researches use additional auxiliary data to pre-train and build their own network, or directly fine tune based on an effective</div></section></section></section><section><section id="sec0013"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Discussion</h2><div class="u-margin-s-bottom" id="para0045">This paper firstly recommends the background knowledge of facial expression recognition, and summarizes the evolution and development of database and algorithm in the field of facial expression recognition. It points out that deep learning has become the mainstream framework in this field. Then, the expression recognition algorithms based on deep learning are divided into two categories (static expression recognition network and dynamic expression recognition network). By comparing the</div></section></section><section><section id="sec0014"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Conclusions</h2><div class="u-margin-s-bottom" id="para0047">In the field of computer vision, based on the research status at home and abroad, facial expression recognition technology has made great progress and development. However, there are still many challenges and difficulties waiting for researchers to solve. For example, the research on facial expression recognition in real scenes, and there is a certain confusion between different expressions. The expression of facial emotion may vary with region, culture, and environment. There are differences</div></section></section><section><section id="coi0001"><h2 id="cesectitle0022" class="u-h4 u-margin-l-top u-margin-xs-bottom">Declaration of Competing Interest</h2><div class="u-margin-s-bottom" id="para0048">The authors declare that there is no conflict of interest in this paper.</div></section></section><section><section id="ack0001"><h2 id="cesectitle0023" class="u-h4 u-margin-l-top u-margin-xs-bottom">Acknowledgment</h2><div class="u-margin-s-bottom" id="para0049">This work is supported by the <span id="gs0001">National Natural Science Foundation of China</span> (No. <span>62006102</span>).</div></section></section></div></div><div class="related-content-links u-display-none-from-md"><button class="button-link button-link-primary button-link-small" type="button"><span class="button-link-text-container"><span class="button-link-text">Special issue articles</span></span></button><button class="button-link button-link-primary button-link-small" type="button"><span class="button-link-text-container"><span class="button-link-text">Recommended articles</span></span></button></div><div class="Tail"></div><div id="preview-section-references"><div class="paginatedReferences u-font-serif"><div class="PageDivider"></div><header><h2 class="u-h4 u-margin-l-ver"><span>References</span><span> (38)</span></h2></header><ul><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Z. </span>Tang</span><em> et al.</em></span><h3><a class="anchor title anchor-primary" href="/science/article/pii/S0960148121005590"><span class="anchor-text-container"><span class="anchor-text">Two-phase deep learning model for short-term wind direction forecasting</span></span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Renew. Energy</h3></div><div class="series">(2021)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="author u-font-sans"><span>C. </span>He</span><h3 class="title">Overview of face recognition technology</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Intell. Comput. Appl.</h3></div><div class="series">(2016)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>M.H. </span>Zhu</span><em> et al.</em></span><h3 class="title">Facial expression recognition method based on sparse representation</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Pattern Recognit. Artif. Intell.</h3></div><div class="series">(2014)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Y.L. </span>Xue</span><em> et al.</em></span><h3 class="title">Robust facial expression recognition method under occlusion conditions</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">J. Beijing Univ. Aeronaut. Astronaut.</h3></div><div class="series">(2010)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Y. </span>Chenglin</span><em> et al.</em></span><h3 class="title">Face recognition framework based on effective computing and adversarial neural network and its implementation in machine vision for social robots</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Comput. Electr. Eng.</h3></div><div class="series">(2021)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Y. </span>Sun</span><em> et al.</em></span><h3 class="title">Deep learning face representation from predicting 10,000 classes</h3><span class="host u-clr-grey6 u-font-sans"></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Y. </span>Sun</span><em> et al.</em></span><h3 class="title">Deep learning face representation by joint identification verification</h3><span class="host u-clr-grey6 u-font-sans"></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Y. </span>Sun</span><em> et al.</em></span><h3 class="title">Deeply learned face representations are sparse, selective, and robust</h3><span class="host u-clr-grey6 u-font-sans"></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>F. </span>Schroff</span><em> et al.</em></span><h3 class="title">Facenet: a unified embedding for face recognition and clustering</h3><span class="host u-clr-grey6 u-font-sans"></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Y. </span>Taigman</span><em> et al.</em></span><h3 class="title">Deepface: closing the gap to human-level performance in face verification</h3><span class="host u-clr-grey6 u-font-sans"></span></li></ul><div class="u-display-none"><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Y. </span>Wen</span><em> et al.</em></span><h3 class="title">A discriminative feature learning approach for deep face recognition</h3><span class="host u-clr-grey6 u-font-sans"><h3 class="title">European Conference on Computer Vision</h3><div class="series">(2016)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>W. </span>Liu</span><em> et al.</em></span><h3 class="title">Large-margin softmax loss for convolutional neural networks</h3><span class="host u-clr-grey6 u-font-sans"></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>F. </span>Wang</span><em> et al.</em></span><h3 class="title">Additive margin softmax for face verification</h3><span class="host u-clr-grey6 u-font-sans"><div class="series">(2018)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>H. </span>Wang</span><em> et al.</em></span><h3 class="title">CosFace: large margin cosine loss for deep face recognition</h3><span class="host u-clr-grey6 u-font-sans"></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>S. </span>Chen</span><em> et al.</em></span><h3 class="title">MobileFaceNets: efficient CNNs for accurate real-time face verification on mobile devices</h3><span class="host u-clr-grey6 u-font-sans"><h3 class="title">Chinese Conference on Biometric Recognition</h3><div class="series">(2018)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>M. </span>Sandler</span><em> et al.</em></span><h3 class="title">MobileNetV2: inverted residuals and linear bottlenecks</h3><span class="host u-clr-grey6 u-font-sans"></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>R. </span>Girshick</span><em> et al.</em></span><h3 class="title">R-CNN for object detection</h3><span class="host u-clr-grey6 u-font-sans"></span></li><li class="bib-reference u-margin-s-bottom"><span>Zhu G., Porikli F., Li H. Tracking randomly moving objects on edge box proposals. arXiv preprint arXiv: 1507.08085,...</span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>J.R.R. </span>Uijlings</span><em> et al.</em></span><h3 class="title">Selective search for object recognition</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Int. J. Comput. Vis.</h3></div><div class="series">(2013)</div></span></li></div><button class="button-alternative button-alternative-secondary u-font-sans u-margin-l-bottom large-alternative button-alternative-icon-left" type="button" id="show-more-refs-btn"><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">View more references</span></span></button></div></div><div id="preview-section-cited-by"><section aria-label="Cited by" class="ListArticles preview"><div class="PageDivider"></div><header id="citing-articles-header"><h2 class="u-h4 u-margin-l-ver u-font-serif">Cited by (86)</h2></header><div aria-describedby="citing-articles-header"><div class="citing-articles u-margin-l-bottom"><ul><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-0-title"><a class="anchor anchor-primary" href="/science/article/pii/S0169260723004418"><span class="anchor-text-container"><span class="anchor-text">Deep neural network technique for automated detection of ADHD and CD using ECG signal</span></span></a></h3><div>2023, Computer Methods and Programs in Biomedicine</div><div class="CitedSection u-margin-s-top"><div class="u-margin-s-left"><div class="cite-header u-text-italic u-font-sans">Citation Excerpt :</div><p class="u-font-serif text-xs">In this study, the ECG segments were classified into three categories: CD, ADHD + CD, and CD using 1-Dimensional (1D) Convolutional Neural Network (CNN) models. The CNN model is well-known for its ability to classify images, and as a result, it has been used in applications like face and object identification [26,27], satellite forecasting [28,29] and analysis of medical images such as MRI, CT, X-RAY, and PET [30,31]. Besides 2-dimensional images, CNN models have also been applied to 1-dimensional biosignals, such as ECG to identify arrhythmias [32,33].</p></div></div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-0-title" aria-controls="citing-articles-article-0" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="spara011">Attention Deficit Hyperactivity problem (ADHD) is a common neurodevelopment problem in children and adolescents that can lead to long-term challenges in life outcomes if left untreated. Also, ADHD is frequently associated with Conduct Disorder (CD), and multiple research have found similarities in clinical signs and behavioral symptoms between both diseases, making differentiation between ADHD, ADHD comorbid with CD (ADHD+CD), and CD a subjective diagnosis. Therefore, the goal of this pilot study is to create the first explainable deep learning (DL) model for objective ECG-based ADHD/CD diagnosis as having an objective biomarker may improve diagnostic accuracy.</div><div class="u-margin-s-bottom" id="spara012">The dataset used in this study consist of ECG data collected from 45 ADHD, 62 ADHD+CD, and 16 CD patients at the Child Guidance Clinic in Singapore. The ECG data were segmented into 2&nbsp;s epochs and directly used to train our 1-dimensional (1D) convolutional neural network (CNN) model.</div><div class="u-margin-s-bottom" id="spara013">The proposed model yielded 96.04% classification accuracy, 96.26% precision, 95.99% sensitivity, and 96.11% F1-score. The Gradient-weighted class activation mapping (Grad-CAM) function was also used to highlight the important ECG characteristics at specific time points that most impact the classification score.</div><div class="u-margin-s-bottom" id="spara014">In addition to achieving model performance results with our suggested DL method, Grad-CAM's implementation also offers vital temporal data that clinicians and other mental healthcare professionals can use to make wise medical judgments. We hope that by conducting this pilot study, we will be able to encourage larger-scale research with a larger biosignal dataset. Hence allowing biosignal-based computer-aided diagnostic (CAD) tools to be implemented in healthcare and ambulatory settings, as ECG can be easily obtained via wearable devices such as smartwatches.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-1-title"><a class="anchor anchor-primary" href="/science/article/pii/S2352710222007288"><span class="anchor-text-container"><span class="anchor-text">Deep learning and computer vision based occupancy CO&lt;inf&gt;2&lt;/inf&gt; level prediction for demand-controlled ventilation (DCV)</span></span></a></h3><div>2022, Journal of Building Engineering</div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-1-title" aria-controls="citing-articles-article-1" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="abspara0010">The present study investigated the potential of the application of a live occupancy detection approach to assist the operations of demand-controlled ventilation (DCV) systems to ensure that sufficient interior thermal conditions and air quality were attained while reducing unnecessary building energy loads to improve building energy performance. Faster region-based convolutional neural network (RCNN) models were trained to detect the number of people and occupancy activities respectively, and deployed to an artificial intelligence (AI)-powered camera. Experimental tests were carried out within a case study room to assess the performance of this approach. Due to the less complexity of people counting model, it achieved an average intersection over union (IoU) detection accuracy of about 98.9%, which was higher than activity detection model of about 88.5%. During the detection, the count-based occupancy profiles were produced according to the real-time information about the number of people and their activities. To estimate the effect of this approach on indoor air quality and energy demand, scenario-based modelling of the case study building under four ventilation scenarios was carried out via building energy simulation (BES). Results showed that the proposed approach could provide demand-driven ventilation controls data on the dynamic changes of occupancy to improve the indoor air quality (IAQ) and address the problem of under- or over-estimation of the ventilation demand when using the static or fixed profiles.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-2-title"><a class="anchor anchor-primary" href="/science/article/pii/S016926072200270X"><span class="anchor-text-container"><span class="anchor-text">SMD-YOLO: An efficient and lightweight detection method for mask wearing status during the COVID-19 pandemic</span></span></a></h3><div>2022, Computer Methods and Programs in Biomedicine</div><div class="CitedSection u-margin-s-top"><div class="u-margin-s-left"><div class="cite-header u-text-italic u-font-sans">Citation Excerpt :</div><p class="u-font-serif text-xs">Therefore, it is of great practical significance to realize the detection for mask wearing status in public places (such as hospitals, campuses etc.). In recent years, a large number of studies have used deep learning to complete object detection and are widely used in biomedicine [6–8], lesions detection [9–11], face detection [12–14] and other fields [15–18]. The existing machine learning and deep learning methods have achieved some results in the task of face mask detection [19—22], however, there are still limitations in the complicated environments.</p></div></div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-2-title" aria-controls="citing-articles-article-2" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="spara027">At present, the COVID-19 epidemic is still spreading worldwide and wearing a mask in public areas is an effective way to prevent the spread of the respiratory virus. Although there are many deep learning methods used for detecting the face masks, there are few lightweight detectors having a good effect on small or medium-size face masks detection in the complicated environments.</div><div class="u-margin-s-bottom" id="spara028">In this work we propose an efficient and lightweight detection method based on YOLOv4-tiny, and a face mask detection and monitoring system for mask wearing status. Two feasible improvement strategies, network structure optimization and K-means++ clustering algorithm, are utilized for improving the detection accuracy on the premise of ensuring the real-time face masks recognition. Particularly, the improved residual module and cross fusion module are designed to aim at extracting the features of small or medium-size targets effectively. Moreover, the enhanced dual attention mechanism and the improved spatial pyramid pooling module are employed for merging sufficiently the deep and shallow semantic information and expanding the receptive field. Afterwards, the detection accuracy is compensated through the combination of activation functions. Finally, the depthwise separable convolution module is used to reduce the quantity of parameters and improve the detection efficiency. Our proposed detector is evaluated on a public face mask dataset, and an ablation experiment is also provided to verify the effectiveness of our proposed model, which is compared with the state-of-the-art (SOTA) models as well.</div><div class="u-margin-s-bottom" id="spara029">Our proposed detector increases the AP (average precision) values in each category of the public face mask dataset compared with the original YOLOv4-tiny. The mAP (mean average precision) is improved by 4.56% and the speed reaches 92.81 FPS. Meanwhile, the quantity of parameters and the FLOPs (floating-point operations) are reduced by 1/3, 16.48%, respectively.</div><div class="u-margin-s-bottom" id="spara030">The proposed detector achieves better overall detection performance compared with other SOTA detectors for real-time mask detection, demonstrated the superiority with both theoretical value and practical significance. The developed system also brings greater flexibility to the application of face mask detection in hospitals, campuses, communities, etc.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-3-title"><a class="anchor anchor-primary" href="https://doi.org/10.1007/s00530-022-00984-w" target="_blank"><span class="anchor-text-container"><span class="anchor-text">A comprehensive review of facial expression recognition techniques</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2023, Multimedia Systems</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-4-title"><a class="anchor anchor-primary" href="https://doi.org/10.3390/computation10090148" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Face Detection &amp; Recognition from Images &amp; Videos Based on CNN &amp; Raspberry Pi</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2022, Computation</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-5-title"><a class="anchor anchor-primary" href="https://doi.org/10.32604/cmc.2022.025953" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Intelligent Sign Language Recognition System for E-Learning Context</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2022, Computers, Materials and Continua</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li></ul><a class="button-alternative button-alternative-secondary large-alternative button-alternative-icon-left" href="http://www.scopus.com/scopus/inward/citedby.url?partnerID=10&amp;rel=3.0.0&amp;eid=2-s2.0-85124002209&amp;md5=efc6284d60efc47572e3d858a84bf2b" target="_blank" id="citing-articles-view-all-btn"><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-right"><path d="M1 99l38-38L1 23l7-7 45 45-45 45z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">View all citing articles on Scopus</span></span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></a></div></div></section></div><div class="PageDivider"></div><a class="anchor full-text-link anchor-primary" href="/science/article/pii/S0169260722000062" aria-disabled="true" tabindex="-1"><span class="anchor-text-container"><span class="anchor-text">View full text</span></span></a><div class="Copyright"><span class="copyright-line">© 2022 Elsevier B.V. All rights reserved.</span></div></article><div class="u-display-block-from-md col-lg-6 col-md-8 pad-right u-padding-s-top"><aside class="RelatedContent u-clr-grey8" aria-label="Related content"><section class="SpecialIssueArticles" id="virtual-special-issue"><section class="RelatedContentPanel u-margin-s-bottom"><header id="virtual-special-issue-articles-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Part of special issue</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="virtual-special-issue-articles-header"><div class="u-margin-s-bottom"><div class="u-margin-s-bottom"><a class="anchor anchor-primary anchor-large" href="/science/journal/01692607/vsi/10GDNNWGNFH"><span class="anchor-text-container"><span class="anchor-text">Deep learning in radiology - from image analysis to image reconstruction</span></span></a><div class="text-xs">Edited by Kelvin Wong, Giancarlo Fortino, Jimmy Zhihua Liu</div></div><a class="button-alternative u-padding-0-left button-alternative-primary medium-alternative button-alternative-icon-left" href="/science/journal/01692607/vsi/10GDNNWGNFH"><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-right"><path d="M1 99l38-38L1 23l7-7 45 45-45 45z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">View special issue</span></span></a></div></div></section></section><section class="RelatedContentPanel u-margin-s-bottom"><header id="recommended-articles-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" data-aa-button="sd:product:journal:article:location=recommended-articles:type=close" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Recommended articles</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="recommended-articles-header"><div id="recommended-articles" class="text-xs"><ul><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article0-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S1568494619307008" title="A novel deep learning method based on attention mechanism for bearing remaining useful life prediction"><span class="anchor-text-container"><span class="anchor-text"><span>A novel deep learning method based on attention mechanism for bearing remaining useful life prediction</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Applied Soft Computing, Volume 86, 2020, Article 105919</div></div><div class="authors"><span>Yuanhang</span> <span>Chen</span>, …, <span>Sijue</span> <span>Li</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article1-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0925231220301193" title="Fine-grained facial expression analysis using dimensional emotion model"><span class="anchor-text-container"><span class="anchor-text"><span>Fine-grained facial expression analysis using dimensional emotion model</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Neurocomputing, Volume 392, 2020, pp. 38-49</div></div><div class="authors"><span>Feng</span> <span>Zhou</span>, …, <span>Baiying</span> <span>Lei</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article2-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S1746809423006560" title="A Bi-Stream hybrid model with MLPBlocks and self-attention mechanism for EEG-based emotion recognition"><span class="anchor-text-container"><span class="anchor-text"><span>A Bi-Stream hybrid model with MLPBlocks and self-attention mechanism for EEG-based emotion recognition</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Biomedical Signal Processing and Control, Volume 86, Part B, 2023, Article 105223</div></div><div class="authors"><span>Wei</span> <span>Li</span>, …, <span>Aiguo</span> <span>Song</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article3-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0167865517302313" title="Multi angle optimal pattern-based deep learning for automatic facial expression recognition"><span class="anchor-text-container"><span class="anchor-text"><span>Multi angle optimal pattern-based deep learning for automatic facial expression recognition</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Pattern Recognition Letters, Volume 139, 2020, pp. 157-165</div></div><div class="authors"><span>Deepak Kumar</span> <span>Jain</span>, …, <span>Kaiqi</span> <span>Huang</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article4-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S135044952100195X" title="Feature-similarity network via soft-label training for infrared facial emotional classification in human-robot interaction"><span class="anchor-text-container"><span class="anchor-text"><span>Feature-similarity network via soft-label training for infrared facial emotional classification in human-robot interaction</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Infrared Physics &amp; Technology, Volume 117, 2021, Article 103823</div></div><div class="authors"><span>Haixia</span> <span>Xiao</span>, <span>Zhengfa</span> <span>Hu</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article5-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0925231218311238" title="A convolutional neural network based on a capsule network with strong generalization for bearing fault diagnosis"><span class="anchor-text-container"><span class="anchor-text"><span>A convolutional neural network based on a capsule network with strong generalization for bearing fault diagnosis</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Neurocomputing, Volume 323, 2019, pp. 62-75</div></div><div class="authors"><span>Zhu</span> <span>Zhiyu</span>, …, <span>Gao</span> <span>Huijun</span></div></div><div class="buttons"></div></li></ul></div><button class="button-link more-recommendations-button u-margin-s-bottom button-link-primary button-link-icon-right" type="button"><span class="button-link-text-container"><span class="button-link-text">Show 3 more articles</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div></section><section class="RelatedContentPanel u-margin-s-bottom"><header id="metrics-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Article Metrics</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="metrics-header"><div class="plumX-metrics"><h3 class="text-s metric-title metric-title-citations">Citations</h3><ul><li class="text-xs metrics"><span>Citation Indexes</span><span>86</span></li></ul><h3 class="text-s metric-title metric-title-captures">Captures</h3><ul><li class="text-xs metrics"><span>Readers</span><span>93</span></li></ul><h3 class="text-s metric-title metric-title-social-media">Social Media</h3><ul><li class="text-xs metrics"><span>Shares, Likes &amp; Comments</span><span>1</span></li></ul><div class="metrics u-margin-m-top u-margin-s-bottom"><img src="https://cdn.plu.mx/3ba727faf225e19d2c759f6ebffc511d/plumx-logo.png" class="plumX-logo" alt="PlumX Metrics Logo"><a class="anchor text-xs anchor-primary" href="https://plu.mx/plum/a/?doi=10.1016%2Fj.cmpb.2022.106621&amp;theme=plum-sciencedirect-theme&amp;hideUsage=true" target="_blank"><span class="anchor-text-container"><span class="anchor-text">View details</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></div></div></section></aside></div></div></div></div><footer role="contentinfo" class="els-footer u-bg-white text-xs u-padding-s-hor u-padding-m-hor-from-sm u-padding-l-hor-from-md u-padding-l-ver u-margin-l-top u-margin-xl-top-from-sm u-margin-l-top-from-md"><div class="els-footer-elsevier u-margin-m-bottom u-margin-0-bottom-from-md u-margin-s-right u-margin-m-right-from-md u-margin-l-right-from-lg"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="https://www.elsevier.com/" target="_blank" aria-label="Elsevier home page (opens in a new tab)" rel="nofollow"><img class="footer-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/47/images/elsevier-non-solus-new-with-wordmark.svg" alt="Elsevier logo with wordmark" height="64" width="58" loading="lazy"></a></div><div class="els-footer-content"><div class="u-remove-if-print"><ul class="els-footer-links u-margin-xs-bottom" style="list-style:none"><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/solutions/sciencedirect" target="_blank" id="els-footer-about-science-direct" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">About ScienceDirect</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0169260722000062" id="els-footer-remote-access" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Remote access</span></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://sd-cart.elsevier.com/?" target="_blank" id="els-footer-shopping-cart" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Shopping cart</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsmediakits.com" target="_blank" id="els-footer-advertise" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Advertise</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://service.elsevier.com/app/contact/supporthub/sciencedirect/" target="_blank" id="els-footer-contact-support" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Contact and support</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/legal/elsevier-website-terms-and-conditions" target="_blank" id="els-footer-terms-condition" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Terms and conditions</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/legal/privacy-policy" target="_blank" id="els-footer-privacy-policy" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Privacy policy</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li></ul></div><p id="els-footer-cookie-message" class="u-remove-if-print">Cookies are used by this site. <!-- --> <button class="button-link ot-sdk-show-settings cookie-btn button-link-primary button-link-small" id="ot-sdk-btn" type="button">Cookie Settings</button></p><p id="els-footer-copyright">All content on this site: Copyright © <!-- -->2024<!-- --> Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.</p></div><div class="els-footer-relx u-margin-0-top u-margin-m-top-from-xs u-margin-0-top-from-md"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="https://www.relx.com/" target="_blank" aria-label="RELX home page (opens in a new tab)" id="els-footer-relx" rel="nofollow"><img loading="lazy" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/60/images/logo-relx-tm.svg" width="93" height="20" alt="RELX group home page"></a></div></footer></div></div></div></div>
      <div id="floating-ui-node" class="floating-ui-node" data-sd-ui-floating-ui="true"></div>
      <iframe style="display: none" src="//acw.clinicalkey.com/SSOCore/update?acw=8aee8e3a2a2ca74c189bc600c4438ca55e60gxrqb%7C%24%7C37F16F5FD7A5B27227E5435E49EB17DB92CB7C15F18BC959B5732B0DCC4C6F27E4DEC7F9AFEEDCE80AB2CB2ED6A8B9342ECCB0E1EAF272AC0E9169905BBD791CB0469A67597464825D387A21AFA2E514&amp;utt=35642ad5a4fe391addb3ef4669a228792f21ad6-J" tabindex="-1"></iframe><iframe style="display: none" src="//acw.scopus.com/SSOCore/update?acw=8aee8e3a2a2ca74c189bc600c4438ca55e60gxrqb%7C%24%7C37F16F5FD7A5B27227E5435E49EB17DB92CB7C15F18BC959B5732B0DCC4C6F27E4DEC7F9AFEEDCE80AB2CB2ED6A8B9342ECCB0E1EAF272AC0E9169905BBD791CB0469A67597464825D387A21AFA2E514&amp;utt=35642ad5a4fe391addb3ef4669a228792f21ad6-J" tabindex="-1"></iframe><iframe style="display: none" src="//acw.sciencedirect.com/SSOCore/update?acw=8aee8e3a2a2ca74c189bc600c4438ca55e60gxrqb%7C%24%7C37F16F5FD7A5B27227E5435E49EB17DB92CB7C15F18BC959B5732B0DCC4C6F27E4DEC7F9AFEEDCE80AB2CB2ED6A8B9342ECCB0E1EAF272AC0E9169905BBD791CB0469A67597464825D387A21AFA2E514&amp;utt=35642ad5a4fe391addb3ef4669a228792f21ad6-J" tabindex="-1"></iframe><iframe style="display: none" src="//acw.elsevier.com/SSOCore/update?acw=8aee8e3a2a2ca74c189bc600c4438ca55e60gxrqb%7C%24%7C37F16F5FD7A5B27227E5435E49EB17DB92CB7C15F18BC959B5732B0DCC4C6F27E4DEC7F9AFEEDCE80AB2CB2ED6A8B9342ECCB0E1EAF272AC0E9169905BBD791CB0469A67597464825D387A21AFA2E514&amp;utt=35642ad5a4fe391addb3ef4669a228792f21ad6-J" tabindex="-1"></iframe>
      <script src="https://assets.adobedtm.com/4a848ae9611a/032db4f73473/launch-a6263b31083f.min.js" type="image/ot-performance" async=""></script>
      
<script type="text/javascript">
    window.pageData = {"content":[{"contentType":"JL","format":"MIME-XHTML","id":"sd:article:pii:S0169260722000062","type":"sd:article:JL:scope-abstract","detail":"sd:article:subtype:fla","publicationType":"journal","issn":"0169-2607","volumeNumber":"215","suppl":"C","provider":"elsevier","entitlementType":"unsubscribed"}],"page":{"businessUnit":"ELS:RP:ST","language":"en","name":"product:journal:article","noTracking":"false","productAppVersion":"abstract-direct","productName":"SD","type":"CP-CA","environment":"prod","loadTimestamp":1734890140627,"loadTime":""},"visitor":{"accessType":"ae:ANON_GUEST","accountId":"ae:228598","accountName":"ae:ScienceDirect Guests","loginStatus":"anonymous","userId":"ae:12975512","ipAddress":"77.165.246.201","appSessionId":"818b1109-3100-4058-889f-9b05b4f71390"}};
    window.pageData.page.loadTime = performance ? Math.round(performance.now()).toString() : '';

    try {
      appData.push({
      event: 'pageLoad',
      page: pageData.page,
      visitor: pageData.visitor,
      content: pageData.content
      })
    } catch(e) {
        console.warn("There was an error loading or running Adobe DTM: ", e);
    }
</script>
      <script nomodule="" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/73/js/core-js/3.20.2/core-js.es.minified.js" type="text/javascript"></script>
      <script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/108/js/react/18.3.1/react.production.min.js" type="text/javascript"></script>
      <script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/108/js/react-dom/18.3.1/react-dom.production.min.js" type="text/javascript"></script>
      <script async="" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1/arp.js" type="text/javascript"></script>
      <script type="text/javascript">
    const pendoData = {"visitor":{"pageName":"SD:product:journal:article","pageType":"CP-CA","pageProduct":"SD","pageLanguage":"en","pageEnvironment":"prod","accessType":"ae:ANON_GUEST","countryCode":"NL"},"account":{"id":"ae:228598","name":"ae:ScienceDirect Guests"},"events":{}};;
    pendoData.events = {
      ready: function () {
        pendo.addAltText();
      },
    };
    function runPendo(data, options) {
  const {
    firstDelay,
    maxRetries,
    urlPrefix,
    urlSuffix,
    apiKey
  } = options;
  (function (apiKey) {
    (function (p, e, n, d, o) {
      var v, w, x, y, z;
      o = p[d] = p[d] || {};
      o._q = [];
      v = ['initialize', 'identify', 'updateOptions', 'pageLoad'];
      for (w = 0, x = v.length; w < x; ++w) (function (m) {
        o[m] = o[m] || function () {
          o._q[m === v[0] ? 'unshift' : 'push']([m].concat([].slice.call(arguments, 0)));
        };
      })(v[w]);
      y = e.createElement(n);
      y.async = !0;
      y.src = urlPrefix + apiKey + urlSuffix;
      z = e.getElementsByTagName(n)[0];
      z.parentNode.insertBefore(y, z);
    })(window, document, 'script', 'pendo');
    pendo.addAltText = function () {
      var target = document.querySelector('body');
      var observer = new MutationObserver(function (mutations) {
        mutations.forEach(function (mutation) {
          if (mutation?.addedNodes?.length) {
            if (mutation.addedNodes[0]?.className?.includes("_pendo-badge")) {
              const badge = mutation.addedNodes[0];
              const altText = badge?.attributes['aria-label'].value ? badge?.attributes['aria-label'].value : 'Feedback';
              const pendoBadgeImage = pendo.dom(`#${badge?.attributes?.id.value} img`);
              if (pendoBadgeImage.length) {
                pendoBadgeImage[0]?.setAttribute('alt', altText);
              }
            }
          }
        });
      });
      var config = {
        attributeFilter: ['data-layout'],
        attributes: true,
        childList: true,
        characterData: true,
        subtree: false
      };
      observer.observe(target, config);
    };
  })(apiKey);
  (function watchAndSetPendo(nextDelay, retryAttempt) {
    if (typeof pageDataTracker === 'object' && typeof pageDataTracker.getVisitorId === 'function' && pageDataTracker.getVisitorId()) {
      data.visitor.id = pageDataTracker.getVisitorId();
      console.debug(`initializing pendo`);
      pendo.initialize(data);
    } else {
      if (retryAttempt > 0) {
        return setTimeout(function () {
          watchAndSetPendo(nextDelay * 2, retryAttempt - 1);
        }, nextDelay);
      }
      pendo.initialize(data);
      console.debug(`gave up ... pendo initialized`);
    }
  })(firstDelay, maxRetries);
}
    runPendo(pendoData, {
      firstDelay: 100,
      maxRetries: 5,
      urlPrefix: 'https://cdn.pendo.io/agent/static/',
      urlSuffix: '/pendo.js',
      apiKey: 'd6c1d995-bc7e-4e53-77f1-2ea4ecbb9565',
    });
  </script>
      <span id="pendo-answer-rating"></span>
      <script type="text/x-mathjax-config;executed=true">
        MathJax.Hub.Config({
          displayAlign: 'left',
          "fast-preview": {
            disabled: true
          },
          CommonHTML: { linebreaks: { automatic: true } },
          PreviewHTML: { linebreaks: { automatic: true } },
          'HTML-CSS': { linebreaks: { automatic: true } },
          SVG: {
            scale: 90,
            linebreaks: { automatic: true }
          }
        });
      </script>
      <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=MML_SVG" type="text/javascript"></script>
      <script async="" src="https://www.googletagservices.com/tag/js/gpt.js" type="text/javascript"></script>
      <script async="" src="https://scholar.google.com/scholar_js/casa.js" type="text/javascript"></script>
      <script data-cfasync="false">
      (function initOneTrust()  {
        const monitor = {
  init: () => {},
  loaded: () => {},
};
        function enableGroup(group) {
  document.querySelectorAll(`script[type*="ot-${group}"]`).forEach(script => {
    script.type = 'text/javascript';
    document.head.appendChild(script);
  });
}
        function runOneTrustCookies(doClear, monitor) {
  const oneTrustConsentSdkId = 'onetrust-consent-sdk';
  const emptyNodeSelectors = 'h3.ot-host-name, h4.ot-host-desc, button.ot-host-box';
  const ariaLabelledByButtonNodes = 'div.ot-accordion-layout > button';
  const ariaAttribute = 'aria-labelledby';
  function adjustOneTrustDOM() {
    const oneTrustRoot = document.getElementById('onetrust-consent-sdk');

    /* remove empty nodes */
    [...(oneTrustRoot?.querySelectorAll(emptyNodeSelectors) ?? [])].filter(e => e.textContent === '').forEach(e => e.remove());

    /* remove invalid aria-labelledby values */
    oneTrustRoot?.querySelectorAll(ariaLabelledByButtonNodes).forEach(e => {
      const presentIdValue = e.getAttribute(ariaAttribute)?.split(' ').filter(label => document.getElementById(label)).join(' ');
      if (presentIdValue) {
        e.setAttribute(ariaAttribute, presentIdValue);
      }
    });
  }
  function observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent) {
    const cb = (mutationList, observer) => {
      const oneTrustRoot = mutationList.filter(mutationRecord => mutationRecord.type === 'childList' && mutationRecord.addedNodes.length).map(mutationRecord => [...mutationRecord.addedNodes]).flat().find(e => e.id === oneTrustConsentSdkId);
      if (oneTrustRoot && typeof OneTrust !== 'undefined') {
        monitor.loaded(true);
        OneTrust.OnConsentChanged(() => {
          const perfAllowed = decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1]?.match('2:([0|1])')[1] === '1';
          if (perfAllowed) {
            enableGroup('performance');
          }
        });
        if (!isConsentPresent && (shouldSetOTDefaults || OneTrust.GetDomainData().ConsentModel.Name === 'implied consent')) {
          OneTrust.AllowAll();
        }
        document.dispatchEvent(new CustomEvent('@sdtech/onetrust/loaded', {}));
        observer.disconnect();
        adjustOneTrustDOM();
      }
    };
    const observer = new MutationObserver(cb);
    observer.observe(document.querySelector('body'), {
      childList: true
    });
  }
  if (doClear) {
    document.cookie = 'OptanonAlertBoxClosed=; expires=Thu, 01 Jan 1970 00:00:00 UTC; samesite=lax; path=/';
  }
  const isConsentPresent = !!decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1];
  const shouldSetOTDefaults = 'true' === 'false' && !document.cookie?.match('OptanonAlertBoxClosed=');
  if (shouldSetOTDefaults) {
    const date = new Date();
    date.setFullYear(date.getFullYear() + 1);
    document.cookie = `OptanonAlertBoxClosed=${new Date().toISOString()}; expires=${date.toUTCString()}; samesite=lax; path=/; domain=sciencedirect.com`;
  }
  observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent, monitor);
  window.addOTScript = () => {
    const otSDK = document.createElement('script');
    otSDK.setAttribute('data-cfasync', 'false');
    otSDK.setAttribute('src', 'https://cdn.cookielaw.org/scripttemplates/otSDKStub.js');
    otSDK.setAttribute('data-document-language', 'true');
    otSDK.setAttribute('data-domain-script', '865ea198-88cc-4e41-8952-1df75d554d02');
    window.addOTScript = () => {};
    document.head.appendChild(otSDK);
    monitor.init();
  };
  window.addEventListener('load', () => window.addOTScript());
}
        if (document.location.host.match(/.sciencedirect.com$/)) {
          runOneTrustCookies(true, monitor);
        }
        else {
          window.addEventListener('load', (event) => {
            enableGroup('performance');
          });
        }
      }());
    </script>
    <script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'8f61fbf179831c82',t:'MTczNDg5MDE0MS4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script><iframe height="1" width="1" style="position: absolute; top: 0px; left: 0px; border: none; visibility: hidden;"></iframe>
  <iframe id="ps_jymaazuk" src="https://service.seamlessaccess.org/ps/" style="display: none; position: absolute; top: -999px; left: -999px;"></iframe><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div id="onetrust-consent-sdk"><div class="onetrust-pc-dark-filter ot-fade-in" style="z-index:2147483645;"></div><div id="onetrust-banner-sdk" class="otFlat bottom ot-wo-title ot-buttons-fw" tabindex="0" role="region" aria-label="Cookie banner"><div role="alertdialog" aria-describedby="onetrust-policy-text" aria-modal="true" aria-label="Privacy"><div class="ot-sdk-container"><div class="ot-sdk-row"><div id="onetrust-group-container" class="ot-sdk-eight ot-sdk-columns"><div class="banner_logo"></div><div id="onetrust-policy"><div id="onetrust-policy-text">We use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. For more information, see our<a class="ot-cookie-policy-link" href="https://www.elsevier.com/legal/cookienotice" target="_blank" aria-label=", opens in a new tab" rel="noopener">Cookie Policy</a></div></div></div><div id="onetrust-button-group-parent" class="ot-sdk-three ot-sdk-columns"><div id="onetrust-button-group"><button id="onetrust-pc-btn-handler" class="cookie-setting-link">Cookie Settings</button>  <button id="onetrust-accept-btn-handler">Accept all cookies</button></div></div></div></div><!-- Close Button --><div id="onetrust-close-btn-container"></div><!-- Close Button END--></div></div><div id="onetrust-pc-sdk" class="otPcCenter ot-hide ot-fade-in" lang="en" aria-label="Preference center" role="region"><div role="alertdialog" aria-modal="true" aria-describedby="ot-pc-desc" style="height: 100%;" aria-label="Cookie Preference Center"><!-- Close Button --><div class="ot-pc-header"><!-- Logo Tag --><div class="ot-pc-logo" role="img" aria-label="Company Logo"><img alt="Company Logo" src="https://cdn.cookielaw.org/logos/static/ot_company_logo.png"></div></div><!-- Close Button --><div id="ot-pc-content" class="ot-pc-scrollbar"><div class="ot-optout-signal ot-hide"><div class="ot-optout-icon"><svg xmlns="http://www.w3.org/2000/svg"><path class="ot-floating-button__svg-fill" d="M14.588 0l.445.328c1.807 1.303 3.961 2.533 6.461 3.688 2.015.93 4.576 1.746 7.682 2.446 0 14.178-4.73 24.133-14.19 29.864l-.398.236C4.863 30.87 0 20.837 0 6.462c3.107-.7 5.668-1.516 7.682-2.446 2.709-1.251 5.01-2.59 6.906-4.016zm5.87 13.88a.75.75 0 00-.974.159l-5.475 6.625-3.005-2.997-.077-.067a.75.75 0 00-.983 1.13l4.172 4.16 6.525-7.895.06-.083a.75.75 0 00-.16-.973z" fill="#FFF" fill-rule="evenodd"></path></svg></div><span></span></div><h2 id="ot-pc-title">Cookie Preference Center</h2><div id="ot-pc-desc">We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our <a href="https://www.elsevier.com/legal/cookienotice/_nocache" target="_blank">Cookie Policy</a> and the list of <a href="https://support.google.com/admanager/answer/9012903" target="_blank">Google Ad-Tech Vendors</a>.
<br>
<br>
You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.
<br>
</div><button id="accept-recommended-btn-handler">Allow all</button><section class="ot-sdk-row ot-cat-grp"><h3 id="ot-category-title"> Manage Consent Preferences</h3><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="1"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-1" aria-labelledby="ot-header-id-1 ot-status-id-1"></button><!-- Accordion header --><div class="ot-acc-hdr ot-always-active-group"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-1">Strictly Necessary Cookies</h4><div id="ot-status-id-1" class="ot-always-active">Always active</div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-1">These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.
<br><br></p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="1">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="3"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-3" aria-labelledby="ot-header-id-3"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-3">Functional Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-3" id="ot-group-id-3" role="switch" class="category-switch-handler" data-optanongroupid="3" aria-labelledby="ot-header-id-3"> <label class="ot-switch" for="ot-group-id-3"><span class="ot-switch-nob" aria-checked="false" role="switch" aria-label="Functional Cookies"></span> <span class="ot-label-txt">Functional Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-3">These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="3">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="2"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-2" aria-labelledby="ot-header-id-2"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-2">Performance Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-2" id="ot-group-id-2" role="switch" class="category-switch-handler" data-optanongroupid="2" aria-labelledby="ot-header-id-2"> <label class="ot-switch" for="ot-group-id-2"><span class="ot-switch-nob" aria-checked="false" role="switch" aria-label="Performance Cookies"></span> <span class="ot-label-txt">Performance Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-2">These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="2">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="4"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-4" aria-labelledby="ot-header-id-4"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-4">Targeting Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-4" id="ot-group-id-4" role="switch" class="category-switch-handler" data-optanongroupid="4" aria-labelledby="ot-header-id-4"> <label class="ot-switch" for="ot-group-id-4"><span class="ot-switch-nob" aria-checked="false" role="switch" aria-label="Targeting Cookies"></span> <span class="ot-label-txt">Targeting Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-4">These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. If you do not allow these cookies, you will experience less targeted advertising.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="4">Cookie Details List‎</button></div></div></div><!-- Groups sections starts --><!-- Group section ends --><!-- Accordion Group section starts --><!-- Accordion Group section ends --></section></div><section id="ot-pc-lst" class="ot-hide ot-hosts-ui ot-pc-scrollbar"><div id="ot-pc-hdr"><div id="ot-lst-title"><button class="ot-link-btn back-btn-handler" aria-label="Back"><svg id="ot-back-arw" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 444.531 444.531" xml:space="preserve"><title>Back Button</title><g><path fill="#656565" d="M213.13,222.409L351.88,83.653c7.05-7.043,10.567-15.657,10.567-25.841c0-10.183-3.518-18.793-10.567-25.835
                    l-21.409-21.416C323.432,3.521,314.817,0,304.637,0s-18.791,3.521-25.841,10.561L92.649,196.425
                    c-7.044,7.043-10.566,15.656-10.566,25.841s3.521,18.791,10.566,25.837l186.146,185.864c7.05,7.043,15.66,10.564,25.841,10.564
                    s18.795-3.521,25.834-10.564l21.409-21.412c7.05-7.039,10.567-15.604,10.567-25.697c0-10.085-3.518-18.746-10.567-25.978
                    L213.13,222.409z"></path></g></svg></button><h3>Cookie List</h3></div><div class="ot-lst-subhdr"><div class="ot-search-cntr"><p role="status" class="ot-scrn-rdr"></p><input id="vendor-search-handler" type="text" name="vendor-search-handler" placeholder="Search…" aria-label="Cookie list search"> <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 -30 110 110" aria-hidden="true"><title>Search Icon</title><path fill="#2e3644" d="M55.146,51.887L41.588,37.786c3.486-4.144,5.396-9.358,5.396-14.786c0-12.682-10.318-23-23-23s-23,10.318-23,23
            s10.318,23,23,23c4.761,0,9.298-1.436,13.177-4.162l13.661,14.208c0.571,0.593,1.339,0.92,2.162,0.92
            c0.779,0,1.518-0.297,2.079-0.837C56.255,54.982,56.293,53.08,55.146,51.887z M23.984,6c9.374,0,17,7.626,17,17s-7.626,17-17,17
            s-17-7.626-17-17S14.61,6,23.984,6z"></path></svg></div><div class="ot-fltr-cntr"><button id="filter-btn-handler" aria-label="Filter" aria-haspopup="true"><svg role="presentation" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 402.577 402.577" xml:space="preserve"><title>Filter Icon</title><g><path fill="#fff" d="M400.858,11.427c-3.241-7.421-8.85-11.132-16.854-11.136H18.564c-7.993,0-13.61,3.715-16.846,11.136
      c-3.234,7.801-1.903,14.467,3.999,19.985l140.757,140.753v138.755c0,4.955,1.809,9.232,5.424,12.854l73.085,73.083
      c3.429,3.614,7.71,5.428,12.851,5.428c2.282,0,4.66-0.479,7.135-1.43c7.426-3.238,11.14-8.851,11.14-16.845V172.166L396.861,31.413
      C402.765,25.895,404.093,19.231,400.858,11.427z"></path></g></svg></button></div><div id="ot-anchor"></div><section id="ot-fltr-modal"><div id="ot-fltr-cnt"><button id="clear-filters-handler">Clear</button><div class="ot-fltr-scrlcnt ot-pc-scrollbar"><div class="ot-fltr-opts"><div class="ot-fltr-opt"><div class="ot-chkbox"><input id="chkbox-id" type="checkbox" class="category-filter-handler"> <label for="chkbox-id"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div></div></div><div class="ot-fltr-btns"><button id="filter-apply-handler">Apply</button> <button id="filter-cancel-handler">Cancel</button></div></div></div></section></div></div><section id="ot-lst-cnt" class="ot-host-cnt ot-pc-scrollbar"><div id="ot-sel-blk"><div class="ot-sel-all"><div class="ot-sel-all-hdr"><span class="ot-consent-hdr">Consent</span> <span class="ot-li-hdr">Leg.Interest</span></div><div class="ot-sel-all-chkbox"><div class="ot-chkbox" id="ot-selall-hostcntr"><input id="select-all-hosts-groups-handler" type="checkbox"> <label for="select-all-hosts-groups-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div><div class="ot-chkbox" id="ot-selall-vencntr"><input id="select-all-vendor-groups-handler" type="checkbox"> <label for="select-all-vendor-groups-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div><div class="ot-chkbox" id="ot-selall-licntr"><input id="select-all-vendor-leg-handler" type="checkbox"> <label for="select-all-vendor-leg-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div></div></div></div><div class="ot-sdk-row"><div class="ot-sdk-column"><ul id="ot-host-lst"></ul></div></div></section></section><div class="ot-pc-footer ot-pc-scrollbar"><div class="ot-btn-container"> <button class="save-preference-btn-handler onetrust-close-btn-handler">Confirm my choices</button></div><!-- Footer logo --><div class="ot-pc-footer-logo"><a href="https://www.onetrust.com/products/cookie-consent/" target="_blank" rel="noopener noreferrer" aria-label="Powered by OneTrust Opens in a new Tab"><img alt="Powered by Onetrust" src="https://cdn.cookielaw.org/logos/static/powered_by_logo.svg" title="Powered by OneTrust Opens in a new Tab"></a></div></div><!-- Cookie subgroup container --><!-- Vendor list link --><!-- Cookie lost link --><!-- Toggle HTML element --><!-- Checkbox HTML --><!-- plus minus--><!-- Arrow SVG element --><!-- Accordion basic element --><span class="ot-scrn-rdr" aria-atomic="true" aria-live="polite"></span><!-- Vendor Service container and item template --></div><iframe class="ot-text-resize" sandbox="allow-same-origin" title="onetrust-text-resize" style="position: absolute; top: -50000px; width: 100em;" aria-hidden="true"></iframe></div></div></body></html>