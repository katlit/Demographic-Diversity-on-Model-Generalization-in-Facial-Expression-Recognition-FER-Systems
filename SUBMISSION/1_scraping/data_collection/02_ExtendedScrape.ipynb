{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a467da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from scholarly import scholarly\n",
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed0b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fer_datasets_LONG = [\n",
    "    #\"Extended Cohn-Kanade\", \n",
    "    #'MMI Facial Expression',\n",
    "    #\"Japanese Female Facial Expression\", \n",
    "    #\"Toronto Face Database\",\n",
    "    \"Binghamton University 3D Facial Expression\",\n",
    "    \"Oulu-CASIA\",\n",
    "    \"Radboud Faces Database\",\n",
    "    \"Karolinska Directed Emotional Faces\",\n",
    "    \"Acted Facial Expressions In The Wild\",\n",
    "    \"Static Facial Expression in the Wild\",\n",
    "    \"CMU Multi-PIE\",\n",
    "    \"Affective Faces Database\",\n",
    "    \"Expression in-the-Wild\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66bfbd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"facial expression recognition\", \"FER\", \"deep learning\", \"machine learning\", \"classification\", \"classifier\", \"neural network\", \"CNN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def75269",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for combination: Binghamton University 3D Facial Expression facial expression recognition\n",
      "Searching for combination: Binghamton University 3D Facial Expression FER\n",
      "Searching for combination: Binghamton University 3D Facial Expression deep learning\n",
      "Searching for combination: Binghamton University 3D Facial Expression machine learning\n",
      "Searching for combination: Binghamton University 3D Facial Expression classification\n",
      "Searching for combination: Binghamton University 3D Facial Expression classifier\n",
      "Searching for combination: Binghamton University 3D Facial Expression neural network\n",
      "Searching for combination: Binghamton University 3D Facial Expression CNN\n",
      "Searching for combination: Oulu-CASIA facial expression recognition\n",
      "Searching for combination: Oulu-CASIA FER\n",
      "Searching for combination: Oulu-CASIA deep learning\n",
      "Searching for combination: Oulu-CASIA machine learning\n",
      "Searching for combination: Oulu-CASIA classification\n",
      "Searching for combination: Oulu-CASIA classifier\n",
      "Searching for combination: Oulu-CASIA neural network\n",
      "Searching for combination: Oulu-CASIA CNN\n",
      "Searching for combination: Radboud Faces Database facial expression recognition\n",
      "Searching for combination: Radboud Faces Database FER\n",
      "Searching for combination: Radboud Faces Database deep learning\n",
      "Searching for combination: Radboud Faces Database machine learning\n",
      "Searching for combination: Radboud Faces Database classification\n",
      "Searching for combination: Radboud Faces Database classifier\n",
      "Searching for combination: Radboud Faces Database neural network\n",
      "Searching for combination: Radboud Faces Database CNN\n",
      "Searching for combination: Karolinska Directed Emotional Faces facial expression recognition\n",
      "Searching for combination: Karolinska Directed Emotional Faces FER\n",
      "Searching for combination: Karolinska Directed Emotional Faces deep learning\n",
      "Searching for combination: Karolinska Directed Emotional Faces machine learning\n",
      "Searching for combination: Karolinska Directed Emotional Faces classification\n",
      "Searching for combination: Karolinska Directed Emotional Faces classifier\n",
      "Searching for combination: Karolinska Directed Emotional Faces neural network\n",
      "Searching for combination: Karolinska Directed Emotional Faces CNN\n",
      "Searching for combination: Acted Facial Expressions In The Wild facial expression recognition\n"
     ]
    },
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMaxTriesExceededException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25308\\967461655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;31m# Start collecting data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m \u001b[0mcollect_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfer_datasets_LONG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data collection completed.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25308\\967461655.py\u001b[0m in \u001b[0;36mcollect_data\u001b[1;34m(fer_datasets_LONG, topics, save_file)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mcombined_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{dataset} {topic}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Searching for combination: {combined_query}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mscholarly_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_scholarly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;31m# Save results to a CSV file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25308\\967461655.py\u001b[0m in \u001b[0;36msearch_scholarly\u001b[1;34m(query, save_file)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Function to search scholarly papers and collect extended information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msearch_scholarly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0msearch_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscholarly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_pubs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpapers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scholarly\\_scholarly.py\u001b[0m in \u001b[0;36msearch_pubs\u001b[1;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001b[0m\n\u001b[0;32m    158\u001b[0m                                   \u001b[0mcitations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcitations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear_low\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myear_low\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear_high\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myear_high\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                                   sort_by=sort_by, include_last_year=include_last_year, start_index=start_index)\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__nav\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_publications\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msearch_citedby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpublication_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scholarly\\_navigator.py\u001b[0m in \u001b[0;36msearch_publications\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0m_SearchScholarIterator\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \"\"\"\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_SearchScholarIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msearch_author_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilled\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msortby\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"citedby\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpublication_limit\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAuthor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scholarly\\publication_parser.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, nav, url)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pubtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPublicationSource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPUBLICATION_SEARCH_SNIPPET\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"/scholar?\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mPublicationSource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJOURNAL_CITATION_LIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nav\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnav\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_total_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_parser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPublicationParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nav\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scholarly\\publication_parser.py\u001b[0m in \u001b[0;36m_load_url\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_load_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# this is temporary until setup json file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nav\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gs_r gs_or gs_scl'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gsc_mpat_ttl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scholarly\\_navigator.py\u001b[0m in \u001b[0;36m_get_soup\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;34m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://scholar.google.com{0}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'\\xa0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scholarly\\_navigator.py\u001b[0m in \u001b[0;36m_get_page\u001b[1;34m(self, pagerequest, premium)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpagerequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxTriesExceededException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot Fetch from Google Scholar.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxTriesExceededException\u001b[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to search scholarly papers and collect extended information\n",
    "def search_scholarly(query, save_file):\n",
    "    search_query = scholarly.search_pubs(query)\n",
    "    papers = []\n",
    "    \n",
    "    # Define common metrics and synonyms for bias\n",
    "    metrics_to_check = [\n",
    "        'accuracy', 'f1', 'precision', 'recall', 'auc', 'roc', \n",
    "        'sensitivity', 'specificity', 'confusion matrix', \n",
    "        'loss function', 'cross-entropy', 'mean squared error', \n",
    "        'overfitting', 'underfitting', 'cross-validation', \n",
    "        'training time', 'inference time', 'statistical significance', \n",
    "        'p-value', 't-test', 'anova', 'correlation', 'regression', \n",
    "        'baseline comparison', \n",
    "        'mae', 'rmse'\n",
    "    ]\n",
    "    \n",
    "    bias_synonyms = [\n",
    "        'bias', 'biasness', 'fairness', 'unfairness', 'equity', \n",
    "        'inequality', 'prejudice', 'discrimination', 'impartiality', \n",
    "        'skewness', 'systematic error'\n",
    "    ]\n",
    "    \n",
    "    for _ in range(30):  # Adjust this number as needed (e.g., 35)\n",
    "        try:\n",
    "            paper = next(search_query)\n",
    "            # Collecting only papers with more than a certain citation threshold (e.g., 100)\n",
    "            if 'num_citations' in paper and paper['num_citations'] >= 100:\n",
    "                paper_info = {\n",
    "                    'Title': paper['bib'].get('title', 'No Title'),\n",
    "                    'Authors': paper['bib'].get('author', 'No Author'),\n",
    "                    'Year': paper['bib'].get('pub_year', None),\n",
    "                    'Cited By': paper['num_citations'],\n",
    "                    'Dataset': query,\n",
    "                    'Abstract': paper['bib'].get('abstract', ''),  # Extract abstract if available\n",
    "                    'DOI': paper['bib'].get('doi', 'No DOI'),      # Extract DOI if available\n",
    "                    'Journal': paper['bib'].get('venue', 'No Journal'),\n",
    "                    'URL': None  # Initialize URL as None\n",
    "                }\n",
    "\n",
    "                # Check for mentions of metrics and bias-related terms in the abstract\n",
    "                abstract = paper_info['Abstract'].lower() if paper_info['Abstract'] else ''\n",
    "                \n",
    "                # Include flags for whether specific metrics are mentioned\n",
    "                for metric in metrics_to_check:\n",
    "                    paper_info[f'Mentions_{metric.capitalize().replace(\" \", \"_\")}'] = metric in abstract\n",
    "                \n",
    "                # Include a separate flag for bias-related terms\n",
    "                paper_info['Mentions_Bias'] = any(bias_term in abstract for bias_term in bias_synonyms)\n",
    "                \n",
    "                # Perform a Google search to find the paper's URL\n",
    "                try:\n",
    "                    search_results = search(paper_info['Title'], num_results=1)  # Get the top search result\n",
    "                    for url in search_results:\n",
    "                        paper_info['URL'] = url\n",
    "                        break  # Only take the first result\n",
    "                except Exception as e:\n",
    "                    print(f\"Error finding URL for {paper_info['Title']}: {e}\")\n",
    "                    paper_info['URL'] = None\n",
    "                \n",
    "                papers.append(paper_info)\n",
    "\n",
    "                # Save to CSV after processing each paper\n",
    "                temp_df = pd.DataFrame(papers)\n",
    "                temp_df.to_csv(save_file, mode='a', header=not pd.io.common.file_exists(save_file), index=False)\n",
    "\n",
    "                # If we've collected 10 highly cited papers, break out of the loop\n",
    "                if len(papers) >= 20:\n",
    "                    break\n",
    "\n",
    "            # Random delay between 30 and 60 seconds to avoid detection\n",
    "            time.sleep(random.uniform(30, 60))\n",
    "        except StopIteration:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "\n",
    "    return papers\n",
    "\n",
    "# Collect data from Scholarly for each combination of dataset and topic\n",
    "def collect_data(fer_datasets_LONG, topics, save_file):\n",
    "    scholarly_results = []\n",
    "\n",
    "    for dataset in fer_datasets_LONG:\n",
    "        for topic in topics:\n",
    "            combined_query = f\"{dataset} {topic}\"\n",
    "            print(f\"Searching for combination: {combined_query}\")\n",
    "            scholarly_results.extend(search_scholarly(combined_query, save_file))\n",
    "\n",
    "# Save results to a CSV file\n",
    "save_file = 'scholarly_papers_combined_extended.csv'\n",
    "\n",
    "# Start collecting data\n",
    "collect_data(fer_datasets_LONG, topics, save_file)\n",
    "\n",
    "print(\"Data collection completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b1bd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
