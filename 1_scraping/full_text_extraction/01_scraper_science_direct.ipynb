{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8a45001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import pdfkit\n",
    "import pyautogui\n",
    "import playwright\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c966ed0",
   "metadata": {},
   "source": [
    "You have to have access for sciencedirect. Before you start to run the script, you have to login to sciencedirect.\n",
    "\n",
    "https://www.sciencedirect.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cccc98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO = True\n",
    "MAX_PAPERS_TO_DOWNLOAD = 3\n",
    "# you have to have access for sciencedirect. Before you start to run the script, you have to login to sciencedirect.\n",
    "# https://www.sciencedirect.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17649231",
   "metadata": {},
   "source": [
    "#### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b754983",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Cited By</th>\n",
       "      <th>Detected_Dataset</th>\n",
       "      <th>Detected_Topic</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Journal</th>\n",
       "      <th>...</th>\n",
       "      <th>Mentions_Statistical_significance</th>\n",
       "      <th>Mentions_P-value</th>\n",
       "      <th>Mentions_T-test</th>\n",
       "      <th>Mentions_Anova</th>\n",
       "      <th>Mentions_Correlation</th>\n",
       "      <th>Mentions_Regression</th>\n",
       "      <th>Mentions_Baseline_comparison</th>\n",
       "      <th>Mentions_Mae</th>\n",
       "      <th>Mentions_Rmse</th>\n",
       "      <th>Mentions_Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10 Automated Face Analysis for Affective Compu...</td>\n",
       "      <td>['JF Cohn', 'F De la Torre']</td>\n",
       "      <td>2015</td>\n",
       "      <td>170</td>\n",
       "      <td>Affective Faces Database</td>\n",
       "      <td>classifier</td>\n",
       "      <td>Differences in manual coding between databases...</td>\n",
       "      <td>No DOI</td>\n",
       "      <td>The Oxford handbook of affective …</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3D facial expression recognition based on auto...</td>\n",
       "      <td>['H Tang', 'TS Huang']</td>\n",
       "      <td>2008</td>\n",
       "      <td>205</td>\n",
       "      <td>Binghamton University 3D Facial Expression</td>\n",
       "      <td>classification, classifier, facial expression ...</td>\n",
       "      <td>facial expression recognition from 3D facial s...</td>\n",
       "      <td>No DOI</td>\n",
       "      <td>… on computer vision and pattern recognition …</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3D facial expression recognition based on prim...</td>\n",
       "      <td>['J Wang', 'L Yin', 'X Wei', 'Y Sun']</td>\n",
       "      <td>2006</td>\n",
       "      <td>440</td>\n",
       "      <td>Binghamton University 3D Facial Expression</td>\n",
       "      <td>facial expression recognition</td>\n",
       "      <td>expressions using 3D facial expression range d...</td>\n",
       "      <td>No DOI</td>\n",
       "      <td>… Vision and Pattern Recognition  …</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0  10 Automated Face Analysis for Affective Compu...   \n",
       "1           1  3D facial expression recognition based on auto...   \n",
       "2           2  3D facial expression recognition based on prim...   \n",
       "\n",
       "                                 Authors  Year  Cited By  \\\n",
       "0           ['JF Cohn', 'F De la Torre']  2015       170   \n",
       "1                 ['H Tang', 'TS Huang']  2008       205   \n",
       "2  ['J Wang', 'L Yin', 'X Wei', 'Y Sun']  2006       440   \n",
       "\n",
       "                             Detected_Dataset  \\\n",
       "0                    Affective Faces Database   \n",
       "1  Binghamton University 3D Facial Expression   \n",
       "2  Binghamton University 3D Facial Expression   \n",
       "\n",
       "                                      Detected_Topic  \\\n",
       "0                                         classifier   \n",
       "1  classification, classifier, facial expression ...   \n",
       "2                      facial expression recognition   \n",
       "\n",
       "                                            Abstract     DOI  \\\n",
       "0  Differences in manual coding between databases...  No DOI   \n",
       "1  facial expression recognition from 3D facial s...  No DOI   \n",
       "2  expressions using 3D facial expression range d...  No DOI   \n",
       "\n",
       "                                          Journal  ...  \\\n",
       "0              The Oxford handbook of affective …  ...   \n",
       "1  … on computer vision and pattern recognition …  ...   \n",
       "2             … Vision and Pattern Recognition  …  ...   \n",
       "\n",
       "  Mentions_Statistical_significance  Mentions_P-value  Mentions_T-test  \\\n",
       "0                             False             False            False   \n",
       "1                             False             False            False   \n",
       "2                             False             False            False   \n",
       "\n",
       "   Mentions_Anova  Mentions_Correlation  Mentions_Regression  \\\n",
       "0           False                 False                False   \n",
       "1           False                 False                False   \n",
       "2           False                 False                False   \n",
       "\n",
       "   Mentions_Baseline_comparison  Mentions_Mae  Mentions_Rmse  Mentions_Bias  \n",
       "0                         False         False          False          False  \n",
       "1                         False         False          False          False  \n",
       "2                         False         False          False          False  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to extract the base domain of a URL (until .com, .org, etc.)\n",
    "def extract_base_domain(url):\n",
    "    if pd.notna(url):\n",
    "        # Split the URL and return the main domain (e.g., 'arxiv.org', 'ieee.org')\n",
    "        return '.'.join(url.split('/')[2].split('.')[-2:])\n",
    "    return None\n",
    "file_path = '../Scrapes_ALL.csv'\n",
    "papers_df = pd.read_csv(file_path)\n",
    "display(papers_df.head(3))\n",
    "# Apply the function to extract base domains\n",
    "papers_df['Base_Domain'] = papers_df['URL'].apply(extract_base_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3671e8",
   "metadata": {},
   "source": [
    "# Get papers from scienecedirect.com \n",
    "\n",
    "Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19508bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers: 40\n"
     ]
    }
   ],
   "source": [
    "scienece_direct_df = papers_df[papers_df['URL'].str.contains('sciencedirect.com', case=False, na=False)]\n",
    "scienece_direct_df = scienece_direct_df.rename(columns={'Unnamed: 0': 'ID'})\n",
    "# shuffle for fun\n",
    "scienece_direct_df = scienece_direct_df.sample(frac=1).reset_index(drop=True)\n",
    "scienece_direct_df = scienece_direct_df.reset_index(drop=True)\n",
    "len(scienece_direct_df['URL'].to_list())\n",
    "print(f\"Number of papers: {len(scienece_direct_df['URL'].to_list())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126095a",
   "metadata": {},
   "source": [
    "### Main Script\n",
    "\n",
    "After starting the script, it will open the Firefox web browser. You will need to enter your ScienceDirect credentials there. Do not forget to push the \"Log in\" button.\n",
    "\n",
    "Please be patient, as it may take some time for the script to start saving the papers based on the links from the `science_direct_df` dataset. The script includes several sleep statements of about 30 seconds to ensure proper loading and execution.\n",
    "\n",
    "The outcome of the script will be `html` files saved in the `x_research_papers_save\\1_raw_files` folder. Each html file is one paper. These html files will be processed in the next script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d13dfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\ITU-BOOK\\Data in Wild\\Project\\DataInWild\\SUBMISSION\\1_scraping\\x_research_papers_save\\1_raw_files\n",
      "Clicked 'Register with institution' button\n",
      "Error during login process: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF75EE438A5+3004357]\n",
      "\t(No symbol) [0x00007FF75EAD9970]\n",
      "\t(No symbol) [0x00007FF75E98582A]\n",
      "\t(No symbol) [0x00007FF75E9D5B8E]\n",
      "\t(No symbol) [0x00007FF75E9D5E7C]\n",
      "\t(No symbol) [0x00007FF75EA1EC27]\n",
      "\t(No symbol) [0x00007FF75E9FBC1F]\n",
      "\t(No symbol) [0x00007FF75EA1BA4C]\n",
      "\t(No symbol) [0x00007FF75E9FB983]\n",
      "\t(No symbol) [0x00007FF75E9C7628]\n",
      "\t(No symbol) [0x00007FF75E9C8791]\n",
      "\tGetHandleVerifier [0x00007FF75EE6A00D+3161901]\n",
      "\tGetHandleVerifier [0x00007FF75EEBE060+3506048]\n",
      "\tGetHandleVerifier [0x00007FF75EEB400D+3465005]\n",
      "\tGetHandleVerifier [0x00007FF75EC30EEB+830987]\n",
      "\t(No symbol) [0x00007FF75EAE467F]\n",
      "\t(No symbol) [0x00007FF75EAE09D4]\n",
      "\t(No symbol) [0x00007FF75EAE0B6D]\n",
      "\t(No symbol) [0x00007FF75EAD0149]\n",
      "\tBaseThreadInitThunk [0x00007FFAF182E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFAF303FBCC+44]\n",
      "\n",
      " Processing paper 40\n",
      "Processing: https://www.sciencedirect.com/science/article/pii/S0925231220309838\n",
      "Content loaded\n",
      "HTML content captured. Length: 454179\n",
      "Saved loaded page as HTML: science_direct_40.html\n",
      " Processing paper 173\n",
      "Processing: https://www.sciencedirect.com/science/article/pii/S0031320317302327\n",
      "Content loaded\n",
      "HTML content captured. Length: 447403\n",
      "Saved loaded page as HTML: science_direct_173.html\n",
      " Processing paper 102\n",
      "Processing: https://www.sciencedirect.com/science/article/pii/S1053811915008873\n",
      "Content loaded\n",
      "HTML content captured. Length: 847332\n",
      "Saved loaded page as HTML: science_direct_102.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make sure that folder is exist\n",
    "DOWNLOAD_DIR = os.path.join(os.path.dirname(os.path.abspath('.')), \"x_research_papers_save\", \"1_raw_files\")\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "print(DOWNLOAD_DIR)\n",
    "\n",
    "def login_to_sciencedirect(driver, username=\"\", password=\"\"):\n",
    "    login_url = \"https://id.elsevier.com/as/authorization.oauth2?platSite=SD%2Fscience&additionalPlatSites=GH%2Fgeneralhospital%2CMDY%2Fmendeley%2CSC%2Fscopus&scope=openid%20email%20profile%20els_auth_info%20els_idp_info%20els_idp_analytics_attrs%20els_sa_discover%20urn%3Acom%3Aelsevier%3Aidp%3Apolicy%3Aproduct%3Aindv_identity&response_type=code&redirect_uri=https%3A%2F%2Fwww.sciencedirect.com%2Fuser%2Fidentity%2Flanding&authType=SINGLE_SIGN_IN&prompt=login&client_id=SDFE-v4&state=retryCounter%3D0%26csrfToken%3D0007d31c-b511-4d2f-962c-46977ec5d3c7%26idpPolicy%3Durn%253Acom%253Aelsevier%253Aidp%253Apolicy%253Aproduct%253Aindv_identity%26returnUrl%3D%252F%26prompt%3Dlogin&els_policy=idp_policy_indv_identity_plus\"\n",
    "    driver.get(login_url)\n",
    "    \n",
    "    try:\n",
    "        # Wait for and click the \"Register with institution\" button\n",
    "        register_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"bdd-elsPrimaryBtn\"))\n",
    "        )\n",
    "        register_button.click()\n",
    "        print(\"Clicked 'Register with institution' button\")\n",
    "    except TimeoutException:\n",
    "        print(\"'Register with institution' button not found or not clickable\")\n",
    "        return False\n",
    "    \n",
    "    # Wait for the page to load\n",
    "    time.sleep(30)\n",
    "    \n",
    "    try:\n",
    "        # Now we're on the institutional login page\n",
    "        # Enter username and password\n",
    "        username_field = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.ID, \"username\"))\n",
    "        )\n",
    "        username_field.clear()  # Clear any pre-filled text\n",
    "        username_field.send_keys(username)\n",
    "        print(\"Entered username\")\n",
    "        \n",
    "        password_field = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.ID, \"password\"))\n",
    "        )\n",
    "        password_field.clear()  # Clear any pre-filled text\n",
    "        password_field.send_keys(password)\n",
    "        print(\"Entered password\")\n",
    "        \n",
    "        # Click the login button\n",
    "        login_button = WebDriverWait(driver, 30).until(\n",
    "            EC.element_to_be_clickable((By.NAME, \"action\"))\n",
    "        )\n",
    "        login_button.click()\n",
    "        print(\"Clicked login button\")\n",
    "    except (TimeoutException, NoSuchElementException) as e:\n",
    "        print(f\"Error during login process: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "    # Wait for login to complete and redirect\n",
    "    try:\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_element_located((By.ID, \"sdMainContent\"))\n",
    "        )\n",
    "        print(\"Login successful - redirected to ScienceDirect main page\")\n",
    "        return True\n",
    "    except TimeoutException:\n",
    "        print(\"Login may have failed or page did not load completely\")\n",
    "        return False\n",
    "\n",
    "\n",
    "    driver.get(url)\n",
    "    print(\"We are in download pdf function\")\n",
    "    \n",
    "    try:\n",
    "        # Wait for the content to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".article-wrapper, #sdMainContent, .Publication\"))\n",
    "        )\n",
    "        print(\"Content loaded\")\n",
    "\n",
    "        # Scroll to ensure all content is loaded\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait for any dynamic content to load after scrolling\n",
    "\n",
    "        # Get the HTML content\n",
    "        html_content = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "        print(\"HTML content captured. Length:\", len(html_content))\n",
    "        \n",
    "        # Save as HTML\n",
    "        html_filename = f\"{filename}.html\"\n",
    "        html_path = os.path.join(DOWNLOAD_DIR, html_filename)\n",
    "        with open(html_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "            print(f\"Saved loaded page as HTML: {html_filename}\")\n",
    "\n",
    "        # Save as PDF\n",
    "        pdf_filename = f\"{filename}.pdf\"\n",
    "        pdf_path = os.path.join(DOWNLOAD_DIR, pdf_filename)\n",
    "        try:\n",
    "            pdfkit.from_string(html_content, pdf_path)\n",
    "            print(f\"Saved loaded page as PDF: {pdf_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving loaded page as PDF: {str(e)}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing {url}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def save_content(driver, url, filename):\n",
    "    driver.get(url)\n",
    "    print(f\"Processing: {url}\")\n",
    "    \n",
    "    try:\n",
    "        # Wait for the content to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".article-wrapper, #sdMainContent, .Publication\"))\n",
    "        )\n",
    "        print(\"Content loaded\")\n",
    "\n",
    "        # Scroll to ensure all content is loaded\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Wait for any dynamic content to load after scrolling\n",
    "\n",
    "        # Get the HTML content\n",
    "        html_content = driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "        print(\"HTML content captured. Length:\", len(html_content))\n",
    "        # print(html_content)\n",
    "        \n",
    "        # Save as HTML\n",
    "        html_filename = f\"{filename}.html\"\n",
    "        html_path = os.path.join(DOWNLOAD_DIR, html_filename)\n",
    "        with open(html_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "        print(f\"Saved loaded page as HTML: {html_filename}\")\n",
    "\n",
    "        # multiple method to save pdf, onyl one was working. Sad.\n",
    "        pdf_filename = f\"{filename}.pdf\"\n",
    "        pdf_path = os.path.join(DOWNLOAD_DIR, pdf_filename)\n",
    "\n",
    "        # Method 1: Use browser's built-in PDF printing (Chrome)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"Attempting Method 1: Browser's built-in PDF printing\")\n",
    "            driver.execute_script('window.print();')\n",
    "            time.sleep(5)  # Wait for the print dialog to process\n",
    "            pyautogui.hotkey('ctrl', 'shift', 'p')  # Change printer to \"Save as PDF\"\n",
    "            time.sleep(1)\n",
    "            pyautogui.press('enter')  # Select \"Save as PDF\"\n",
    "            time.sleep(1)\n",
    "            pyautogui.write(pdf_path)  # Type the file path\n",
    "            time.sleep(1)\n",
    "            pyautogui.press('enter')  # Save the PDF\n",
    "\n",
    "            print(f\"PDF should be saved as: {pdf_path}\")\n",
    "            time.sleep(5)  # Wait for the save process to complete\n",
    "            if os.path.exists(pdf_path):\n",
    "                print(f\"PDF successfully saved: {pdf_filename}\")\n",
    "            \n",
    "            else:\n",
    "                print(f\"PDF was not saved at the expected location: {pdf_path}\")\n",
    "            print(\"Method 1 completed. Check your downloads folder for the PDF.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Method 1 failed: {str(e)}\")\n",
    "\n",
    "        # Method 2: Use pdfkit (if installed)\n",
    "        try:\n",
    "            print(\"Attempting Method 2: pdfkit\")\n",
    "            import pdfkit\n",
    "            pdfkit.from_string(html_content, pdf_path)\n",
    "            print(f\"Method 2 succeeded. Saved PDF: {pdf_filename}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Method 2 failed: {str(e)}\")\n",
    "\n",
    "        # Method 3: Use WeasyPrint (if installed)\n",
    "        try:\n",
    "            print(\"Attempting Method 3: WeasyPrint\")\n",
    "            from weasyprint import HTML\n",
    "            HTML(string=html_content).write_pdf(pdf_path)\n",
    "            print(f\"Method 3 succeeded. Saved PDF: {pdf_filename}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Method 3 failed: {str(e)}\")\n",
    "\n",
    "        # Method 4: Use Playwright to generate PDF (if installed)\n",
    "        try:\n",
    "            print(\"Attempting Method 4: Playwright\")\n",
    "            from playwright.sync_api import sync_playwright\n",
    "            with sync_playwright() as p:\n",
    "                browser = p.chromium.launch()\n",
    "                page = browser.new_page()\n",
    "                page.set_content(html_content)\n",
    "                page.pdf(path=pdf_path)\n",
    "                browser.close()\n",
    "            print(f\"Method 4 succeeded. Saved PDF: {pdf_filename}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Method 4 failed: {str(e)}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        with open(html_path) as f:\n",
    "            pdfkit.from_file(f, f\"{filename}.pdf\")\n",
    "            print(f\"Saved loaded page as pdf: {html_filename}\")\n",
    "\n",
    "        # Extract and save text content\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        text_content = soup.get_text(separator='\\n', strip=True)\n",
    "        \n",
    "        text_filename = f\"{filename}.txt\"\n",
    "        text_path = os.path.join(DOWNLOAD_DIR, text_filename)\n",
    "        with open(text_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(text_content)\n",
    "        print(f\"Saved text content: {text_filename}\")\n",
    "        \"\"\"\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing {url}: {str(e)}\")\n",
    "        return False\n",
    "   \n",
    "def main():\n",
    "\n",
    "\n",
    "    # Initialize the WebDriver (make sure you have the appropriate driver installed)\n",
    "    driver = webdriver.Chrome()  # or webdriver.Firefox(), etc.\n",
    "    \n",
    "    try:\n",
    "        # Login to ScienceDirect\n",
    "        login_to_sciencedirect(driver)\n",
    "        \n",
    "        # Iterate through the URLs and download PDFs\n",
    "        c = 0\n",
    "        for index, row in scienece_direct_df.iterrows():\n",
    "            if DEMO and c >= MAX_PAPERS_TO_DOWNLOAD:\n",
    "                break\n",
    "            else:\n",
    "                ID = row[\"ID\"]\n",
    "                print(f\" Processing paper {ID}\")\n",
    "                url = row['URL']\n",
    "                # Generate a filename based on some criteria, e.g., the paper's title\n",
    "                filename = f\"science_direct_{ID}\"\n",
    "                # success = download_pdf(driver, url, filename)\n",
    "                success = save_content(driver, url, filename)\n",
    "                if success:\n",
    "                    scienece_direct_df.at[index, 'Downloaded'] = 'Yes'\n",
    "                else:\n",
    "                    scienece_direct_df.at[index, 'Downloaded'] = 'No'\n",
    "\n",
    "            c += 1\n",
    "        \n",
    "        # Save the updated DataFrame\n",
    "        scienece_direct_df.to_csv('sciencedirect_papers_status.csv', index=False)\n",
    "    \n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
