<html lang="en-US" class="Preview toolbar-stuck"><head>
      <meta name="citation_pii" content="S0925231220309838">
<meta name="citation_issn" content="0925-2312">
<meta name="citation_volume" content="411">
<meta name="citation_lastpage" content="350">
<meta name="citation_publisher" content="Elsevier">
<meta name="citation_firstpage" content="340">
<meta name="citation_journal_title" content="Neurocomputing">
<meta name="citation_type" content="JOUR">
<meta name="citation_doi" content="10.1016/j.neucom.2020.06.014">
<meta name="dc.identifier" content="10.1016/j.neucom.2020.06.014">
<meta name="citation_article_type" content="Full-length article">
<meta property="og:description" content="Facial expression recognition is a hot research topic and can be applied in many computer vision fields, such as human–computer interaction, affective…">
<meta property="og:image" content="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00336-cov150h.gif">
<meta name="citation_title" content="Attention mechanism-based CNN for facial expression recognition">
<meta property="og:title" content="Attention mechanism-based CNN for facial expression recognition">
<meta name="citation_publication_date" content="2020/10/21">
<meta name="citation_online_date" content="2020/06/12">
<meta name="robots" content="INDEX,FOLLOW,NOARCHIVE,NOCACHE,NOODP,NOYDIR">
      <title>Attention mechanism-based CNN for facial expression recognition - ScienceDirect</title>
      <link rel="canonical" href="https://www.sciencedirect.com/science/article/abs/pii/S0925231220309838">
      <meta name="tdm-reservation" content="1">
      <meta name="tdm-policy" content="https://www.elsevier.com/tdm/tdmrep-policy.json">
      <meta property="og:type" content="article">
      <meta name="viewport" content="initial-scale=1">
      <meta name="SDTech" content="Proudly brought to you by the SD Technology team">
      <script async="" src="https://cdn.pendo.io/agent/static/d6c1d995-bc7e-4e53-77f1-2ea4ecbb9565/pendo.js"></script><script type="text/javascript">(function newRelicBrowserProSPA() {
  ;
  window.NREUM || (NREUM = {});
  NREUM.init = {
    privacy: {
      cookies_enabled: false
    },
    ajax: {
      deny_list: ["bam-cell.nr-data.net"]
    }
  };
  ;
  NREUM.loader_config = {
    accountID: "2128461",
    trustKey: "2038175",
    agentID: "1118783207",
    licenseKey: "7ac4127487",
    applicationID: "814813181"
  };
  ;
  NREUM.info = {
    beacon: "bam.nr-data.net",
    errorBeacon: "bam.nr-data.net",
    licenseKey: "7ac4127487",
    applicationID: "814813181",
    sa: 1
  };
  ; /*! For license information please see nr-loader-spa-1.238.0.min.js.LICENSE.txt */
  (() => {
    "use strict";

    var e,
      t,
      r = {
        5763: (e, t, r) => {
          r.d(t, {
            P_: () => f,
            Mt: () => p,
            C5: () => s,
            DL: () => v,
            OP: () => T,
            lF: () => D,
            Yu: () => y,
            Dg: () => h,
            CX: () => c,
            GE: () => b,
            sU: () => _
          });
          var n = r(8632),
            i = r(9567);
          const o = {
              beacon: n.ce.beacon,
              errorBeacon: n.ce.errorBeacon,
              licenseKey: void 0,
              applicationID: void 0,
              sa: void 0,
              queueTime: void 0,
              applicationTime: void 0,
              ttGuid: void 0,
              user: void 0,
              account: void 0,
              product: void 0,
              extra: void 0,
              jsAttributes: {},
              userAttributes: void 0,
              atts: void 0,
              transactionName: void 0,
              tNamePlain: void 0
            },
            a = {};
          function s(e) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            if (!a[e]) throw new Error("Info for ".concat(e, " was never set"));
            return a[e];
          }
          function c(e, t) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            a[e] = (0, i.D)(t, o), (0, n.Qy)(e, a[e], "info");
          }
          var u = r(7056);
          const d = () => {
              const e = {
                blockSelector: "[data-nr-block]",
                maskInputOptions: {
                  password: !0
                }
              };
              return {
                allow_bfcache: !0,
                privacy: {
                  cookies_enabled: !0
                },
                ajax: {
                  deny_list: void 0,
                  block_internal: !0,
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                distributed_tracing: {
                  enabled: void 0,
                  exclude_newrelic_header: void 0,
                  cors_use_newrelic_header: void 0,
                  cors_use_tracecontext_headers: void 0,
                  allowed_origins: void 0
                },
                session: {
                  domain: void 0,
                  expiresMs: u.oD,
                  inactiveMs: u.Hb
                },
                ssl: void 0,
                obfuscate: void 0,
                jserrors: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                metrics: {
                  enabled: !0
                },
                page_action: {
                  enabled: !0,
                  harvestTimeSeconds: 30
                },
                page_view_event: {
                  enabled: !0
                },
                page_view_timing: {
                  enabled: !0,
                  harvestTimeSeconds: 30,
                  long_task: !1
                },
                session_trace: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                harvest: {
                  tooManyRequestsDelay: 60
                },
                session_replay: {
                  enabled: !1,
                  harvestTimeSeconds: 60,
                  sampleRate: .1,
                  errorSampleRate: .1,
                  maskTextSelector: "*",
                  maskAllInputs: !0,
                  get blockClass() {
                    return "nr-block";
                  },
                  get ignoreClass() {
                    return "nr-ignore";
                  },
                  get maskTextClass() {
                    return "nr-mask";
                  },
                  get blockSelector() {
                    return e.blockSelector;
                  },
                  set blockSelector(t) {
                    e.blockSelector += ",".concat(t);
                  },
                  get maskInputOptions() {
                    return e.maskInputOptions;
                  },
                  set maskInputOptions(t) {
                    e.maskInputOptions = {
                      ...t,
                      password: !0
                    };
                  }
                },
                spa: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                }
              };
            },
            l = {};
          function f(e) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            if (!l[e]) throw new Error("Configuration for ".concat(e, " was never set"));
            return l[e];
          }
          function h(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            l[e] = (0, i.D)(t, d()), (0, n.Qy)(e, l[e], "config");
          }
          function p(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            var r = f(e);
            if (r) {
              for (var n = t.split("."), i = 0; i < n.length - 1; i++) if ("object" != typeof (r = r[n[i]])) return;
              r = r[n[n.length - 1]];
            }
            return r;
          }
          const g = {
              accountID: void 0,
              trustKey: void 0,
              agentID: void 0,
              licenseKey: void 0,
              applicationID: void 0,
              xpid: void 0
            },
            m = {};
          function v(e) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            if (!m[e]) throw new Error("LoaderConfig for ".concat(e, " was never set"));
            return m[e];
          }
          function b(e, t) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            m[e] = (0, i.D)(t, g), (0, n.Qy)(e, m[e], "loader_config");
          }
          const y = (0, n.mF)().o;
          var w = r(385),
            A = r(6818);
          const x = {
              buildEnv: A.Re,
              bytesSent: {},
              queryBytesSent: {},
              customTransaction: void 0,
              disabled: !1,
              distMethod: A.gF,
              isolatedBacklog: !1,
              loaderType: void 0,
              maxBytes: 3e4,
              offset: Math.floor(w._A?.performance?.timeOrigin || w._A?.performance?.timing?.navigationStart || Date.now()),
              onerror: void 0,
              origin: "" + w._A.location,
              ptid: void 0,
              releaseIds: {},
              session: void 0,
              xhrWrappable: "function" == typeof w._A.XMLHttpRequest?.prototype?.addEventListener,
              version: A.q4,
              denyList: void 0
            },
            E = {};
          function T(e) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            if (!E[e]) throw new Error("Runtime for ".concat(e, " was never set"));
            return E[e];
          }
          function _(e, t) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            E[e] = (0, i.D)(t, x), (0, n.Qy)(e, E[e], "runtime");
          }
          function D(e) {
            return function (e) {
              try {
                const t = s(e);
                return !!t.licenseKey && !!t.errorBeacon && !!t.applicationID;
              } catch (e) {
                return !1;
              }
            }(e);
          }
        },
        9567: (e, t, r) => {
          r.d(t, {
            D: () => i
          });
          var n = r(50);
          function i(e, t) {
            try {
              if (!e || "object" != typeof e) return (0, n.Z)("Setting a Configurable requires an object as input");
              if (!t || "object" != typeof t) return (0, n.Z)("Setting a Configurable requires a model to set its initial properties");
              const r = Object.create(Object.getPrototypeOf(t), Object.getOwnPropertyDescriptors(t)),
                o = 0 === Object.keys(r).length ? e : r;
              for (let a in o) if (void 0 !== e[a]) try {
                "object" == typeof e[a] && "object" == typeof t[a] ? r[a] = i(e[a], t[a]) : r[a] = e[a];
              } catch (e) {
                (0, n.Z)("An error occurred while setting a property of a Configurable", e);
              }
              return r;
            } catch (e) {
              (0, n.Z)("An error occured while setting a Configurable", e);
            }
          }
        },
        6818: (e, t, r) => {
          r.d(t, {
            Re: () => i,
            gF: () => o,
            q4: () => n
          });
          const n = "1.238.0",
            i = "PROD",
            o = "CDN";
        },
        385: (e, t, r) => {
          r.d(t, {
            FN: () => a,
            IF: () => u,
            Nk: () => l,
            Tt: () => s,
            _A: () => o,
            il: () => n,
            pL: () => c,
            v6: () => i,
            w1: () => d
          });
          const n = "undefined" != typeof window && !!window.document,
            i = "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self.navigator instanceof WorkerNavigator || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis.navigator instanceof WorkerNavigator),
            o = n ? window : "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis),
            a = "" + o?.location,
            s = /iPad|iPhone|iPod/.test(navigator.userAgent),
            c = s && "undefined" == typeof SharedWorker,
            u = (() => {
              const e = navigator.userAgent.match(/Firefox[/\s](\d+\.\d+)/);
              return Array.isArray(e) && e.length >= 2 ? +e[1] : 0;
            })(),
            d = Boolean(n && window.document.documentMode),
            l = !!navigator.sendBeacon;
        },
        1117: (e, t, r) => {
          r.d(t, {
            w: () => o
          });
          var n = r(50);
          const i = {
            agentIdentifier: "",
            ee: void 0
          };
          class o {
            constructor(e) {
              try {
                if ("object" != typeof e) return (0, n.Z)("shared context requires an object as input");
                this.sharedContext = {}, Object.assign(this.sharedContext, i), Object.entries(e).forEach(e => {
                  let [t, r] = e;
                  Object.keys(i).includes(t) && (this.sharedContext[t] = r);
                });
              } catch (e) {
                (0, n.Z)("An error occured while setting SharedContext", e);
              }
            }
          }
        },
        8e3: (e, t, r) => {
          r.d(t, {
            L: () => d,
            R: () => c
          });
          var n = r(8325),
            i = r(1284),
            o = r(4322),
            a = r(3325);
          const s = {};
          function c(e, t) {
            const r = {
              staged: !1,
              priority: a.p[t] || 0
            };
            u(e), s[e].get(t) || s[e].set(t, r);
          }
          function u(e) {
            e && (s[e] || (s[e] = new Map()));
          }
          function d() {
            let e = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : "",
              t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : "feature";
            if (u(e), !e || !s[e].get(t)) return a(t);
            s[e].get(t).staged = !0;
            const r = [...s[e]];
            function a(t) {
              const r = e ? n.ee.get(e) : n.ee,
                a = o.X.handlers;
              if (r.backlog && a) {
                var s = r.backlog[t],
                  c = a[t];
                if (c) {
                  for (var u = 0; s && u < s.length; ++u) l(s[u], c);
                  (0, i.D)(c, function (e, t) {
                    (0, i.D)(t, function (t, r) {
                      r[0].on(e, r[1]);
                    });
                  });
                }
                delete a[t], r.backlog[t] = null, r.emit("drain-" + t, []);
              }
            }
            r.every(e => {
              let [t, r] = e;
              return r.staged;
            }) && (r.sort((e, t) => e[1].priority - t[1].priority), r.forEach(e => {
              let [t] = e;
              a(t);
            }));
          }
          function l(e, t) {
            var r = e[1];
            (0, i.D)(t[r], function (t, r) {
              var n = e[0];
              if (r[0] === n) {
                var i = r[1],
                  o = e[3],
                  a = e[2];
                i.apply(o, a);
              }
            });
          }
        },
        8325: (e, t, r) => {
          r.d(t, {
            A: () => c,
            ee: () => u
          });
          var n = r(8632),
            i = r(2210),
            o = r(5763);
          class a {
            constructor(e) {
              this.contextId = e;
            }
          }
          var s = r(3117);
          const c = "nr@context:".concat(s.a),
            u = function e(t, r) {
              var n = {},
                s = {},
                d = {},
                f = !1;
              try {
                f = 16 === r.length && (0, o.OP)(r).isolatedBacklog;
              } catch (e) {}
              var h = {
                on: g,
                addEventListener: g,
                removeEventListener: function (e, t) {
                  var r = n[e];
                  if (!r) return;
                  for (var i = 0; i < r.length; i++) r[i] === t && r.splice(i, 1);
                },
                emit: function (e, r, n, i, o) {
                  !1 !== o && (o = !0);
                  if (u.aborted && !i) return;
                  t && o && t.emit(e, r, n);
                  for (var a = p(n), c = m(e), d = c.length, l = 0; l < d; l++) c[l].apply(a, r);
                  var f = b()[s[e]];
                  f && f.push([h, e, r, a]);
                  return a;
                },
                get: v,
                listeners: m,
                context: p,
                buffer: function (e, t) {
                  const r = b();
                  if (t = t || "feature", h.aborted) return;
                  Object.entries(e || {}).forEach(e => {
                    let [n, i] = e;
                    s[i] = t, t in r || (r[t] = []);
                  });
                },
                abort: l,
                aborted: !1,
                isBuffering: function (e) {
                  return !!b()[s[e]];
                },
                debugId: r,
                backlog: f ? {} : t && "object" == typeof t.backlog ? t.backlog : {}
              };
              return h;
              function p(e) {
                return e && e instanceof a ? e : e ? (0, i.X)(e, c, () => new a(c)) : new a(c);
              }
              function g(e, t) {
                n[e] = m(e).concat(t);
              }
              function m(e) {
                return n[e] || [];
              }
              function v(t) {
                return d[t] = d[t] || e(h, t);
              }
              function b() {
                return h.backlog;
              }
            }(void 0, "globalEE"),
            d = (0, n.fP)();
          function l() {
            u.aborted = !0, u.backlog = {};
          }
          d.ee || (d.ee = u);
        },
        5546: (e, t, r) => {
          r.d(t, {
            E: () => n,
            p: () => i
          });
          var n = r(8325).ee.get("handle");
          function i(e, t, r, i, o) {
            o ? (o.buffer([e], i), o.emit(e, t, r)) : (n.buffer([e], i), n.emit(e, t, r));
          }
        },
        4322: (e, t, r) => {
          r.d(t, {
            X: () => o
          });
          var n = r(5546);
          o.on = a;
          var i = o.handlers = {};
          function o(e, t, r, o) {
            a(o || n.E, i, e, t, r);
          }
          function a(e, t, r, i, o) {
            o || (o = "feature"), e || (e = n.E);
            var a = t[o] = t[o] || {};
            (a[r] = a[r] || []).push([e, i]);
          }
        },
        3239: (e, t, r) => {
          r.d(t, {
            bP: () => s,
            iz: () => c,
            m$: () => a
          });
          var n = r(385);
          let i = !1,
            o = !1;
          try {
            const e = {
              get passive() {
                return i = !0, !1;
              },
              get signal() {
                return o = !0, !1;
              }
            };
            n._A.addEventListener("test", null, e), n._A.removeEventListener("test", null, e);
          } catch (e) {}
          function a(e, t) {
            return i || o ? {
              capture: !!e,
              passive: i,
              signal: t
            } : !!e;
          }
          function s(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            window.addEventListener(e, t, a(r, n));
          }
          function c(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            document.addEventListener(e, t, a(r, n));
          }
        },
        3117: (e, t, r) => {
          r.d(t, {
            a: () => n
          });
          const n = (0, r(4402).Rl)();
        },
        4402: (e, t, r) => {
          r.d(t, {
            Ht: () => u,
            M: () => c,
            Rl: () => a,
            ky: () => s
          });
          var n = r(385);
          const i = "xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx";
          function o(e, t) {
            return e ? 15 & e[t] : 16 * Math.random() | 0;
          }
          function a() {
            const e = n._A?.crypto || n._A?.msCrypto;
            let t,
              r = 0;
            return e && e.getRandomValues && (t = e.getRandomValues(new Uint8Array(31))), i.split("").map(e => "x" === e ? o(t, ++r).toString(16) : "y" === e ? (3 & o() | 8).toString(16) : e).join("");
          }
          function s(e) {
            const t = n._A?.crypto || n._A?.msCrypto;
            let r,
              i = 0;
            t && t.getRandomValues && (r = t.getRandomValues(new Uint8Array(31)));
            const a = [];
            for (var s = 0; s < e; s++) a.push(o(r, ++i).toString(16));
            return a.join("");
          }
          function c() {
            return s(16);
          }
          function u() {
            return s(32);
          }
        },
        7056: (e, t, r) => {
          r.d(t, {
            Bq: () => n,
            Hb: () => o,
            oD: () => i
          });
          const n = "NRBA",
            i = 144e5,
            o = 18e5;
        },
        7894: (e, t, r) => {
          function n() {
            return Math.round(performance.now());
          }
          r.d(t, {
            z: () => n
          });
        },
        7243: (e, t, r) => {
          r.d(t, {
            e: () => o
          });
          var n = r(385),
            i = {};
          function o(e) {
            if (e in i) return i[e];
            if (0 === (e || "").indexOf("data:")) return {
              protocol: "data"
            };
            let t;
            var r = n._A?.location,
              o = {};
            if (n.il) t = document.createElement("a"), t.href = e;else try {
              t = new URL(e, r.href);
            } catch (e) {
              return o;
            }
            o.port = t.port;
            var a = t.href.split("://");
            !o.port && a[1] && (o.port = a[1].split("/")[0].split("@").pop().split(":")[1]), o.port && "0" !== o.port || (o.port = "https" === a[0] ? "443" : "80"), o.hostname = t.hostname || r.hostname, o.pathname = t.pathname, o.protocol = a[0], "/" !== o.pathname.charAt(0) && (o.pathname = "/" + o.pathname);
            var s = !t.protocol || ":" === t.protocol || t.protocol === r.protocol,
              c = t.hostname === r.hostname && t.port === r.port;
            return o.sameOrigin = s && (!t.hostname || c), "/" === o.pathname && (i[e] = o), o;
          }
        },
        50: (e, t, r) => {
          function n(e, t) {
            "function" == typeof console.warn && (console.warn("New Relic: ".concat(e)), t && console.warn(t));
          }
          r.d(t, {
            Z: () => n
          });
        },
        2587: (e, t, r) => {
          r.d(t, {
            N: () => c,
            T: () => u
          });
          var n = r(8325),
            i = r(5546),
            o = r(8e3),
            a = r(3325);
          const s = {
            stn: [a.D.sessionTrace],
            err: [a.D.jserrors, a.D.metrics],
            ins: [a.D.pageAction],
            spa: [a.D.spa],
            sr: [a.D.sessionReplay, a.D.sessionTrace]
          };
          function c(e, t) {
            const r = n.ee.get(t);
            e && "object" == typeof e && (Object.entries(e).forEach(e => {
              let [t, n] = e;
              void 0 === u[t] && (s[t] ? s[t].forEach(e => {
                n ? (0, i.p)("feat-" + t, [], void 0, e, r) : (0, i.p)("block-" + t, [], void 0, e, r), (0, i.p)("rumresp-" + t, [Boolean(n)], void 0, e, r);
              }) : n && (0, i.p)("feat-" + t, [], void 0, void 0, r), u[t] = Boolean(n));
            }), Object.keys(s).forEach(e => {
              void 0 === u[e] && (s[e]?.forEach(t => (0, i.p)("rumresp-" + e, [!1], void 0, t, r)), u[e] = !1);
            }), (0, o.L)(t, a.D.pageViewEvent));
          }
          const u = {};
        },
        2210: (e, t, r) => {
          r.d(t, {
            X: () => i
          });
          var n = Object.prototype.hasOwnProperty;
          function i(e, t, r) {
            if (n.call(e, t)) return e[t];
            var i = r();
            if (Object.defineProperty && Object.keys) try {
              return Object.defineProperty(e, t, {
                value: i,
                writable: !0,
                enumerable: !1
              }), i;
            } catch (e) {}
            return e[t] = i, i;
          }
        },
        1284: (e, t, r) => {
          r.d(t, {
            D: () => n
          });
          const n = (e, t) => Object.entries(e || {}).map(e => {
            let [r, n] = e;
            return t(r, n);
          });
        },
        4351: (e, t, r) => {
          r.d(t, {
            P: () => o
          });
          var n = r(8325);
          const i = () => {
            const e = new WeakSet();
            return (t, r) => {
              if ("object" == typeof r && null !== r) {
                if (e.has(r)) return;
                e.add(r);
              }
              return r;
            };
          };
          function o(e) {
            try {
              return JSON.stringify(e, i());
            } catch (e) {
              try {
                n.ee.emit("internal-error", [e]);
              } catch (e) {}
            }
          }
        },
        3960: (e, t, r) => {
          r.d(t, {
            K: () => a,
            b: () => o
          });
          var n = r(3239);
          function i() {
            return "undefined" == typeof document || "complete" === document.readyState;
          }
          function o(e, t) {
            if (i()) return e();
            (0, n.bP)("load", e, t);
          }
          function a(e) {
            if (i()) return e();
            (0, n.iz)("DOMContentLoaded", e);
          }
        },
        8632: (e, t, r) => {
          r.d(t, {
            EZ: () => u,
            Qy: () => c,
            ce: () => o,
            fP: () => a,
            gG: () => d,
            mF: () => s
          });
          var n = r(7894),
            i = r(385);
          const o = {
            beacon: "bam.nr-data.net",
            errorBeacon: "bam.nr-data.net"
          };
          function a() {
            return i._A.NREUM || (i._A.NREUM = {}), void 0 === i._A.newrelic && (i._A.newrelic = i._A.NREUM), i._A.NREUM;
          }
          function s() {
            let e = a();
            return e.o || (e.o = {
              ST: i._A.setTimeout,
              SI: i._A.setImmediate,
              CT: i._A.clearTimeout,
              XHR: i._A.XMLHttpRequest,
              REQ: i._A.Request,
              EV: i._A.Event,
              PR: i._A.Promise,
              MO: i._A.MutationObserver,
              FETCH: i._A.fetch
            }), e;
          }
          function c(e, t, r) {
            let i = a();
            const o = i.initializedAgents || {},
              s = o[e] || {};
            return Object.keys(s).length || (s.initializedAt = {
              ms: (0, n.z)(),
              date: new Date()
            }), i.initializedAgents = {
              ...o,
              [e]: {
                ...s,
                [r]: t
              }
            }, i;
          }
          function u(e, t) {
            a()[e] = t;
          }
          function d() {
            return function () {
              let e = a();
              const t = e.info || {};
              e.info = {
                beacon: o.beacon,
                errorBeacon: o.errorBeacon,
                ...t
              };
            }(), function () {
              let e = a();
              const t = e.init || {};
              e.init = {
                ...t
              };
            }(), s(), function () {
              let e = a();
              const t = e.loader_config || {};
              e.loader_config = {
                ...t
              };
            }(), a();
          }
        },
        7956: (e, t, r) => {
          r.d(t, {
            N: () => i
          });
          var n = r(3239);
          function i(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] && arguments[1],
              r = arguments.length > 2 ? arguments[2] : void 0,
              i = arguments.length > 3 ? arguments[3] : void 0;
            return void (0, n.iz)("visibilitychange", function () {
              if (t) return void ("hidden" == document.visibilityState && e());
              e(document.visibilityState);
            }, r, i);
          }
        },
        1214: (e, t, r) => {
          r.d(t, {
            em: () => b,
            u5: () => j,
            QU: () => O,
            _L: () => I,
            Gm: () => H,
            Lg: () => L,
            BV: () => G,
            Kf: () => K
          });
          var n = r(8325),
            i = r(3117);
          const o = "nr@original:".concat(i.a);
          var a = Object.prototype.hasOwnProperty,
            s = !1;
          function c(e, t) {
            return e || (e = n.ee), r.inPlace = function (e, t, n, i, o) {
              n || (n = "");
              const a = "-" === n.charAt(0);
              for (let s = 0; s < t.length; s++) {
                const c = t[s],
                  u = e[c];
                d(u) || (e[c] = r(u, a ? c + n : n, i, c, o));
              }
            }, r.flag = o, r;
            function r(t, r, n, s, c) {
              return d(t) ? t : (r || (r = ""), nrWrapper[o] = t, function (e, t, r) {
                if (Object.defineProperty && Object.keys) try {
                  return Object.keys(e).forEach(function (r) {
                    Object.defineProperty(t, r, {
                      get: function () {
                        return e[r];
                      },
                      set: function (t) {
                        return e[r] = t, t;
                      }
                    });
                  }), t;
                } catch (e) {
                  u([e], r);
                }
                for (var n in e) a.call(e, n) && (t[n] = e[n]);
              }(t, nrWrapper, e), nrWrapper);
              function nrWrapper() {
                var o, a, d, l;
                try {
                  a = this, o = [...arguments], d = "function" == typeof n ? n(o, a) : n || {};
                } catch (t) {
                  u([t, "", [o, a, s], d], e);
                }
                i(r + "start", [o, a, s], d, c);
                try {
                  return l = t.apply(a, o);
                } catch (e) {
                  throw i(r + "err", [o, a, e], d, c), e;
                } finally {
                  i(r + "end", [o, a, l], d, c);
                }
              }
            }
            function i(r, n, i, o) {
              if (!s || t) {
                var a = s;
                s = !0;
                try {
                  e.emit(r, n, i, t, o);
                } catch (t) {
                  u([t, r, n, i], e);
                }
                s = a;
              }
            }
          }
          function u(e, t) {
            t || (t = n.ee);
            try {
              t.emit("internal-error", e);
            } catch (e) {}
          }
          function d(e) {
            return !(e && e instanceof Function && e.apply && !e[o]);
          }
          var l = r(2210),
            f = r(385);
          const h = {},
            p = f._A.XMLHttpRequest,
            g = "addEventListener",
            m = "removeEventListener",
            v = "nr@wrapped:".concat(n.A);
          function b(e) {
            var t = function (e) {
              return (e || n.ee).get("events");
            }(e);
            if (h[t.debugId]++) return t;
            h[t.debugId] = 1;
            var r = c(t, !0);
            function i(e) {
              r.inPlace(e, [g, m], "-", o);
            }
            function o(e, t) {
              return e[1];
            }
            return "getPrototypeOf" in Object && (f.il && y(document, i), y(f._A, i), y(p.prototype, i)), t.on(g + "-start", function (e, t) {
              var n = e[1];
              if (null !== n && ("function" == typeof n || "object" == typeof n)) {
                var i = (0, l.X)(n, v, function () {
                  var e = {
                    object: function () {
                      if ("function" != typeof n.handleEvent) return;
                      return n.handleEvent.apply(n, arguments);
                    },
                    function: n
                  }[typeof n];
                  return e ? r(e, "fn-", null, e.name || "anonymous") : n;
                });
                this.wrapped = e[1] = i;
              }
            }), t.on(m + "-start", function (e) {
              e[1] = this.wrapped || e[1];
            }), t;
          }
          function y(e, t) {
            let r = e;
            for (; "object" == typeof r && !Object.prototype.hasOwnProperty.call(r, g);) r = Object.getPrototypeOf(r);
            for (var n = arguments.length, i = new Array(n > 2 ? n - 2 : 0), o = 2; o < n; o++) i[o - 2] = arguments[o];
            r && t(r, ...i);
          }
          var w = "fetch-",
            A = w + "body-",
            x = ["arrayBuffer", "blob", "json", "text", "formData"],
            E = f._A.Request,
            T = f._A.Response,
            _ = "prototype";
          const D = {};
          function j(e) {
            const t = function (e) {
              return (e || n.ee).get("fetch");
            }(e);
            if (!(E && T && f._A.fetch)) return t;
            if (D[t.debugId]++) return t;
            function r(e, r, i) {
              var o = e[r];
              "function" == typeof o && (e[r] = function () {
                var e,
                  r = [...arguments],
                  a = {};
                t.emit(i + "before-start", [r], a), a[n.A] && a[n.A].dt && (e = a[n.A].dt);
                var s = o.apply(this, r);
                return t.emit(i + "start", [r, e], s), s.then(function (e) {
                  return t.emit(i + "end", [null, e], s), e;
                }, function (e) {
                  throw t.emit(i + "end", [e], s), e;
                });
              });
            }
            return D[t.debugId] = 1, x.forEach(e => {
              r(E[_], e, A), r(T[_], e, A);
            }), r(f._A, "fetch", w), t.on(w + "end", function (e, r) {
              var n = this;
              if (r) {
                var i = r.headers.get("content-length");
                null !== i && (n.rxSize = i), t.emit(w + "done", [null, r], n);
              } else t.emit(w + "done", [e], n);
            }), t;
          }
          const C = {},
            N = ["pushState", "replaceState"];
          function O(e) {
            const t = function (e) {
              return (e || n.ee).get("history");
            }(e);
            return !f.il || C[t.debugId]++ || (C[t.debugId] = 1, c(t).inPlace(window.history, N, "-")), t;
          }
          var S = r(3239);
          const P = {},
            R = ["appendChild", "insertBefore", "replaceChild"];
          function I(e) {
            const t = function (e) {
              return (e || n.ee).get("jsonp");
            }(e);
            if (!f.il || P[t.debugId]) return t;
            P[t.debugId] = !0;
            var r = c(t),
              i = /[?&](?:callback|cb)=([^&#]+)/,
              o = /(.*)\.([^.]+)/,
              a = /^(\w+)(\.|$)(.*)$/;
            function s(e, t) {
              if (!e) return t;
              const r = e.match(a),
                n = r[1];
              return s(r[3], t[n]);
            }
            return r.inPlace(Node.prototype, R, "dom-"), t.on("dom-start", function (e) {
              !function (e) {
                if (!e || "string" != typeof e.nodeName || "script" !== e.nodeName.toLowerCase()) return;
                if ("function" != typeof e.addEventListener) return;
                var n = (a = e.src, c = a.match(i), c ? c[1] : null);
                var a, c;
                if (!n) return;
                var u = function (e) {
                  var t = e.match(o);
                  if (t && t.length >= 3) return {
                    key: t[2],
                    parent: s(t[1], window)
                  };
                  return {
                    key: e,
                    parent: window
                  };
                }(n);
                if ("function" != typeof u.parent[u.key]) return;
                var d = {};
                function l() {
                  t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                function f() {
                  t.emit("jsonp-error", [], d), t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                r.inPlace(u.parent, [u.key], "cb-", d), e.addEventListener("load", l, (0, S.m$)(!1)), e.addEventListener("error", f, (0, S.m$)(!1)), t.emit("new-jsonp", [e.src], d);
              }(e[0]);
            }), t;
          }
          const k = {};
          function H(e) {
            const t = function (e) {
              return (e || n.ee).get("mutation");
            }(e);
            if (!f.il || k[t.debugId]) return t;
            k[t.debugId] = !0;
            var r = c(t),
              i = f._A.MutationObserver;
            return i && (window.MutationObserver = function (e) {
              return this instanceof i ? new i(r(e, "fn-")) : i.apply(this, arguments);
            }, MutationObserver.prototype = i.prototype), t;
          }
          const z = {};
          function L(e) {
            const t = function (e) {
              return (e || n.ee).get("promise");
            }(e);
            if (z[t.debugId]) return t;
            z[t.debugId] = !0;
            var r = t.context,
              i = c(t),
              a = f._A.Promise;
            return a && function () {
              function e(r) {
                var n = t.context(),
                  o = i(r, "executor-", n, null, !1);
                const s = Reflect.construct(a, [o], e);
                return t.context(s).getCtx = function () {
                  return n;
                }, s;
              }
              f._A.Promise = e, Object.defineProperty(e, "name", {
                value: "Promise"
              }), e.toString = function () {
                return a.toString();
              }, Object.setPrototypeOf(e, a), ["all", "race"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  let i = !1;
                  [...(e || [])].forEach(e => {
                    this.resolve(e).then(a("all" === r), a(!1));
                  });
                  const o = n.apply(this, arguments);
                  return o;
                  function a(e) {
                    return function () {
                      t.emit("propagate", [null, !i], o, !1, !1), i = i || !e;
                    };
                  }
                };
              }), ["resolve", "reject"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  const r = n.apply(this, arguments);
                  return e !== r && t.emit("propagate", [e, !0], r, !1, !1), r;
                };
              }), e.prototype = a.prototype;
              const n = a.prototype.then;
              a.prototype.then = function () {
                var e = this,
                  o = r(e);
                o.promise = e;
                for (var a = arguments.length, s = new Array(a), c = 0; c < a; c++) s[c] = arguments[c];
                s[0] = i(s[0], "cb-", o, null, !1), s[1] = i(s[1], "cb-", o, null, !1);
                const u = n.apply(this, s);
                return o.nextPromise = u, t.emit("propagate", [e, !0], u, !1, !1), u;
              }, a.prototype.then[o] = n, t.on("executor-start", function (e) {
                e[0] = i(e[0], "resolve-", this, null, !1), e[1] = i(e[1], "resolve-", this, null, !1);
              }), t.on("executor-err", function (e, t, r) {
                e[1](r);
              }), t.on("cb-end", function (e, r, n) {
                t.emit("propagate", [n, !0], this.nextPromise, !1, !1);
              }), t.on("propagate", function (e, r, n) {
                this.getCtx && !r || (this.getCtx = function () {
                  if (e instanceof Promise) var r = t.context(e);
                  return r && r.getCtx ? r.getCtx() : this;
                });
              });
            }(), t;
          }
          const M = {},
            B = "setTimeout",
            F = "setInterval",
            U = "clearTimeout",
            q = "-start",
            Z = "-",
            V = [B, "setImmediate", F, U, "clearImmediate"];
          function G(e) {
            const t = function (e) {
              return (e || n.ee).get("timer");
            }(e);
            if (M[t.debugId]++) return t;
            M[t.debugId] = 1;
            var r = c(t);
            return r.inPlace(f._A, V.slice(0, 2), B + Z), r.inPlace(f._A, V.slice(2, 3), F + Z), r.inPlace(f._A, V.slice(3), U + Z), t.on(F + q, function (e, t, n) {
              e[0] = r(e[0], "fn-", null, n);
            }), t.on(B + q, function (e, t, n) {
              this.method = n, this.timerDuration = isNaN(e[1]) ? 0 : +e[1], e[0] = r(e[0], "fn-", this, n);
            }), t;
          }
          var W = r(50);
          const X = {},
            Q = ["open", "send"];
          function K(e) {
            var t = e || n.ee;
            const r = function (e) {
              return (e || n.ee).get("xhr");
            }(t);
            if (X[r.debugId]++) return r;
            X[r.debugId] = 1, b(t);
            var i = c(r),
              o = f._A.XMLHttpRequest,
              a = f._A.MutationObserver,
              s = f._A.Promise,
              u = f._A.setInterval,
              d = "readystatechange",
              l = ["onload", "onerror", "onabort", "onloadstart", "onloadend", "onprogress", "ontimeout"],
              h = [],
              p = f._A.XMLHttpRequest = function (e) {
                const t = new o(e),
                  n = r.context(t);
                try {
                  r.emit("new-xhr", [t], n), t.addEventListener(d, (a = n, function () {
                    var e = this;
                    e.readyState > 3 && !a.resolved && (a.resolved = !0, r.emit("xhr-resolved", [], e)), i.inPlace(e, l, "fn-", A);
                  }), (0, S.m$)(!1));
                } catch (e) {
                  (0, W.Z)("An error occurred while intercepting XHR", e);
                  try {
                    r.emit("internal-error", [e]);
                  } catch (e) {}
                }
                var a;
                return t;
              };
            function g(e, t) {
              i.inPlace(t, ["onreadystatechange"], "fn-", A);
            }
            if (function (e, t) {
              for (var r in e) t[r] = e[r];
            }(o, p), p.prototype = o.prototype, i.inPlace(p.prototype, Q, "-xhr-", A), r.on("send-xhr-start", function (e, t) {
              g(e, t), function (e) {
                h.push(e), a && (m ? m.then(w) : u ? u(w) : (v = -v, y.data = v));
              }(t);
            }), r.on("open-xhr-start", g), a) {
              var m = s && s.resolve();
              if (!u && !s) {
                var v = 1,
                  y = document.createTextNode(v);
                new a(w).observe(y, {
                  characterData: !0
                });
              }
            } else t.on("fn-end", function (e) {
              e[0] && e[0].type === d || w();
            });
            function w() {
              for (var e = 0; e < h.length; e++) g(0, h[e]);
              h.length && (h = []);
            }
            function A(e, t) {
              return t;
            }
            return r;
          }
        },
        7825: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.ajax;
        },
        6660: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.jserrors;
        },
        3081: (e, t, r) => {
          r.d(t, {
            gF: () => o,
            mY: () => i,
            t9: () => n,
            vz: () => s,
            xS: () => a
          });
          const n = r(3325).D.metrics,
            i = "sm",
            o = "cm",
            a = "storeSupportabilityMetrics",
            s = "storeEventMetrics";
        },
        4649: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageAction;
        },
        7633: (e, t, r) => {
          r.d(t, {
            Dz: () => i,
            OJ: () => a,
            qw: () => o,
            t9: () => n
          });
          const n = r(3325).D.pageViewEvent,
            i = "firstbyte",
            o = "domcontent",
            a = "windowload";
        },
        9251: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageViewTiming;
        },
        3614: (e, t, r) => {
          r.d(t, {
            BST_RESOURCE: () => i,
            END: () => s,
            FEATURE_NAME: () => n,
            FN_END: () => u,
            FN_START: () => c,
            PUSH_STATE: () => d,
            RESOURCE: () => o,
            START: () => a
          });
          const n = r(3325).D.sessionTrace,
            i = "bstResource",
            o = "resource",
            a = "-start",
            s = "-end",
            c = "fn" + a,
            u = "fn" + s,
            d = "pushState";
        },
        7836: (e, t, r) => {
          r.d(t, {
            BODY: () => x,
            CB_END: () => E,
            CB_START: () => u,
            END: () => A,
            FEATURE_NAME: () => i,
            FETCH: () => _,
            FETCH_BODY: () => v,
            FETCH_DONE: () => m,
            FETCH_START: () => g,
            FN_END: () => c,
            FN_START: () => s,
            INTERACTION: () => f,
            INTERACTION_API: () => d,
            INTERACTION_EVENTS: () => o,
            JSONP_END: () => b,
            JSONP_NODE: () => p,
            JS_TIME: () => T,
            MAX_TIMER_BUDGET: () => a,
            REMAINING: () => l,
            SPA_NODE: () => h,
            START: () => w,
            originalSetTimeout: () => y
          });
          var n = r(5763);
          const i = r(3325).D.spa,
            o = ["click", "submit", "keypress", "keydown", "keyup", "change"],
            a = 999,
            s = "fn-start",
            c = "fn-end",
            u = "cb-start",
            d = "api-ixn-",
            l = "remaining",
            f = "interaction",
            h = "spaNode",
            p = "jsonpNode",
            g = "fetch-start",
            m = "fetch-done",
            v = "fetch-body-",
            b = "jsonp-end",
            y = n.Yu.ST,
            w = "-start",
            A = "-end",
            x = "-body",
            E = "cb" + A,
            T = "jsTime",
            _ = "fetch";
        },
        5938: (e, t, r) => {
          r.d(t, {
            W: () => o
          });
          var n = r(5763),
            i = r(8325);
          class o {
            constructor(e, t, r) {
              this.agentIdentifier = e, this.aggregator = t, this.ee = i.ee.get(e, (0, n.OP)(this.agentIdentifier).isolatedBacklog), this.featureName = r, this.blocked = !1;
            }
          }
        },
        9144: (e, t, r) => {
          r.d(t, {
            j: () => m
          });
          var n = r(3325),
            i = r(5763),
            o = r(5546),
            a = r(8325),
            s = r(7894),
            c = r(8e3),
            u = r(3960),
            d = r(385),
            l = r(50),
            f = r(3081),
            h = r(8632);
          function p() {
            const e = (0, h.gG)();
            ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease", "addPageAction", "setCurrentRouteName", "setPageViewName", "setCustomAttribute", "interaction", "noticeError", "setUserId", "setApplicationVersion"].forEach(t => {
              e[t] = function () {
                for (var r = arguments.length, n = new Array(r), i = 0; i < r; i++) n[i] = arguments[i];
                return function (t) {
                  for (var r = arguments.length, n = new Array(r > 1 ? r - 1 : 0), i = 1; i < r; i++) n[i - 1] = arguments[i];
                  let o = [];
                  return Object.values(e.initializedAgents).forEach(e => {
                    e.exposed && e.api[t] && o.push(e.api[t](...n));
                  }), o.length > 1 ? o : o[0];
                }(t, ...n);
              };
            });
          }
          var g = r(2587);
          function m(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : {},
              m = arguments.length > 2 ? arguments[2] : void 0,
              v = arguments.length > 3 ? arguments[3] : void 0,
              {
                init: b,
                info: y,
                loader_config: w,
                runtime: A = {
                  loaderType: m
                },
                exposed: x = !0
              } = t;
            const E = (0, h.gG)();
            y || (b = E.init, y = E.info, w = E.loader_config), (0, i.Dg)(e, b || {}), (0, i.GE)(e, w || {}), y.jsAttributes ??= {}, d.v6 && (y.jsAttributes.isWorker = !0), (0, i.CX)(e, y);
            const T = (0, i.P_)(e);
            A.denyList = [...(T.ajax?.deny_list || []), ...(T.ajax?.block_internal ? [y.beacon, y.errorBeacon] : [])], (0, i.sU)(e, A), p();
            const _ = function (e, t) {
              t || (0, c.R)(e, "api");
              const h = {};
              var p = a.ee.get(e),
                g = p.get("tracer"),
                m = "api-",
                v = m + "ixn-";
              function b(t, r, n, o) {
                const a = (0, i.C5)(e);
                return null === r ? delete a.jsAttributes[t] : (0, i.CX)(e, {
                  ...a,
                  jsAttributes: {
                    ...a.jsAttributes,
                    [t]: r
                  }
                }), A(m, n, !0, o || null === r ? "session" : void 0)(t, r);
              }
              function y() {}
              ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease"].forEach(e => h[e] = A(m, e, !0, "api")), h.addPageAction = A(m, "addPageAction", !0, n.D.pageAction), h.setCurrentRouteName = A(m, "routeName", !0, n.D.spa), h.setPageViewName = function (t, r) {
                if ("string" == typeof t) return "/" !== t.charAt(0) && (t = "/" + t), (0, i.OP)(e).customTransaction = (r || "http://custom.transaction") + t, A(m, "setPageViewName", !0)();
              }, h.setCustomAttribute = function (e, t) {
                let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2];
                if ("string" == typeof e) {
                  if (["string", "number"].includes(typeof t) || null === t) return b(e, t, "setCustomAttribute", r);
                  (0, l.Z)("Failed to execute setCustomAttribute.\nNon-null value must be a string or number type, but a type of <".concat(typeof t, "> was provided."));
                } else (0, l.Z)("Failed to execute setCustomAttribute.\nName must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setUserId = function (e) {
                if ("string" == typeof e || null === e) return b("enduser.id", e, "setUserId", !0);
                (0, l.Z)("Failed to execute setUserId.\nNon-null value must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setApplicationVersion = function (e) {
                if ("string" == typeof e || null === e) return b("application.version", e, "setApplicationVersion", !1);
                (0, l.Z)("Failed to execute setApplicationVersion. Expected <String | null>, but got <".concat(typeof e, ">."));
              }, h.interaction = function () {
                return new y().get();
              };
              var w = y.prototype = {
                createTracer: function (e, t) {
                  var r = {},
                    i = this,
                    a = "function" == typeof t;
                  return (0, o.p)(v + "tracer", [(0, s.z)(), e, r], i, n.D.spa, p), function () {
                    if (g.emit((a ? "" : "no-") + "fn-start", [(0, s.z)(), i, a], r), a) try {
                      return t.apply(this, arguments);
                    } catch (e) {
                      throw g.emit("fn-err", [arguments, this, e], r), e;
                    } finally {
                      g.emit("fn-end", [(0, s.z)()], r);
                    }
                  };
                }
              };
              function A(e, t, r, i) {
                return function () {
                  return (0, o.p)(f.xS, ["API/" + t + "/called"], void 0, n.D.metrics, p), i && (0, o.p)(e + t, [(0, s.z)(), ...arguments], r ? null : this, i, p), r ? void 0 : this;
                };
              }
              function x() {
                r.e(111).then(r.bind(r, 7438)).then(t => {
                  let {
                    setAPI: r
                  } = t;
                  r(e), (0, c.L)(e, "api");
                }).catch(() => (0, l.Z)("Downloading runtime APIs failed..."));
              }
              return ["actionText", "setName", "setAttribute", "save", "ignore", "onEnd", "getContext", "end", "get"].forEach(e => {
                w[e] = A(v, e, void 0, n.D.spa);
              }), h.noticeError = function (e, t) {
                "string" == typeof e && (e = new Error(e)), (0, o.p)(f.xS, ["API/noticeError/called"], void 0, n.D.metrics, p), (0, o.p)("err", [e, (0, s.z)(), !1, t], void 0, n.D.jserrors, p);
              }, d.il ? (0, u.b)(() => x(), !0) : x(), h;
            }(e, v);
            return (0, h.Qy)(e, _, "api"), (0, h.Qy)(e, x, "exposed"), (0, h.EZ)("activatedFeatures", g.T), _;
          }
        },
        3325: (e, t, r) => {
          r.d(t, {
            D: () => n,
            p: () => i
          });
          const n = {
              ajax: "ajax",
              jserrors: "jserrors",
              metrics: "metrics",
              pageAction: "page_action",
              pageViewEvent: "page_view_event",
              pageViewTiming: "page_view_timing",
              sessionReplay: "session_replay",
              sessionTrace: "session_trace",
              spa: "spa"
            },
            i = {
              [n.pageViewEvent]: 1,
              [n.pageViewTiming]: 2,
              [n.metrics]: 3,
              [n.jserrors]: 4,
              [n.ajax]: 5,
              [n.sessionTrace]: 6,
              [n.pageAction]: 7,
              [n.spa]: 8,
              [n.sessionReplay]: 9
            };
        }
      },
      n = {};
    function i(e) {
      var t = n[e];
      if (void 0 !== t) return t.exports;
      var o = n[e] = {
        exports: {}
      };
      return r[e](o, o.exports, i), o.exports;
    }
    i.m = r, i.d = (e, t) => {
      for (var r in t) i.o(t, r) && !i.o(e, r) && Object.defineProperty(e, r, {
        enumerable: !0,
        get: t[r]
      });
    }, i.f = {}, i.e = e => Promise.all(Object.keys(i.f).reduce((t, r) => (i.f[r](e, t), t), [])), i.u = e => "nr-spa.1097a448-1.238.0.min.js", i.o = (e, t) => Object.prototype.hasOwnProperty.call(e, t), e = {}, t = "NRBA-1.238.0.PROD:", i.l = (r, n, o, a) => {
      if (e[r]) e[r].push(n);else {
        var s, c;
        if (void 0 !== o) for (var u = document.getElementsByTagName("script"), d = 0; d < u.length; d++) {
          var l = u[d];
          if (l.getAttribute("src") == r || l.getAttribute("data-webpack") == t + o) {
            s = l;
            break;
          }
        }
        s || (c = !0, (s = document.createElement("script")).charset = "utf-8", s.timeout = 120, i.nc && s.setAttribute("nonce", i.nc), s.setAttribute("data-webpack", t + o), s.src = r), e[r] = [n];
        var f = (t, n) => {
            s.onerror = s.onload = null, clearTimeout(h);
            var i = e[r];
            if (delete e[r], s.parentNode && s.parentNode.removeChild(s), i && i.forEach(e => e(n)), t) return t(n);
          },
          h = setTimeout(f.bind(null, void 0, {
            type: "timeout",
            target: s
          }), 12e4);
        s.onerror = f.bind(null, s.onerror), s.onload = f.bind(null, s.onload), c && document.head.appendChild(s);
      }
    }, i.r = e => {
      "undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(e, Symbol.toStringTag, {
        value: "Module"
      }), Object.defineProperty(e, "__esModule", {
        value: !0
      });
    }, i.p = "https://js-agent.newrelic.com/", (() => {
      var e = {
        801: 0,
        92: 0
      };
      i.f.j = (t, r) => {
        var n = i.o(e, t) ? e[t] : void 0;
        if (0 !== n) if (n) r.push(n[2]);else {
          var o = new Promise((r, i) => n = e[t] = [r, i]);
          r.push(n[2] = o);
          var a = i.p + i.u(t),
            s = new Error();
          i.l(a, r => {
            if (i.o(e, t) && (0 !== (n = e[t]) && (e[t] = void 0), n)) {
              var o = r && ("load" === r.type ? "missing" : r.type),
                a = r && r.target && r.target.src;
              s.message = "Loading chunk " + t + " failed.\n(" + o + ": " + a + ")", s.name = "ChunkLoadError", s.type = o, s.request = a, n[1](s);
            }
          }, "chunk-" + t, t);
        }
      };
      var t = (t, r) => {
          var n,
            o,
            [a, s, c] = r,
            u = 0;
          if (a.some(t => 0 !== e[t])) {
            for (n in s) i.o(s, n) && (i.m[n] = s[n]);
            if (c) c(i);
          }
          for (t && t(r); u < a.length; u++) o = a[u], i.o(e, o) && e[o] && e[o][0](), e[o] = 0;
        },
        r = self["webpackChunk:NRBA-1.238.0.PROD"] = self["webpackChunk:NRBA-1.238.0.PROD"] || [];
      r.forEach(t.bind(null, 0)), r.push = t.bind(null, r.push.bind(r));
    })(), (() => {
      var e = i(50);
      class t {
        addPageAction(t, r) {
          (0, e.Z)("Call to agent api addPageAction failed. The session trace feature is not currently initialized.");
        }
        setPageViewName(t, r) {
          (0, e.Z)("Call to agent api setPageViewName failed. The page view feature is not currently initialized.");
        }
        setCustomAttribute(t, r, n) {
          (0, e.Z)("Call to agent api setCustomAttribute failed. The js errors feature is not currently initialized.");
        }
        noticeError(t, r) {
          (0, e.Z)("Call to agent api noticeError failed. The js errors feature is not currently initialized.");
        }
        setUserId(t) {
          (0, e.Z)("Call to agent api setUserId failed. The js errors feature is not currently initialized.");
        }
        setApplicationVersion(t) {
          (0, e.Z)("Call to agent api setApplicationVersion failed. The agent is not currently initialized.");
        }
        setErrorHandler(t) {
          (0, e.Z)("Call to agent api setErrorHandler failed. The js errors feature is not currently initialized.");
        }
        finished(t) {
          (0, e.Z)("Call to agent api finished failed. The page action feature is not currently initialized.");
        }
        addRelease(t, r) {
          (0, e.Z)("Call to agent api addRelease failed. The agent is not currently initialized.");
        }
      }
      var r = i(3325),
        n = i(5763);
      const o = Object.values(r.D);
      function a(e) {
        const t = {};
        return o.forEach(r => {
          t[r] = function (e, t) {
            return !1 !== (0, n.Mt)(t, "".concat(e, ".enabled"));
          }(r, e);
        }), t;
      }
      var s = i(9144);
      var c = i(5546),
        u = i(385),
        d = i(8e3),
        l = i(5938),
        f = i(3960);
      class h extends l.W {
        constructor(e, t, r) {
          let n = !(arguments.length > 3 && void 0 !== arguments[3]) || arguments[3];
          super(e, t, r), this.auto = n, this.abortHandler, this.featAggregate, this.onAggregateImported, n && (0, d.R)(e, r);
        }
        importAggregator() {
          let t = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : {};
          if (this.featAggregate || !this.auto) return;
          const r = u.il && !0 === (0, n.Mt)(this.agentIdentifier, "privacy.cookies_enabled");
          let o;
          this.onAggregateImported = new Promise(e => {
            o = e;
          });
          const a = async () => {
            let n;
            try {
              if (r) {
                const {
                  setupAgentSession: e
                } = await i.e(111).then(i.bind(i, 3228));
                n = e(this.agentIdentifier);
              }
            } catch (t) {
              (0, e.Z)("A problem occurred when starting up session manager. This page will not start or extend any session.", t);
            }
            try {
              if (!this.shouldImportAgg(this.featureName, n)) return (0, d.L)(this.agentIdentifier, this.featureName), void o(!1);
              const {
                  lazyFeatureLoader: e
                } = await i.e(111).then(i.bind(i, 8582)),
                {
                  Aggregate: r
                } = await e(this.featureName, "aggregate");
              this.featAggregate = new r(this.agentIdentifier, this.aggregator, t), o(!0);
            } catch (t) {
              (0, e.Z)("Downloading and initializing ".concat(this.featureName, " failed..."), t), this.abortHandler?.(), o(!1);
            }
          };
          u.il ? (0, f.b)(() => a(), !0) : a();
        }
        shouldImportAgg(e, t) {
          return e !== r.D.sessionReplay || !!n.Yu.MO && !1 !== (0, n.Mt)(this.agentIdentifier, "session_trace.enabled") && (!!t?.isNew || !!t?.state.sessionReplay);
        }
      }
      var p = i(7633),
        g = i(7894);
      class m extends h {
        static featureName = p.t9;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          if (super(e, t, p.t9, i), ("undefined" == typeof PerformanceNavigationTiming || u.Tt) && "undefined" != typeof PerformanceTiming) {
            const t = (0, n.OP)(e);
            t[p.Dz] = Math.max(Date.now() - t.offset, 0), (0, f.K)(() => t[p.qw] = Math.max((0, g.z)() - t[p.Dz], 0)), (0, f.b)(() => {
              const e = (0, g.z)();
              t[p.OJ] = Math.max(e - t[p.Dz], 0), (0, c.p)("timing", ["load", e], void 0, r.D.pageViewTiming, this.ee);
            });
          }
          this.importAggregator();
        }
      }
      var v = i(1117),
        b = i(1284);
      class y extends v.w {
        constructor(e) {
          super(e), this.aggregatedData = {};
        }
        store(e, t, r, n, i) {
          var o = this.getBucket(e, t, r, i);
          return o.metrics = function (e, t) {
            t || (t = {
              count: 0
            });
            return t.count += 1, (0, b.D)(e, function (e, r) {
              t[e] = w(r, t[e]);
            }), t;
          }(n, o.metrics), o;
        }
        merge(e, t, r, n, i) {
          var o = this.getBucket(e, t, n, i);
          if (o.metrics) {
            var a = o.metrics;
            a.count += r.count, (0, b.D)(r, function (e, t) {
              if ("count" !== e) {
                var n = a[e],
                  i = r[e];
                i && !i.c ? a[e] = w(i.t, n) : a[e] = function (e, t) {
                  if (!t) return e;
                  t.c || (t = A(t.t));
                  return t.min = Math.min(e.min, t.min), t.max = Math.max(e.max, t.max), t.t += e.t, t.sos += e.sos, t.c += e.c, t;
                }(i, a[e]);
              }
            });
          } else o.metrics = r;
        }
        storeMetric(e, t, r, n) {
          var i = this.getBucket(e, t, r);
          return i.stats = w(n, i.stats), i;
        }
        getBucket(e, t, r, n) {
          this.aggregatedData[e] || (this.aggregatedData[e] = {});
          var i = this.aggregatedData[e][t];
          return i || (i = this.aggregatedData[e][t] = {
            params: r || {}
          }, n && (i.custom = n)), i;
        }
        get(e, t) {
          return t ? this.aggregatedData[e] && this.aggregatedData[e][t] : this.aggregatedData[e];
        }
        take(e) {
          for (var t = {}, r = "", n = !1, i = 0; i < e.length; i++) t[r = e[i]] = x(this.aggregatedData[r]), t[r].length && (n = !0), delete this.aggregatedData[r];
          return n ? t : null;
        }
      }
      function w(e, t) {
        return null == e ? function (e) {
          e ? e.c++ : e = {
            c: 1
          };
          return e;
        }(t) : t ? (t.c || (t = A(t.t)), t.c += 1, t.t += e, t.sos += e * e, e > t.max && (t.max = e), e < t.min && (t.min = e), t) : {
          t: e
        };
      }
      function A(e) {
        return {
          t: e,
          min: e,
          max: e,
          sos: e * e,
          c: 1
        };
      }
      function x(e) {
        return "object" != typeof e ? [] : (0, b.D)(e, E);
      }
      function E(e, t) {
        return t;
      }
      var T = i(8632),
        _ = i(4402),
        D = i(4351);
      var j = i(7956),
        C = i(3239),
        N = i(9251);
      class O extends h {
        static featureName = N.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, N.t, r), u.il && ((0, n.OP)(e).initHidden = Boolean("hidden" === document.visibilityState), (0, j.N)(() => (0, c.p)("docHidden", [(0, g.z)()], void 0, N.t, this.ee), !0), (0, C.bP)("pagehide", () => (0, c.p)("winPagehide", [(0, g.z)()], void 0, N.t, this.ee)), this.importAggregator());
        }
      }
      var S = i(3081);
      class P extends h {
        static featureName = S.t9;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, S.t9, r), this.importAggregator();
        }
      }
      var R = i(6660);
      class I {
        constructor(e, t, r, n) {
          this.name = "UncaughtError", this.message = e, this.sourceURL = t, this.line = r, this.column = n;
        }
      }
      class k extends h {
        static featureName = R.t;
        #e = new Set();
        constructor(e, t) {
          let n = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, R.t, n);
          try {
            this.removeOnAbort = new AbortController();
          } catch (e) {}
          this.ee.on("fn-err", (e, t, n) => {
            this.abortHandler && !this.#e.has(n) && (this.#e.add(n), (0, c.p)("err", [this.#t(n), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }), this.ee.on("internal-error", e => {
            this.abortHandler && (0, c.p)("ierr", [this.#t(e), (0, g.z)(), !0], void 0, r.D.jserrors, this.ee);
          }), u._A.addEventListener("unhandledrejection", e => {
            this.abortHandler && (0, c.p)("err", [this.#r(e), (0, g.z)(), !1, {
              unhandledPromiseRejection: 1
            }], void 0, r.D.jserrors, this.ee);
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), u._A.addEventListener("error", e => {
            this.abortHandler && (this.#e.has(e.error) ? this.#e.delete(e.error) : (0, c.p)("err", [this.#n(e), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
        }
        #i() {
          this.removeOnAbort?.abort(), this.#e.clear(), this.abortHandler = void 0;
        }
        #t(e) {
          return e instanceof Error ? e : void 0 !== e?.message ? new I(e.message, e.filename || e.sourceURL, e.lineno || e.line, e.colno || e.col) : new I("string" == typeof e ? e : (0, D.P)(e));
        }
        #r(e) {
          let t = "Unhandled Promise Rejection: ";
          if (e?.reason instanceof Error) try {
            return e.reason.message = t + e.reason.message, e.reason;
          } catch (t) {
            return e.reason;
          }
          if (void 0 === e.reason) return new I(t);
          const r = this.#t(e.reason);
          return r.message = t + r.message, r;
        }
        #n(e) {
          return e.error instanceof Error ? e.error : new I(e.message, e.filename, e.lineno, e.colno);
        }
      }
      var H = i(2210);
      let z = 1;
      const L = "nr@id";
      function M(e) {
        const t = typeof e;
        return !e || "object" !== t && "function" !== t ? -1 : e === u._A ? 0 : (0, H.X)(e, L, function () {
          return z++;
        });
      }
      function B(e) {
        if ("string" == typeof e && e.length) return e.length;
        if ("object" == typeof e) {
          if ("undefined" != typeof ArrayBuffer && e instanceof ArrayBuffer && e.byteLength) return e.byteLength;
          if ("undefined" != typeof Blob && e instanceof Blob && e.size) return e.size;
          if (!("undefined" != typeof FormData && e instanceof FormData)) try {
            return (0, D.P)(e).length;
          } catch (e) {
            return;
          }
        }
      }
      var F = i(1214),
        U = i(7243);
      class q {
        constructor(e) {
          this.agentIdentifier = e;
        }
        generateTracePayload(e) {
          if (!this.shouldGenerateTrace(e)) return null;
          var t = (0, n.DL)(this.agentIdentifier);
          if (!t) return null;
          var r = (t.accountID || "").toString() || null,
            i = (t.agentID || "").toString() || null,
            o = (t.trustKey || "").toString() || null;
          if (!r || !i) return null;
          var a = (0, _.M)(),
            s = (0, _.Ht)(),
            c = Date.now(),
            u = {
              spanId: a,
              traceId: s,
              timestamp: c
            };
          return (e.sameOrigin || this.isAllowedOrigin(e) && this.useTraceContextHeadersForCors()) && (u.traceContextParentHeader = this.generateTraceContextParentHeader(a, s), u.traceContextStateHeader = this.generateTraceContextStateHeader(a, c, r, i, o)), (e.sameOrigin && !this.excludeNewrelicHeader() || !e.sameOrigin && this.isAllowedOrigin(e) && this.useNewrelicHeaderForCors()) && (u.newrelicHeader = this.generateTraceHeader(a, s, c, r, i, o)), u;
        }
        generateTraceContextParentHeader(e, t) {
          return "00-" + t + "-" + e + "-01";
        }
        generateTraceContextStateHeader(e, t, r, n, i) {
          return i + "@nr=0-1-" + r + "-" + n + "-" + e + "----" + t;
        }
        generateTraceHeader(e, t, r, n, i, o) {
          if (!("function" == typeof u._A?.btoa)) return null;
          var a = {
            v: [0, 1],
            d: {
              ty: "Browser",
              ac: n,
              ap: i,
              id: e,
              tr: t,
              ti: r
            }
          };
          return o && n !== o && (a.d.tk = o), btoa((0, D.P)(a));
        }
        shouldGenerateTrace(e) {
          return this.isDtEnabled() && this.isAllowedOrigin(e);
        }
        isAllowedOrigin(e) {
          var t = !1,
            r = {};
          if ((0, n.Mt)(this.agentIdentifier, "distributed_tracing") && (r = (0, n.P_)(this.agentIdentifier).distributed_tracing), e.sameOrigin) t = !0;else if (r.allowed_origins instanceof Array) for (var i = 0; i < r.allowed_origins.length; i++) {
            var o = (0, U.e)(r.allowed_origins[i]);
            if (e.hostname === o.hostname && e.protocol === o.protocol && e.port === o.port) {
              t = !0;
              break;
            }
          }
          return t;
        }
        isDtEnabled() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.enabled;
        }
        excludeNewrelicHeader() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.exclude_newrelic_header;
        }
        useNewrelicHeaderForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !1 !== e.cors_use_newrelic_header;
        }
        useTraceContextHeadersForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.cors_use_tracecontext_headers;
        }
      }
      var Z = i(7825),
        V = ["load", "error", "abort", "timeout"],
        G = V.length,
        W = n.Yu.REQ,
        X = n.Yu.XHR;
      class Q extends h {
        static featureName = Z.t;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, Z.t, i), (0, n.OP)(e).xhrWrappable && (this.dt = new q(e), this.handler = (e, t, r, n) => (0, c.p)(e, t, r, n, this.ee), (0, F.u5)(this.ee), (0, F.Kf)(this.ee), function (e, t, i, o) {
            function a(e) {
              var t = this;
              t.totalCbs = 0, t.called = 0, t.cbTime = 0, t.end = E, t.ended = !1, t.xhrGuids = {}, t.lastSize = null, t.loadCaptureCalled = !1, t.params = this.params || {}, t.metrics = this.metrics || {}, e.addEventListener("load", function (r) {
                _(t, e);
              }, (0, C.m$)(!1)), u.IF || e.addEventListener("progress", function (e) {
                t.lastSize = e.loaded;
              }, (0, C.m$)(!1));
            }
            function s(e) {
              this.params = {
                method: e[0]
              }, T(this, e[1]), this.metrics = {};
            }
            function c(t, r) {
              var i = (0, n.DL)(e);
              i.xpid && this.sameOrigin && r.setRequestHeader("X-NewRelic-ID", i.xpid);
              var a = o.generateTracePayload(this.parsedOrigin);
              if (a) {
                var s = !1;
                a.newrelicHeader && (r.setRequestHeader("newrelic", a.newrelicHeader), s = !0), a.traceContextParentHeader && (r.setRequestHeader("traceparent", a.traceContextParentHeader), a.traceContextStateHeader && r.setRequestHeader("tracestate", a.traceContextStateHeader), s = !0), s && (this.dt = a);
              }
            }
            function d(e, r) {
              var n = this.metrics,
                i = e[0],
                o = this;
              if (n && i) {
                var a = B(i);
                a && (n.txSize = a);
              }
              this.startTime = (0, g.z)(), this.listener = function (e) {
                try {
                  "abort" !== e.type || o.loadCaptureCalled || (o.params.aborted = !0), ("load" !== e.type || o.called === o.totalCbs && (o.onloadCalled || "function" != typeof r.onload) && "function" == typeof o.end) && o.end(r);
                } catch (e) {
                  try {
                    t.emit("internal-error", [e]);
                  } catch (e) {}
                }
              };
              for (var s = 0; s < G; s++) r.addEventListener(V[s], this.listener, (0, C.m$)(!1));
            }
            function l(e, t, r) {
              this.cbTime += e, t ? this.onloadCalled = !0 : this.called += 1, this.called !== this.totalCbs || !this.onloadCalled && "function" == typeof r.onload || "function" != typeof this.end || this.end(r);
            }
            function f(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && !this.xhrGuids[r] && (this.xhrGuids[r] = !0, this.totalCbs += 1);
            }
            function h(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && this.xhrGuids[r] && (delete this.xhrGuids[r], this.totalCbs -= 1);
            }
            function p() {
              this.endTime = (0, g.z)();
            }
            function m(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-added", [e[1], e[2]], r);
            }
            function v(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-removed", [e[1], e[2]], r);
            }
            function b(e, t, r) {
              t instanceof X && ("onload" === r && (this.onload = !0), ("load" === (e[0] && e[0].type) || this.onload) && (this.xhrCbStart = (0, g.z)()));
            }
            function y(e, r) {
              this.xhrCbStart && t.emit("xhr-cb-time", [(0, g.z)() - this.xhrCbStart, this.onload, r], r);
            }
            function w(e) {
              var t,
                r = e[1] || {};
              if ("string" == typeof e[0] ? 0 === (t = e[0]).length && u.il && (t = "" + u._A.location.href) : e[0] && e[0].url ? t = e[0].url : u._A?.URL && e[0] && e[0] instanceof URL ? t = e[0].href : "function" == typeof e[0].toString && (t = e[0].toString()), "string" == typeof t && 0 !== t.length) {
                t && (this.parsedOrigin = (0, U.e)(t), this.sameOrigin = this.parsedOrigin.sameOrigin);
                var n = o.generateTracePayload(this.parsedOrigin);
                if (n && (n.newrelicHeader || n.traceContextParentHeader)) if (e[0] && e[0].headers) s(e[0].headers, n) && (this.dt = n);else {
                  var i = {};
                  for (var a in r) i[a] = r[a];
                  i.headers = new Headers(r.headers || {}), s(i.headers, n) && (this.dt = n), e.length > 1 ? e[1] = i : e.push(i);
                }
              }
              function s(e, t) {
                var r = !1;
                return t.newrelicHeader && (e.set("newrelic", t.newrelicHeader), r = !0), t.traceContextParentHeader && (e.set("traceparent", t.traceContextParentHeader), t.traceContextStateHeader && e.set("tracestate", t.traceContextStateHeader), r = !0), r;
              }
            }
            function A(e, t) {
              this.params = {}, this.metrics = {}, this.startTime = (0, g.z)(), this.dt = t, e.length >= 1 && (this.target = e[0]), e.length >= 2 && (this.opts = e[1]);
              var r,
                n = this.opts || {},
                i = this.target;
              "string" == typeof i ? r = i : "object" == typeof i && i instanceof W ? r = i.url : u._A?.URL && "object" == typeof i && i instanceof URL && (r = i.href), T(this, r);
              var o = ("" + (i && i instanceof W && i.method || n.method || "GET")).toUpperCase();
              this.params.method = o, this.txSize = B(n.body) || 0;
            }
            function x(e, t) {
              var n;
              this.endTime = (0, g.z)(), this.params || (this.params = {}), this.params.status = t ? t.status : 0, "string" == typeof this.rxSize && this.rxSize.length > 0 && (n = +this.rxSize);
              var o = {
                txSize: this.txSize,
                rxSize: n,
                duration: (0, g.z)() - this.startTime
              };
              i("xhr", [this.params, o, this.startTime, this.endTime, "fetch"], this, r.D.ajax);
            }
            function E(e) {
              var t = this.params,
                n = this.metrics;
              if (!this.ended) {
                this.ended = !0;
                for (var o = 0; o < G; o++) e.removeEventListener(V[o], this.listener, !1);
                t.aborted || (n.duration = (0, g.z)() - this.startTime, this.loadCaptureCalled || 4 !== e.readyState ? null == t.status && (t.status = 0) : _(this, e), n.cbTime = this.cbTime, i("xhr", [t, n, this.startTime, this.endTime, "xhr"], this, r.D.ajax));
              }
            }
            function T(e, t) {
              var r = (0, U.e)(t),
                n = e.params;
              n.hostname = r.hostname, n.port = r.port, n.protocol = r.protocol, n.host = r.hostname + ":" + r.port, n.pathname = r.pathname, e.parsedOrigin = r, e.sameOrigin = r.sameOrigin;
            }
            function _(e, t) {
              e.params.status = t.status;
              var r = function (e, t) {
                var r = e.responseType;
                return "json" === r && null !== t ? t : "arraybuffer" === r || "blob" === r || "json" === r ? B(e.response) : "text" === r || "" === r || void 0 === r ? B(e.responseText) : void 0;
              }(t, e.lastSize);
              if (r && (e.metrics.rxSize = r), e.sameOrigin) {
                var n = t.getResponseHeader("X-NewRelic-App-Data");
                n && (e.params.cat = n.split(", ").pop());
              }
              e.loadCaptureCalled = !0;
            }
            t.on("new-xhr", a), t.on("open-xhr-start", s), t.on("open-xhr-end", c), t.on("send-xhr-start", d), t.on("xhr-cb-time", l), t.on("xhr-load-added", f), t.on("xhr-load-removed", h), t.on("xhr-resolved", p), t.on("addEventListener-end", m), t.on("removeEventListener-end", v), t.on("fn-end", y), t.on("fetch-before-start", w), t.on("fetch-start", A), t.on("fn-start", b), t.on("fetch-done", x);
          }(e, this.ee, this.handler, this.dt), this.importAggregator());
        }
      }
      var K = i(3614);
      const {
        BST_RESOURCE: Y,
        RESOURCE: J,
        START: ee,
        END: te,
        FEATURE_NAME: re,
        FN_END: ne,
        FN_START: ie,
        PUSH_STATE: oe
      } = K;
      var ae = i(7836);
      const {
        FEATURE_NAME: se,
        START: ce,
        END: ue,
        BODY: de,
        CB_END: le,
        JS_TIME: fe,
        FETCH: he,
        FN_START: pe,
        CB_START: ge,
        FN_END: me
      } = ae;
      var ve = i(4649);
      class be extends h {
        static featureName = ve.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, ve.t, r), this.importAggregator();
        }
      }
      new class extends t {
        constructor(t) {
          let r = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : (0, _.ky)(16);
          super(), u._A ? (this.agentIdentifier = r, this.sharedAggregator = new y({
            agentIdentifier: this.agentIdentifier
          }), this.features = {}, this.desiredFeatures = new Set(t.features || []), this.desiredFeatures.add(m), Object.assign(this, (0, s.j)(this.agentIdentifier, t, t.loaderType || "agent")), this.start()) : (0, e.Z)("Failed to initial the agent. Could not determine the runtime environment.");
        }
        get config() {
          return {
            info: (0, n.C5)(this.agentIdentifier),
            init: (0, n.P_)(this.agentIdentifier),
            loader_config: (0, n.DL)(this.agentIdentifier),
            runtime: (0, n.OP)(this.agentIdentifier)
          };
        }
        start() {
          const t = "features";
          try {
            const n = a(this.agentIdentifier),
              i = [...this.desiredFeatures];
            i.sort((e, t) => r.p[e.featureName] - r.p[t.featureName]), i.forEach(t => {
              if (n[t.featureName] || t.featureName === r.D.pageViewEvent) {
                const i = function (e) {
                  switch (e) {
                    case r.D.ajax:
                      return [r.D.jserrors];
                    case r.D.sessionTrace:
                      return [r.D.ajax, r.D.pageViewEvent];
                    case r.D.sessionReplay:
                      return [r.D.sessionTrace];
                    case r.D.pageViewTiming:
                      return [r.D.pageViewEvent];
                    default:
                      return [];
                  }
                }(t.featureName);
                i.every(e => n[e]) || (0, e.Z)("".concat(t.featureName, " is enabled but one or more dependent features has been disabled (").concat((0, D.P)(i), "). This may cause unintended consequences or missing data...")), this.features[t.featureName] = new t(this.agentIdentifier, this.sharedAggregator);
              }
            }), (0, T.Qy)(this.agentIdentifier, this.features, t);
          } catch (r) {
            (0, e.Z)("Failed to initialize all enabled instrument classes (agent aborted) -", r);
            for (const e in this.features) this.features[e].abortHandler?.();
            const n = (0, T.fP)();
            return delete n.initializedAgents[this.agentIdentifier]?.api, delete n.initializedAgents[this.agentIdentifier]?.[t], delete this.sharedAggregator, n.ee?.abort(), delete n.ee?.get(this.agentIdentifier), !1;
          }
        }
        addToTrace(t) {
          (0, e.Z)("Call to agent api addToTrace failed. The page action feature is not currently initialized.");
        }
        setCurrentRouteName(t) {
          (0, e.Z)("Call to agent api setCurrentRouteName failed. The spa feature is not currently initialized.");
        }
        interaction() {
          (0, e.Z)("Call to agent api interaction failed. The spa feature is not currently initialized.");
        }
      }({
        features: [Q, m, O, class extends h {
          static featureName = re;
          constructor(e, t) {
            if (super(e, t, re, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            const n = this.ee;
            let i;
            (0, F.QU)(n), this.eventsEE = (0, F.em)(n), this.eventsEE.on(ie, function (e, t) {
              this.bstStart = (0, g.z)();
            }), this.eventsEE.on(ne, function (e, t) {
              (0, c.p)("bst", [e[0], t, this.bstStart, (0, g.z)()], void 0, r.D.sessionTrace, n);
            }), n.on(oe + ee, function (e) {
              this.time = (0, g.z)(), this.startPath = location.pathname + location.hash;
            }), n.on(oe + te, function (e) {
              (0, c.p)("bstHist", [location.pathname + location.hash, this.startPath, this.time], void 0, r.D.sessionTrace, n);
            });
            try {
              i = new PerformanceObserver(e => {
                const t = e.getEntries();
                (0, c.p)(Y, [t], void 0, r.D.sessionTrace, n);
              }), i.observe({
                type: J,
                buffered: !0
              });
            } catch (e) {}
            this.importAggregator({
              resourceObserver: i
            });
          }
        }, P, be, k, class extends h {
          static featureName = se;
          constructor(e, t) {
            if (super(e, t, se, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            if (!(0, n.OP)(e).xhrWrappable) return;
            try {
              this.removeOnAbort = new AbortController();
            } catch (e) {}
            let r,
              i = 0;
            const o = this.ee.get("tracer"),
              a = (0, F._L)(this.ee),
              s = (0, F.Lg)(this.ee),
              c = (0, F.BV)(this.ee),
              d = (0, F.Kf)(this.ee),
              l = this.ee.get("events"),
              f = (0, F.u5)(this.ee),
              h = (0, F.QU)(this.ee),
              p = (0, F.Gm)(this.ee);
            function m(e, t) {
              h.emit("newURL", ["" + window.location, t]);
            }
            function v() {
              i++, r = window.location.hash, this[pe] = (0, g.z)();
            }
            function b() {
              i--, window.location.hash !== r && m(0, !0);
              var e = (0, g.z)();
              this[fe] = ~~this[fe] + e - this[pe], this[me] = e;
            }
            function y(e, t) {
              e.on(t, function () {
                this[t] = (0, g.z)();
              });
            }
            this.ee.on(pe, v), s.on(ge, v), a.on(ge, v), this.ee.on(me, b), s.on(le, b), a.on(le, b), this.ee.buffer([pe, me, "xhr-resolved"], this.featureName), l.buffer([pe], this.featureName), c.buffer(["setTimeout" + ue, "clearTimeout" + ce, pe], this.featureName), d.buffer([pe, "new-xhr", "send-xhr" + ce], this.featureName), f.buffer([he + ce, he + "-done", he + de + ce, he + de + ue], this.featureName), h.buffer(["newURL"], this.featureName), p.buffer([pe], this.featureName), s.buffer(["propagate", ge, le, "executor-err", "resolve" + ce], this.featureName), o.buffer([pe, "no-" + pe], this.featureName), a.buffer(["new-jsonp", "cb-start", "jsonp-error", "jsonp-end"], this.featureName), y(f, he + ce), y(f, he + "-done"), y(a, "new-jsonp"), y(a, "jsonp-end"), y(a, "cb-start"), h.on("pushState-end", m), h.on("replaceState-end", m), window.addEventListener("hashchange", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("load", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("popstate", function () {
              m(0, i > 1);
            }, (0, C.m$)(!0, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
          }
          #i() {
            this.removeOnAbort?.abort(), this.abortHandler = void 0;
          }
        }],
        loaderType: "spa"
      });
    })();
  })();
})()</script>
      <link rel="shortcut icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
      <link rel="icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
      <link rel="stylesheet" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1/arp.css">
      <link href="//cdn.pendo.io" rel="dns-prefetch">
      <link href="https://cdn.pendo.io" rel="preconnect" crossorigin="anonymous">
      <link rel="dns-prefetch" href="https://smetrics.elsevier.com">
      
      <script type="text/javascript">
        var targetServerState = JSON.stringify({"4D6368F454EC41940A4C98A6@AdobeOrg":{"sdid":{"supplementalDataIDCurrent":"1261C895738955EA-03FC167676ABA14B","supplementalDataIDCurrentConsumed":{"payload:target-global-mbox":true},"supplementalDataIDLastConsumed":{}}}});
        window.appData = window.appData || [];
        window.pageTargeting = {"region":"eu-west-1","platform":"sdtech","entitled":false,"crawler":"","journal":"Neurocomputing","auth":"AE"};
        window.arp = {
          config: {"adobeSuite":"elsevier-sd-prod","arsUrl":"https://ars.els-cdn.com","recommendationsFeedback":{"enabled":true,"url":"https://feedback.recs.d.elsevier.com/raw/events","timeout":60000},"googleMapsApiKey":"AIzaSyCBYU6I6lrbEU6wQXUEIte3NwGtm3jwHQc","mediaBaseUrl":"https://ars.els-cdn.com/content/image/","strictMode":false,"seamlessAccess":{"enableSeamlessAccess":true,"scriptUrl":"https://unpkg.com/@theidentityselector/thiss-ds@1.0.13/dist/thiss-ds.js","persistenceUrl":"https://service.seamlessaccess.org/ps/","persistenceContext":"seamlessaccess.org","scienceDirectUrl":"https://www.sciencedirect.com","shibAuthUrl":"https://auth.elsevier.com/ShibAuth/institutionLogin"},"reaxys":{"apiUrl":"https://reaxys-sdlc.reaxys.com","origin":"sciencedirect","queryBuilderHostPath":"https://www.reaxys.com/reaxys/secured/hopinto.do","url":"https://www.reaxys.com"},"oneTrustCookie":{"enabled":true},"ssrn":{"url":"https://papers.ssrn.com","path":"/sol3/papers.cfm"},"plumX":"https://api.plu.mx/widget/elsevier/artifact","assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1"},
          subscriptions: [],
          subscribe: function(cb) {
            var self = this;
            var i = this.subscriptions.push(cb) - 1;
            return function unsubscribe() {
              self.subscriptions.splice(i, 1);
            }
          },
        };
        window.addEventListener('beforeprint', () => pendo.onGuideDismissed());
      </script>
    <script data-cfasync="false" src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" data-domain-script="865ea198-88cc-4e41-8952-1df75d554d02"></script><meta http-equiv="origin-trial" content="AlK2UR5SkAlj8jjdEc9p3F3xuFYlF6LYjAML3EOqw1g26eCwWPjdmecULvBH5MVPoqKYrOfPhYVL71xAXI1IBQoAAAB8eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="Amm8/NmvvQfhwCib6I7ZsmUxiSCfOxWxHayJwyU1r3gRIItzr7bNQid6O8ZYaE1GSQTa69WwhPC9flq/oYkRBwsAAACCeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="A9wSqI5i0iwGdf6L1CERNdmsTPgVu44ewj8QxTBYgsv1LCPUVF7YmWOvTappqB1139jAymxUW/RO8zmMqo4zlAAAAACNeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MzY4MTI4MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A+d7vJfYtay4OUbdtRPZA3y7bKQLsxaMEPmxgfhBGqKXNrdkCQeJlUwqa6EBbSfjwFtJWTrWIioXeMW+y8bWAgQAAACTeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MzY4MTI4MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><script src="https://securepubads.g.doubleclick.net/pagead/managed/js/gpt/m202412090101/pubads_impl.js" async=""></script><link href="https://securepubads.g.doubleclick.net/pagead/managed/dict/m202412050101/gpt" rel="compression-dictionary"><script src="https://unpkg.com/@theidentityselector/thiss-ds@1.0.13/dist/thiss-ds.js" async=""></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
</style><script src="https://cdn.cookielaw.org/scripttemplates/202402.1.0/otBannerSdk.js" async="" type="text/javascript"></script><style id="onetrust-style">#onetrust-banner-sdk{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}#onetrust-banner-sdk .onetrust-vendors-list-handler{cursor:pointer;color:#1f96db;font-size:inherit;font-weight:bold;text-decoration:none;margin-left:5px}#onetrust-banner-sdk .onetrust-vendors-list-handler:hover{color:#1f96db}#onetrust-banner-sdk:focus{outline:2px solid #000;outline-offset:-2px}#onetrust-banner-sdk a:focus{outline:2px solid #000}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{outline-offset:1px}#onetrust-banner-sdk.ot-bnr-w-logo .ot-bnr-logo{height:64px;width:64px}#onetrust-banner-sdk .ot-tcf2-vendor-count.ot-text-bold{font-weight:bold}#onetrust-banner-sdk .ot-close-icon,#onetrust-pc-sdk .ot-close-icon,#ot-sync-ntfy .ot-close-icon{background-size:contain;background-repeat:no-repeat;background-position:center;height:12px;width:12px}#onetrust-banner-sdk .powered-by-logo,#onetrust-banner-sdk .ot-pc-footer-logo a,#onetrust-pc-sdk .powered-by-logo,#onetrust-pc-sdk .ot-pc-footer-logo a,#ot-sync-ntfy .powered-by-logo,#ot-sync-ntfy .ot-pc-footer-logo a{background-size:contain;background-repeat:no-repeat;background-position:center;height:25px;width:152px;display:block;text-decoration:none;font-size:.75em}#onetrust-banner-sdk .powered-by-logo:hover,#onetrust-banner-sdk .ot-pc-footer-logo a:hover,#onetrust-pc-sdk .powered-by-logo:hover,#onetrust-pc-sdk .ot-pc-footer-logo a:hover,#ot-sync-ntfy .powered-by-logo:hover,#ot-sync-ntfy .ot-pc-footer-logo a:hover{color:#565656}#onetrust-banner-sdk h3 *,#onetrust-banner-sdk h4 *,#onetrust-banner-sdk h6 *,#onetrust-banner-sdk button *,#onetrust-banner-sdk a[data-parent-id] *,#onetrust-pc-sdk h3 *,#onetrust-pc-sdk h4 *,#onetrust-pc-sdk h6 *,#onetrust-pc-sdk button *,#onetrust-pc-sdk a[data-parent-id] *,#ot-sync-ntfy h3 *,#ot-sync-ntfy h4 *,#ot-sync-ntfy h6 *,#ot-sync-ntfy button *,#ot-sync-ntfy a[data-parent-id] *{font-size:inherit;font-weight:inherit;color:inherit}#onetrust-banner-sdk .ot-hide,#onetrust-pc-sdk .ot-hide,#ot-sync-ntfy .ot-hide{display:none !important}#onetrust-banner-sdk button.ot-link-btn:hover,#onetrust-pc-sdk button.ot-link-btn:hover,#ot-sync-ntfy button.ot-link-btn:hover{text-decoration:underline;opacity:1}#onetrust-pc-sdk .ot-sdk-row .ot-sdk-column{padding:0}#onetrust-pc-sdk .ot-sdk-container{padding-right:0}#onetrust-pc-sdk .ot-sdk-row{flex-direction:initial;width:100%}#onetrust-pc-sdk [type=checkbox]:checked,#onetrust-pc-sdk [type=checkbox]:not(:checked){pointer-events:initial}#onetrust-pc-sdk [type=checkbox]:disabled+label::before,#onetrust-pc-sdk [type=checkbox]:disabled+label:after,#onetrust-pc-sdk [type=checkbox]:disabled+label{pointer-events:none;opacity:.7}#onetrust-pc-sdk #vendor-list-content{transform:translate3d(0, 0, 0)}#onetrust-pc-sdk li input[type=checkbox]{z-index:1}#onetrust-pc-sdk li .ot-checkbox label{z-index:2}#onetrust-pc-sdk li .ot-checkbox input[type=checkbox]{height:auto;width:auto}#onetrust-pc-sdk li .host-title a,#onetrust-pc-sdk li .ot-host-name a,#onetrust-pc-sdk li .accordion-text,#onetrust-pc-sdk li .ot-acc-txt{z-index:2;position:relative}#onetrust-pc-sdk input{margin:3px .1ex}#onetrust-pc-sdk .pc-logo,#onetrust-pc-sdk .ot-pc-logo{height:60px;width:180px;background-position:center;background-size:contain;background-repeat:no-repeat;display:inline-flex;justify-content:center;align-items:center}#onetrust-pc-sdk .pc-logo img,#onetrust-pc-sdk .ot-pc-logo img{max-height:100%;max-width:100%}#onetrust-pc-sdk .screen-reader-only,#onetrust-pc-sdk .ot-scrn-rdr,.ot-sdk-cookie-policy .screen-reader-only,.ot-sdk-cookie-policy .ot-scrn-rdr{border:0;clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}#onetrust-pc-sdk.ot-fade-in,.onetrust-pc-dark-filter.ot-fade-in,#onetrust-banner-sdk.ot-fade-in{animation-name:onetrust-fade-in;animation-duration:400ms;animation-timing-function:ease-in-out}#onetrust-pc-sdk.ot-hide{display:none !important}.onetrust-pc-dark-filter.ot-hide{display:none !important}#ot-sdk-btn.ot-sdk-show-settings,#ot-sdk-btn.optanon-show-settings{color:#68b631;border:1px solid #68b631;height:auto;white-space:normal;word-wrap:break-word;padding:.8em 2em;font-size:.8em;line-height:1.2;cursor:pointer;-moz-transition:.1s ease;-o-transition:.1s ease;-webkit-transition:1s ease;transition:.1s ease}#ot-sdk-btn.ot-sdk-show-settings:hover,#ot-sdk-btn.optanon-show-settings:hover{color:#fff;background-color:#68b631}.onetrust-pc-dark-filter{background:rgba(0,0,0,.5);z-index:2147483646;width:100%;height:100%;overflow:hidden;position:fixed;top:0;bottom:0;left:0}@keyframes onetrust-fade-in{0%{opacity:0}100%{opacity:1}}.ot-cookie-label{text-decoration:underline}@media only screen and (min-width: 426px)and (max-width: 896px)and (orientation: landscape){#onetrust-pc-sdk p{font-size:.75em}}#onetrust-banner-sdk .banner-option-input:focus+label{outline:1px solid #000;outline-style:auto}.category-vendors-list-handler+a:focus,.category-vendors-list-handler+a:focus-visible{outline:2px solid #000}#onetrust-pc-sdk .ot-userid-title{margin-top:10px}#onetrust-pc-sdk .ot-userid-title>span,#onetrust-pc-sdk .ot-userid-timestamp>span{font-weight:700}#onetrust-pc-sdk .ot-userid-desc{font-style:italic}#onetrust-pc-sdk .ot-host-desc a{pointer-events:initial}#onetrust-pc-sdk .ot-ven-hdr>p a{position:relative;z-index:2;pointer-events:initial}#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info a,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info a{margin-right:auto}#onetrust-pc-sdk .ot-pc-footer-logo img{width:136px;height:16px}#onetrust-pc-sdk .ot-pur-vdr-count{font-weight:400;font-size:.7rem;padding-top:3px;display:block}#onetrust-banner-sdk .ot-optout-signal,#onetrust-pc-sdk .ot-optout-signal{border:1px solid #32ae88;border-radius:3px;padding:5px;margin-bottom:10px;background-color:#f9fffa;font-size:.85rem;line-height:2}#onetrust-banner-sdk .ot-optout-signal .ot-optout-icon,#onetrust-pc-sdk .ot-optout-signal .ot-optout-icon{display:inline;margin-right:5px}#onetrust-banner-sdk .ot-optout-signal svg,#onetrust-pc-sdk .ot-optout-signal svg{height:20px;width:30px;transform:scale(0.5)}#onetrust-banner-sdk .ot-optout-signal svg path,#onetrust-pc-sdk .ot-optout-signal svg path{fill:#32ae88}#onetrust-banner-sdk,#onetrust-pc-sdk,#ot-sdk-cookie-policy,#ot-sync-ntfy{font-size:16px}#onetrust-banner-sdk *,#onetrust-banner-sdk ::after,#onetrust-banner-sdk ::before,#onetrust-pc-sdk *,#onetrust-pc-sdk ::after,#onetrust-pc-sdk ::before,#ot-sdk-cookie-policy *,#ot-sdk-cookie-policy ::after,#ot-sdk-cookie-policy ::before,#ot-sync-ntfy *,#ot-sync-ntfy ::after,#ot-sync-ntfy ::before{-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box}#onetrust-banner-sdk div,#onetrust-banner-sdk span,#onetrust-banner-sdk h1,#onetrust-banner-sdk h2,#onetrust-banner-sdk h3,#onetrust-banner-sdk h4,#onetrust-banner-sdk h5,#onetrust-banner-sdk h6,#onetrust-banner-sdk p,#onetrust-banner-sdk img,#onetrust-banner-sdk svg,#onetrust-banner-sdk button,#onetrust-banner-sdk section,#onetrust-banner-sdk a,#onetrust-banner-sdk label,#onetrust-banner-sdk input,#onetrust-banner-sdk ul,#onetrust-banner-sdk li,#onetrust-banner-sdk nav,#onetrust-banner-sdk table,#onetrust-banner-sdk thead,#onetrust-banner-sdk tr,#onetrust-banner-sdk td,#onetrust-banner-sdk tbody,#onetrust-banner-sdk .ot-main-content,#onetrust-banner-sdk .ot-toggle,#onetrust-banner-sdk #ot-content,#onetrust-banner-sdk #ot-pc-content,#onetrust-banner-sdk .checkbox,#onetrust-pc-sdk div,#onetrust-pc-sdk span,#onetrust-pc-sdk h1,#onetrust-pc-sdk h2,#onetrust-pc-sdk h3,#onetrust-pc-sdk h4,#onetrust-pc-sdk h5,#onetrust-pc-sdk h6,#onetrust-pc-sdk p,#onetrust-pc-sdk img,#onetrust-pc-sdk svg,#onetrust-pc-sdk button,#onetrust-pc-sdk section,#onetrust-pc-sdk a,#onetrust-pc-sdk label,#onetrust-pc-sdk input,#onetrust-pc-sdk ul,#onetrust-pc-sdk li,#onetrust-pc-sdk nav,#onetrust-pc-sdk table,#onetrust-pc-sdk thead,#onetrust-pc-sdk tr,#onetrust-pc-sdk td,#onetrust-pc-sdk tbody,#onetrust-pc-sdk .ot-main-content,#onetrust-pc-sdk .ot-toggle,#onetrust-pc-sdk #ot-content,#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk .checkbox,#ot-sdk-cookie-policy div,#ot-sdk-cookie-policy span,#ot-sdk-cookie-policy h1,#ot-sdk-cookie-policy h2,#ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy h5,#ot-sdk-cookie-policy h6,#ot-sdk-cookie-policy p,#ot-sdk-cookie-policy img,#ot-sdk-cookie-policy svg,#ot-sdk-cookie-policy button,#ot-sdk-cookie-policy section,#ot-sdk-cookie-policy a,#ot-sdk-cookie-policy label,#ot-sdk-cookie-policy input,#ot-sdk-cookie-policy ul,#ot-sdk-cookie-policy li,#ot-sdk-cookie-policy nav,#ot-sdk-cookie-policy table,#ot-sdk-cookie-policy thead,#ot-sdk-cookie-policy tr,#ot-sdk-cookie-policy td,#ot-sdk-cookie-policy tbody,#ot-sdk-cookie-policy .ot-main-content,#ot-sdk-cookie-policy .ot-toggle,#ot-sdk-cookie-policy #ot-content,#ot-sdk-cookie-policy #ot-pc-content,#ot-sdk-cookie-policy .checkbox,#ot-sync-ntfy div,#ot-sync-ntfy span,#ot-sync-ntfy h1,#ot-sync-ntfy h2,#ot-sync-ntfy h3,#ot-sync-ntfy h4,#ot-sync-ntfy h5,#ot-sync-ntfy h6,#ot-sync-ntfy p,#ot-sync-ntfy img,#ot-sync-ntfy svg,#ot-sync-ntfy button,#ot-sync-ntfy section,#ot-sync-ntfy a,#ot-sync-ntfy label,#ot-sync-ntfy input,#ot-sync-ntfy ul,#ot-sync-ntfy li,#ot-sync-ntfy nav,#ot-sync-ntfy table,#ot-sync-ntfy thead,#ot-sync-ntfy tr,#ot-sync-ntfy td,#ot-sync-ntfy tbody,#ot-sync-ntfy .ot-main-content,#ot-sync-ntfy .ot-toggle,#ot-sync-ntfy #ot-content,#ot-sync-ntfy #ot-pc-content,#ot-sync-ntfy .checkbox{font-family:inherit;font-weight:normal;-webkit-font-smoothing:auto;letter-spacing:normal;line-height:normal;padding:0;margin:0;height:auto;min-height:0;max-height:none;width:auto;min-width:0;max-width:none;border-radius:0;border:none;clear:none;float:none;position:static;bottom:auto;left:auto;right:auto;top:auto;text-align:left;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;white-space:normal;background:none;overflow:visible;vertical-align:baseline;visibility:visible;z-index:auto;box-shadow:none}#onetrust-banner-sdk label:before,#onetrust-banner-sdk label:after,#onetrust-banner-sdk .checkbox:after,#onetrust-banner-sdk .checkbox:before,#onetrust-pc-sdk label:before,#onetrust-pc-sdk label:after,#onetrust-pc-sdk .checkbox:after,#onetrust-pc-sdk .checkbox:before,#ot-sdk-cookie-policy label:before,#ot-sdk-cookie-policy label:after,#ot-sdk-cookie-policy .checkbox:after,#ot-sdk-cookie-policy .checkbox:before,#ot-sync-ntfy label:before,#ot-sync-ntfy label:after,#ot-sync-ntfy .checkbox:after,#ot-sync-ntfy .checkbox:before{content:"";content:none}#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{position:relative;width:100%;max-width:100%;margin:0 auto;padding:0 20px;box-sizing:border-box}#onetrust-banner-sdk .ot-sdk-column,#onetrust-banner-sdk .ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-column,#onetrust-pc-sdk .ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-column,#ot-sdk-cookie-policy .ot-sdk-columns{width:100%;float:left;box-sizing:border-box;padding:0;display:initial}@media(min-width: 400px){#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{width:90%;padding:0}}@media(min-width: 550px){#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{width:100%}#onetrust-banner-sdk .ot-sdk-column,#onetrust-banner-sdk .ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-column,#onetrust-pc-sdk .ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-column,#ot-sdk-cookie-policy .ot-sdk-columns{margin-left:4%}#onetrust-banner-sdk .ot-sdk-column:first-child,#onetrust-banner-sdk .ot-sdk-columns:first-child,#onetrust-pc-sdk .ot-sdk-column:first-child,#onetrust-pc-sdk .ot-sdk-columns:first-child,#ot-sdk-cookie-policy .ot-sdk-column:first-child,#ot-sdk-cookie-policy .ot-sdk-columns:first-child{margin-left:0}#onetrust-banner-sdk .ot-sdk-two.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-two.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-two.ot-sdk-columns{width:13.3333333333%}#onetrust-banner-sdk .ot-sdk-three.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-three.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-three.ot-sdk-columns{width:22%}#onetrust-banner-sdk .ot-sdk-four.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-four.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-four.ot-sdk-columns{width:30.6666666667%}#onetrust-banner-sdk .ot-sdk-eight.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-eight.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-eight.ot-sdk-columns{width:65.3333333333%}#onetrust-banner-sdk .ot-sdk-nine.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-nine.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-nine.ot-sdk-columns{width:74%}#onetrust-banner-sdk .ot-sdk-ten.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-ten.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-ten.ot-sdk-columns{width:82.6666666667%}#onetrust-banner-sdk .ot-sdk-eleven.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-eleven.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-eleven.ot-sdk-columns{width:91.3333333333%}#onetrust-banner-sdk .ot-sdk-twelve.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-twelve.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-twelve.ot-sdk-columns{width:100%;margin-left:0}}#onetrust-banner-sdk h1,#onetrust-banner-sdk h2,#onetrust-banner-sdk h3,#onetrust-banner-sdk h4,#onetrust-banner-sdk h5,#onetrust-banner-sdk h6,#onetrust-pc-sdk h1,#onetrust-pc-sdk h2,#onetrust-pc-sdk h3,#onetrust-pc-sdk h4,#onetrust-pc-sdk h5,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h1,#ot-sdk-cookie-policy h2,#ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy h5,#ot-sdk-cookie-policy h6{margin-top:0;font-weight:600;font-family:inherit}#onetrust-banner-sdk h1,#onetrust-pc-sdk h1,#ot-sdk-cookie-policy h1{font-size:1.5rem;line-height:1.2}#onetrust-banner-sdk h2,#onetrust-pc-sdk h2,#ot-sdk-cookie-policy h2{font-size:1.5rem;line-height:1.25}#onetrust-banner-sdk h3,#onetrust-pc-sdk h3,#ot-sdk-cookie-policy h3{font-size:1.5rem;line-height:1.3}#onetrust-banner-sdk h4,#onetrust-pc-sdk h4,#ot-sdk-cookie-policy h4{font-size:1.5rem;line-height:1.35}#onetrust-banner-sdk h5,#onetrust-pc-sdk h5,#ot-sdk-cookie-policy h5{font-size:1.5rem;line-height:1.5}#onetrust-banner-sdk h6,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h6{font-size:1.5rem;line-height:1.6}@media(min-width: 550px){#onetrust-banner-sdk h1,#onetrust-pc-sdk h1,#ot-sdk-cookie-policy h1{font-size:1.5rem}#onetrust-banner-sdk h2,#onetrust-pc-sdk h2,#ot-sdk-cookie-policy h2{font-size:1.5rem}#onetrust-banner-sdk h3,#onetrust-pc-sdk h3,#ot-sdk-cookie-policy h3{font-size:1.5rem}#onetrust-banner-sdk h4,#onetrust-pc-sdk h4,#ot-sdk-cookie-policy h4{font-size:1.5rem}#onetrust-banner-sdk h5,#onetrust-pc-sdk h5,#ot-sdk-cookie-policy h5{font-size:1.5rem}#onetrust-banner-sdk h6,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h6{font-size:1.5rem}}#onetrust-banner-sdk p,#onetrust-pc-sdk p,#ot-sdk-cookie-policy p{margin:0 0 1em 0;font-family:inherit;line-height:normal}#onetrust-banner-sdk a,#onetrust-pc-sdk a,#ot-sdk-cookie-policy a{color:#565656;text-decoration:underline}#onetrust-banner-sdk a:hover,#onetrust-pc-sdk a:hover,#ot-sdk-cookie-policy a:hover{color:#565656;text-decoration:none}#onetrust-banner-sdk .ot-sdk-button,#onetrust-banner-sdk button,#onetrust-pc-sdk .ot-sdk-button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy .ot-sdk-button,#ot-sdk-cookie-policy button{margin-bottom:1rem;font-family:inherit}#onetrust-banner-sdk .ot-sdk-button,#onetrust-banner-sdk button,#onetrust-pc-sdk .ot-sdk-button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy .ot-sdk-button,#ot-sdk-cookie-policy button{display:inline-block;height:38px;padding:0 30px;color:#555;text-align:center;font-size:.9em;font-weight:400;line-height:38px;letter-spacing:.01em;text-decoration:none;white-space:nowrap;background-color:rgba(0,0,0,0);border-radius:2px;border:1px solid #bbb;cursor:pointer;box-sizing:border-box}#onetrust-banner-sdk .ot-sdk-button:hover,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus,#onetrust-pc-sdk .ot-sdk-button:hover,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus,#ot-sdk-cookie-policy .ot-sdk-button:hover,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus{color:#333;border-color:#888;opacity:.7}#onetrust-banner-sdk .ot-sdk-button:focus,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:focus,#onetrust-pc-sdk .ot-sdk-button:focus,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:focus,#ot-sdk-cookie-policy .ot-sdk-button:focus,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:focus{outline:2px solid #000}#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary,#onetrust-banner-sdk button.ot-sdk-button-primary,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary,#onetrust-pc-sdk button.ot-sdk-button-primary,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary,#ot-sdk-cookie-policy button.ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary{color:#fff;background-color:#33c3f0;border-color:#33c3f0}#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary:hover,#onetrust-banner-sdk button.ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary:hover,#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary:focus,#onetrust-banner-sdk button.ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary:focus,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary:hover,#onetrust-pc-sdk button.ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary:hover,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary:focus,#onetrust-pc-sdk button.ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary:hover,#ot-sdk-cookie-policy button.ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary:focus,#ot-sdk-cookie-policy button.ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary:focus{color:#fff;background-color:#1eaedb;border-color:#1eaedb}#onetrust-banner-sdk input[type=text],#onetrust-pc-sdk input[type=text],#ot-sdk-cookie-policy input[type=text]{height:38px;padding:6px 10px;background-color:#fff;border:1px solid #d1d1d1;border-radius:4px;box-shadow:none;box-sizing:border-box}#onetrust-banner-sdk input[type=text],#onetrust-pc-sdk input[type=text],#ot-sdk-cookie-policy input[type=text]{-webkit-appearance:none;-moz-appearance:none;appearance:none}#onetrust-banner-sdk input[type=text]:focus,#onetrust-pc-sdk input[type=text]:focus,#ot-sdk-cookie-policy input[type=text]:focus{border:1px solid #000;outline:0}#onetrust-banner-sdk label,#onetrust-pc-sdk label,#ot-sdk-cookie-policy label{display:block;margin-bottom:.5rem;font-weight:600}#onetrust-banner-sdk input[type=checkbox],#onetrust-pc-sdk input[type=checkbox],#ot-sdk-cookie-policy input[type=checkbox]{display:inline}#onetrust-banner-sdk ul,#onetrust-pc-sdk ul,#ot-sdk-cookie-policy ul{list-style:circle inside}#onetrust-banner-sdk ul,#onetrust-pc-sdk ul,#ot-sdk-cookie-policy ul{padding-left:0;margin-top:0}#onetrust-banner-sdk ul ul,#onetrust-pc-sdk ul ul,#ot-sdk-cookie-policy ul ul{margin:1.5rem 0 1.5rem 3rem;font-size:90%}#onetrust-banner-sdk li,#onetrust-pc-sdk li,#ot-sdk-cookie-policy li{margin-bottom:1rem}#onetrust-banner-sdk th,#onetrust-banner-sdk td,#onetrust-pc-sdk th,#onetrust-pc-sdk td,#ot-sdk-cookie-policy th,#ot-sdk-cookie-policy td{padding:12px 15px;text-align:left;border-bottom:1px solid #e1e1e1}#onetrust-banner-sdk button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy button{margin-bottom:1rem;font-family:inherit}#onetrust-banner-sdk .ot-sdk-container:after,#onetrust-banner-sdk .ot-sdk-row:after,#onetrust-pc-sdk .ot-sdk-container:after,#onetrust-pc-sdk .ot-sdk-row:after,#ot-sdk-cookie-policy .ot-sdk-container:after,#ot-sdk-cookie-policy .ot-sdk-row:after{content:"";display:table;clear:both}#onetrust-banner-sdk .ot-sdk-row,#onetrust-pc-sdk .ot-sdk-row,#ot-sdk-cookie-policy .ot-sdk-row{margin:0;max-width:none;display:block}#onetrust-banner-sdk{box-shadow:0 0 18px rgba(0,0,0,.2)}#onetrust-banner-sdk.otFlat{position:fixed;z-index:2147483645;bottom:0;right:0;left:0;background-color:#fff;max-height:90%;overflow-x:hidden;overflow-y:auto}#onetrust-banner-sdk.otFlat.top{top:0px;bottom:auto}#onetrust-banner-sdk.otRelFont{font-size:1rem}#onetrust-banner-sdk>.ot-sdk-container{overflow:hidden}#onetrust-banner-sdk::-webkit-scrollbar{width:11px}#onetrust-banner-sdk::-webkit-scrollbar-thumb{border-radius:10px;background:#c1c1c1}#onetrust-banner-sdk{scrollbar-arrow-color:#c1c1c1;scrollbar-darkshadow-color:#c1c1c1;scrollbar-face-color:#c1c1c1;scrollbar-shadow-color:#c1c1c1}#onetrust-banner-sdk #onetrust-policy{margin:1.25em 0 .625em 2em;overflow:hidden}#onetrust-banner-sdk #onetrust-policy .ot-gv-list-handler{float:left;font-size:.82em;padding:0;margin-bottom:0;border:0;line-height:normal;height:auto;width:auto}#onetrust-banner-sdk #onetrust-policy-title{font-size:1.2em;line-height:1.3;margin-bottom:10px}#onetrust-banner-sdk #onetrust-policy-text{clear:both;text-align:left;font-size:.88em;line-height:1.4}#onetrust-banner-sdk #onetrust-policy-text *{font-size:inherit;line-height:inherit}#onetrust-banner-sdk #onetrust-policy-text a{font-weight:bold;margin-left:5px}#onetrust-banner-sdk #onetrust-policy-title,#onetrust-banner-sdk #onetrust-policy-text{color:dimgray;float:left}#onetrust-banner-sdk #onetrust-button-group-parent{min-height:1px;text-align:center}#onetrust-banner-sdk #onetrust-button-group{display:inline-block}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{background-color:#68b631;color:#fff;border-color:#68b631;margin-right:1em;min-width:125px;height:auto;white-space:normal;word-break:break-word;word-wrap:break-word;padding:12px 10px;line-height:1.2;font-size:.813em;font-weight:600}#onetrust-banner-sdk #onetrust-pc-btn-handler.cookie-setting-link{background-color:#fff;border:none;color:#68b631;text-decoration:underline;padding-left:0;padding-right:0}#onetrust-banner-sdk .onetrust-close-btn-ui{width:44px;height:44px;background-size:12px;border:none;position:relative;margin:auto;padding:0}#onetrust-banner-sdk .banner_logo{display:none}#onetrust-banner-sdk.ot-bnr-w-logo .ot-bnr-logo{position:absolute;top:50%;transform:translateY(-50%);left:0px}#onetrust-banner-sdk.ot-bnr-w-logo #onetrust-policy{margin-left:65px}#onetrust-banner-sdk .ot-b-addl-desc{clear:both;float:left;display:block}#onetrust-banner-sdk #banner-options{float:left;display:table;margin-right:0;margin-left:1em;width:calc(100% - 1em)}#onetrust-banner-sdk .banner-option-input{cursor:pointer;width:auto;height:auto;border:none;padding:0;padding-right:3px;margin:0 0 10px;font-size:.82em;line-height:1.4}#onetrust-banner-sdk .banner-option-input *{pointer-events:none;font-size:inherit;line-height:inherit}#onetrust-banner-sdk .banner-option-input[aria-expanded=true]~.banner-option-details{display:block;height:auto}#onetrust-banner-sdk .banner-option-input[aria-expanded=true] .ot-arrow-container{transform:rotate(90deg)}#onetrust-banner-sdk .banner-option{margin-bottom:12px;margin-left:0;border:none;float:left;padding:0}#onetrust-banner-sdk .banner-option:first-child{padding-left:2px}#onetrust-banner-sdk .banner-option:not(:first-child){padding:0;border:none}#onetrust-banner-sdk .banner-option-header{cursor:pointer;display:inline-block}#onetrust-banner-sdk .banner-option-header :first-child{color:dimgray;font-weight:bold;float:left}#onetrust-banner-sdk .banner-option-header .ot-arrow-container{display:inline-block;border-top:6px solid rgba(0,0,0,0);border-bottom:6px solid rgba(0,0,0,0);border-left:6px solid dimgray;margin-left:10px;vertical-align:middle}#onetrust-banner-sdk .banner-option-details{display:none;font-size:.83em;line-height:1.5;padding:10px 0px 5px 10px;margin-right:10px;height:0px}#onetrust-banner-sdk .banner-option-details *{font-size:inherit;line-height:inherit;color:dimgray}#onetrust-banner-sdk .ot-arrow-container,#onetrust-banner-sdk .banner-option-details{transition:all 300ms ease-in 0s;-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s}#onetrust-banner-sdk .ot-dpd-container{float:left}#onetrust-banner-sdk .ot-dpd-title{margin-bottom:10px}#onetrust-banner-sdk .ot-dpd-title,#onetrust-banner-sdk .ot-dpd-desc{font-size:.88em;line-height:1.4;color:dimgray}#onetrust-banner-sdk .ot-dpd-title *,#onetrust-banner-sdk .ot-dpd-desc *{font-size:inherit;line-height:inherit}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text *{margin-bottom:0}#onetrust-banner-sdk.ot-iab-2 .onetrust-vendors-list-handler{display:block;margin-left:0;margin-top:5px;clear:both;margin-bottom:0;padding:0;border:0;height:auto;width:auto}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group button{display:block}#onetrust-banner-sdk.ot-close-btn-link{padding-top:25px}#onetrust-banner-sdk.ot-close-btn-link #onetrust-close-btn-container{top:15px;transform:none;right:15px}#onetrust-banner-sdk.ot-close-btn-link #onetrust-close-btn-container button{padding:0;white-space:pre-wrap;border:none;height:auto;line-height:1.5;text-decoration:underline;font-size:.69em}#onetrust-banner-sdk #onetrust-policy-text,#onetrust-banner-sdk .ot-dpd-desc,#onetrust-banner-sdk .ot-b-addl-desc{font-size:.813em;line-height:1.5}#onetrust-banner-sdk .ot-dpd-desc{margin-bottom:10px}#onetrust-banner-sdk .ot-dpd-desc>.ot-b-addl-desc{margin-top:10px;margin-bottom:10px;font-size:1em}@media only screen and (max-width: 425px){#onetrust-banner-sdk #onetrust-close-btn-container{position:absolute;top:6px;right:2px}#onetrust-banner-sdk #onetrust-policy{margin-left:0;margin-top:3em}#onetrust-banner-sdk #onetrust-button-group{display:block}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{width:100%}#onetrust-banner-sdk .onetrust-close-btn-ui{top:auto;transform:none}#onetrust-banner-sdk #onetrust-policy-title{display:inline;float:none}#onetrust-banner-sdk #banner-options{margin:0;padding:0;width:100%}}@media only screen and (min-width: 426px)and (max-width: 896px){#onetrust-banner-sdk #onetrust-close-btn-container{position:absolute;top:0;right:0}#onetrust-banner-sdk #onetrust-policy{margin-left:1em;margin-right:1em}#onetrust-banner-sdk .onetrust-close-btn-ui{top:10px;right:10px}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:95%}#onetrust-banner-sdk.ot-iab-2 #onetrust-group-container{width:100%}#onetrust-banner-sdk.ot-bnr-w-logo #onetrust-button-group-parent{padding-left:50px}#onetrust-banner-sdk #onetrust-button-group-parent{width:100%;position:relative;margin-left:0}#onetrust-banner-sdk #onetrust-button-group button{display:inline-block}#onetrust-banner-sdk #onetrust-button-group{margin-right:0;text-align:center}#onetrust-banner-sdk .has-reject-all-button #onetrust-pc-btn-handler{float:left}#onetrust-banner-sdk .has-reject-all-button #onetrust-reject-all-handler,#onetrust-banner-sdk .has-reject-all-button #onetrust-accept-btn-handler{float:right}#onetrust-banner-sdk .has-reject-all-button #onetrust-button-group{width:calc(100% - 2em);margin-right:0}#onetrust-banner-sdk .has-reject-all-button #onetrust-pc-btn-handler.cookie-setting-link{padding-left:0px;text-align:left}#onetrust-banner-sdk.ot-buttons-fw .ot-sdk-three button{width:100%;text-align:center}#onetrust-banner-sdk.ot-buttons-fw #onetrust-button-group-parent button{float:none}#onetrust-banner-sdk.ot-buttons-fw #onetrust-pc-btn-handler.cookie-setting-link{text-align:center}}@media only screen and (min-width: 550px){#onetrust-banner-sdk .banner-option:not(:first-child){border-left:1px solid #d8d8d8;padding-left:25px}}@media only screen and (min-width: 425px)and (max-width: 550px){#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group,#onetrust-banner-sdk.ot-iab-2 #onetrust-policy,#onetrust-banner-sdk.ot-iab-2 .banner-option{width:100%}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-accept-btn-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-reject-all-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-pc-btn-handler{width:100%}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-accept-btn-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-reject-all-handler{float:left}}@media only screen and (min-width: 769px){#onetrust-banner-sdk #onetrust-button-group{margin-right:30%}#onetrust-banner-sdk #banner-options{margin-left:2em;margin-right:5em;margin-bottom:1.25em;width:calc(100% - 7em)}}@media only screen and (min-width: 897px)and (max-width: 1023px){#onetrust-banner-sdk.vertical-align-content #onetrust-button-group-parent{position:absolute;top:50%;left:75%;transform:translateY(-50%)}#onetrust-banner-sdk #onetrust-close-btn-container{top:50%;margin:auto;transform:translate(-50%, -50%);position:absolute;padding:0;right:0}#onetrust-banner-sdk #onetrust-close-btn-container button{position:relative;margin:0;right:-22px;top:2px}}@media only screen and (min-width: 1024px){#onetrust-banner-sdk #onetrust-close-btn-container{top:50%;margin:auto;transform:translate(-50%, -50%);position:absolute;right:0}#onetrust-banner-sdk #onetrust-close-btn-container button{right:-12px}#onetrust-banner-sdk #onetrust-policy{margin-left:2em}#onetrust-banner-sdk.vertical-align-content #onetrust-button-group-parent{position:absolute;top:50%;left:60%;transform:translateY(-50%)}#onetrust-banner-sdk .ot-optout-signal{width:50%}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-title{width:50%}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text,#onetrust-banner-sdk.ot-iab-2 :not(.ot-dpd-desc)>.ot-b-addl-desc{margin-bottom:1em;width:50%;border-right:1px solid #d8d8d8;padding-right:1rem}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text{margin-bottom:0;padding-bottom:1em}#onetrust-banner-sdk.ot-iab-2 :not(.ot-dpd-desc)>.ot-b-addl-desc{margin-bottom:0;padding-bottom:1em}#onetrust-banner-sdk.ot-iab-2 .ot-dpd-container{width:45%;padding-left:1rem;display:inline-block;float:none}#onetrust-banner-sdk.ot-iab-2 .ot-dpd-title{line-height:1.7}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group-parent{left:auto;right:4%;margin-left:0}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group button{display:block}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:auto;width:30%}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:60%}#onetrust-banner-sdk #onetrust-button-group{margin-right:auto}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{margin-top:1em}}@media only screen and (min-width: 890px){#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group-parent{padding-left:3%;padding-right:4%;margin-left:0}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{margin-right:0;margin-top:1.25em;width:100%}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button{width:100%;margin-bottom:5px;margin-top:5px}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type{margin-bottom:20px}}@media only screen and (min-width: 1280px){#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:55%}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{width:44%;padding-left:2%;padding-right:2%}#onetrust-banner-sdk:not(.ot-iab-2).vertical-align-content #onetrust-button-group-parent{position:absolute;left:55%}}
        #onetrust-consent-sdk #onetrust-banner-sdk {background-color: #FFF;}
            #onetrust-consent-sdk #onetrust-policy-title,
                    #onetrust-consent-sdk #onetrust-policy-text,
                    #onetrust-consent-sdk .ot-b-addl-desc,
                    #onetrust-consent-sdk .ot-dpd-desc,
                    #onetrust-consent-sdk .ot-dpd-title,
                    #onetrust-consent-sdk #onetrust-policy-text *:not(.onetrust-vendors-list-handler),
                    #onetrust-consent-sdk .ot-dpd-desc *:not(.onetrust-vendors-list-handler),
                    #onetrust-consent-sdk #onetrust-banner-sdk #banner-options *,
                    #onetrust-banner-sdk .ot-cat-header,
                    #onetrust-banner-sdk .ot-optout-signal
                    {
                        color: #2E2E2E;
                    }
            #onetrust-consent-sdk #onetrust-banner-sdk .banner-option-details {
                    background-color: #E9E9E9;}
             #onetrust-consent-sdk #onetrust-banner-sdk a[href],
                    #onetrust-consent-sdk #onetrust-banner-sdk a[href] font,
                    #onetrust-consent-sdk #onetrust-banner-sdk .ot-link-btn
                        {
                            color: #007398;
                        }#onetrust-consent-sdk #onetrust-accept-btn-handler,
                         #onetrust-banner-sdk #onetrust-reject-all-handler {
                            background-color: #007398;border-color: #007398;
                color: #FFF;
            }
            #onetrust-consent-sdk #onetrust-banner-sdk *:focus,
            #onetrust-consent-sdk #onetrust-banner-sdk:focus {
               outline-color: #000000;
               outline-width: 1px;
            }
            #onetrust-consent-sdk #onetrust-pc-btn-handler,
            #onetrust-consent-sdk #onetrust-pc-btn-handler.cookie-setting-link {
                color: #6CC04A; border-color: #6CC04A;
                background-color:
                #FFF;
            }/*! Extra code to blur out background */
.onetrust-pc-dark-filter{
background:rgba(0,0,0,.5);
z-index:2147483646;
width:100%;
height:100%;
overflow:hidden;
position:fixed;
top:0;
bottom:0;
left:0;
backdrop-filter: initial
}

/*! v6.12.0 2021-01-19 */
div#onetrust-consent-sdk #onetrust-banner-sdk{border-top:2px solid #eb6500!important;outline:1px solid transparent;box-shadow:none;padding:24px}div#onetrust-consent-sdk button{border-radius:0!important;box-shadow:none!important;box-sizing:border-box!important;font-size:20px!important;font-weight:400!important;letter-spacing:0!important;max-width:none!important;white-space:nowrap!important}div#onetrust-consent-sdk button:not(.ot-link-btn){background-color:#007398!important;border:2px solid #007398!important;color:#fff!important;height:48px!important;padding:0 1em!important;width:auto!important}div#onetrust-consent-sdk button:hover{background-color:#fff!important;border-color:#eb6500!important;color:#2e2e2e!important}div#onetrust-consent-sdk button.ot-link-btn{color:#007398!important;font-size:16px!important;text-decoration:underline}div#onetrust-consent-sdk button.ot-link-btn:hover{color: #2e2e2e!important;text-decoration-color:#eb6500!important}div#onetrust-consent-sdk a,div#onetrust-pc-sdk a{color:#007398!important;text-decoration:underline!important}div#onetrust-consent-sdk a,div#onetrust-consent-sdk button,div#onetrust-consent-sdk p:hover{opacity:1!important}div#onetrust-consent-sdk a:focus,div#onetrust-consent-sdk button:focus,div#onetrust-consent-sdk input:focus{outline:2px solid #eb6500!important;outline-offset:1px!important}div#onetrust-banner-sdk .ot-sdk-container{padding:0;width:auto}div#onetrust-banner-sdk .ot-sdk-row{align-items:flex-start;box-sizing:border-box;display:flex;flex-direction:column;justify-content:space-between;margin:auto;max-width:1152px}div#onetrust-banner-sdk .ot-sdk-row:after{display:none}div#onetrust-banner-sdk #onetrust-group-container,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-group-container,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{flex-grow:1;width:auto}div#onetrust-banner-sdk #onetrust-policy,div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy{margin:0;overflow:visible}div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy-text,div#onetrust-consent-sdk #onetrust-policy-text{font-size:16px;line-height:24px;max-width:44em;margin:0}div#onetrust-consent-sdk #onetrust-policy-text a[href]{font-weight:400;margin-left:8px}div#onetrust-banner-sdk #onetrust-button-group-parent{flex:0 0 auto;margin:32px 0 0;width:100%}div#onetrust-banner-sdk #onetrust-button-group{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;margin:-8px}div#onetrust-banner-sdk .banner-actions-container{display:flex;flex:1 0 auto}div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type,div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto;margin:8px;width:auto}div#onetrust-consent-sdk #onetrust-pc-btn-handler{background-color:#fff!important;color:#2e2e2e!important}div#onetrust-banner-sdk #onetrust-close-btn-container{display:none}@media only screen and (min-width:556px){div#onetrust-consent-sdk #onetrust-banner-sdk{padding:40px}div#onetrust-banner-sdk #onetrust-policy{margin:0 40px 0 0}div#onetrust-banner-sdk .ot-sdk-row{align-items:center;flex-direction:row}div#onetrust-banner-sdk #onetrust-button-group-parent,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-button-group-parent,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:0;padding:0;width:auto}div#onetrust-banner-sdk #onetrust-button-group,div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{align-items:stretch;flex-direction:column-reverse;margin:0}div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto}}@media only screen and (min-width:768px){div#onetrust-banner-sdk #onetrust-policy{margin:0 48px 0 0}div#onetrust-consent-sdk #onetrust-banner-sdk{padding:48px}}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-size:16px;line-height:24px}div#onetrust-consent-sdk #onetrust-pc-sdk p,div#onetrust-pc-sdk #ot-pc-desc,div#onetrust-pc-sdk .category-host-list-handler,div#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{font-size:16px;font-weight:400;line-height:24px}div#onetrust-consent-sdk a:hover,div#onetrust-pc-sdk a:hover{color:#2e2e2e!important;text-decoration-color:#eb6500!important}div#onetrust-pc-sdk{border-radius:0;bottom:0;height:auto;left:0;margin:auto;max-width:100%;overflow:hidden;right:0;top:0;width:512px;max-height:800px}div#onetrust-pc-sdk .ot-pc-header{display:none}div#onetrust-pc-sdk #ot-pc-content{overscroll-behavior:contain;padding:0 12px 0 24px;margin:16px 4px 0 0;top:0;right:16px;left:0;width:auto}div#onetrust-pc-sdk #ot-category-title,div#onetrust-pc-sdk #ot-pc-title{font-size:24px;font-weight:400;line-height:32px;margin:0 0 16px}div#onetrust-pc-sdk #ot-pc-desc{padding:0}div#onetrust-pc-sdk #ot-pc-desc a{display:inline}div#onetrust-pc-sdk #accept-recommended-btn-handler{display:none!important}div#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:2px solid #eb6500;outline-offset:-1px;transition:none}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{border-width:0 0 2px}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{border-width:2px 0}div#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding:8px 0;width:100%}div#onetrust-pc-sdk .ot-plus-minus{transform:translateY(2px)}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item>button{background:0 0!important;border:0!important;height:44px!important;max-width:none!important;width:calc(100% - 48px)!important}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-weight:700}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding:0}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item .ot-acc-grpdesc{padding:0;width:100%}div#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border:0;padding:0}div#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp{margin:0}div#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:calc(100% - 160px)}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{width:calc(100% - 88px)}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{color:#2e2e2e;font-size:12px;font-weight:400;line-height:1.5;padding-right:48px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:before{border-radius:12px;position:absolute;right:0;top:0;content:'';background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:after{border-radius:50%;position:absolute;right:5px;top:4px;content:'';background-color:#eb6500;height:12px;width:12px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active,div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl{right:2px}div#onetrust-pc-sdk .ot-switch{display:block;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob,div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob:before{background-color:#737373;height:8px;left:4px;top:4px;width:8px}div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{background-color:#eb6500;height:12px;left:0;top:2px;width:12px}div#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch .ot-switch-nob{box-shadow:0 0;outline:2px solid #eb6500!important;outline-offset:1px;transition:none}div#onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt{background-color:transparent;padding-left:3px}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr,div#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr{overflow:visible;width:100%}div#onetrust-pc-sdk .ot-pc-footer{border-top:0 solid}div#onetrust-pc-sdk .ot-btn-container{padding-top:24px;text-align:center}div#onetrust-pc-sdk .ot-pc-footer button{margin:8px 0;background-color:#fff}div#onetrust-pc-sdk .ot-pc-footer-logo{background-color:#fff}div#onetrust-pc-sdk #ot-lst-title span{font-size:24px;font-weight:400;line-height:32px}div#onetrust-pc-sdk #ot-host-lst .ot-host-desc,div#onetrust-pc-sdk #ot-host-lst .ot-host-expand,div#onetrust-pc-sdk #ot-host-lst .ot-host-name,div#onetrust-pc-sdk #ot-host-lst .ot-host-name a,div#onetrust-pc-sdk .back-btn-handler,div#onetrust-pc-sdk .ot-host-opt li>div div{font-size:16px;font-weight:400;line-height:24px}div#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{width:100%}div#onetrust-pc-sdk #ot-pc-lst{top:0}div#onetrust-pc-sdk .back-btn-handler{text-decoration:none!important}div#onetrust-pc-sdk #filter-btn-handler:hover svg{filter:invert(1)}div#onetrust-pc-sdk .back-btn-handler svg{width:16px;height:16px}div#onetrust-pc-sdk .ot-host-item>button{background:0 0!important;border:0!important;height:66px!important;max-width:none!important;width:calc(100% - 5px)!important;transform:translate(2px,2px)}div#onetrust-pc-sdk .ot-host-item{border-bottom:2px solid #b9b9b9;padding:0}div#onetrust-pc-sdk .ot-host-item .ot-acc-hdr{margin:0 0 -6px;padding:8px 0}div#onetrust-pc-sdk ul li:first-child{border-top:2px solid #b9b9b9}div#onetrust-pc-sdk .ot-host-item .ot-plus-minus{margin:0 8px 0 0}div#onetrust-pc-sdk .ot-search-cntr{width:calc(100% - 48px)}div#onetrust-pc-sdk .ot-host-opt .ot-host-info{background-color:transparent}div#onetrust-pc-sdk .ot-host-opt li>div div{padding:0}div#onetrust-pc-sdk #vendor-search-handler{border-radius:0;border-color:#939393;border-style:solid;border-width:2px 0 2px 2px;font-size:20px;height:48px;margin:0}div#onetrust-pc-sdk #ot-pc-hdr{margin-left:24px}div#onetrust-pc-sdk .ot-lst-subhdr{width:calc(100% - 24px)}div#onetrust-pc-sdk .ot-lst-subhdr svg{right:0;top:8px}div#onetrust-pc-sdk .ot-fltr-cntr{box-sizing:border-box;right:0;width:48px}div#onetrust-pc-sdk #filter-btn-handler{width:48px!important;padding:8px!important}div#onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,div#onetrust-pc-sdk button#filter-apply-handler,div#onetrust-pc-sdk button#filter-cancel-handler{height:2em!important;padding-left:14px!important;padding-right:14px!important}div#onetrust-pc-sdk #ot-fltr-cnt{box-shadow:0 0;border:1px solid #8e8e8e;border-radius:0}div#onetrust-pc-sdk .ot-fltr-scrlcnt{max-height:calc(100% - 80px)}div#onetrust-pc-sdk #ot-fltr-modal{max-height:400px}div#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:16px}div#onetrust-pc-sdk #ot-lst-cnt{margin-left:24px;width:calc(100% - 48px)}div#onetrust-pc-sdk #ot-anchor{display:none!important}

/* 2023-12-04  Fix for button order in mobile view*/
@media (max-width: 550px) {
  #onetrust-accept-btn-handler {order: 1;  }
  #onetrust-reject-all-handler { order: 2;  }
  #onetrust-pc-btn-handler { order: 3;  }
}


/*! Extra code to blur our background */
.onetrust-pc-dark-filter{
backdrop-filter: blur(3px)
}
#onetrust-pc-sdk.otPcCenter{overflow:hidden;position:fixed;margin:0 auto;top:5%;right:0;left:0;width:40%;max-width:575px;min-width:575px;border-radius:2.5px;z-index:2147483647;background-color:#fff;-webkit-box-shadow:0px 2px 10px -3px #999;-moz-box-shadow:0px 2px 10px -3px #999;box-shadow:0px 2px 10px -3px #999}#onetrust-pc-sdk.otPcCenter[dir=rtl]{right:0;left:0}#onetrust-pc-sdk.otRelFont{font-size:1rem}#onetrust-pc-sdk .ot-optout-signal{margin-top:.625rem}#onetrust-pc-sdk #ot-addtl-venlst .ot-arw-cntr,#onetrust-pc-sdk #ot-addtl-venlst .ot-plus-minus,#onetrust-pc-sdk .ot-hide-tgl{visibility:hidden}#onetrust-pc-sdk #ot-addtl-venlst .ot-arw-cntr *,#onetrust-pc-sdk #ot-addtl-venlst .ot-plus-minus *,#onetrust-pc-sdk .ot-hide-tgl *{visibility:hidden}#onetrust-pc-sdk #ot-gn-venlst .ot-ven-item .ot-acc-hdr{min-height:40px}#onetrust-pc-sdk .ot-pc-header{height:39px;padding:10px 0 10px 30px;border-bottom:1px solid #e9e9e9}#onetrust-pc-sdk #ot-pc-title,#onetrust-pc-sdk #ot-category-title,#onetrust-pc-sdk .ot-cat-header,#onetrust-pc-sdk #ot-lst-title,#onetrust-pc-sdk .ot-ven-hdr .ot-ven-name,#onetrust-pc-sdk .ot-always-active{font-weight:bold;color:dimgray}#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:55%;font-weight:700}#onetrust-pc-sdk .ot-cat-item p{clear:both;float:left;margin-top:10px;margin-bottom:5px;line-height:1.5;font-size:.812em;color:dimgray}#onetrust-pc-sdk .ot-close-icon{height:44px;width:44px;background-size:10px}#onetrust-pc-sdk #ot-pc-title{float:left;font-size:1em;line-height:1.5;margin-bottom:10px;margin-top:10px;width:100%}#onetrust-pc-sdk #accept-recommended-btn-handler{margin-right:10px;margin-bottom:25px;outline-offset:-1px}#onetrust-pc-sdk #ot-pc-desc{clear:both;width:100%;font-size:.812em;line-height:1.5;margin-bottom:25px}#onetrust-pc-sdk #ot-pc-desc a{margin-left:5px}#onetrust-pc-sdk #ot-pc-desc *{font-size:inherit;line-height:inherit}#onetrust-pc-sdk #ot-pc-desc ul li{padding:10px 0px}#onetrust-pc-sdk a{color:#656565;cursor:pointer}#onetrust-pc-sdk a:hover{color:#3860be}#onetrust-pc-sdk label{margin-bottom:0}#onetrust-pc-sdk #vdr-lst-dsc{font-size:.812em;line-height:1.5;padding:10px 15px 5px 15px}#onetrust-pc-sdk button{max-width:394px;padding:12px 30px;line-height:1;word-break:break-word;word-wrap:break-word;white-space:normal;font-weight:bold;height:auto}#onetrust-pc-sdk .ot-link-btn{padding:0;margin-bottom:0;border:0;font-weight:normal;line-height:normal;width:auto;height:auto}#onetrust-pc-sdk #ot-pc-content{position:absolute;overflow-y:scroll;padding-left:0px;padding-right:30px;top:60px;bottom:110px;margin:1px 3px 0 30px;width:calc(100% - 63px)}#onetrust-pc-sdk .ot-vs-list .ot-always-active,#onetrust-pc-sdk .ot-cat-grp .ot-always-active{float:right;clear:none;color:#3860be;margin:0;font-size:.813em;line-height:1.3}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar-track{margin-right:20px}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar{width:11px}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar-thumb{border-radius:10px;background:#d8d8d8}#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:#000 1px solid}#onetrust-pc-sdk .ot-pc-scrollbar{scrollbar-arrow-color:#d8d8d8;scrollbar-darkshadow-color:#d8d8d8;scrollbar-face-color:#d8d8d8;scrollbar-shadow-color:#d8d8d8}#onetrust-pc-sdk .save-preference-btn-handler{margin-right:20px}#onetrust-pc-sdk .ot-pc-refuse-all-handler{margin-right:10px}#onetrust-pc-sdk #ot-pc-desc .privacy-notice-link{margin-left:0;margin-right:8px}#onetrust-pc-sdk #ot-pc-desc .ot-imprint-handler{margin-left:0;margin-right:8px}#onetrust-pc-sdk .ot-subgrp-cntr{display:inline-block;clear:both;width:100%;padding-top:15px}#onetrust-pc-sdk .ot-switch+.ot-subgrp-cntr{padding-top:10px}#onetrust-pc-sdk ul.ot-subgrps{margin:0;font-size:initial}#onetrust-pc-sdk ul.ot-subgrps li p,#onetrust-pc-sdk ul.ot-subgrps li h5{font-size:.813em;line-height:1.4;color:dimgray}#onetrust-pc-sdk ul.ot-subgrps .ot-switch{min-height:auto}#onetrust-pc-sdk ul.ot-subgrps .ot-switch-nob{top:0}#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr{display:inline-block;width:100%}#onetrust-pc-sdk ul.ot-subgrps .ot-acc-txt{margin:0}#onetrust-pc-sdk ul.ot-subgrps li{padding:0;border:none}#onetrust-pc-sdk ul.ot-subgrps li h5{position:relative;top:5px;font-weight:bold;margin-bottom:0;float:left}#onetrust-pc-sdk li.ot-subgrp{margin-left:20px;overflow:auto}#onetrust-pc-sdk li.ot-subgrp>h5{width:calc(100% - 100px)}#onetrust-pc-sdk .ot-cat-item p>ul,#onetrust-pc-sdk li.ot-subgrp p>ul{margin:0px;list-style:disc;margin-left:15px;font-size:inherit}#onetrust-pc-sdk .ot-cat-item p>ul li,#onetrust-pc-sdk li.ot-subgrp p>ul li{font-size:inherit;padding-top:10px;padding-left:0px;padding-right:0px;border:none}#onetrust-pc-sdk .ot-cat-item p>ul li:last-child,#onetrust-pc-sdk li.ot-subgrp p>ul li:last-child{padding-bottom:10px}#onetrust-pc-sdk .ot-pc-logo{height:40px;width:120px}#onetrust-pc-sdk .ot-pc-footer{position:absolute;bottom:0px;width:100%;max-height:160px;border-top:1px solid #d8d8d8}#onetrust-pc-sdk.ot-ftr-stacked .ot-pc-refuse-all-handler{margin-bottom:0px}#onetrust-pc-sdk.ot-ftr-stacked #ot-pc-content{bottom:160px}#onetrust-pc-sdk.ot-ftr-stacked .ot-pc-footer button{width:100%;max-width:none}#onetrust-pc-sdk.ot-ftr-stacked .ot-btn-container{margin:0 30px;width:calc(100% - 60px);padding-right:0}#onetrust-pc-sdk .ot-pc-footer-logo{height:30px;width:100%;text-align:right;background:#f4f4f4}#onetrust-pc-sdk .ot-pc-footer-logo a{display:inline-block;margin-top:5px;margin-right:10px}#onetrust-pc-sdk[dir=rtl] .ot-pc-footer-logo{direction:rtl}#onetrust-pc-sdk[dir=rtl] .ot-pc-footer-logo a{margin-right:25px}#onetrust-pc-sdk .ot-tgl{float:right;position:relative;z-index:1}#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background-color:#468254;border:1px solid #fff}#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{-webkit-transform:translateX(20px);-ms-transform:translateX(20px);transform:translateX(20px);background-color:#fff;border-color:#fff}#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch{outline:#000 solid 1px}#onetrust-pc-sdk .ot-switch{position:relative;display:inline-block;width:45px;height:25px}#onetrust-pc-sdk .ot-switch-nob{position:absolute;cursor:pointer;top:0;left:0;right:0;bottom:0;background-color:#767676;border:1px solid #ddd;transition:all .2s ease-in 0s;-moz-transition:all .2s ease-in 0s;-o-transition:all .2s ease-in 0s;-webkit-transition:all .2s ease-in 0s;border-radius:20px}#onetrust-pc-sdk .ot-switch-nob:before{position:absolute;content:"";height:18px;width:18px;bottom:3px;left:3px;background-color:#fff;-webkit-transition:.4s;transition:.4s;border-radius:20px}#onetrust-pc-sdk .ot-chkbox input:checked~label::before{background-color:#3860be}#onetrust-pc-sdk .ot-chkbox input+label::after{content:none;color:#fff}#onetrust-pc-sdk .ot-chkbox input:checked+label::after{content:""}#onetrust-pc-sdk .ot-chkbox input:focus+label::before{outline-style:solid;outline-width:2px;outline-style:auto}#onetrust-pc-sdk .ot-chkbox label{position:relative;display:inline-block;padding-left:30px;cursor:pointer;font-weight:500}#onetrust-pc-sdk .ot-chkbox label::before,#onetrust-pc-sdk .ot-chkbox label::after{position:absolute;content:"";display:inline-block;border-radius:3px}#onetrust-pc-sdk .ot-chkbox label::before{height:18px;width:18px;border:1px solid #3860be;left:0px;top:auto}#onetrust-pc-sdk .ot-chkbox label::after{height:5px;width:9px;border-left:3px solid;border-bottom:3px solid;transform:rotate(-45deg);-o-transform:rotate(-45deg);-ms-transform:rotate(-45deg);-webkit-transform:rotate(-45deg);left:4px;top:5px}#onetrust-pc-sdk .ot-label-txt{display:none}#onetrust-pc-sdk .ot-chkbox input,#onetrust-pc-sdk .ot-tgl input{position:absolute;opacity:0;width:0;height:0}#onetrust-pc-sdk .ot-arw-cntr{float:right;position:relative;pointer-events:none}#onetrust-pc-sdk .ot-arw-cntr .ot-arw{width:16px;height:16px;margin-left:5px;color:dimgray;display:inline-block;vertical-align:middle;-webkit-transition:all 150ms ease-in 0s;-moz-transition:all 150ms ease-in 0s;-o-transition:all 150ms ease-in 0s;transition:all 150ms ease-in 0s}#onetrust-pc-sdk input:checked~.ot-acc-hdr .ot-arw,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-arw-cntr svg{transform:rotate(90deg);-o-transform:rotate(90deg);-ms-transform:rotate(90deg);-webkit-transform:rotate(90deg)}#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:#000 1px solid}#onetrust-pc-sdk .ot-tgl-cntr,#onetrust-pc-sdk .ot-arw-cntr{display:inline-block}#onetrust-pc-sdk .ot-tgl-cntr{width:45px;float:right;margin-top:2px}#onetrust-pc-sdk #ot-lst-cnt .ot-tgl-cntr{margin-top:10px}#onetrust-pc-sdk .ot-always-active-subgroup{width:auto;padding-left:0px !important;top:3px;position:relative}#onetrust-pc-sdk .ot-label-status{padding-left:5px;font-size:.75em;display:none}#onetrust-pc-sdk .ot-arw-cntr{margin-top:-1px}#onetrust-pc-sdk .ot-arw-cntr svg{-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s;transition:all 300ms ease-in 0s;height:10px;width:10px}#onetrust-pc-sdk input:checked~.ot-acc-hdr .ot-arw{transform:rotate(90deg);-o-transform:rotate(90deg);-ms-transform:rotate(90deg);-webkit-transform:rotate(90deg)}#onetrust-pc-sdk .ot-arw{width:10px;margin-left:15px;transition:all 300ms ease-in 0s;-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s}#onetrust-pc-sdk .ot-vlst-cntr{margin-bottom:0}#onetrust-pc-sdk .ot-hlst-cntr{margin-top:5px;display:inline-block;width:100%}#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a,#onetrust-pc-sdk .category-host-list-handler{clear:both;color:#3860be;margin-left:0;font-size:.813em;text-decoration:none;float:left;overflow:hidden}#onetrust-pc-sdk .category-vendors-list-handler:hover,#onetrust-pc-sdk .category-vendors-list-handler+a:hover,#onetrust-pc-sdk .category-host-list-handler:hover{text-decoration-line:underline}#onetrust-pc-sdk .category-vendors-list-handler+a{clear:none}#onetrust-pc-sdk .ot-vlst-cntr .ot-ext-lnk,#onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{display:inline-block;height:13px;width:13px;background-repeat:no-repeat;margin-left:1px;margin-top:6px;cursor:pointer}#onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{margin-bottom:-1px}#onetrust-pc-sdk .back-btn-handler{font-size:1em;text-decoration:none}#onetrust-pc-sdk .back-btn-handler:hover{opacity:.6}#onetrust-pc-sdk #ot-lst-title h3{display:inline-block;word-break:break-word;word-wrap:break-word;margin-bottom:0;color:#656565;font-size:1em;font-weight:bold;margin-left:15px}#onetrust-pc-sdk #ot-lst-title{margin:10px 0 10px 0px;font-size:1em;text-align:left}#onetrust-pc-sdk #ot-pc-hdr{margin:0 0 0 30px;height:auto;width:auto}#onetrust-pc-sdk #ot-pc-hdr input::placeholder{color:#d4d4d4;font-style:italic}#onetrust-pc-sdk #vendor-search-handler{height:31px;width:100%;border-radius:50px;font-size:.8em;padding-right:35px;padding-left:15px;float:left;margin-left:15px}#onetrust-pc-sdk .ot-ven-name{display:block;width:auto;padding-right:5px}#onetrust-pc-sdk #ot-lst-cnt{overflow-y:auto;margin-left:20px;margin-right:7px;width:calc(100% - 27px);max-height:calc(100% - 80px);height:100%;transform:translate3d(0, 0, 0)}#onetrust-pc-sdk #ot-pc-lst{width:100%;bottom:100px;position:absolute;top:60px}#onetrust-pc-sdk #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr .ot-arw-cntr,#onetrust-pc-sdk #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr .ot-arw-cntr *{visibility:hidden}#onetrust-pc-sdk #ot-pc-lst .ot-tgl-cntr{right:12px;position:absolute}#onetrust-pc-sdk #ot-pc-lst .ot-arw-cntr{float:right;position:relative}#onetrust-pc-sdk #ot-pc-lst .ot-arw{margin-left:10px}#onetrust-pc-sdk #ot-pc-lst .ot-acc-hdr{overflow:hidden;cursor:pointer}#onetrust-pc-sdk .ot-vlst-cntr{overflow:hidden}#onetrust-pc-sdk #ot-sel-blk{overflow:hidden;width:100%;position:sticky;position:-webkit-sticky;top:0;z-index:3}#onetrust-pc-sdk #ot-back-arw{height:12px;width:12px}#onetrust-pc-sdk .ot-lst-subhdr{width:100%;display:inline-block}#onetrust-pc-sdk .ot-search-cntr{float:left;width:78%;position:relative}#onetrust-pc-sdk .ot-search-cntr>svg{width:30px;height:30px;position:absolute;float:left;right:-15px}#onetrust-pc-sdk .ot-fltr-cntr{float:right;right:50px;position:relative}#onetrust-pc-sdk #filter-btn-handler{background-color:#3860be;border-radius:17px;display:inline-block;position:relative;width:32px;height:32px;-moz-transition:.1s ease;-o-transition:.1s ease;-webkit-transition:1s ease;transition:.1s ease;padding:0;margin:0}#onetrust-pc-sdk #filter-btn-handler:hover{background-color:#3860be}#onetrust-pc-sdk #filter-btn-handler svg{width:12px;height:12px;margin:3px 10px 0 10px;display:block;position:static;right:auto;top:auto}#onetrust-pc-sdk .ot-ven-link,#onetrust-pc-sdk .ot-ven-legclaim-link{color:#3860be;text-decoration:none;font-weight:100;display:inline-block;padding-top:10px;transform:translate(0, 1%);-o-transform:translate(0, 1%);-ms-transform:translate(0, 1%);-webkit-transform:translate(0, 1%);position:relative;z-index:2}#onetrust-pc-sdk .ot-ven-link *,#onetrust-pc-sdk .ot-ven-legclaim-link *{font-size:inherit}#onetrust-pc-sdk .ot-ven-link:hover,#onetrust-pc-sdk .ot-ven-legclaim-link:hover{text-decoration:underline}#onetrust-pc-sdk .ot-ven-hdr{width:calc(100% - 160px);height:auto;float:left;word-break:break-word;word-wrap:break-word;vertical-align:middle;padding-bottom:3px}#onetrust-pc-sdk .ot-ven-link,#onetrust-pc-sdk .ot-ven-legclaim-link{letter-spacing:.03em;font-size:.75em;font-weight:400}#onetrust-pc-sdk .ot-ven-dets{border-radius:2px;background-color:#f8f8f8}#onetrust-pc-sdk .ot-ven-dets li:first-child p:first-child{border-top:none}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:not(:first-child){border-top:1px solid #ddd !important}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p{display:inline-block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p:nth-of-type(odd){width:30%}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p:nth-of-type(even){width:50%;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p,#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc h4{padding-top:5px;padding-bottom:5px;display:block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc h4{display:inline-block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p:nth-last-child(-n+1){padding-bottom:10px}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p:nth-child(-n+2):not(.disc-pur){padding-top:10px}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur-cont{display:inline}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur{position:relative;width:50% !important;word-break:break-word;word-wrap:break-word;left:calc(30% + 17px)}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur:nth-child(-n+1){position:static}#onetrust-pc-sdk .ot-ven-dets p,#onetrust-pc-sdk .ot-ven-dets h4,#onetrust-pc-sdk .ot-ven-dets span{font-size:.69em;text-align:left;vertical-align:middle;word-break:break-word;word-wrap:break-word;margin:0;padding-bottom:10px;padding-left:15px;color:#2e3644}#onetrust-pc-sdk .ot-ven-dets h4{padding-top:5px}#onetrust-pc-sdk .ot-ven-dets span{color:dimgray;padding:0;vertical-align:baseline}#onetrust-pc-sdk .ot-ven-dets .ot-ven-pur h4{border-top:1px solid #e9e9e9;border-bottom:1px solid #e9e9e9;padding-bottom:5px;margin-bottom:5px;font-weight:bold}#onetrust-pc-sdk #ot-host-lst .ot-sel-all{float:right;position:relative;margin-right:42px;top:10px}#onetrust-pc-sdk #ot-host-lst .ot-sel-all input[type=checkbox]{width:auto;height:auto}#onetrust-pc-sdk #ot-host-lst .ot-sel-all label{height:20px;width:20px;padding-left:0px}#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{overflow:hidden;width:95%}#onetrust-pc-sdk .ot-host-hdr{position:relative;z-index:1;pointer-events:none;width:calc(100% - 125px);float:left}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-desc{display:inline-block;width:90%}#onetrust-pc-sdk .ot-host-name{pointer-events:none}#onetrust-pc-sdk .ot-host-hdr>a{text-decoration:underline;font-size:.82em;position:relative;z-index:2;float:left;margin-bottom:5px;pointer-events:initial}#onetrust-pc-sdk .ot-host-name+a{margin-top:5px}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-name a,#onetrust-pc-sdk .ot-host-desc,#onetrust-pc-sdk .ot-host-info{color:dimgray;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-name a{font-weight:bold;font-size:.82em;line-height:1.3}#onetrust-pc-sdk .ot-host-name a{font-size:1em}#onetrust-pc-sdk .ot-host-expand{margin-top:3px;margin-bottom:3px;clear:both;display:block;color:#3860be;font-size:.72em;font-weight:normal}#onetrust-pc-sdk .ot-host-expand *{font-size:inherit}#onetrust-pc-sdk .ot-host-desc,#onetrust-pc-sdk .ot-host-info{font-size:.688em;line-height:1.4;font-weight:normal}#onetrust-pc-sdk .ot-host-desc{margin-top:10px}#onetrust-pc-sdk .ot-host-opt{margin:0;font-size:inherit;display:inline-block;width:100%}#onetrust-pc-sdk .ot-host-opt li>div div{font-size:.8em;padding:5px 0}#onetrust-pc-sdk .ot-host-opt li>div div:nth-child(1){width:30%;float:left}#onetrust-pc-sdk .ot-host-opt li>div div:nth-child(2){width:70%;float:left;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-host-info{border:none;display:inline-block;width:calc(100% - 10px);padding:10px;margin-bottom:10px;background-color:#f8f8f8}#onetrust-pc-sdk .ot-host-info>div{overflow:auto}#onetrust-pc-sdk #no-results{text-align:center;margin-top:30px}#onetrust-pc-sdk #no-results p{font-size:1em;color:#2e3644;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk #no-results p span{font-weight:bold}#onetrust-pc-sdk #ot-fltr-modal{width:100%;height:auto;display:none;-moz-transition:.2s ease;-o-transition:.2s ease;-webkit-transition:2s ease;transition:.2s ease;overflow:hidden;opacity:1;right:0}#onetrust-pc-sdk #ot-fltr-modal .ot-label-txt{display:inline-block;font-size:.85em;color:dimgray}#onetrust-pc-sdk #ot-fltr-cnt{z-index:2147483646;background-color:#fff;position:absolute;height:90%;max-height:300px;width:325px;left:210px;margin-top:10px;margin-bottom:20px;padding-right:10px;border-radius:3px;-webkit-box-shadow:0px 0px 12px 2px #c7c5c7;-moz-box-shadow:0px 0px 12px 2px #c7c5c7;box-shadow:0px 0px 12px 2px #c7c5c7}#onetrust-pc-sdk .ot-fltr-scrlcnt{overflow-y:auto;overflow-x:hidden;clear:both;max-height:calc(100% - 60px)}#onetrust-pc-sdk #ot-anchor{border:12px solid rgba(0,0,0,0);display:none;position:absolute;z-index:2147483647;right:55px;top:75px;transform:rotate(45deg);-o-transform:rotate(45deg);-ms-transform:rotate(45deg);-webkit-transform:rotate(45deg);background-color:#fff;-webkit-box-shadow:-3px -3px 5px -2px #c7c5c7;-moz-box-shadow:-3px -3px 5px -2px #c7c5c7;box-shadow:-3px -3px 5px -2px #c7c5c7}#onetrust-pc-sdk .ot-fltr-btns{margin-left:15px}#onetrust-pc-sdk #filter-apply-handler{margin-right:15px}#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:25px;margin-left:15px;width:75%;position:relative}#onetrust-pc-sdk .ot-fltr-opt p{display:inline-block;margin:0;font-size:.9em;color:#2e3644}#onetrust-pc-sdk .ot-chkbox label span{font-size:.85em;color:dimgray}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]+label::after{content:none;color:#fff}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]:checked+label::after{content:""}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]:focus+label::before{outline-style:solid;outline-width:2px;outline-style:auto}#onetrust-pc-sdk #ot-selall-vencntr,#onetrust-pc-sdk #ot-selall-adtlvencntr,#onetrust-pc-sdk #ot-selall-hostcntr,#onetrust-pc-sdk #ot-selall-licntr,#onetrust-pc-sdk #ot-selall-gnvencntr{right:15px;position:relative;width:20px;height:20px;float:right}#onetrust-pc-sdk #ot-selall-vencntr label,#onetrust-pc-sdk #ot-selall-adtlvencntr label,#onetrust-pc-sdk #ot-selall-hostcntr label,#onetrust-pc-sdk #ot-selall-licntr label,#onetrust-pc-sdk #ot-selall-gnvencntr label{float:left;padding-left:0}#onetrust-pc-sdk #ot-ven-lst:first-child{border-top:1px solid #e2e2e2}#onetrust-pc-sdk ul{list-style:none;padding:0}#onetrust-pc-sdk ul li{position:relative;margin:0;padding:15px 15px 15px 10px;border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk ul li h3{font-size:.75em;color:#656565;margin:0;display:inline-block;width:70%;height:auto;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk ul li p{margin:0;font-size:.7em}#onetrust-pc-sdk ul li input[type=checkbox]{position:absolute;cursor:pointer;width:100%;height:100%;opacity:0;margin:0;top:0;left:0}#onetrust-pc-sdk .ot-cat-item>button:focus,#onetrust-pc-sdk .ot-acc-cntr>button:focus,#onetrust-pc-sdk li>button:focus{outline:#000 solid 2px}#onetrust-pc-sdk .ot-cat-item>button,#onetrust-pc-sdk .ot-acc-cntr>button,#onetrust-pc-sdk li>button{position:absolute;cursor:pointer;width:100%;height:100%;margin:0;top:0;left:0;z-index:1;max-width:none;border:none}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=false]~.ot-acc-txt,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=false]~.ot-acc-txt,#onetrust-pc-sdk li>button[aria-expanded=false]~.ot-acc-txt{margin-top:0;max-height:0;opacity:0;overflow:hidden;width:100%;transition:.25s ease-out;display:none}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=true]~.ot-acc-txt,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=true]~.ot-acc-txt,#onetrust-pc-sdk li>button[aria-expanded=true]~.ot-acc-txt{transition:.1s ease-in;margin-top:10px;width:100%;overflow:auto;display:block}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=true]~.ot-acc-grpcntr,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=true]~.ot-acc-grpcntr,#onetrust-pc-sdk li>button[aria-expanded=true]~.ot-acc-grpcntr{width:auto;margin-top:0px;padding-bottom:10px}#onetrust-pc-sdk .ot-host-item>button:focus,#onetrust-pc-sdk .ot-ven-item>button:focus{outline:0;border:2px solid #000}#onetrust-pc-sdk .ot-hide-acc>button{pointer-events:none}#onetrust-pc-sdk .ot-hide-acc .ot-plus-minus>*,#onetrust-pc-sdk .ot-hide-acc .ot-arw-cntr>*{visibility:hidden}#onetrust-pc-sdk .ot-hide-acc .ot-acc-hdr{min-height:30px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt){padding-right:10px;width:calc(100% - 37px);margin-top:10px;max-height:calc(100% - 90px)}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk{background-color:#f9f9fc;border:1px solid #e2e2e2;width:calc(100% - 2px);padding-bottom:5px;padding-top:5px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt{border:unset;background-color:unset}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all-hdr{display:none}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all{padding-right:.5rem}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all .ot-chkbox{right:0}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-sel-all{padding-right:34px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-sel-all-chkbox{width:auto}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) ul li{border:1px solid #e2e2e2;margin-bottom:10px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-acc-cntr>.ot-acc-hdr{padding:10px 0 10px 15px}#onetrust-pc-sdk.ot-addtl-vendors .ot-sel-all-chkbox{float:right}#onetrust-pc-sdk.ot-addtl-vendors .ot-plus-minus~.ot-sel-all-chkbox{right:34px}#onetrust-pc-sdk.ot-addtl-vendors #ot-ven-lst:first-child{border-top:none}#onetrust-pc-sdk .ot-acc-cntr{position:relative;border-left:1px solid #e2e2e2;border-right:1px solid #e2e2e2;border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk .ot-acc-cntr input{z-index:1}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr{background-color:#f9f9fc;padding:5px 0 5px 15px;width:auto}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr .ot-plus-minus{vertical-align:middle;top:auto}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr .ot-arw-cntr{right:10px}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr input{z-index:2}#onetrust-pc-sdk .ot-acc-cntr.ot-add-tech .ot-acc-hdr{padding:10px 0 10px 15px}#onetrust-pc-sdk .ot-acc-cntr>input[type=checkbox]:checked~.ot-acc-hdr{border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-txt{padding-left:10px;padding-right:10px}#onetrust-pc-sdk .ot-acc-cntr button[aria-expanded=true]~.ot-acc-txt{width:auto}#onetrust-pc-sdk .ot-acc-cntr .ot-addtl-venbox{display:none}#onetrust-pc-sdk .ot-vlst-cntr{margin-bottom:0;width:100%}#onetrust-pc-sdk .ot-vensec-title{font-size:.813em;vertical-align:middle;display:inline-block}#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a{margin-left:0;margin-top:10px}#onetrust-pc-sdk #ot-selall-vencntr.line-through label::after,#onetrust-pc-sdk #ot-selall-adtlvencntr.line-through label::after,#onetrust-pc-sdk #ot-selall-licntr.line-through label::after,#onetrust-pc-sdk #ot-selall-hostcntr.line-through label::after,#onetrust-pc-sdk #ot-selall-gnvencntr.line-through label::after{height:auto;border-left:0;transform:none;-o-transform:none;-ms-transform:none;-webkit-transform:none;left:5px;top:9px}#onetrust-pc-sdk #ot-category-title{float:left;padding-bottom:10px;font-size:1em;width:100%}#onetrust-pc-sdk .ot-cat-grp{margin-top:10px}#onetrust-pc-sdk .ot-cat-item{line-height:1.1;margin-top:10px;display:inline-block;width:100%}#onetrust-pc-sdk .ot-btn-container{text-align:right}#onetrust-pc-sdk .ot-btn-container button{display:inline-block;font-size:.75em;letter-spacing:.08em;margin-top:19px}#onetrust-pc-sdk #close-pc-btn-handler.ot-close-icon{position:absolute;top:10px;right:0;z-index:1;padding:0;background-color:rgba(0,0,0,0);border:none}#onetrust-pc-sdk #close-pc-btn-handler.ot-close-icon svg{display:block;height:10px;width:10px}#onetrust-pc-sdk #clear-filters-handler{margin-top:20px;margin-bottom:10px;float:right;max-width:200px;text-decoration:none;color:#3860be;font-size:.9em;font-weight:bold;background-color:rgba(0,0,0,0);border-color:rgba(0,0,0,0);padding:1px}#onetrust-pc-sdk #clear-filters-handler:hover{color:#2285f7}#onetrust-pc-sdk #clear-filters-handler:focus{outline:#000 solid 1px}#onetrust-pc-sdk .ot-enbl-chr h4~.ot-tgl,#onetrust-pc-sdk .ot-enbl-chr h4~.ot-always-active{right:45px}#onetrust-pc-sdk .ot-enbl-chr h4~.ot-tgl+.ot-tgl{right:120px}#onetrust-pc-sdk .ot-enbl-chr .ot-pli-hdr.ot-leg-border-color span:first-child{width:90px}#onetrust-pc-sdk .ot-enbl-chr li.ot-subgrp>h5+.ot-tgl-cntr{padding-right:25px}#onetrust-pc-sdk .ot-plus-minus{width:20px;height:20px;font-size:1.5em;position:relative;display:inline-block;margin-right:5px;top:3px}#onetrust-pc-sdk .ot-plus-minus span{position:absolute;background:#27455c;border-radius:1px}#onetrust-pc-sdk .ot-plus-minus span:first-of-type{top:25%;bottom:25%;width:10%;left:45%}#onetrust-pc-sdk .ot-plus-minus span:last-of-type{left:25%;right:25%;height:10%;top:45%}#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-arw,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:first-of-type,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:last-of-type{transform:rotate(90deg)}#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:last-of-type{left:50%;right:50%}#onetrust-pc-sdk #ot-selall-vencntr label,#onetrust-pc-sdk #ot-selall-adtlvencntr label,#onetrust-pc-sdk #ot-selall-hostcntr label,#onetrust-pc-sdk #ot-selall-licntr label{position:relative;display:inline-block;width:20px;height:20px}#onetrust-pc-sdk .ot-host-item .ot-plus-minus,#onetrust-pc-sdk .ot-ven-item .ot-plus-minus{float:left;margin-right:8px;top:10px}#onetrust-pc-sdk .ot-ven-item ul{list-style:none inside;font-size:100%;margin:0}#onetrust-pc-sdk .ot-ven-item ul li{margin:0 !important;padding:0;border:none !important}#onetrust-pc-sdk .ot-pli-hdr{color:#77808e;overflow:hidden;padding-top:7.5px;padding-bottom:7.5px;width:calc(100% - 2px);border-top-left-radius:3px;border-top-right-radius:3px}#onetrust-pc-sdk .ot-pli-hdr span:first-child{top:50%;transform:translateY(50%);max-width:90px}#onetrust-pc-sdk .ot-pli-hdr span:last-child{padding-right:10px;max-width:95px;text-align:center}#onetrust-pc-sdk .ot-li-title{float:right;font-size:.813em}#onetrust-pc-sdk .ot-pli-hdr.ot-leg-border-color{background-color:#f4f4f4;border:1px solid #d8d8d8}#onetrust-pc-sdk .ot-pli-hdr.ot-leg-border-color span:first-child{text-align:left;width:70px}#onetrust-pc-sdk li.ot-subgrp>h5,#onetrust-pc-sdk .ot-cat-header{width:calc(100% - 130px)}#onetrust-pc-sdk li.ot-subgrp>h5+.ot-tgl-cntr{padding-left:13px}#onetrust-pc-sdk .ot-acc-grpcntr .ot-acc-grpdesc{margin-bottom:5px}#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border-top:1px solid #d8d8d8}#onetrust-pc-sdk .ot-acc-grpcntr .ot-vlst-cntr+.ot-subgrp-cntr{border-top:none}#onetrust-pc-sdk .ot-acc-hdr .ot-arw-cntr+.ot-tgl-cntr,#onetrust-pc-sdk .ot-acc-txt h4+.ot-tgl-cntr{padding-left:13px}#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-subgrp>h5,#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-cat-header{width:calc(100% - 145px)}#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item h5+.ot-tgl-cntr,#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-cat-header+.ot-tgl{padding-left:28px}#onetrust-pc-sdk .ot-sel-all-hdr,#onetrust-pc-sdk .ot-sel-all-chkbox{display:inline-block;width:100%;position:relative}#onetrust-pc-sdk .ot-sel-all-chkbox{z-index:1}#onetrust-pc-sdk .ot-sel-all{margin:0;position:relative;padding-right:23px;float:right}#onetrust-pc-sdk .ot-consent-hdr,#onetrust-pc-sdk .ot-li-hdr{float:right;font-size:.812em;line-height:normal;text-align:center;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-li-hdr{max-width:100px;padding-right:10px}#onetrust-pc-sdk .ot-consent-hdr{max-width:55px}#onetrust-pc-sdk #ot-selall-licntr{display:block;width:21px;height:auto;float:right;position:relative;right:80px}#onetrust-pc-sdk #ot-selall-licntr label{position:absolute}#onetrust-pc-sdk .ot-ven-ctgl{margin-left:66px}#onetrust-pc-sdk .ot-ven-litgl+.ot-arw-cntr{margin-left:81px}#onetrust-pc-sdk .ot-enbl-chr .ot-host-cnt .ot-tgl-cntr{width:auto}#onetrust-pc-sdk #ot-lst-cnt:not(.ot-host-cnt) .ot-tgl-cntr{width:auto;top:auto;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-chkbox{position:relative;display:inline-block;width:20px;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-chkbox label{position:absolute;padding:0;width:20px;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 2rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk .ot-acc-grpdesc+.ot-leg-btn-container{padding-left:20px;padding-right:20px;width:calc(100% - 40px);margin-bottom:5px}#onetrust-pc-sdk .ot-subgrp .ot-leg-btn-container{margin-bottom:5px}#onetrust-pc-sdk #ot-ven-lst .ot-leg-btn-container{margin-top:10px}#onetrust-pc-sdk .ot-leg-btn-container{display:inline-block;width:100%;margin-bottom:10px}#onetrust-pc-sdk .ot-leg-btn-container button{height:auto;padding:6.5px 8px;margin-bottom:0;letter-spacing:0;font-size:.75em;line-height:normal}#onetrust-pc-sdk .ot-leg-btn-container svg{display:none;height:14px;width:14px;padding-right:5px;vertical-align:sub}#onetrust-pc-sdk .ot-active-leg-btn{cursor:default;pointer-events:none}#onetrust-pc-sdk .ot-active-leg-btn svg{display:inline-block}#onetrust-pc-sdk .ot-remove-objection-handler{text-decoration:underline;padding:0;font-size:.75em;font-weight:600;line-height:1;padding-left:10px}#onetrust-pc-sdk .ot-obj-leg-btn-handler span{font-weight:bold;text-align:center;font-size:inherit;line-height:1.5}#onetrust-pc-sdk.ot-close-btn-link #close-pc-btn-handler{border:none;height:auto;line-height:1.5;text-decoration:underline;font-size:.69em;background:none;right:15px;top:15px;width:auto;font-weight:normal}#onetrust-pc-sdk .ot-pgph-link{font-size:.813em !important;margin-top:5px;position:relative}#onetrust-pc-sdk .ot-pgph-link.ot-pgph-link-subgroup{margin-bottom:1rem}#onetrust-pc-sdk .ot-pgph-contr{margin:0 2.5rem}#onetrust-pc-sdk .ot-pgph-title{font-size:1.18rem;margin-bottom:2rem}#onetrust-pc-sdk .ot-pgph-desc{font-size:1rem;font-weight:400;margin-bottom:2rem;line-height:1.5rem}#onetrust-pc-sdk .ot-pgph-desc:not(:last-child):after{content:"";width:96%;display:block;margin:0 auto;padding-bottom:2rem;border-bottom:1px solid #e9e9e9}#onetrust-pc-sdk .ot-cat-header{float:left;font-weight:600;font-size:.875em;line-height:1.5;max-width:90%;vertical-align:middle}#onetrust-pc-sdk .ot-vnd-item>button:focus{outline:#000 solid 2px}#onetrust-pc-sdk .ot-vnd-item>button{position:absolute;cursor:pointer;width:100%;height:100%;margin:0;top:0;left:0;z-index:1;max-width:none;border:none}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=false]~.ot-acc-txt{margin-top:0;max-height:0;opacity:0;overflow:hidden;width:100%;transition:.25s ease-out;display:none}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=true]~.ot-acc-txt{transition:.1s ease-in;margin-top:10px;width:100%;overflow:auto;display:block}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=true]~.ot-acc-grpcntr{width:auto;margin-top:0px;padding-bottom:10px}#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{position:relative;border-radius:2px;margin:0;padding:0;border:1px solid #d8d8d8;border-top:none;width:calc(100% - 2px);float:left}#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{margin-top:10px;border-top:1px solid #d8d8d8}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc{padding-left:20px;padding-right:20px;width:calc(100% - 40px);font-size:.812em;margin-bottom:10px;margin-top:15px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc>ul{padding-top:10px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc>ul li{padding-top:0;line-height:1.5;padding-bottom:10px}#onetrust-pc-sdk .ot-accordion-layout div+.ot-acc-grpdesc{margin-top:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr:first-child{margin-top:10px}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr:last-child,#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr:last-child{margin-bottom:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding-top:11.5px;padding-bottom:11.5px;padding-left:20px;padding-right:20px;width:calc(100% - 40px);display:inline-block}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-txt{width:100%;padding:0}#onetrust-pc-sdk .ot-accordion-layout .ot-subgrp-cntr{padding-left:20px;padding-right:15px;padding-bottom:0;width:calc(100% - 35px)}#onetrust-pc-sdk .ot-accordion-layout .ot-subgrp{padding-right:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpcntr{z-index:1;position:relative}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header+.ot-arw-cntr{position:absolute;top:50%;transform:translateY(-50%);right:20px;margin-top:-2px}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header+.ot-arw-cntr .ot-arw{width:15px;height:20px;margin-left:5px;color:dimgray}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{float:none;color:#2e3644;margin:0;display:inline-block;height:auto;word-wrap:break-word;min-height:inherit}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr,#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding-left:20px;width:calc(100% - 20px);display:inline-block;margin-top:0;padding-bottom:2px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{position:relative;min-height:25px}#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl,#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{position:absolute;top:50%;transform:translateY(-50%);right:20px}#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl+.ot-tgl{right:95px}#onetrust-pc-sdk .ot-accordion-layout .category-vendors-list-handler,#onetrust-pc-sdk .ot-accordion-layout .category-vendors-list-handler+a{margin-top:5px}#onetrust-pc-sdk #ot-lst-cnt{margin-top:1rem;max-height:calc(100% - 96px)}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 2rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info{margin-bottom:1rem;padding-left:.75rem;padding-right:.75rem;display:flex;flex-direction:column}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info[data-vnd-info-key*=DPOEmail]{border-top:1px solid #d8d8d8;padding-top:1rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info[data-vnd-info-key*=DPOLink]{border-bottom:1px solid #d8d8d8;padding-bottom:1rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info .ot-vnd-lbl{font-weight:bold;font-size:.85em;margin-bottom:.5rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info .ot-vnd-cnt{margin-left:.5rem;font-weight:500;font-size:.85rem}#onetrust-pc-sdk .ot-vs-list,#onetrust-pc-sdk .ot-vnd-serv{width:auto;padding:1rem 1.25rem;padding-bottom:0}#onetrust-pc-sdk .ot-vs-list .ot-vnd-serv-hdr-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-serv-hdr-cntr{padding-bottom:.75rem;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-vs-list .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-weight:600;font-size:.95em;line-height:2;margin-left:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item{border:none;margin:0;padding:0}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item button,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item button{outline:none;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item button[aria-expanded=true],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item button[aria-expanded=true]{border-bottom:none}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:first-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:first-child{margin-top:.25rem;border-top:unset}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:last-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:last-child{margin-bottom:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:last-child button,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:last-child button{border-bottom:none}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 1.75rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info{margin-bottom:1rem;padding-left:.75rem;padding-right:.75rem;display:flex;flex-direction:column}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOEmail],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOEmail]{border-top:1px solid #d8d8d8;padding-top:1rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOLink],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOLink]{border-bottom:1px solid #d8d8d8;padding-bottom:1rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info .ot-vnd-lbl,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info .ot-vnd-lbl{font-weight:bold;font-size:.85em;margin-bottom:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info .ot-vnd-cnt,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info .ot-vnd-cnt{margin-left:.5rem;font-weight:500;font-size:.85rem}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt{padding-left:40px}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-size:.8em}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt .ot-cat-header,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt .ot-cat-header{font-size:.8em}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv{margin-bottom:1rem;padding:1rem .95rem}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv .ot-vnd-serv-hdr-cntr{padding-bottom:.75rem;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-weight:700;font-size:.8em;line-height:20px;margin-left:.82rem}#onetrust-pc-sdk .ot-subgrp-cntr .ot-cat-header{font-weight:700;font-size:.8em;line-height:20px}#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-vnd-serv .ot-vnd-lst-cont .ot-accordion-layout .ot-acc-hdr div.ot-chkbox{margin-left:.82rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr{padding:.7rem 0;margin:0;display:flex;width:100%;align-items:center;justify-content:space-between}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr div:first-child,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr div:first-child{margin-left:.5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr div:last-child,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr div:last-child{margin-right:.5rem;margin-left:.5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-always-active{position:relative;right:unset;top:unset;transform:unset}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-plus-minus{top:0}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-arw-cntr{float:none;top:unset;right:unset;transform:unset;margin-top:-2px;position:relative}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-cat-header{flex:1;margin:0 .5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-tgl{position:relative;transform:none;right:0;top:0;float:none}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox{position:relative;margin:0 .5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox label{padding:0}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox label::before{position:relative}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox input{position:absolute;cursor:pointer;width:100%;height:100%;opacity:0;margin:0;top:0;left:0;z-index:1}#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp .ot-acc-hdr h5.ot-cat-header,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp .ot-acc-hdr h4.ot-cat-header{margin:0}#onetrust-pc-sdk .ot-vs-config .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp h5{top:0;line-height:20px}#onetrust-pc-sdk .ot-vs-list{display:flex;flex-direction:column;padding:0;margin:.5rem 4px}#onetrust-pc-sdk .ot-vs-selc-all{display:flex;padding:0;float:unset;align-items:center;justify-content:flex-start}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf{justify-content:flex-end}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf.ot-caret-conf .ot-sel-all-chkbox{margin-right:48px}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf .ot-sel-all-chkbox{margin:0;padding:0;margin-right:14px;justify-content:flex-end}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr.ot-chkbox,#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr.ot-tgl{display:inline-block;right:unset;width:auto;height:auto;float:none}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr label{width:45px;height:25px}#onetrust-pc-sdk .ot-vs-selc-all .ot-sel-all-chkbox{margin-right:11px;margin-left:.75rem;display:flex;align-items:center}#onetrust-pc-sdk .ot-vs-selc-all .sel-all-hdr{margin:0 1.25rem;font-size:.812em;line-height:normal;text-align:center;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-vnd-list-cnt #ot-selall-vencntr.ot-chkbox{float:unset;right:0}#onetrust-pc-sdk[dir=rtl] #ot-back-arw,#onetrust-pc-sdk[dir=rtl] input~.ot-acc-hdr .ot-arw{transform:rotate(180deg);-o-transform:rotate(180deg);-ms-transform:rotate(180deg);-webkit-transform:rotate(180deg)}#onetrust-pc-sdk[dir=rtl] input:checked~.ot-acc-hdr .ot-arw{transform:rotate(270deg);-o-transform:rotate(270deg);-ms-transform:rotate(270deg);-webkit-transform:rotate(270deg)}#onetrust-pc-sdk[dir=rtl] .ot-chkbox label::after{transform:rotate(45deg);-webkit-transform:rotate(45deg);-o-transform:rotate(45deg);-ms-transform:rotate(45deg);border-left:0;border-right:3px solid}#onetrust-pc-sdk[dir=rtl] .ot-search-cntr>svg{right:0}@media only screen and (max-width: 600px){#onetrust-pc-sdk.otPcCenter{left:0;min-width:100%;height:100%;top:0;border-radius:0}#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk.ot-ftr-stacked .ot-btn-container{margin:1px 3px 0 10px;padding-right:10px;width:calc(100% - 23px)}#onetrust-pc-sdk .ot-btn-container button{max-width:none;letter-spacing:.01em}#onetrust-pc-sdk #close-pc-btn-handler{top:10px;right:17px}#onetrust-pc-sdk p{font-size:.7em}#onetrust-pc-sdk #ot-pc-hdr{margin:10px 10px 0 5px;width:calc(100% - 15px)}#onetrust-pc-sdk .vendor-search-handler{font-size:1em}#onetrust-pc-sdk #ot-back-arw{margin-left:12px}#onetrust-pc-sdk #ot-lst-cnt{margin:0;padding:0 5px 0 10px;min-width:95%}#onetrust-pc-sdk .switch+p{max-width:80%}#onetrust-pc-sdk .ot-ftr-stacked button{width:100%}#onetrust-pc-sdk #ot-fltr-cnt{max-width:320px;width:90%;border-top-right-radius:0;border-bottom-right-radius:0;margin:0;margin-left:15px;left:auto;right:40px;top:85px}#onetrust-pc-sdk .ot-fltr-opt{margin-left:25px;margin-bottom:10px}#onetrust-pc-sdk .ot-pc-refuse-all-handler{margin-bottom:0}#onetrust-pc-sdk #ot-fltr-cnt{right:40px}}@media only screen and (max-width: 476px){#onetrust-pc-sdk .ot-fltr-cntr,#onetrust-pc-sdk #ot-fltr-cnt{right:10px}#onetrust-pc-sdk #ot-anchor{right:25px}#onetrust-pc-sdk button{width:100%}#onetrust-pc-sdk:not(.ot-addtl-vendors) #ot-pc-lst:not(.ot-enbl-chr) .ot-sel-all{padding-right:9px}#onetrust-pc-sdk:not(.ot-addtl-vendors) #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr{right:0}}@media only screen and (max-width: 896px)and (max-height: 425px)and (orientation: landscape){#onetrust-pc-sdk.otPcCenter{left:0;top:0;min-width:100%;height:100%;border-radius:0}#onetrust-pc-sdk .ot-pc-header{height:auto;min-height:20px}#onetrust-pc-sdk .ot-pc-header .ot-pc-logo{max-height:30px}#onetrust-pc-sdk .ot-pc-footer{max-height:60px;overflow-y:auto}#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk #ot-pc-lst{bottom:70px}#onetrust-pc-sdk.ot-ftr-stacked #ot-pc-content{bottom:70px}#onetrust-pc-sdk #ot-anchor{left:initial;right:50px}#onetrust-pc-sdk #ot-lst-title{margin-top:12px}#onetrust-pc-sdk #ot-lst-title *{font-size:inherit}#onetrust-pc-sdk #ot-pc-hdr input{margin-right:0;padding-right:45px}#onetrust-pc-sdk .switch+p{max-width:85%}#onetrust-pc-sdk #ot-sel-blk{position:static}#onetrust-pc-sdk #ot-pc-lst{overflow:auto}#onetrust-pc-sdk #ot-lst-cnt{max-height:none;overflow:initial}#onetrust-pc-sdk #ot-lst-cnt.no-results{height:auto}#onetrust-pc-sdk input{font-size:1em !important}#onetrust-pc-sdk p{font-size:.6em}#onetrust-pc-sdk #ot-fltr-modal{width:100%;top:0}#onetrust-pc-sdk ul li p,#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a,#onetrust-pc-sdk .category-host-list-handler{font-size:.6em}#onetrust-pc-sdk.ot-shw-fltr #ot-anchor{display:none !important}#onetrust-pc-sdk.ot-shw-fltr #ot-pc-lst{height:100% !important;overflow:hidden;top:0px}#onetrust-pc-sdk.ot-shw-fltr #ot-fltr-cnt{margin:0;height:100%;max-height:none;padding:10px;top:0;width:calc(100% - 20px);position:absolute;right:0;left:0;max-width:none}#onetrust-pc-sdk.ot-shw-fltr .ot-fltr-scrlcnt{max-height:calc(100% - 65px)}}
            #onetrust-consent-sdk #onetrust-pc-sdk,
                #onetrust-consent-sdk #ot-search-cntr,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-switch.ot-toggle,
                #onetrust-consent-sdk #onetrust-pc-sdk ot-grp-hdr1 .checkbox,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-title:after
                ,#onetrust-consent-sdk #onetrust-pc-sdk #ot-sel-blk,
                        #onetrust-consent-sdk #onetrust-pc-sdk #ot-fltr-cnt,
                        #onetrust-consent-sdk #onetrust-pc-sdk #ot-anchor {
                    background-color: #FFF;
                }
               
            #onetrust-consent-sdk #onetrust-pc-sdk h3,
                #onetrust-consent-sdk #onetrust-pc-sdk h4,
                #onetrust-consent-sdk #onetrust-pc-sdk h5,
                #onetrust-consent-sdk #onetrust-pc-sdk h6,
                #onetrust-consent-sdk #onetrust-pc-sdk p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-ven-lst .ot-ven-opts p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-desc,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-title,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-li-title,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-sel-all-hdr span,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-fltr-modal #modal-header,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-checkbox label span,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-sel-blk p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-lst-title h3,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst .back-btn-handler p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst .ot-ven-name,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-ven-lst .consent-category,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-inactive-leg-btn,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-label-status,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-chkbox label span,
                #onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-optout-signal
                {
                    color: #2E2E2E;
                }
             #onetrust-consent-sdk #onetrust-pc-sdk .privacy-notice-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-pgph-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler + a,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-host-list-handler,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-ven-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-ven-legclaim-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-name a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-acc-hdr .ot-host-expand,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-content #ot-pc-desc .ot-link-btn,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info a
                    {
                        color: #007398;
                    }
            #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler:hover { text-decoration: underline;}
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt,
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-txt .ot-subgrp-tgl .ot-switch.ot-toggle
             {
                background-color: #F8F8F8;
            }
             #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-txt .ot-ven-dets
                            {
                                background-color: #F8F8F8;
                            }
        #onetrust-consent-sdk #onetrust-pc-sdk
            button:not(#clear-filters-handler):not(.ot-close-icon):not(#filter-btn-handler):not(.ot-remove-objection-handler):not(.ot-obj-leg-btn-handler):not([aria-expanded]):not(.ot-link-btn),
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-active-leg-btn {
                background-color: #007398;border-color: #007398;
                color: #FFF;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-active-menu {
                border-color: #007398;
            }
            
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-remove-objection-handler{
                background-color: transparent;
                border: 1px solid transparent;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-inactive-leg-btn {
                background-color: #FFFFFF;
                color: #78808E; border-color: #78808E;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-tgl input:focus + .ot-switch, .ot-switch .ot-switch-nob, .ot-switch .ot-switch-nob:before,
            #onetrust-pc-sdk .ot-checkbox input[type="checkbox"]:focus + label::before,
            #onetrust-pc-sdk .ot-chkbox input[type="checkbox"]:focus + label::before {
                outline-color: #000000;
                outline-width: 1px;
            }
            #onetrust-pc-sdk .ot-host-item > button:focus, #onetrust-pc-sdk .ot-ven-item > button:focus {
                border: 1px solid #000000;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk *:focus,
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-vlst-cntr > a:focus {
               outline: 1px solid #000000;
            }#onetrust-pc-sdk .ot-vlst-cntr .ot-ext-lnk,  #onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{
                    background-image: url('https://cdn.cookielaw.org/logos/static/ot_external_link.svg');
                }
            /*! Extra code to blur out background */
.onetrust-pc-dark-filter{
background:rgba(0,0,0,.5);
z-index:2147483646;
width:100%;
height:100%;
overflow:hidden;
position:fixed;
top:0;
bottom:0;
left:0;
backdrop-filter: initial
}

/*! v6.12.0 2021-01-19 */
div#onetrust-consent-sdk #onetrust-banner-sdk{border-top:2px solid #eb6500!important;outline:1px solid transparent;box-shadow:none;padding:24px}div#onetrust-consent-sdk button{border-radius:0!important;box-shadow:none!important;box-sizing:border-box!important;font-size:20px!important;font-weight:400!important;letter-spacing:0!important;max-width:none!important;white-space:nowrap!important}div#onetrust-consent-sdk button:not(.ot-link-btn){background-color:#007398!important;border:2px solid #007398!important;color:#fff!important;height:48px!important;padding:0 1em!important;width:auto!important}div#onetrust-consent-sdk button:hover{background-color:#fff!important;border-color:#eb6500!important;color:#2e2e2e!important}div#onetrust-consent-sdk button.ot-link-btn{color:#007398!important;font-size:16px!important;text-decoration:underline}div#onetrust-consent-sdk button.ot-link-btn:hover{color: #2e2e2e!important;text-decoration-color:#eb6500!important}div#onetrust-consent-sdk a,div#onetrust-pc-sdk a{color:#007398!important;text-decoration:underline!important}div#onetrust-consent-sdk a,div#onetrust-consent-sdk button,div#onetrust-consent-sdk p:hover{opacity:1!important}div#onetrust-consent-sdk a:focus,div#onetrust-consent-sdk button:focus,div#onetrust-consent-sdk input:focus{outline:2px solid #eb6500!important;outline-offset:1px!important}div#onetrust-banner-sdk .ot-sdk-container{padding:0;width:auto}div#onetrust-banner-sdk .ot-sdk-row{align-items:flex-start;box-sizing:border-box;display:flex;flex-direction:column;justify-content:space-between;margin:auto;max-width:1152px}div#onetrust-banner-sdk .ot-sdk-row:after{display:none}div#onetrust-banner-sdk #onetrust-group-container,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-group-container,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{flex-grow:1;width:auto}div#onetrust-banner-sdk #onetrust-policy,div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy{margin:0;overflow:visible}div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy-text,div#onetrust-consent-sdk #onetrust-policy-text{font-size:16px;line-height:24px;max-width:44em;margin:0}div#onetrust-consent-sdk #onetrust-policy-text a[href]{font-weight:400;margin-left:8px}div#onetrust-banner-sdk #onetrust-button-group-parent{flex:0 0 auto;margin:32px 0 0;width:100%}div#onetrust-banner-sdk #onetrust-button-group{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;margin:-8px}div#onetrust-banner-sdk .banner-actions-container{display:flex;flex:1 0 auto}div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type,div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto;margin:8px;width:auto}div#onetrust-consent-sdk #onetrust-pc-btn-handler{background-color:#fff!important;color:#2e2e2e!important}div#onetrust-banner-sdk #onetrust-close-btn-container{display:none}@media only screen and (min-width:556px){div#onetrust-consent-sdk #onetrust-banner-sdk{padding:40px}div#onetrust-banner-sdk #onetrust-policy{margin:0 40px 0 0}div#onetrust-banner-sdk .ot-sdk-row{align-items:center;flex-direction:row}div#onetrust-banner-sdk #onetrust-button-group-parent,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-button-group-parent,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:0;padding:0;width:auto}div#onetrust-banner-sdk #onetrust-button-group,div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{align-items:stretch;flex-direction:column-reverse;margin:0}div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto}}@media only screen and (min-width:768px){div#onetrust-banner-sdk #onetrust-policy{margin:0 48px 0 0}div#onetrust-consent-sdk #onetrust-banner-sdk{padding:48px}}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-size:16px;line-height:24px}div#onetrust-consent-sdk #onetrust-pc-sdk p,div#onetrust-pc-sdk #ot-pc-desc,div#onetrust-pc-sdk .category-host-list-handler,div#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{font-size:16px;font-weight:400;line-height:24px}div#onetrust-consent-sdk a:hover,div#onetrust-pc-sdk a:hover{color:#2e2e2e!important;text-decoration-color:#eb6500!important}div#onetrust-pc-sdk{border-radius:0;bottom:0;height:auto;left:0;margin:auto;max-width:100%;overflow:hidden;right:0;top:0;width:512px;max-height:800px}div#onetrust-pc-sdk .ot-pc-header{display:none}div#onetrust-pc-sdk #ot-pc-content{overscroll-behavior:contain;padding:0 12px 0 24px;margin:16px 4px 0 0;top:0;right:16px;left:0;width:auto}div#onetrust-pc-sdk #ot-category-title,div#onetrust-pc-sdk #ot-pc-title{font-size:24px;font-weight:400;line-height:32px;margin:0 0 16px}div#onetrust-pc-sdk #ot-pc-desc{padding:0}div#onetrust-pc-sdk #ot-pc-desc a{display:inline}div#onetrust-pc-sdk #accept-recommended-btn-handler{display:none!important}div#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:2px solid #eb6500;outline-offset:-1px;transition:none}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{border-width:0 0 2px}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{border-width:2px 0}div#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding:8px 0;width:100%}div#onetrust-pc-sdk .ot-plus-minus{transform:translateY(2px)}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item>button{background:0 0!important;border:0!important;height:44px!important;max-width:none!important;width:calc(100% - 48px)!important}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-weight:700}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding:0}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item .ot-acc-grpdesc{padding:0;width:100%}div#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border:0;padding:0}div#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp{margin:0}div#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:calc(100% - 160px)}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{width:calc(100% - 88px)}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{color:#2e2e2e;font-size:12px;font-weight:400;line-height:1.5;padding-right:48px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:before{border-radius:12px;position:absolute;right:0;top:0;content:'';background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:after{border-radius:50%;position:absolute;right:5px;top:4px;content:'';background-color:#eb6500;height:12px;width:12px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active,div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl{right:2px}div#onetrust-pc-sdk .ot-switch{display:block;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob,div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob:before{background-color:#737373;height:8px;left:4px;top:4px;width:8px}div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{background-color:#eb6500;height:12px;left:0;top:2px;width:12px}div#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch .ot-switch-nob{box-shadow:0 0;outline:2px solid #eb6500!important;outline-offset:1px;transition:none}div#onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt{background-color:transparent;padding-left:3px}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr,div#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr{overflow:visible;width:100%}div#onetrust-pc-sdk .ot-pc-footer{border-top:0 solid}div#onetrust-pc-sdk .ot-btn-container{padding-top:24px;text-align:center}div#onetrust-pc-sdk .ot-pc-footer button{margin:8px 0;background-color:#fff}div#onetrust-pc-sdk .ot-pc-footer-logo{background-color:#fff}div#onetrust-pc-sdk #ot-lst-title span{font-size:24px;font-weight:400;line-height:32px}div#onetrust-pc-sdk #ot-host-lst .ot-host-desc,div#onetrust-pc-sdk #ot-host-lst .ot-host-expand,div#onetrust-pc-sdk #ot-host-lst .ot-host-name,div#onetrust-pc-sdk #ot-host-lst .ot-host-name a,div#onetrust-pc-sdk .back-btn-handler,div#onetrust-pc-sdk .ot-host-opt li>div div{font-size:16px;font-weight:400;line-height:24px}div#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{width:100%}div#onetrust-pc-sdk #ot-pc-lst{top:0}div#onetrust-pc-sdk .back-btn-handler{text-decoration:none!important}div#onetrust-pc-sdk #filter-btn-handler:hover svg{filter:invert(1)}div#onetrust-pc-sdk .back-btn-handler svg{width:16px;height:16px}div#onetrust-pc-sdk .ot-host-item>button{background:0 0!important;border:0!important;height:66px!important;max-width:none!important;width:calc(100% - 5px)!important;transform:translate(2px,2px)}div#onetrust-pc-sdk .ot-host-item{border-bottom:2px solid #b9b9b9;padding:0}div#onetrust-pc-sdk .ot-host-item .ot-acc-hdr{margin:0 0 -6px;padding:8px 0}div#onetrust-pc-sdk ul li:first-child{border-top:2px solid #b9b9b9}div#onetrust-pc-sdk .ot-host-item .ot-plus-minus{margin:0 8px 0 0}div#onetrust-pc-sdk .ot-search-cntr{width:calc(100% - 48px)}div#onetrust-pc-sdk .ot-host-opt .ot-host-info{background-color:transparent}div#onetrust-pc-sdk .ot-host-opt li>div div{padding:0}div#onetrust-pc-sdk #vendor-search-handler{border-radius:0;border-color:#939393;border-style:solid;border-width:2px 0 2px 2px;font-size:20px;height:48px;margin:0}div#onetrust-pc-sdk #ot-pc-hdr{margin-left:24px}div#onetrust-pc-sdk .ot-lst-subhdr{width:calc(100% - 24px)}div#onetrust-pc-sdk .ot-lst-subhdr svg{right:0;top:8px}div#onetrust-pc-sdk .ot-fltr-cntr{box-sizing:border-box;right:0;width:48px}div#onetrust-pc-sdk #filter-btn-handler{width:48px!important;padding:8px!important}div#onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,div#onetrust-pc-sdk button#filter-apply-handler,div#onetrust-pc-sdk button#filter-cancel-handler{height:2em!important;padding-left:14px!important;padding-right:14px!important}div#onetrust-pc-sdk #ot-fltr-cnt{box-shadow:0 0;border:1px solid #8e8e8e;border-radius:0}div#onetrust-pc-sdk .ot-fltr-scrlcnt{max-height:calc(100% - 80px)}div#onetrust-pc-sdk #ot-fltr-modal{max-height:400px}div#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:16px}div#onetrust-pc-sdk #ot-lst-cnt{margin-left:24px;width:calc(100% - 48px)}div#onetrust-pc-sdk #ot-anchor{display:none!important}

/* 2023-12-04  Fix for button order in mobile view*/
@media (max-width: 550px) {
  #onetrust-accept-btn-handler {order: 1;  }
  #onetrust-reject-all-handler { order: 2;  }
  #onetrust-pc-btn-handler { order: 3;  }
}


/*! Extra code to blur our background */
.onetrust-pc-dark-filter{
backdrop-filter: blur(3px)
}
.ot-sdk-cookie-policy{font-family:inherit;font-size:16px}.ot-sdk-cookie-policy.otRelFont{font-size:1rem}.ot-sdk-cookie-policy h3,.ot-sdk-cookie-policy h4,.ot-sdk-cookie-policy h6,.ot-sdk-cookie-policy p,.ot-sdk-cookie-policy li,.ot-sdk-cookie-policy a,.ot-sdk-cookie-policy th,.ot-sdk-cookie-policy #cookie-policy-description,.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group,.ot-sdk-cookie-policy #cookie-policy-title{color:dimgray}.ot-sdk-cookie-policy #cookie-policy-description{margin-bottom:1em}.ot-sdk-cookie-policy h4{font-size:1.2em}.ot-sdk-cookie-policy h6{font-size:1em;margin-top:2em}.ot-sdk-cookie-policy th{min-width:75px}.ot-sdk-cookie-policy a,.ot-sdk-cookie-policy a:hover{background:#fff}.ot-sdk-cookie-policy thead{background-color:#f6f6f4;font-weight:bold}.ot-sdk-cookie-policy .ot-mobile-border{display:none}.ot-sdk-cookie-policy section{margin-bottom:2em}.ot-sdk-cookie-policy table{border-collapse:inherit}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy{font-family:inherit;font-size:1rem}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h6,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy p,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-title{color:dimgray}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description{margin-bottom:1em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup{margin-left:1.5em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group-desc,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-table-header,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy span,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td{font-size:.9em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td span,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td a{font-size:inherit}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group{font-size:1em;margin-bottom:.6em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-title{margin-bottom:1.2em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy>section{margin-bottom:1em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th{min-width:75px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a:hover{background:#fff}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead{background-color:#f6f6f4;font-weight:bold}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-mobile-border{display:none}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy section{margin-bottom:2em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup ul li{list-style:disc;margin-left:1.5em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup ul li h4{display:inline-block}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table{border-collapse:inherit;margin:auto;border:1px solid #d7d7d7;border-radius:5px;border-spacing:initial;width:100%;overflow:hidden}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table td{border-bottom:1px solid #d7d7d7;border-right:1px solid #d7d7d7}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td{border-bottom:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr th:last-child,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr td:last-child{border-right:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-host,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-cookies-type{width:25%}.ot-sdk-cookie-policy[dir=rtl]{text-align:left}#ot-sdk-cookie-policy h3{font-size:1.5em}@media only screen and (max-width: 530px){.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) table,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) thead,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tbody,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) th,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr{display:block}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) thead tr{position:absolute;top:-9999px;left:-9999px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr{margin:0 0 1em 0}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr:nth-child(odd),.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr:nth-child(odd) a{background:#f6f6f4}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td{border:none;border-bottom:1px solid #eee;position:relative;padding-left:50%}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td:before{position:absolute;height:100%;left:6px;width:40%;padding-right:10px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) .ot-mobile-border{display:inline-block;background-color:#e4e4e4;position:absolute;height:100%;top:0;left:45%;width:2px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td:before{content:attr(data-label);font-weight:bold}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) li{word-break:break-word;word-wrap:break-word}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table{overflow:hidden}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table td{border:none;border-bottom:1px solid #d7d7d7}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tbody,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tr{display:block}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-host,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-cookies-type{width:auto}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tr{margin:0 0 1em 0}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td:before{height:100%;width:40%;padding-right:10px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td:before{content:attr(data-label);font-weight:bold}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li{word-break:break-word;word-wrap:break-word}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead tr{position:absolute;top:-9999px;left:-9999px;z-index:-9999}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td{border-bottom:1px solid #d7d7d7;border-right:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td:last-child{border-bottom:0px}}
                
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h5,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h6,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy p,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy span,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description {
                        color: #696969;
                    }
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th {
                        color: #696969;
                    }
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group {
                        color: #696969;
                    }
                    
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-title {
                            color: #696969;
                        }
                    
            
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table th {
                            background-color: #F8F8F8;
                        }
                    
            .ot-floating-button__front{background-image:url('https://cdn.cookielaw.org/logos/static/ot_persistent_cookie_icon.png')}</style></head>
    <body data-sd-ui-layer-boundary="true"><div id="MathJax_Message" style="display: none;"></div>
      <script type="text/javascript">
        window.__PRELOADED_STATE__ = {"abstracts":{"content":[{"$$":[{"$":{"id":"st005"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"sp0005"},"#name":"simple-para","$$":[{"#name":"text","$$":[{"#name":"text","$$":[{"#name":"topic-link","_":"Facial expression recognition","$":{"href":"/topics/biochemistry-genetics-and-molecular-biology/facial-recognition","term":"Facial expression recognition"}},{"#name":"__text__","_":" is a hot "}]},{"#name":"topic-link","_":"research topic","$":{"href":"/topics/computer-science/research-topic","term":"research topic"}},{"#name":"text","$$":[{"#name":"text","$$":[{"#name":"__text__","_":" and can be applied in many "},{"#name":"topic-link","_":"computer vision","$":{"href":"/topics/engineering/computervision","term":"computer vision"}},{"#name":"text","$$":[{"#name":"__text__","_":" fields, such as human–computer interaction, "},{"#name":"topic-link","_":"affective computing","$":{"href":"/topics/computer-science/affective-computing","term":"affective computing"}},{"#name":"__text__","_":" and so on. In this paper, we propose a novel end-to-end network with "}]}]},{"#name":"topic-link","_":"attention mechanism","$":{"href":"/topics/computer-science/attention-machine-learning","term":"attention mechanism"}},{"#name":"text","$$":[{"#name":"__text__","_":" for automatic facial expression recognition. The new "},{"#name":"topic-link","_":"network architecture","$":{"href":"/topics/computer-science/network-architecture","term":"network architecture"}},{"#name":"__text__","_":" consists of four parts, i.e., the feature extraction module, the attention module, the reconstruction module and the classification module. The "}]}]}]},{"#name":"topic-link","_":"LBP","$":{"href":"/topics/engineering/local-binary-pattern","term":"LBP"}},{"#name":"text","$$":[{"#name":"text","$$":[{"#name":"__text__","_":" features extract image "},{"#name":"topic-link","_":"texture information","$":{"href":"/topics/computer-science/texture-information","term":"texture information"}},{"#name":"__text__","_":" and then catch the small movements of the faces, which can improve the network performance. Attention mechanism can make the "}]},{"#name":"topic-link","_":"neural network","$":{"href":"/topics/computer-science/neural-network","term":"neural network"}},{"#name":"text","$$":[{"#name":"text","$$":[{"#name":"__text__","_":" pay more attention to useful features. We combine LBP features and attention mechanism to enhance the attention model to obtain better results. In addition, we collected and labelled a new facial expression dataset of seven expressions from 35 subjects aged from 20 to 25. For each subject, we captured both "},{"#name":"topic-link","_":"RGB images","$":{"href":"/topics/engineering/rgb-image","term":"RGB images"}},{"#name":"__text__","_":" and depth images with a "}]},{"#name":"topic-link","_":"Microsoft Kinect sensor","$":{"href":"/topics/computer-science/microsoft-kinect-sensor","term":"Microsoft Kinect sensor"}},{"#name":"__text__","_":". For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. We apply the newly proposed method to our own dataset and four representative expression datasets, i.e., JAFFE, CK+, FER2013 and Oulu-CASIA. The experimental results demonstrate the feasibility and effectiveness of the proposed method."}]}]}]}],"$":{"view":"all","id":"as005"},"#name":"abstract-sec"}],"$":{"view":"all","id":"ab005","lang":"en","class":"author"},"#name":"abstract"}],"floats":[],"footnotes":[],"attachments":[]},"accessbarConfig":{"fallback":false,"id":"accessbar","version":"0.0.1","analytics":{"location":"accessbar","eventName":"ctaImpression"},"ariaLabel":{"accessbar":"Download options and search","componentsList":"PDF Options"},"banners":[{"id":"BannerSsrn"}],"components":[{"analytics":[{"ids":["accessbar:clinicalkeycta:inst-known:sdcust-unknown:ent-no:ra-no:source-linkinghub:method-ip"],"eventName":"ctaClick"}],"label":"Access through&nbsp;**ClinicalKey**","id":"ClinicalKey"},{"ariaLabel":"Access through your organization","institutionLogoAltText":"Seamless access","analytics":[{"ids":["accessbar:accesscta:inst-unknown:sdcust-unknown:ent-unknown:ra-yes:source-seamlessaccess:method-shib"],"eventName":"ctaClick"}],"labelPrefix":"Access through","defaultLabelSuffix":"your organization","href":"/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0925231220309838","id":"RemoteAccess"},{"analytics":[{"ids":["accessbar:purchase-pdf"],"eventName":"ctaClick"}],"label":"Purchase PDF","href":"/getaccess/pii/S0925231220309838/purchase","rel":"noreferrer noopener","target":"_blank","id":"PurchasePDF"},{"analytics":[{"ids":["accessbar:another-institution"],"eventName":"ctaClick"}],"label":"Access through another organization","href":"/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0925231220309838","id":"RemoteAccessOther"}],"search":{"inputPlaceHolder":"Search ScienceDirect","ariaLabel":{"input":"Search ScienceDirect","submit":"Submit search"},"formAction":"/search#submit","analytics":[{"ids":["accessbar:search"],"eventName":"searchStart"}],"id":"QuickSearch"}},"adobeTarget":{"sd:genai-question-and-answer":{}},"article":{"accessOptions":{},"analyticsMetadata":{"accountId":"228598","accountName":"ScienceDirect Guests","loginStatus":"anonymous","userId":"12975512","isLoggedIn":false},"cid":"271597","content-family":"serial","copyright-line":"© 2020 Elsevier B.V. All rights reserved.","cover-date-years":["2020"],"cover-date-start":"2020-10-21","cover-date-text":"21 October 2020","document-subtype":"fla","document-type":"article","eid":"1-s2.0-S0925231220309838","doi":"10.1016/j.neucom.2020.06.014","first-fp":"340","hub-eid":"1-s2.0-S0925231220X00336","issuePii":"S0925231220X00336","item-weight":"FULL-TEXT","language":"en","last-lp":"350","last-author":{"#name":"last-author","$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"$$":[{"#name":"author","$":{"biographyid":"bg025","id":"au025","author-id":"S0925231220309838-7480a9ce833ed48716b63edbda059763"},"$$":[{"#name":"given-name","_":"Zhaojie"},{"#name":"surname","_":"Ju"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_original_draft"},"_":"Writing - original draft"},{"#name":"cross-ref","$":{"id":"c0150","refid":"af010"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"cross-ref","$":{"id":"c0155","refid":"cor1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIyaWQlMjIlM0ElMjJlbTAwNSUyMiUyQyUyMnR5cGUlMjIlM0ElMjJlbWFpbCUyMiUyQyUyMmhyZWYlMjIlM0ElMjJtYWlsdG8lM0F6aGFvamllLmp1JTQwcG9ydC5hYy51ayUyMiU3RCUyQyUyMl8lMjIlM0ElMjJ6aGFvamllLmp1JTQwcG9ydC5hYy51ayUyMiU3RA=="}]}]},"normalized-first-auth-initial":"J","normalized-first-auth-surname":"LI","open-research":{"#name":"open-research","$":{"xmlns:xocs":true},"$$":[{"#name":"or-agreements","$$":[{"#name":"or-agreement","$$":[{"#name":"or-agreement-name","_":"HEFCE"},{"#name":"or-agreement-terms","_":"none"}]}]}]},"pages":[{"last-page":"350","first-page":"340"}],"pii":"S0925231220309838","self-archiving":{"#name":"self-archiving","$":{"xmlns:xocs":true},"$$":[{"#name":"sa-start-date","_":"2021-07-03T00:00:00.000Z"},{"#name":"sa-user-license","_":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}]},"srctitle":"Neurocomputing","suppl":"C","timestamp":"2020-09-11T22:33:17.352222Z","title":{"content":[{"#name":"title","$":{"id":"tm005"},"_":"Attention mechanism-based CNN for facial expression recognition"}],"floats":[],"footnotes":[],"attachments":[]},"vol-first":"411","vol-iss-suppl-text":"Volume 411","userSettings":{"forceAbstract":false,"creditCardPurchaseAllowed":true,"blockFullTextForAnonymousAccess":false,"disableWholeIssueDownload":false,"preventTransactionalAccess":false,"preventDocumentDelivery":true},"contentType":"JL","crossmark":true,"document-references":44,"freeHtmlGiven":false,"ssoUrls":["//acw.clinicalkey.com/SSOCore/update?acw=fdf9c8642b80a043f9996e064f67fbe1b665gxrqb%7C%24%7C1F993354FDC4636854CA051B2E6645FBD3B3E6BEC8842AEFCFFADCF3DC776483EEA08326AB2B6239563D972C978BBA0685832BCFD11735920E9169905BBD791CB0469A67597464825D387A21AFA2E514&utt=79d2580046fe3912678df967d40ea758362f47c","//acw.scopus.com/SSOCore/update?acw=fdf9c8642b80a043f9996e064f67fbe1b665gxrqb%7C%24%7C1F993354FDC4636854CA051B2E6645FBD3B3E6BEC8842AEFCFFADCF3DC776483EEA08326AB2B6239563D972C978BBA0685832BCFD11735920E9169905BBD791CB0469A67597464825D387A21AFA2E514&utt=79d2580046fe3912678df967d40ea758362f47c","//acw.sciencedirect.com/SSOCore/update?acw=fdf9c8642b80a043f9996e064f67fbe1b665gxrqb%7C%24%7C1F993354FDC4636854CA051B2E6645FBD3B3E6BEC8842AEFCFFADCF3DC776483EEA08326AB2B6239563D972C978BBA0685832BCFD11735920E9169905BBD791CB0469A67597464825D387A21AFA2E514&utt=79d2580046fe3912678df967d40ea758362f47c","//acw.elsevier.com/SSOCore/update?acw=fdf9c8642b80a043f9996e064f67fbe1b665gxrqb%7C%24%7C1F993354FDC4636854CA051B2E6645FBD3B3E6BEC8842AEFCFFADCF3DC776483EEA08326AB2B6239563D972C978BBA0685832BCFD11735920E9169905BBD791CB0469A67597464825D387A21AFA2E514&utt=79d2580046fe3912678df967d40ea758362f47c"],"userProfile":{"departmentName":"ScienceDirect Guests","accessType":"GUEST","accountId":"228598","webUserId":"12975512","accountName":"ScienceDirect Guests","departmentId":"291352","userType":"NORMAL","hasMultipleOrganizations":false,"accountNumber":"C000228598"},"access":{"openAccess":false,"openArchive":false},"aipType":"none","articleEntitlement":{"entitled":false,"isCasaUser":false,"usageInfo":"(12975512,U|291352,D|228598,A|3,P|2,PL)(SDFE,CON|fdf9c8642b80a043f9996e064f67fbe1b665gxrqb,SSO|ANON_GUEST,ACCESS_TYPE)","entitledByAccount":false},"crawlerInformation":{"canCrawlPDFContent":false,"isCrawler":false},"dates":{"Available online":"12 June 2020","Received":"5 January 2020","Revised":["23 April 2020"],"Accepted":"2 June 2020","Publication date":"21 October 2020","Version of Record":"3 July 2020"},"downloadFullIssue":false,"entitlementReason":"unsubscribed","features":["aamAttachments","keywords","references","biography","preview"],"hasBody":true,"has-large-authors":false,"hasScholarlyAbstract":true,"headerConfig":{"contactUrl":"https://service.elsevier.com/app/contact/supporthub/sciencedirect/","userName":"","userEmail":"","orgName":"ScienceDirect Guests","webUserId":"12975512","libraryBanner":null,"shib_regUrl":"","tick_regUrl":"","recentInstitutions":[],"canActivatePersonalization":false,"hasInstitutionalAssociation":false,"hasMultiOrg":false,"userType":"GUEST","userAnonymity":"ANON_GUEST","allowCart":true,"environment":"prod","cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com"},"isCorpReq":false,"isPdfFullText":false,"issn":"09252312","issn-primary-formatted":"0925-2312","issRange":"","isThirdParty":false,"pageCount":11,"publication-content":{"noElsevierLogo":false,"imprintPublisher":{"displayName":"Elsevier","id":"47"},"isSpecialIssue":false,"isSampleIssue":false,"transactionsBlocked":false,"publicationOpenAccess":{"oaStatus":"","oaArticleCount":576,"openArchiveStatus":false,"openArchiveArticleCount":19,"openAccessStartDate":"","oaAllowsAuthorPaid":true},"issue-cover":{"attachment":[{"attachment-eid":"1-s2.0-S0925231220X00336-cov200h.gif","file-basename":"cov200h","extension":"gif","filename":"cov200h.gif","ucs-locator":["https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220X00336/cover/DOWNSAMPLED200/image/gif/ee998c3fef616ee2a37da33c85557e18/cov200h.gif"],"attachment-type":"IMAGE-COVER-H200","filesize":"5256","pixel-height":"200","pixel-width":"149"},{"attachment-eid":"1-s2.0-S0925231220X00336-cov150h.gif","file-basename":"cov150h","extension":"gif","filename":"cov150h.gif","ucs-locator":["https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220X00336/cover/DOWNSAMPLED/image/gif/8ea0464aee0ee7c33b1fc54ca412a4e5/cov150h.gif"],"attachment-type":"IMAGE-COVER-H150","filesize":"3684","pixel-height":"150","pixel-width":"112"}]},"smallCoverUrl":"https://ars.els-cdn.com/content/image/S09252312.gif","title":"neurocomputing","contentTypeCode":"JL","images":{"coverImage":"https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00336-cov150h.gif","logo":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1/image/elsevier-non-solus.png","logoAltText":"Elsevier"},"publicationCoverImageUrl":"https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00336-cov150h.gif"},"volRange":"411","titleString":"Attention mechanism-based CNN for facial expression recognition","ssrn":{},"renderingMode":"Preview","isAbstract":true,"isContentVisible":false,"ajaxLinks":{"referredToBy":true,"authorMetadata":true},"pdfEmbed":false,"displayViewFullText":false},"authors":{"content":[{"#name":"author-group","$":{"id":"ag005"},"$$":[{"#name":"author","$":{"biographyid":"bg005","id":"au005","author-id":"S0925231220309838-b8e0db7615e597047ea479976eff249f"},"$$":[{"#name":"given-name","_":"Jing"},{"#name":"surname","_":"Li"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_original_draft"},"_":"Writing - original draft"},{"#name":"cross-ref","$":{"id":"c0130","refid":"af005"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"biographyid":"bg010","id":"au010","author-id":"S0925231220309838-7f7d38721b6c4d53bf61b170dafc06ea"},"$$":[{"#name":"given-name","_":"Kan"},{"#name":"surname","_":"Jin"},{"#name":"cross-ref","$":{"id":"c0135","refid":"af005"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"biographyid":"bg015","id":"au015","author-id":"S0925231220309838-df5250f072e86ff1ef645a7edf552847"},"$$":[{"#name":"given-name","_":"Dalin"},{"#name":"surname","_":"Zhou"},{"#name":"cross-ref","$":{"id":"c0140","refid":"af010"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]},{"#name":"author","$":{"biographyid":"bg020","id":"au020","author-id":"S0925231220309838-dafff61daf979cc880c54bf7660332dc"},"$$":[{"#name":"given-name","_":"Naoyuki"},{"#name":"surname","_":"Kubota"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"cross-ref","$":{"id":"c0145","refid":"af015"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"c"}]}]},{"#name":"author","$":{"biographyid":"bg025","id":"au025","author-id":"S0925231220309838-7480a9ce833ed48716b63edbda059763"},"$$":[{"#name":"given-name","_":"Zhaojie"},{"#name":"surname","_":"Ju"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_original_draft"},"_":"Writing - original draft"},{"#name":"cross-ref","$":{"id":"c0150","refid":"af010"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"cross-ref","$":{"id":"c0155","refid":"cor1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIyaWQlMjIlM0ElMjJlbTAwNSUyMiUyQyUyMnR5cGUlMjIlM0ElMjJlbWFpbCUyMiUyQyUyMmhyZWYlMjIlM0ElMjJtYWlsdG8lM0F6aGFvamllLmp1JTQwcG9ydC5hYy51ayUyMiU3RCUyQyUyMl8lMjIlM0ElMjJ6aGFvamllLmp1JTQwcG9ydC5hYy51ayUyMiU3RA=="}]},{"#name":"affiliation","$":{"id":"af005","affiliation-id":"S0925231220309838-db6ea6446ed7323c47485d455d20f819"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","_":"School of Information Engineering, Nanchang University, Nanchang 330031, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Information Engineering"},{"#name":"organization","_":"Nanchang University"},{"#name":"city","_":"Nanchang"},{"#name":"postal-code","_":"330031"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"stx005"},"_":"School of Information Engineering, Nanchang University, Nanchang 330031, China"}]},{"#name":"affiliation","$":{"id":"af010","affiliation-id":"S0925231220309838-2fd2feae665eb651d7910c1efd60aa49"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","_":"School of Computing, University of Portsmouth, Portsmouth PO1 3HE, UK"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Computing"},{"#name":"organization","_":"University of Portsmouth"},{"#name":"city","_":"Portsmouth"},{"#name":"postal-code","_":"PO1 3HE"},{"#name":"country","_":"UK"}]},{"#name":"source-text","$":{"id":"stx010"},"_":"School of Computing, University of Portsmouth, Portsmouth PO1 3HE, UK"}]},{"#name":"affiliation","$":{"id":"af015","affiliation-id":"S0925231220309838-36a7e8ec3743be600c29dd36f00bbcc0"},"$$":[{"#name":"label","_":"c"},{"#name":"textfn","_":"Graduate School of Systems Design, Tokyo Metropolitan University, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Graduate School of Systems Design"},{"#name":"organization","_":"Tokyo Metropolitan University"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"stx015"},"_":"Graduate School of Systems Design, Tokyo Metropolitan University, China"}]},{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"affiliations":{"af005":{"#name":"affiliation","$":{"id":"af005","affiliation-id":"S0925231220309838-db6ea6446ed7323c47485d455d20f819"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","_":"School of Information Engineering, Nanchang University, Nanchang 330031, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Information Engineering"},{"#name":"organization","_":"Nanchang University"},{"#name":"city","_":"Nanchang"},{"#name":"postal-code","_":"330031"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"stx005"},"_":"School of Information Engineering, Nanchang University, Nanchang 330031, China"}]},"af010":{"#name":"affiliation","$":{"id":"af010","affiliation-id":"S0925231220309838-2fd2feae665eb651d7910c1efd60aa49"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","_":"School of Computing, University of Portsmouth, Portsmouth PO1 3HE, UK"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Computing"},{"#name":"organization","_":"University of Portsmouth"},{"#name":"city","_":"Portsmouth"},{"#name":"postal-code","_":"PO1 3HE"},{"#name":"country","_":"UK"}]},{"#name":"source-text","$":{"id":"stx010"},"_":"School of Computing, University of Portsmouth, Portsmouth PO1 3HE, UK"}]},"af015":{"#name":"affiliation","$":{"id":"af015","affiliation-id":"S0925231220309838-36a7e8ec3743be600c29dd36f00bbcc0"},"$$":[{"#name":"label","_":"c"},{"#name":"textfn","_":"Graduate School of Systems Design, Tokyo Metropolitan University, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Graduate School of Systems Design"},{"#name":"organization","_":"Tokyo Metropolitan University"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"stx015"},"_":"Graduate School of Systems Design, Tokyo Metropolitan University, China"}]}},"correspondences":{"cor1":{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author."}]}},"attachments":[],"scopusAuthorIds":{},"articles":{}},"authorMetadata":[],"banner":{"expanded":false},"biographies":{"content":[{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg005","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00045","locator":"fx1","href":"pii:S0925231220309838/fx1","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0010","view":"all"},"_":"Jing Li received the B.E. degree in Electronic Information Engineering from Nanchang University, China, in 2005, and obtained her PhD degree in Electronic and Electrical Engineering from the University of Sheffield, UK, in 2011. From 2011 to 2012, she was a Research Associate with the Department of Computer Science at the University of Sheffield. Currently, she is an Associate Professor with the School of Information Engineering at Nanchang University. Her research interests include visual tracking, behavior recognition, and crowd scene analysis. She has authored or coauthored in various journals, such as IEEE Transactions on Industrial Informatics, IEEE Transactions on Image Processing, Information Sciences (Elsevier), etc."}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg010","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00050","locator":"fx2","href":"pii:S0925231220309838/fx2","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0015","view":"all"},"_":"Kan Jin received the B.E. degree in Mechatronic Engineering from Hubei Polytechnic University, China, in 2017. He is currently pursuing the M.S. degree in the School of Information Engineering at Nanchang University, China. His research interests include facial expression recognition and crowd counting."}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg015","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00055","locator":"fx3","href":"pii:S0925231220309838/fx3","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0020","view":"all"},"_":"Dalin Zhou received the B.S. degree in automation from the University of Science and Technology of China, Hefei, China, in 2012, the Ph.D. degree in computing from the University of Portsmouth, UK, in 2018 and is currently a Lecturer in Computer Science with the School of Computing, the University of Portsmouth, UK. His current research interests include signal processing, machine learning, computational intelligence, biomedical robotics and multimodal sensor fusion. His current research contributes to the monitoring and rehabilitation of limb motor function improving the daily life activity and working capability for both the disadvantaged group of limb-impaired patients and the aging community."}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg020","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00060","locator":"fx4","href":"pii:S0925231220309838/fx4","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0025","view":"all"},"$$":[{"#name":"__text__","_":"Naoyuki Kubota,"},{"#name":"hsp","$":{"sp":"0.25"}},{"#name":"__text__","_":"Faculty of Systems Design, Tokyo Metropolitan University, Tokyo, Japan Naoyuki Kubota received the B.Sc. degree from Osaka Kyoiku University, Kashiwara, Japan, in 1992, the M.Eng. degree from Hokkaido University, Hokkaido, Japan, in 1994, and the D.E. degree from Nagoya University, Nagoya, Japan, in 1997. He joined the Osaka Institute of Technology, Osaka, Japan, in 1997. He joined the Department of Human and Artificial Intelligence Systems, University of Fukui, Fukui, Japan, as an Associate Professor in 2000. He joined the Department of Mechanical Engineering, Tokyo Metropolitan University, Tokyo, Japan, in 2004. He was an Associate Professor from 2005 to 2012, and has been a Professor since 2012 at the Department of System Design, Tokyo Metropolitan University."}]}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg025","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00065","locator":"fx5","href":"pii:S0925231220309838/fx5","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0030","view":"all"},"_":"Zhaojie Ju received the B.S. in automatic control and the M.S. in intelligent robotics both from Huazhong University of Science and Technology, China, and the Ph.D. degree in intelligent robotics at the University of Portsmouth, UK. He held a research appointment at the University College London, London, U.K., before he started his independent academic position at the University of Portsmouth, U.K., in 2012. His research interests include machine intelligence, pattern recognition, and their applications on human motion analysis, multi-fingered robotic hand control, human–robot interaction and collaboration, and robot skill learning. He has authored or co-authored over 180 publications in journals, book chapters, and conference proceedings and received four best paper awards and one Best AE Award in ICRA2018."}]}],"floats":[],"footnotes":[],"attachments":[{"attachment-eid":"1-s2.0-S0925231220309838-fx1.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx1/DOWNSAMPLED/image/jpeg/d2d59e80bf74e9671f42699fd98145c3/fx1.jpg","file-basename":"fx1","filename":"fx1.jpg","extension":"jpg","filesize":"5641","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220309838-fx2.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx2/DOWNSAMPLED/image/jpeg/937e99f0333c57cea6ae9883dac4a803/fx2.jpg","file-basename":"fx2","filename":"fx2.jpg","extension":"jpg","filesize":"5735","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220309838-fx3.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx3/DOWNSAMPLED/image/jpeg/8f854280a9dd43e042cadb9d582d43af/fx3.jpg","file-basename":"fx3","filename":"fx3.jpg","extension":"jpg","filesize":"7192","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220309838-fx4.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx4/DOWNSAMPLED/image/jpeg/80dc799dc726c313460c56c1acdd9b24/fx4.jpg","file-basename":"fx4","filename":"fx4.jpg","extension":"jpg","filesize":"4756","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220309838-fx5.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx5/DOWNSAMPLED/image/jpeg/2ed7f3840a33bbd8a4600759dd274d38/fx5.jpg","file-basename":"fx5","filename":"fx5.jpg","extension":"jpg","filesize":"6361","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220309838-fx1.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx1/THUMBNAIL/image/gif/8bbb982b06f312f13bb9c3fd5d3f11f9/fx1.sml","file-basename":"fx1","filename":"fx1.sml","extension":"sml","filesize":"16195","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220309838-fx2.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx2/THUMBNAIL/image/gif/263ab112104b61e363351937daf6d187/fx2.sml","file-basename":"fx2","filename":"fx2.sml","extension":"sml","filesize":"13494","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220309838-fx3.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx3/THUMBNAIL/image/gif/eb01a3de56d5e84f6e7abaa288fae1a5/fx3.sml","file-basename":"fx3","filename":"fx3.sml","extension":"sml","filesize":"16385","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220309838-fx4.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx4/THUMBNAIL/image/gif/44745c38531ee1e6a1b3e0ac7abbec8e/fx4.sml","file-basename":"fx4","filename":"fx4.sml","extension":"sml","filesize":"11422","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220309838-fx5.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx5/THUMBNAIL/image/gif/f385afb145741e271872a424e0ad1331/fx5.sml","file-basename":"fx5","filename":"fx5.sml","extension":"sml","filesize":"15239","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220309838-fx1_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx1/HIGHRES/image/jpeg/ed169733e266c387298186dada47bbae/fx1_lrg.jpg","file-basename":"fx1","filename":"fx1_lrg.jpg","extension":"jpg","filesize":"14883","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"},{"attachment-eid":"1-s2.0-S0925231220309838-fx2_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx2/HIGHRES/image/jpeg/f2f45dbdd96160f109305e8e5e5f1d7b/fx2_lrg.jpg","file-basename":"fx2","filename":"fx2_lrg.jpg","extension":"jpg","filesize":"15373","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"},{"attachment-eid":"1-s2.0-S0925231220309838-fx3_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx3/HIGHRES/image/jpeg/7864a7482642cdb1445820cbd8e3a0bb/fx3_lrg.jpg","file-basename":"fx3","filename":"fx3_lrg.jpg","extension":"jpg","filesize":"22752","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"},{"attachment-eid":"1-s2.0-S0925231220309838-fx4_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx4/HIGHRES/image/jpeg/c5d2430616e7dd996dd4984ba34eb3b9/fx4_lrg.jpg","file-basename":"fx4","filename":"fx4_lrg.jpg","extension":"jpg","filesize":"13545","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"},{"attachment-eid":"1-s2.0-S0925231220309838-fx5_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx5/HIGHRES/image/jpeg/9e49feb3d4b3d576910851109f62f819/fx5_lrg.jpg","file-basename":"fx5","filename":"fx5_lrg.jpg","extension":"jpg","filesize":"18630","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"}]},"body":{},"chapters":{"toc":[],"isLoading":false},"changeViewLinks":{"showFullTextLink":true,"showAbstractLink":false},"citingArticles":{"hitCount":263,"viewMoreUrl":"http://www.scopus.com/scopus/inward/citedby.url?partnerID=10&rel=3.0.0&eid=2-s2.0-85087331607&md5=ba6a1756cbf7d149f11ac631079ec6a","articles":[{"articleTitle":"Emotion recognition and artificial intelligence: A systematic review (2014–2023) and research recommendations","authors":"Khare S.K., Blanes-Vidal V., Acharya U.R.","doi":"10.1016/j.inffus.2023.102019","externalArticle":false,"issn":"15662535","openAccess":1,"pii":"S1566253523003354","publicationDate":"2024-02-01","publicationTitle":"Information Fusion","publicationYear":"2024","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85171873155&md5=43d3ca4dce89cf8b0b942d554ef41da","scopusEid":"2-s2.0-85171873155","thirdParty":false,"volume":"Volume 102","abstract":{"$$":[{"$$":[{"$":{"id":"d1e11283"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"d1e11286"},"#name":"simple-para","_":"Emotion recognition is the ability to precisely infer human emotions from numerous sources and modalities using questionnaires, physical signals, and physiological signals. Recently, emotion recognition has gained attention because of its diverse application areas, like affective computing, healthcare, human–robot interactions, and market research. This paper provides a comprehensive and systematic review of emotion recognition techniques of the current decade. The paper includes emotion recognition using physical and physiological signals. Physical signals involve speech and facial expression, while physiological signals include electroencephalogram, electrocardiogram, galvanic skin response, and eye tracking. The paper provides an introduction to various emotion models, stimuli used for emotion elicitation, and the background of existing automated emotion recognition systems. This paper covers comprehensive searching and scanning of well-known datasets followed by design criteria for review. After a thorough analysis and discussion, we selected 142 journal articles using PRISMA guidelines. The review provides a detailed analysis of existing studies and available datasets of emotion recognition. Our review analysis also presented potential challenges in the existing literature and directions for future research."}],"$":{"view":"all","id":"d1e11285"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e11282","class":"author"},"#name":"abstract"},{"$$":[{"$":{"id":"d1e11289"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"d1e11298"},"#name":"para","_":"A systematic review of emotion recognition comprising journal articles of the last decade culled from renowned databases."}],"$":{"id":"d1e11295"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"d1e11303"},"#name":"para","_":"Inclusion of physical and physiological signals used for emotion recognition using artificial intelligence."}],"$":{"id":"d1e11300"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"d1e11308"},"#name":"para","_":"A detailed examination of fine-grained emotion recognition research, including resources, approaches, and datasets."}],"$":{"id":"d1e11305"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"d1e11313"},"#name":"para","_":"Identifying research gaps and future research directions for emotion recognition."}],"$":{"id":"d1e11310"},"#name":"list-item"}],"$":{"id":"d1e11294"},"#name":"list"}],"$":{"view":"all","id":"d1e11292"},"#name":"simple-para"}],"$":{"view":"all","id":"d1e11291"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e11288","class":"author-highlights"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"}},{"articleTitle":"A hybrid approach for forecasting ship motion using CNN–GRU–AM and GCWOA","authors":"Li M., Xu D., Hong W.C.","doi":"10.1016/j.asoc.2021.108084","externalArticle":false,"issn":"15684946","openAccess":0,"pii":"S1568494621009832","publicationDate":"2022-01-01","publicationTitle":"Applied Soft Computing","publicationYear":"2022","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85120372801&md5=4b629cd49ac1598789a41f43809ecceb","scopusEid":"2-s2.0-85120372801","thirdParty":false,"volume":"Volume 114","abstract":{"$$":[{"$$":[{"$":{"id":"d1e1274"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"d1e1277"},"#name":"simple-para","_":"The motion of a ship, which has six degrees of freedom, is a complex nonlinear dynamic process with variable periodicity and chaotic characteristics. With the development of smart ships, modern high-precision equipment needs the help from high accuracy of ship motion (SHM) forecasting. Existing models will not easily be able to satisfy future accuracy requirements. Therefore, to improve the accuracy of SHM forecasts, by firstly determining the sequence features of SHM time series, a convolutional neural network (CNN) was used herein to extract automatically spatial feature vectors. Considering the variable-period characteristics of SHM time series, a gated recurrent unit (GRU) was used to learn the inherent time characteristics and to extract temporal feature vectors. The attention mechanism (AM) was developed to control the effect of feature vectors on the output to solve the problem of the contribution of feature vectors. Integrating the above methods, an SHM hybrid forecasting model, the SHM CNN–GRU–AM (SHM-C&G&A) model, was established. Secondly, in view of the difficulty of selecting the hyperparameters of a hybrid model, on account of the defects of the whale optimization algorithm (WOA), a normal cloud local search (NCLS) algorithm was developed. Exploiting the advantages of the normal cloud search (NCS) and the genetic algorithm (GA), a genetic random global search (GRGS) algorithm was developed. Then, a hybrid genetic cloud whale optimization algorithm (GCWOA) was developed and used to optimize the hyperparameters of the SHM-C&G&A model. Accordingly, a hybrid forecasting approach that integrates SHM-C&G&A and GCWOA was proposed; it is referred to as GCWOA-SHM-C&G&A. Finally, ship heave and pitch time series data are used to analyze an example to test the forecasting effectiveness of SHM-C&G&A and the optimization performance of GCWOA. The experimental results reveal that the proposed SHM-C&G&A model is more robust that the other models that are considered in this paper, and exhibits better nonlinear characteristics. The proposed GCWOA yields a better combination of hyperparameters than contrast algorithms in the forecasting process."}],"$":{"view":"all","id":"d1e1276"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e1273","class":"author"},"#name":"abstract"},{"$$":[{"$":{"id":"d1e1291"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"d1e1300"},"#name":"para","_":"A ship motion (SHM) forecasting model was established, namely SHM-C&G&A model."}],"$":{"id":"d1e1297"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"d1e1305"},"#name":"para","_":"The paper constructed a hybrid genetic cloud whale optimization algorithm (GCWOA)."}],"$":{"id":"d1e1302"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"d1e1310"},"#name":"para","_":"The proposed model shows stronger robustness with the enhancement of nonlinear characteristics."}],"$":{"id":"d1e1307"},"#name":"list-item"}],"$":{"id":"d1e1296"},"#name":"list"}],"$":{"view":"all","id":"d1e1294"},"#name":"simple-para"}],"$":{"view":"all","id":"d1e1293"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e1290","class":"author-highlights"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"}},{"articleTitle":"Distract Your Attention: Multi-Head Cross Attention Network for Facial Expression Recognition","authors":"Wen Z., Lin W., Xu G.","doi":"10.3390/biomimetics8020199","externalArticle":true,"openAccess":0,"publicationDate":"June 2023","publicationTitle":"Biomimetics","publicationYear":"2023","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85163797016&md5=7372ebcdd1aa22b2658a37e9769d76ec","scopusEid":"2-s2.0-85163797016","thirdParty":false,"volume":"Volume 8","abstract":{}},{"articleTitle":"Deep Learning-Based IoT System for Remote Monitoring and Early Detection of Health Issues in Real-Time","authors":"Islam M.R., Kabir M.M., Che D.","doi":"10.3390/s23115204","externalArticle":true,"openAccess":0,"publicationDate":"June 2023","publicationTitle":"Sensors","publicationYear":"2023","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85161608834&md5=143244c6d5d8ca94dd95f353cdd451e","scopusEid":"2-s2.0-85161608834","thirdParty":false,"volume":"Volume 23","abstract":{}},{"articleTitle":"Facial Expression Recognition With Visual Transformers and Attentional Selective Fusion","authors":"Ma F., Sun B., Li S.","doi":"10.1109/TAFFC.2021.3122146","externalArticle":true,"openAccess":0,"page":"1236-1248","publicationDate":"1 April 2023","publicationTitle":"IEEE Transactions on Affective Computing","publicationYear":"2023","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85118543968&md5=2ccfeec17b48b88b6a36c685af839ca","scopusEid":"2-s2.0-85118543968","thirdParty":false,"volume":"Volume 14","abstract":{}},{"articleTitle":"Emotion Recognition of Students Based on Facial Expressions in Online Education Based on the Perspective of Computer Simulation","authors":"Wang W., Xu K., Miao X.","doi":"10.1155/2020/4065207","externalArticle":true,"openAccess":0,"publicationDate":"2020","publicationTitle":"Complexity","publicationYear":"2020","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85091872115&md5=b7b6e6d8273233e64813bbbc7984239","scopusEid":"2-s2.0-85091872115","thirdParty":false,"volume":"Volume 2020","abstract":{}}]},"combinedContentItems":{"content":[{"#name":"keywords","$$":[{"#name":"keywords","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:xoe":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"class":"keyword","id":"kg005","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st010"},"_":"Keywords"},{"#name":"keyword","$":{"id":"k0005"},"$$":[{"#name":"text","_":"Facial Expression Recognition"}]},{"#name":"keyword","$":{"id":"k0010"},"$$":[{"#name":"text","_":"Convolutional Neural Network"}]},{"#name":"keyword","$":{"id":"k0015"},"$$":[{"#name":"text","_":"Attention Mechanism"}]},{"#name":"keyword","$":{"id":"k0020"},"$$":[{"#name":"text","_":"Local Binary Patten"}]},{"#name":"keyword","$":{"id":"k0025"},"$$":[{"#name":"text","_":"Image Classification"}]}]}]},{"#name":"miscellaneous","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:xoe":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"ms005"},"_":"Communicated by Y. Liu"}],"floats":[],"footnotes":[],"attachments":[]},"crossMark":{"isOpen":false},"domainConfig":{"cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1"},"downloadIssue":{"openOnPageLoad":false,"isOpen":false,"downloadCapOpen":false,"articles":[],"selected":[]},"enrichedContent":{"tableOfContents":false,"researchData":{"hasResearchData":false,"dataProfile":{},"openData":{},"mendeleyData":{},"databaseLinking":{}},"geospatialData":{"attachments":[]},"interactiveCaseInsights":{},"virtualMicroscope":{}},"entitledRecommendations":{"openOnPageLoad":false,"isOpen":false,"articles":[],"selected":[],"currentPage":1,"totalPages":1},"exam":{},"helpText":{"keyDates":{"html":"<div class=\"key-dates-help\"><h3 class=\"u-margin-s-bottom u-h4\">Publication milestones</h3><p class=\"u-margin-m-bottom\">The dates displayed for an article provide information on when various publication milestones were reached at the journal that has published the article. Where applicable, activities on preceding journals at which the article was previously under consideration are not shown (for instance submission, revisions, rejection).</p><p class=\"u-margin-xs-bottom\">The publication milestones include:</p><ul class=\"key-dates-help-list u-margin-m-bottom u-padding-s-left\"><li><span class=\"u-text-italic\">Received</span>: The date the article was originally submitted to the journal.</li><li><span class=\"u-text-italic\">Revised</span>: The date the most recent revision of the article was submitted to the journal. Dates corresponding to intermediate revisions are not shown.</li><li><span class=\"u-text-italic\">Accepted</span>: The date the article was accepted for publication in the journal.</li><li><span class=\"u-text-italic\">Available online</span>: The date a version of the article was made available online in the journal.</li><li><span class=\"u-text-italic\">Version of Record</span>: The date the finalized version of the article was made available in the journal.</li></ul><p>More information on publishing policies can be found on the <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://www.elsevier.com/about/policies-and-standards/publishing-ethics\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">Publishing Ethics Policies</span></span></a> page. View our <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://www.elsevier.com/researcher/author/submit-your-paper\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">Publishing with Elsevier: step-by-step</span></span></a> page to learn more about the publishing process. For any questions on your own submission or other questions related to publishing an article, <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://service.elsevier.com/app/phone/supporthub/publishing\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">contact our Researcher support team.</span></span></a></p></div>","title":"What do these dates mean?"}},"glossary":{},"issueNavigation":{"previous":{},"next":{}},"linkingHubLinks":{},"metrics":{"metricGroup":{"citations":[],"captures":[],"mentions":[],"socialMedia":[]},"isLoading":false,"error":false},"preview":{"content":[{"#name":"introduction","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0005","view":"all"},"$$":[{"#name":"label","_":"1"},{"#name":"section-title","$":{"id":"st015"},"_":"Introduction"},{"#name":"para","$":{"id":"p0005","view":"all"},"_":"Facial expression is one of the most direct signals to express inner feelings in people's daily communication. The physical or mental state of a person at one time can be obtained by analyzing facial expressions. Therefore, facial expression recognition is of great significance in autopilot, human–computer interaction, medical treatment and other fields related to facial expression, and has gradually become a more and more important research direction. In machine learning, a variety of facial expression recognition algorithms have been proposed. Due to the complexity, diversity, occlusion, lighting and other challenges in facial expression recognition, the recognition accuracy in practical applications is still unsatisfactory."},{"#name":"para","$":{"id":"p0010","view":"all"},"_":"In this paper, our goal is to design a recognition model that can automatically and accurately recognize different expressions in various types of images. Generally, the process of facial expression recognition consists of the following steps: i) pre-processing of the facial expression data; ii) feature extraction of facial expressions; and iii) classification of facial expressions. The process is depicted in Fig. 1. We usually consider two kinds of features, namely, facial features and face model features. The facial features are specific points on the face, like eyes, mouth, and eyebrows; the face model features are the features used to model the face. Therefore, there are several ways for facial representation, like using the whole face to get the holistic representation, using specific points for local representation, and combining different points to get a hybrid approach. The final step is to define some set of categories to which the expression belongs."},{"#name":"para","$":{"id":"p0015","view":"all"},"_":"When dealing with expression recognition as a classification problem, traditional methods often use hand-crafted features such as Local Binary Patterns (LBP) and traditional machine learning algorithms such as Support Vector Machine (SVM) to classify. These methods may work well on datasets collected under laboratory conditions, but with the introduction of more challenging expression datasets in uncontrollable environments (e.g., FER2013), they cannot effectively achieve this task. Fortunately, deep learning has made a breakthrough in convenience and effectiveness since it has been used to deal with the image classification problem."},{"#name":"para","$":{"id":"p0020","view":"all"},"_":"The attention mechanism has been widely used in various computer vision tasks such as saliency detection [15], crowd counting [16] and facial expression recognition [38]. The operation can select the most useful features for classification by learning an intermediate attention map and then applying element-wise product on attention maps and source feature maps to weight the importance of different features. For the task of facial expression recognition, the features that are useful for recognition are mainly in some key parts such as eyes, nose and mouth. The attention mechanism increases the weights of these key features and helps improve the expression recognition results."},{"#name":"para","$":{"id":"p0025","view":"all"},"_":"In this paper, we design a novel Convolutional Neural Network with an attention model for recognizing facial expressions. In [43], it showed that using LBP features is better than using HOG and Gabor features because LBP can achieve rotation invariance and grey-scale invariance and thus is suitable for extracting texture features at different scales and can solve the imbalance of displacement, rotation angles and illumination conditions in facial images. In addition, LBP features can reflect fine facial changes in skin textures like wrinkles and furrows, which shows the changes of expressions. In [38], an end-to-end network with an attention model was presented for facial expression recognition. The attention module makes the network focus more on useful features which are vital for expression recognition by increasing the weights of these features. This makes the network recognize expressions more efficiently. Inspired by [38], [43], we combine LBP features with an attention model for facial expression recognition. Embedding the attention model into the network allows the network to pay different attention and weight to different parts of the input data. This can make the neural network pay more attention to useful features, which is vital to expression recognition. Furthermore, we combine LBP features with convolution features to improve our recognition results. The proposed method has been tested on five facial expression datasets, which are CK+ [11], JAFFE [13], FER2013 [39], Oulu-CASIA [25], and our self-collected Nanchang University Facial Expression (NCUFE)."},{"#name":"para","$":{"id":"p0030","view":"all"},"_":"To verify the effectiveness of our algorithm, we collected a new facial expression dataset called NCUFE. The dataset consists of seven expressions (i.e., anger, disgust, fear, happiness, sadness, surprise and neutral). We collected these facial expression images from 35 graduate students (6 females and 29 males) by a Microsoft Kinect sensor for acquiring both RGB images and depth images. The sample images are shown in Fig. 2. For each student, the size of these two types of images is 1280*1024 and 512*424, respectively. For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. During the process of image capture, the students sat on a chair in front of the Kinect and faced the camera. The distance between the face and the Kinect was about 100 cm. We asked each student to look the expression examples printed on some pieces of paper and then make seven expressions."},{"#name":"para","$":{"id":"p0035","view":"all"},"$$":[{"#name":"__text__","_":"The main contributions of this paper are as follows:"},{"#name":"list","$":{"id":"l0005"},"$$":[{"#name":"list-item","$":{"id":"o0005"},"$$":[{"#name":"label","_":"1)"},{"#name":"para","$":{"id":"p0040","view":"all"},"_":"We introduce a novel facial expression recognition method with attention mechanism. Not only raw images, but also LBP features are added to the attention layers of the network. LBP features contain texture information and can reflect fine facial changes in skin textures, which can help distinguish expressions with subtle difference."}]},{"#name":"list-item","$":{"id":"o0010"},"$$":[{"#name":"label","_":"2)"},{"#name":"para","$":{"id":"p0045","view":"all"},"_":"We collected and labelled a new dataset named Nanchang University Facial Expression (NCUFE) for facial expression recognition. The dataset includes 490 image sequence collected from 35 subjects labeled with seven facial expressions (i.e., anger, disgust, fear, happiness, sadness, surprise and neutral). For each subject, we captured both RGB images and depth images."}]},{"#name":"list-item","$":{"id":"o0015"},"$$":[{"#name":"label","_":"3)"},{"#name":"para","$":{"id":"p0050","view":"all"},"_":"We implement substantial experiments on five different datasets, as shown in Fig. 3. There are not only datasets collected under laboratory conditions, such as CK+, JAFFE, Oulu-CASIA and NCUFE, but also those collected in real world like FER2013. We also compare the model performance with some state-of-the-art expression recognition algorithms, and the results show that our model is superior."}]}]}]},{"#name":"para","$":{"id":"p0055","view":"all"},"_":"The remainder of this paper is as follows. In Section 2, we introduce the related works in expression recognition and the existing algorithms. In Section 3, we describe the proposed method in detail. We describe our experimental process and results on different datasets and compare them with the results of the state-of-the-art algorithms in Section 4. We give a conclusion of the whole paper in Section 5."}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0010","view":"all"},"$$":[{"#name":"label","_":"2"},{"#name":"section-title","$":{"id":"st020"},"_":"Related works"},{"#name":"para","$":{"id":"p0060","view":"all"},"_":"Traditional facial feature extraction algorithms can be separated into two categories: 1) geometric-based methods, such as Active Appearance Models (AAM) [17]; and 2) appearance-based methods, such as LBP [9] and Gabor Wavelet Representation [21]. After feature description, the features are fed into a classifier, such as SVM [22] and K-nearest Neighbors (KNN) [24], for recognizing different facial expressions. Therefore, the performance of the classifier depends to a large extent on the quality "}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0015","view":"all"},"$$":[{"#name":"label","_":"3"},{"#name":"section-title","$":{"id":"st025"},"_":"The proposed method"},{"#name":"section","$":{"id":"s0020","view":"all"},"$$":[{"#name":"label","_":"3.1"},{"#name":"section-title","$":{"id":"st030"},"_":"Network architecture"},{"#name":"para","$":{"id":"p0090","view":"all"},"_":"In this section, we introduce our newly proposed convolutional neural network with attention mechanism for automatically recognizing facial expressions. The new network consists of four parts, i.e., the feature extraction module, the attention module, the reconstruction module and the classification module. The architecture starts from the feature extraction module composed of two separate CNN processing streams: one is for raw images and the other is for LBP feature maps. Our model uses pure"}]}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0040","view":"all"},"$$":[{"#name":"label","_":"4"},{"#name":"section-title","$":{"id":"st050"},"_":"Experimental results"},{"#name":"para","$":{"id":"p0150","view":"all"},"_":"In this work, we design a novel deep Convolutional Neural Network with an attention model to automatically recognizing facial expressions. Except for the famous facial expression datasets such as CK+ [11], JAFFE [13], Oulu-CASIA [25] and FER2013 [39], we also evaluate our proposed method on our self-collected dataset NCUFE. Because CK+, JAFFE, Oulu-CASIA and NCUFE do not provide specified training and testing sets, we employ 5-fold cross-validation protocol in these four datasets. The proposed"}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0080","view":"all"},"$$":[{"#name":"label","_":"5"},{"#name":"section-title","$":{"id":"st090"},"_":"Conclusions and future work"},{"#name":"para","$":{"id":"p0195","view":"all"},"_":"This paper presents a novel convolutional neural network with attention mechanism for facial expression recognition. The method fuses LBP features and convolution features, and then is combined with attention mechanism to improve the performance of the network. In order to prevent overfitting and ensure the generalization ability of the network, we apply data augmentation in the datasets we used in the experiments. In addition, we collected a new dataset called Nanchang University Facial"}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0090","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st100"},"_":"CRediT authorship contribution statement"},{"#name":"para","$":{"id":"p0210","view":"all"},"$$":[{"#name":"bold","_":"Jing Li:"},{"#name":"__text__","_":" Conceptualization, Methodology, Writing - original draft. "},{"#name":"bold","_":"Kan Jin:"},{"#name":"__text__","_":" . "},{"#name":"bold","_":"Dalin Zhou:"},{"#name":"__text__","_":" . "},{"#name":"bold","_":"Naoyuki Kubota:"},{"#name":"__text__","_":" Writing - review & editing. "},{"#name":"bold","_":"Zhaojie Ju:"},{"#name":"__text__","_":" Conceptualization, Methodology, Writing - original draft."}]}]}]},{"#name":"section","$$":[{"#name":"conflict-of-interest","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"coi005","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st105"},"_":"Declaration of Competing Interest"},{"#name":"para","$":{"id":"p0215","view":"all"},"_":"The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper."}]}]},{"#name":"section","$$":[{"#name":"acknowledgment","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"ak005","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st110"},"_":"Acknowledgements"},{"#name":"para","$":{"id":"p0220","view":"all"},"$$":[{"#name":"__text__","_":"This work is supported by "},{"#name":"grant-sponsor","$":{"id":"gp005","sponsor-id":"https://doi.org/10.13039/501100001809","role":"http://www.elsevier.com/xml/linking-roles/grant-sponsor","type":"simple"},"_":"National Natural Science Foundation of China"},{"#name":"__text__","_":" under Grant "},{"#name":"grant-number","$":{"refid":"gp005"},"_":"61963027"},{"#name":"__text__","_":", "},{"#name":"grant-number","$":{"refid":"gp005"},"_":"61703198"},{"#name":"__text__","_":", and "},{"#name":"grant-number","$":{"refid":"gp005"},"_":"51575412"},{"#name":"__text__","_":", Natural Science Foundation for Distinguished Young Scholars of Jiangxi Province under Grant "},{"#name":"grant-number","$":{"refid":"gp005"},"_":"2018ACB21014"},{"#name":"__text__","_":"."}]}]}]},{"#name":"section","$$":[{"#name":"biography","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg005","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00045","locator":"fx1","href":"pii:S0925231220309838/fx1","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0010","view":"all"},"_":"Jing Li received the B.E. degree in Electronic Information Engineering from Nanchang University, China, in 2005, and obtained her PhD degree in Electronic and Electrical Engineering from the University of Sheffield, UK, in 2011. From 2011 to 2012, she was a Research Associate with the Department of Computer Science at the University of Sheffield. Currently, she is an Associate Professor with the School of Information Engineering at Nanchang University. Her research interests include visual"}]}]}],"floats":[],"footnotes":[],"attachments":[]},"rawtext":"","recommendations":{"articles":[{"pii":"S0925231215001605","doi":"10.1016/j.neucom.2015.02.011","journalTitle":"Neurocomputing","publicationYear":"2015","publicationDate":"2015-07-02","volumeSupText":"Volume 159","articleNumber":"","pageRange":"126-136","trace-token":"AAAAQEomoRCHqPdFztJJX21UddXDA92oern-USeCwxBD5HQH8B6sD3CgVUsme7Y3Z58edCbM-GRut9H8VAuMF-W0bi1RMg41ptKz53KqT6tV2fxG2bN82Q","authors":{"content":[{"#name":"author-group","$":{"id":"ag0005"},"$$":[{"#name":"author","$":{"id":"au0005","biographyid":"bio0005"},"$$":[{"#name":"given-name","_":"Mengyi"},{"#name":"surname","_":"Liu"}]},{"#name":"author","$":{"id":"au0010","biographyid":"bio0010"},"$$":[{"#name":"given-name","_":"Shaoxin"},{"#name":"surname","_":"Li"}]},{"#name":"author","$":{"id":"au0015","biographyid":"bio0015"},"$$":[{"#name":"given-name","_":"Shiguang"},{"#name":"surname","_":"Shan"},{"#name":"cross-ref","$":{"id":"cr03410","refid":"cor1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"id":"eadd0005","type":"email"},"_":"sgshan@ict.ac.cn"}]},{"#name":"author","$":{"id":"au0020","biographyid":"bio0020"},"$$":[{"#name":"given-name","_":"Xilin"},{"#name":"surname","_":"Chen"}]},{"#name":"affiliation","$":{"id":"aff0005"},"$$":[{"#name":"textfn","_":"Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS"},{"#name":"city","_":"Beijing"},{"#name":"postal-code","_":"100190"},{"#name":"country","_":"China"}]}]},{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au0020","biographyid":"bio0020"},"$$":[{"#name":"given-name","_":"Xilin"},{"#name":"surname","_":"Chen"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"tit0005"},"_":"AU-inspired Deep Networks for Facial Expression Feature Learning"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"159","isThirdParty":false,"language":"en","issn-primary-unformatted":"09252312","issn-primary-formatted":"0925-2312"},{"pii":"S0925231218303266","doi":"10.1016/j.neucom.2018.03.034","journalTitle":"Neurocomputing","publicationYear":"2018","publicationDate":"2018-06-28","volumeSupText":"Volume 296","articleNumber":"","pageRange":"12-22","trace-token":"AAAAQEomoRCHqPdFztJJX21UddVH2Dm88-OCu0mp1fhKkZTWaffdRQ_FbJAIgPVvdoS3XL3eKUyR9y96EHEOuymcE3N3huJExrRfnuzWJG6POQeT2T5UAA","authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","biographyid":"b1","author-id":"S0925231218303266-97aae119f322f5cd5f087c74f3c17c4c"},"$$":[{"#name":"given-name","_":"Wenyun"},{"#name":"surname","_":"Sun"},{"#name":"cross-ref","$":{"id":"crf0031","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"id":"au0002","biographyid":"b2","author-id":"S0925231218303266-4b3b53f3187bc4e45d0997445a041e03"},"$$":[{"#name":"given-name","_":"Haitao"},{"#name":"surname","_":"Zhao"},{"#name":"cross-ref","$":{"id":"crf0032","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]},{"#name":"author","$":{"id":"au0003","biographyid":"b3","author-id":"S0925231218303266-ef4dc0c462815be81863818509f5f13e","orcid":"0000-0002-4293-0869"},"$$":[{"#name":"given-name","_":"Zhong"},{"#name":"surname","_":"Jin"},{"#name":"cross-ref","$":{"id":"crf0033","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"cross-ref","$":{"id":"crf0034","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:zhongjin@njust.edu.cn","id":"ead0001"},"_":"zhongjin@njust.edu.cn"}]},{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0925231218303266-7f5947cf0b156760d3e864eaa6b1a3c2"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"School of Computer Science and Engineering, Nanjing University of Science and Technology, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Computer Science and Engineering"},{"#name":"organization","_":"Nanjing University of Science and Technology"},{"#name":"country","_":"China"}]}]},{"#name":"affiliation","$":{"id":"aff0002","affiliation-id":"S0925231218303266-bdc8e8b9d297139665d9e059dd2953b7"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","$":{"id":"cetextfn0002"},"_":"School of Information Science and Engineering, East China University of Science and Technology, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Information Science and Engineering"},{"#name":"organization","_":"East China University of Science and Technology"},{"#name":"country","_":"China"}]}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cor1"},"_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au0003","biographyid":"b3","author-id":"S0925231218303266-ef4dc0c462815be81863818509f5f13e","orcid":"0000-0002-4293-0869"},"$$":[{"#name":"given-name","_":"Zhong"},{"#name":"surname","_":"Jin"},{"#name":"cross-ref","$":{"id":"crf0033","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"cross-ref","$":{"id":"crf0034","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:zhongjin@njust.edu.cn","id":"ead0001"},"_":"zhongjin@njust.edu.cn"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"ct0001"},"_":"A visual attention based ROI detection method for facial expression recognition"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"296","isThirdParty":false,"language":"en","issn-primary-unformatted":"09252312","issn-primary-formatted":"0925-2312"},{"pii":"S0167865517303902","doi":"10.1016/j.patrec.2017.10.022","journalTitle":"Pattern Recognition Letters","publicationYear":"2019","publicationDate":"2019-03-01","volumeSupText":"Volume 119","articleNumber":"","pageRange":"49-61","trace-token":"AAAAQEomoRCHqPdFztJJX21UddULBUPIkCQrXXtMWGLgaJBT_AUpiGSQMSGOrQlP0ZIASrIDkoqN5hDmGOW4C7RYV2vKX3m2LD3f9bB0wCJsrDVVmc5J0w","authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","author-id":"S0167865517303902-a171207aab44d338ff492bf69ceb2af0","orcid":"0000-0002-6907-3756"},"$$":[{"#name":"given-name","_":"Ning"},{"#name":"surname","_":"Sun"},{"#name":"cross-ref","$":{"id":"crf0001","refid":"cor0001"},"_":"*"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0001","type":"email","href":"mailto:sunning@njupt.edu.cn"},"_":"sunning@njupt.edu.cn"}]},{"#name":"author","$":{"id":"au0002","author-id":"S0167865517303902-e50392b846f7aad5c7d60f74457fb8f2"},"$$":[{"#name":"surname","_":"Li"},{"#name":"given-name","_":"Qi"}]},{"#name":"author","$":{"id":"au0003","author-id":"S0167865517303902-d302f6b5cda9933b015da80bce88ad55"},"$$":[{"#name":"given-name","_":"Ruizhi"},{"#name":"surname","_":"Huan"}]},{"#name":"author","$":{"id":"au0004","author-id":"S0167865517303902-018cf1fd6d69d800bd8eecdd7808021e"},"$$":[{"#name":"given-name","_":"Jixin"},{"#name":"surname","_":"Liu"}]},{"#name":"author","$":{"id":"au0005","author-id":"S0167865517303902-88992248ea3c8cfe79e051366d26ff88"},"$$":[{"#name":"given-name","_":"Guang"},{"#name":"surname","_":"Han"}]},{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0167865517303902-37e94b859cc1a5e45a35803c1e20df8f"},"$$":[{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"Engineering Research Center of Wideband Wireless Communication Technology, Ministry of Education, Nanjing University of Posts and Telecommunications, Nanjing 210003, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Engineering Research Center of Wideband Wireless Communication Technology"},{"#name":"organization","_":"Ministry of Education"},{"#name":"organization","_":"Nanjing University of Posts and Telecommunications"},{"#name":"city","_":"Nanjing"},{"#name":"postal-code","_":"210003"},{"#name":"country","_":"China"}]}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cetext0001"},"_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au0005","author-id":"S0167865517303902-88992248ea3c8cfe79e051366d26ff88"},"$$":[{"#name":"given-name","_":"Guang"},{"#name":"surname","_":"Han"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"tte0001"},"_":"Deep spatial-temporal feature fusion for facial expression recognition in static images"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"sco","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"119","isThirdParty":false,"language":"en","issn-primary-unformatted":"01678655","issn-primary-formatted":"0167-8655"},{"pii":"S0925231218311342","doi":"10.1016/j.neucom.2018.09.061","journalTitle":"Neurocomputing","publicationYear":"2018","publicationDate":"2018-12-17","volumeSupText":"Volume 322","articleNumber":"","pageRange":"130-140","trace-token":"AAAAQEomoRCHqPdFztJJX21UddVH2Dm88-OCu0mp1fhKkZTWp7awdiU4oCSq735TwEZJSOWiaWd5Moivy4yPNdw_F5gzdy6UG9TZ4RzUhk0HhVWEbJNxKA","authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","biographyid":"b1","author-id":"S0925231218311342-e8503e056476df49bc53e068b7e183b1"},"$$":[{"#name":"given-name","_":"Yuzhu"},{"#name":"surname","_":"Ji"},{"#name":"cross-ref","$":{"id":"crf0001","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"id":"au0002","biographyid":"b2","author-id":"S0925231218311342-fb3723e3c93b7690a7846410573b53fb"},"$$":[{"#name":"given-name","_":"Haijun"},{"#name":"surname","_":"Zhang"},{"#name":"cross-ref","$":{"id":"crf0002","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"cross-ref","$":{"id":"crf0003","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:hjzhang@hit.edu.cn","id":"ead0001"},"_":"hjzhang@hit.edu.cn"}]},{"#name":"author","$":{"id":"au0003","biographyid":"b3","author-id":"S0925231218311342-ae901d0b01bbf615da7cbcb7ba0d77f3"},"$$":[{"#name":"given-name","_":"Q.M."},{"#name":"surname","_":"Jonathan Wu"},{"#name":"cross-ref","$":{"id":"crf0004","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]},{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0925231218311342-bf2449da9889eb800834028a39ab0363"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"Department of Computer Science, Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Computer Science, Shenzhen Graduate School"},{"#name":"organization","_":"Harbin Institute of Technology"},{"#name":"city","_":"Shenzhen"},{"#name":"country","_":"China"}]}]},{"#name":"affiliation","$":{"id":"aff0002","affiliation-id":"S0925231218311342-ae686c8ef0db583ed81a275af0aa74c2"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","$":{"id":"cetextfn0002"},"_":"Department of Electrical and Computer Engineering, University of Windsor, Ontario, Canada"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Electrical and Computer Engineering"},{"#name":"organization","_":"University of Windsor"},{"#name":"city","_":"Ontario"},{"#name":"country","_":"Canada"}]}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cor1"},"_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au0003","biographyid":"b3","author-id":"S0925231218311342-ae901d0b01bbf615da7cbcb7ba0d77f3"},"$$":[{"#name":"given-name","_":"Q.M."},{"#name":"surname","_":"Jonathan Wu"},{"#name":"cross-ref","$":{"id":"crf0004","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"ct0001"},"_":"Salient object detection via multi-scale attention CNN"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"322","isThirdParty":false,"language":"en","issn-primary-unformatted":"09252312","issn-primary-formatted":"0925-2312"},{"pii":"S0167865521000489","doi":"10.1016/j.patrec.2021.01.029","journalTitle":"Pattern Recognition Letters","publicationYear":"2021","publicationDate":"2021-05-01","volumeSupText":"Volume 145","articleNumber":"","pageRange":"58-66","trace-token":"AAAAQEomoRCHqPdFztJJX21UddXRc9iWiUhHsHwj0xAF41VXCrTtwNHAIM1onkmsG2ptSv_uU7qs9t-MJjwN4deQZ1Dw8wxapcpFQutvhX_XnO0wpxODnw","authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","author-id":"S0167865521000489-045ab9a403d3d4873ab431a0873a4420"},"$$":[{"#name":"given-name","_":"Darshan"},{"#name":"surname","_":"Gera"},{"#name":"cross-ref","$":{"id":"crf0002","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"cross-ref","$":{"id":"crf0003","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ead0001","type":"email","href":"mailto:darshangera@sssihl.edu.in"},"_":"darshangera@sssihl.edu.in"}]},{"#name":"author","$":{"id":"au0002","author-id":"S0167865521000489-0ce32fb0bb07c0868763d7bb78bd03bb"},"$$":[{"#name":"given-name","_":"S"},{"#name":"surname","_":"Balasubramanian"},{"#name":"cross-ref","$":{"id":"crf0004","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]},{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0167865521000489-1dc63c1ab0bff15cab90d1304cec4d83"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","$":{"id":"textfn0001"},"_":"SSSIHL, DMACS, Brindavan, 560067, India"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"SSSIHL"},{"#name":"organization","_":"DMACS"},{"#name":"city","_":"Brindavan"},{"#name":"postal-code","_":"560067"},{"#name":"country","_":"India"}]},{"#name":"source-text","$":{"id":"st0001"},"_":"SSSIHL, DMACS, Brindavan, 560067, India"}]},{"#name":"affiliation","$":{"id":"aff0002","affiliation-id":"S0167865521000489-7bdaad32fd42c7af63924211a15b4707"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","$":{"id":"textfn0002"},"_":"SSSIHL, DMACS, Puttaparthi, 515134, India"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"SSSIHL"},{"#name":"organization","_":"DMACS"},{"#name":"city","_":"Puttaparthi"},{"#name":"postal-code","_":"515134"},{"#name":"country","_":"India"}]},{"#name":"source-text","$":{"id":"st0002"},"_":"SSSIHL, DMACS, Puttaparthi, 515134, India"}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cor1"},"_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au0002","author-id":"S0167865521000489-0ce32fb0bb07c0868763d7bb78bd03bb"},"$$":[{"#name":"given-name","_":"S"},{"#name":"surname","_":"Balasubramanian"},{"#name":"cross-ref","$":{"id":"crf0004","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"ct0001"},"_":"Landmark guidance independent spatio-channel attention and complementary context information based facial expression recognition"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"sco","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"145","isThirdParty":false,"language":"en","issn-primary-unformatted":"01678655","issn-primary-formatted":"0167-8655"},{"pii":"S1568494619307008","doi":"10.1016/j.asoc.2019.105919","journalTitle":"Applied Soft Computing","publicationYear":"2020","publicationDate":"2020-01-01","volumeSupText":"Volume 86","articleNumber":"105919","pageRange":"105919","trace-token":"AAAAQEomoRCHqPdFztJJX21UddXN3h2LRkoqCA4_9M4MQI8Sth9o-57sGiNGuMwwNrjVGaPDRPRuO7SsP_w_eOJZ2URk-x9238JKvB1CIkl8WX-HtPfHoQ","authors":{"content":[{"#name":"author-group","$":{"id":"d1e700"},"$$":[{"#name":"author","$":{"id":"au000001","author-id":"S1568494619307008-e880833c1f27997c7ce26fbb3cb7c893"},"$$":[{"#name":"given-name","_":"Yuanhang"},{"#name":"surname","_":"Chen"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea1","type":"email","href":"mailto:cyh.wne@gmail.com"},"_":"cyh.wne@gmail.com"}]},{"#name":"author","$":{"id":"au000002","author-id":"S1568494619307008-867e09acf237c4f53681fdaa1e525aef","orcid":"0000-0002-0911-830X"},"$$":[{"#name":"given-name","_":"Gaoliang"},{"#name":"surname","_":"Peng"},{"#name":"cross-ref","$":{"refid":"cor1","id":"d1e713"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea2","type":"email","href":"mailto:pgl7782@hit.edu.cn"},"_":"pgl7782@hit.edu.cn"}]},{"#name":"author","$":{"id":"au000003","author-id":"S1568494619307008-8a8bcbcb0ea5654c97ba5252b22085e6"},"$$":[{"#name":"given-name","_":"Zhiyu"},{"#name":"surname","_":"Zhu"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea3","type":"email","href":"mailto:zbzhzhy@gmail.com"},"_":"zbzhzhy@gmail.com"}]},{"#name":"author","$":{"id":"au000004","author-id":"S1568494619307008-71f2da4b4c2562294f17387e0715f191"},"$$":[{"#name":"given-name","_":"Sijue"},{"#name":"surname","_":"Li"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea4","type":"email","href":"mailto:lisijue@hit.edu.cn"},"_":"lisijue@hit.edu.cn"}]},{"#name":"affiliation","$":{"affiliation-id":"S1568494619307008-eada8f77ca611705c5cc22be88802548","id":"aff1"},"$$":[{"#name":"textfn","_":"State Key Laboratory of Robotics and System, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin 150001, Heilongjiang Province, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"State Key Laboratory of Robotics and System, Harbin Institute of Technology"},{"#name":"address-line","_":"No. 92 Xidazhi Street, Harbin 150001, Heilongjiang Province"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"afs46"},"_":"State Key Laboratory of Robotics and System, Harbin Institute of Technology, No. 92 Xidazhi Street, Harbin 150001, Heilongjiang Province, China"}]},{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au000004","author-id":"S1568494619307008-71f2da4b4c2562294f17387e0715f191"},"$$":[{"#name":"given-name","_":"Sijue"},{"#name":"surname","_":"Li"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea4","type":"email","href":"mailto:lisijue@hit.edu.cn"},"_":"lisijue@hit.edu.cn"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"d1e697"},"_":"A novel deep learning method based on attention mechanism for bearing remaining useful life prediction"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","pdf":{"urlType":null},"iss-first":"","vol-first":"86","isThirdParty":false,"language":"en","issn-primary-unformatted":"15684946","issn-primary-formatted":"1568-4946"}]},"references":{"content":[{"#name":"bibliography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bi005","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st115"},"_":"References"},{"#name":"bibliography-sec","$":{"id":"bs005","view":"all"},"$$":[{"#name":"bib-reference","$":{"id":"b0015"},"$$":[{"#name":"label","_":"[1]"},{"#name":"other-ref","$":{"id":"h0015","refId":"1"},"$$":[{"#name":"textref","_":"Y.-H. Lai, S.-H. Lai, Emotion-preserving representation learning via generative adversarial network for multi-view facial expression recognition, in: Automatic Face & Gesture Recognition (FG 2018), 2018 13th IEEE International Conference on. IEEE, 2018, pp. 263–270"}]}]},{"#name":"bib-reference","$":{"id":"b0020"},"$$":[{"#name":"label","_":"[2]"},{"#name":"other-ref","$":{"id":"h0020","refId":"2"},"$$":[{"#name":"textref","_":"A. Mollahosseini, D. Chan, M.H. Mahoor, Going deeper in facial expression recognition using deep neural networks, (2016) 1–10"}]}]},{"#name":"bib-reference","$":{"id":"b0025"},"$$":[{"#name":"label","_":"[3]"},{"#name":"other-ref","$":{"id":"h0025","refId":"3"},"$$":[{"#name":"textref","_":"C. Szegedy, W. Liu, Y. Jia, et al., Going deeper with convolutions, IEEE Conference on Computer Vision and Pattern Recognition. IEEE Computer Society, 2015, pp. 1–9."}]}]},{"#name":"bib-reference","$":{"id":"b0030"},"$$":[{"#name":"label","_":"[4]"},{"#name":"other-ref","$":{"id":"h0030","refId":"4"},"$$":[{"#name":"textref","_":"K. He, X. Zhang, S. Ren, et al., Deep residual learning for image recognition, (2015) 770–778"}]}]},{"#name":"bib-reference","$":{"id":"b0035"},"$$":[{"#name":"label","_":"[5]"},{"#name":"reference","$":{"id":"h0035","refId":"5"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"surname","_":"Sun"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Jin"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Z."},{"#name":"surname","_":"Zhao"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"An efficient unconstrained facial expression recognition algorithm based on stack binarized auto-encoders and binarized neural networks"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Neurocomputing"}]},{"#name":"volume-nr","_":"267"}]},{"#name":"date","_":"2017"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"385"},{"#name":"last-page","_":"395"}]}]}]},{"#name":"source-text","$":{"id":"stx025"},"_":"Sun, H. Zhao, Z. Jin, An efficient unconstrained facial expression recognition algorithm based on stack binarized auto-encoders and binarized neural networks, Neurocomputing 267 (2017) 385-395."}]},{"#name":"bib-reference","$":{"id":"b0040"},"$$":[{"#name":"label","_":"[6]"},{"#name":"other-ref","$":{"id":"h0040","refId":"6"},"$$":[{"#name":"textref","_":"C. Szegedy, S. Ioffe, V. Vanhoucke, et al., Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, 2016"}]}]},{"#name":"bib-reference","$":{"id":"b0045"},"$$":[{"#name":"label","_":"[7]"},{"#name":"other-ref","$":{"id":"h0045","refId":"7"},"$$":[{"#name":"textref","_":"B. Hasani, M.H. Mahoor, Spatio-temporal facial expression recognition using convolutional neural networks and conditional random fields, (2017) 790–795"}]}]},{"#name":"bib-reference","$":{"id":"b0050"},"$$":[{"#name":"label","_":"[8]"},{"#name":"reference","$":{"id":"h0050","refId":"8"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Z."},{"#name":"surname","_":"Yu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"G."},{"#name":"surname","_":"Liu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Q."},{"#name":"surname","_":"Liu"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Spatio-temporal convolutional features with nested LSTM for facial expression recognition[J]"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Neurocomputing"}]},{"#name":"volume-nr","_":"317"}]},{"#name":"date","_":"2018"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"50"},{"#name":"last-page","_":"57"}]}]}]},{"#name":"source-text","$":{"id":"stx030"},"_":"Yu Z, Liu G, Liu Q, et al. Spatio-temporal convolutional features with nested LSTM for facial expression recognition[J]. Neurocomputing, 2018, 317: 50-57."}]},{"#name":"bib-reference","$":{"id":"b0060"},"$$":[{"#name":"label","_":"[9]"},{"#name":"reference","$":{"id":"h0060","refId":"9"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"T."},{"#name":"surname","_":"Ojala"}]},{"#name":"author","$$":[{"#name":"given-name","_":"I."},{"#name":"surname","_":"Harwood"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A comparative study of texture measures with classification based on feature distributions"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Pattern Recogn."}]},{"#name":"volume-nr","_":"29"}]},{"#name":"issue-nr","_":"1"},{"#name":"date","_":"1996"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"51"},{"#name":"last-page","_":"59"}]}]}]},{"#name":"source-text","$":{"id":"stx035"},"_":"Ojala T, Harwood I. A Comparative Study of Texture Measures with Classification Based on Feature Distributions [J]. Pattern Recognition, 1996, 29(1):51-59."}]},{"#name":"bib-reference","$":{"id":"b0070"},"$$":[{"#name":"label","_":"[10]"},{"#name":"other-ref","$":{"id":"h0070","refId":"10"},"$$":[{"#name":"textref","_":"T. Ojala, M. Pietikinen, T. Menp, Multiresolution grayscale and rotation invariant texture classification with local binary patterns, IEEE PAMI, vol. 24, no. 7, 2002"}]}]},{"#name":"bib-reference","$":{"id":"b0075"},"$$":[{"#name":"label","_":"[11]"},{"#name":"other-ref","$":{"id":"h0075","refId":"11"},"$$":[{"#name":"textref","_":"P. Lucey, J.F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, I. Matthews, The extended cohn-kanade dataset (ck+): a complete dataset for action unit and emotion-specified expression, in: Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, IEEE, 2010, pp. 94–101."}]}]},{"#name":"bib-reference","$":{"id":"b0080"},"$$":[{"#name":"label","_":"[12]"},{"#name":"reference","$":{"id":"h0080","refId":"12"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"W."},{"#name":"surname","_":"Sun"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Zhao"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Z."},{"#name":"surname","_":"Jin"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A visual attention based ROI detection method for facial expression recognition"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Neurocomputing"}]},{"#name":"volume-nr","_":"296"}]},{"#name":"date","_":"2018"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"12"},{"#name":"last-page","_":"22"}]}]}]},{"#name":"source-text","$":{"id":"stx045"},"_":"Sun W, Zhao H, Jin Z. A visual attention based ROI detection method for facial expression recognition [J]. Neurocomputing, 2018, 296: 12-22."}]},{"#name":"bib-reference","$":{"id":"b0085"},"$$":[{"#name":"label","_":"[13]"},{"#name":"other-ref","$":{"id":"h0085","refId":"13"},"$$":[{"#name":"textref","_":"M. Lyons, S. Akamatsu, M. Kamachi, J. Gyoba, Coding facial expressions with Gabor wavelets, in: Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition, 1998, pp. 200–205"}]}]},{"#name":"bib-reference","$":{"id":"b0090"},"$$":[{"#name":"label","_":"[14]"},{"#name":"other-ref","$":{"id":"h0090","refId":"14"},"$$":[{"#name":"textref","_":"G. Huang, Z. Liu, K. Q. Weinberger, L. van der Maaten, Densely connected convolutional networks. arXiv preprint arXiv:1608.06993, 2016"}]}]},{"#name":"bib-reference","$":{"id":"b0095"},"$$":[{"#name":"label","_":"[15]"},{"#name":"other-ref","$":{"id":"h0095","refId":"15"},"$$":[{"#name":"textref","_":"T. Zhao, X. Wu, Pyramid feature attention network for saliency detection, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, 3085–3094"}]}]},{"#name":"bib-reference","$":{"id":"b0100"},"$$":[{"#name":"label","_":"[16]"},{"#name":"other-ref","$":{"id":"h0100","refId":"16"},"$$":[{"#name":"textref","_":"R.R. Varior, B. Shuai, J. Tighe, et al., Scale-Aware Attention Network for Crowd Counting. arXiv preprint arXiv:1901.06026, 2019."}]}]},{"#name":"bib-reference","$":{"id":"b0105"},"$$":[{"#name":"label","_":"[17]"},{"#name":"other-ref","$":{"id":"h0105","refId":"17"},"$$":[{"#name":"textref","_":"T.F. Cootes, G.J. Edwards, C.J. Taylor, Active appearance models, IEEE Trans. Pattern Anal. Mach. Intell. 23 (6) (2011) 6815"}]}]},{"#name":"bib-reference","$":{"id":"b0110"},"$$":[{"#name":"label","_":"[18]"},{"#name":"other-ref","$":{"id":"h0110","refId":"18"},"$$":[{"#name":"textref","_":"W. Wang, Q. Sun, T. Chen, et al., A Fine-Grained Facial Expression Database for End-to-End Multi-Pose Facial Expression Recognition, arXiv preprint arXiv:1907.10838, 2019."}]}]},{"#name":"bib-reference","$":{"id":"b0115"},"$$":[{"#name":"label","_":"[19]"},{"#name":"other-ref","$":{"id":"h0115","refId":"19"},"$$":[{"#name":"textref","_":"C.M. Kuo, S.H. Lai, M. Sarkis, A compact deep learning model for robust facial expression recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2018, pp. 2121–2129"}]}]},{"#name":"bib-reference","$":{"id":"b0120"},"$$":[{"#name":"label","_":"[20]"},{"#name":"other-ref","$":{"id":"h0120","refId":"20"},"$$":[{"#name":"textref","_":"C. Turan, K.M. Lam, X. He, Soft Locality Preserving Map (SLPM) for Facial Expression Recognition. arXiv preprint arXiv:1801.03754, 2018."}]}]},{"#name":"bib-reference","$":{"id":"b0125"},"$$":[{"#name":"label","_":"[21]"},{"#name":"other-ref","$":{"id":"h0125","refId":"21"},"$$":[{"#name":"textref","_":"Z. Zhang, M. Lyons, M. Schuster, S. Akamatsu, Comparison between geometry-based and Gabor-wavelets-based facial expression recognition using multi-layer perceptron, in Third IEEE International Conference on Automatic Face and Gesture Recognition, 1998. Proceedings, Nara 1998, pp. 454_9."}]}]},{"#name":"bib-reference","$":{"id":"b0130"},"$$":[{"#name":"label","_":"[22]"},{"#name":"reference","$":{"id":"h0130","refId":"22"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Cortes"}]},{"#name":"author","$$":[{"#name":"given-name","_":"V.N."},{"#name":"surname","_":"Vapnik"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Support vector networks"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Mach. Learn."}]},{"#name":"volume-nr","_":"20"}]},{"#name":"date","_":"1995"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"273"},{"#name":"last-page","_":"297"}]}]}]},{"#name":"source-text","$":{"id":"stx050"},"_":"C. Cortes, V.N. Vapnik, Support vector networks, Mach. Learn. 20 (1995) 273–297."}]},{"#name":"bib-reference","$":{"id":"b0135"},"$$":[{"#name":"label","_":"[23]"},{"#name":"reference","$":{"id":"h0135","refId":"23"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Zhang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Huang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Du"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Facial expression recognition based on deep evolutional spatial-temporal networks"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IEEE Trans. Image Process."}]},{"#name":"volume-nr","_":"26"}]},{"#name":"issue-nr","_":"9"},{"#name":"date","_":"2017"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"4193"},{"#name":"last-page","_":"4203"}]}]}]},{"#name":"source-text","$":{"id":"stx055"},"_":"Zhang K, Huang Y, Du Y, et al. Facial expression recognition based on deep evolutional spatial-temporal networks[J]. IEEE Transactions on Image Processing, 2017, 26(9): 4193-4203."}]},{"#name":"bib-reference","$":{"id":"b0140"},"$$":[{"#name":"label","_":"[24]"},{"#name":"other-ref","$":{"id":"h0140","refId":"24"},"$$":[{"#name":"textref","_":"T. Cover, P. Hart, Nearest neighbor pattern classification, IEEE Trans. Inform. Theor. 13 (1) (1967) pp. 21_7"}]}]},{"#name":"bib-reference","$":{"id":"b0145"},"$$":[{"#name":"label","_":"[25]"},{"#name":"reference","$":{"id":"h0145","refId":"25"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"G."},{"#name":"surname","_":"Zhao"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Huang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Taini"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Facial expression recognition from near-infrared videos"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Image Vision Comput."}]},{"#name":"volume-nr","_":"29"}]},{"#name":"issue-nr","_":"9"},{"#name":"date","_":"2011"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"607"},{"#name":"last-page","_":"619"}]}]}]},{"#name":"source-text","$":{"id":"stx060"},"_":"Zhao G, Huang X, Taini M, et al. Facial expression recognition from near-infrared videos[J]. Image and Vision Computing, 2011, 29(9): 607-619."}]},{"#name":"bib-reference","$":{"id":"b0150"},"$$":[{"#name":"label","_":"[26]"},{"#name":"other-ref","$":{"id":"h0150","refId":"26"},"$$":[{"#name":"textref","_":"Huiyuan Yang, Umur Ciftci, Lijun Yin, Facial expression recognition by de-expression residue learning, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018"}]}]},{"#name":"bib-reference","$":{"id":"b0155"},"$$":[{"#name":"label","_":"[27]"},{"#name":"other-ref","$":{"id":"h0155","refId":"27"},"$$":[{"#name":"textref","_":"P. Liu, S. Han, Z. Meng Y. Tong, Facial expression recognition via a boosted deep belief network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014, pp. 1805–1812"}]}]},{"#name":"bib-reference","$":{"id":"b0160"},"$$":[{"#name":"label","_":"[28]"},{"#name":"other-ref","$":{"id":"h0160","refId":"28"},"$$":[{"#name":"textref","_":"Zhong, Lei, et al., A graph-structured representation with BRNN for static-based facial expression recognition, 2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019), IEEE, 2019."}]}]},{"#name":"bib-reference","$":{"id":"b0165"},"$$":[{"#name":"label","_":"[29]"},{"#name":"other-ref","$":{"id":"h0165","refId":"29"},"$$":[{"#name":"textref","_":"Arriaga, Octavio, Matias Valdenegro-Toro, Paul Plöger, Real-time convolutional neural networks for emotion and gender classification. arXiv preprint arXiv:1710.07557 (2017)."}]}]},{"#name":"bib-reference","$":{"id":"b0170"},"$$":[{"#name":"label","_":"[30]"},{"#name":"reference","$":{"id":"h0170","refId":"30"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Shao"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Qian"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Three convolutional neural network models for facial expression recognition in the wild"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Neurocomputing"}]},{"#name":"volume-nr","_":"355"}]},{"#name":"date","_":"2019"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"82"},{"#name":"last-page","_":"92"}]}]}]},{"#name":"source-text","$":{"id":"stx065"},"_":"Shao J, Qian Y. Three convolutional neural network models for facial expression recognition in the wild[J]. Neurocomputing, 2019, 355: 82-92."}]},{"#name":"bib-reference","$":{"id":"b0175"},"$$":[{"#name":"label","_":"[31]"},{"#name":"other-ref","$":{"id":"h0175","refId":"31"},"$$":[{"#name":"textref","_":"D. Hamester, P. Barros, S. Wermter, Face expression recognition with a 2-channel convolutional neural network, in: Neural Networks (IJCNN), 2015 International Joint Conference on, IEEE, 2015, pp. 1–8"}]}]},{"#name":"bib-reference","$":{"id":"b0180"},"$$":[{"#name":"label","_":"[32]"},{"#name":"reference","$":{"id":"h0180","refId":"32"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Simonyan"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Zisserman"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Very deep convolutional networks for large-scale image recognition"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Comput. Sci."}]}]},{"#name":"date","_":"2014"}]}]}]},{"#name":"source-text","$":{"id":"stx070"},"_":"Simonyan K, Zisserman A. Very Deep Convolutional Networks for Large-Scale Image Recognition [J]. Computer Science, 2014."}]},{"#name":"bib-reference","$":{"id":"b0185"},"$$":[{"#name":"label","_":"[33]"},{"#name":"other-ref","$":{"id":"h0185","refId":"33"},"$$":[{"#name":"textref","_":"P. Rodriguez, G. Cucurull, J. Gonalez, et al., Deep pain: exploiting long short-term memory networks for facial expression classification, IEEE Trans. Cybern. PP (99) (2017) 1–11"}]}]},{"#name":"bib-reference","$":{"id":"b0190"},"$$":[{"#name":"label","_":"[34]"},{"#name":"other-ref","$":{"id":"h0190","refId":"34"},"$$":[{"#name":"textref","_":"J. Li, Y. Mi, J. Yu, et al., A novel convolutional neural network for facial expression recognition, International Conference on Cognitive Systems and Signal Processing. Springer, Singapore, 2018, pp. 310–320"}]}]},{"#name":"bib-reference","$":{"id":"b0195"},"$$":[{"#name":"label","_":"[35]"},{"#name":"other-ref","$":{"id":"h0195","refId":"35"},"$$":[{"#name":"textref","_":"H. Yang, U. Ciftci, L. Yin, Facial expression recognition by de-expression residue learning, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 2168–2177"}]}]},{"#name":"bib-reference","$":{"id":"b0200"},"$$":[{"#name":"label","_":"[36]"},{"#name":"other-ref","$":{"id":"h0200","refId":"36"},"$$":[{"#name":"textref","_":"Y. Lecun, L. Bottou, Y. Bengio, et al., Gradient-based learning applied to document recognition, Proc. IEEE 86 (11) (1998) 2278–2324"}]}]},{"#name":"bib-reference","$":{"id":"b0205"},"$$":[{"#name":"label","_":"[37]"},{"#name":"reference","$":{"id":"h0205","refId":"37"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Z."},{"#name":"surname","_":"Zhang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"P."},{"#name":"surname","_":"Luo"}]},{"#name":"author","$$":[{"#name":"given-name","_":"C.L."},{"#name":"surname","_":"Chen"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Tang"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"From facial expression recognition to interpersonal relation prediction"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Int. J. Comput. Vis."}]},{"#name":"volume-nr","_":"126"}]},{"#name":"issue-nr","_":"5"},{"#name":"date","_":"2018"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"20"}]}]}]},{"#name":"source-text","$":{"id":"stx075"},"_":"Z. Zhang, P. Luo, C. L. Chen, and X. Tang, “From facial expression recognition to interpersonal relation prediction,” International Journal of Computer Vision, vol. 126, no. 5, pp. 1–20, 2018"}]},{"#name":"bib-reference","$":{"id":"b0210"},"$$":[{"#name":"label","_":"[38]"},{"#name":"other-ref","$":{"id":"h0210","refId":"38"},"$$":[{"#name":"textref","_":"P.D.M. Fernandez, F.A.G. Peña, T.I. Ren, et al., FERAtt: facial expression recognition with attention net. arXiv preprint arXiv:1902.03284, 2019."}]}]},{"#name":"bib-reference","$":{"id":"b0215"},"$$":[{"#name":"label","_":"[39]"},{"#name":"other-ref","$":{"id":"h0215","refId":"39"},"$$":[{"#name":"textref","_":"https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data"}]}]},{"#name":"bib-reference","$":{"id":"b0220"},"$$":[{"#name":"label","_":"[40]"},{"#name":"other-ref","$":{"id":"h0220","refId":"40"},"$$":[{"#name":"textref","_":"Y. Guo, D. Tao, J. Yu, H. Xiong, Y. Li, D. Tao, Deep neural networks with relativity learning for facial expression recognition, in: Multimedia & Expo Workshops (ICMEW), 2016 IEEE International Conference on, IEEE, 2016, pp. 1–6."}]}]},{"#name":"bib-reference","$":{"id":"b0225"},"$$":[{"#name":"label","_":"[41]"},{"#name":"other-ref","$":{"id":"h0225","refId":"41"},"$$":[{"#name":"textref","_":"B.-K. Kim, S.-Y. Dong, J. Roh, G. Kim, S.-Y. Lee, Fusing aligned and non-aligned face information for automatic affect recognition in the wild: A deep learning approach, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2016, pp. 48–57"}]}]},{"#name":"bib-reference","$":{"id":"b0230"},"$$":[{"#name":"label","_":"[42]"},{"#name":"other-ref","$":{"id":"h0230","refId":"42"},"$$":[{"#name":"textref","_":"C. Pramerdorfer, M. Kampel, Facial expression recognition using convolutional neural networks: State of the art, arXiv preprint arXiv:1612.02903, 2016."}]}]},{"#name":"bib-reference","$":{"id":"b0235"},"$$":[{"#name":"label","_":"[43]"},{"#name":"other-ref","$":{"id":"h0235","refId":"43"},"$$":[{"#name":"textref","_":"Dhwani Mehta, Mohammad Faridul Haque Siddiqui, Ahmad Y. Javaid, Recognition of emotion intensities using machine learning algorithms: a comparative study, Sensors 19 (8) (2019) 1897"}]}]},{"#name":"bib-reference","$":{"id":"b0240"},"$$":[{"#name":"label","_":"[44]"},{"#name":"other-ref","$":{"id":"h0240","refId":"44"},"$$":[{"#name":"textref","_":"T. Connie, M. Al-Shabi, W.P. Cheah, et al., Facial expression recognition using a hybrid CNN–SIFT aggregator, International Workshop on Multi-disciplinary Trends in Artificial Intelligence, Springer, Cham, 2017, pp. 139–149"}]}]}]}]}],"floats":[],"footnotes":[],"attachments":[],"sourceTextMap":{"5":"Sun, H. Zhao, Z. Jin, An efficient unconstrained facial expression recognition algorithm based on stack binarized auto-encoders and binarized neural networks, Neurocomputing 267 (2017) 385-395.","8":"Yu Z, Liu G, Liu Q, et al. Spatio-temporal convolutional features with nested LSTM for facial expression recognition[J]. Neurocomputing, 2018, 317: 50-57.","9":"Ojala T, Harwood I. A Comparative Study of Texture Measures with Classification Based on Feature Distributions [J]. Pattern Recognition, 1996, 29(1):51-59.","12":"Sun W, Zhao H, Jin Z. A visual attention based ROI detection method for facial expression recognition [J]. Neurocomputing, 2018, 296: 12-22.","22":"C. Cortes, V.N. Vapnik, Support vector networks, Mach. Learn. 20 (1995) 273–297.","23":"Zhang K, Huang Y, Du Y, et al. Facial expression recognition based on deep evolutional spatial-temporal networks[J]. IEEE Transactions on Image Processing, 2017, 26(9): 4193-4203.","25":"Zhao G, Huang X, Taini M, et al. Facial expression recognition from near-infrared videos[J]. Image and Vision Computing, 2011, 29(9): 607-619.","30":"Shao J, Qian Y. Three convolutional neural network models for facial expression recognition in the wild[J]. Neurocomputing, 2019, 355: 82-92.","32":"Simonyan K, Zisserman A. Very Deep Convolutional Networks for Large-Scale Image Recognition [J]. Computer Science, 2014.","37":"Z. Zhang, P. Luo, C. L. Chen, and X. Tang, “From facial expression recognition to interpersonal relation prediction,” International Journal of Computer Vision, vol. 126, no. 5, pp. 1–20, 2018"}},"referenceLinks":{"external":[{"refId":5,"scopusHubEid":"2-s2.0-85021789014"},{"refId":8,"scopusHubEid":"2-s2.0-85052749914"},{"refId":12,"scopusHubEid":"2-s2.0-85044515478"},{"refId":22,"scopusHubEid":"2-s2.0-34249753618"},{"refId":23,"scopusHubEid":"2-s2.0-85027517303"},{"refId":25,"scopusHubEid":"2-s2.0-80052725518"},{"refId":30,"scopusHubEid":"2-s2.0-85065595874"}],"internal":[{"refId":5,"pii":"S0925231217311785","filesize":"2MB","pdf":{"urlType":"download","url":"/science/article/pii/S0925231217311785/pdfft?md5=7fbe0b1c4dc1cca0c398830dccaaac06&pid=1-s2.0-S0925231217311785-main.pdf"}},{"refId":8,"pii":"S0925231218308634","filesize":"2MB","pdf":{"urlType":"download","url":"/science/article/pii/S0925231218308634/pdfft?md5=41149ff1659402937f3542b188491f6c&pid=1-s2.0-S0925231218308634-main.pdf"}},{"refId":9,"pii":"0031320395000674","filesize":"582KB","pdf":{"urlType":"download","url":"/science/article/pii/0031320395000674/pdf?md5=5c75587242849348976ac5833537e301&pid=1-s2.0-0031320395000674-main.pdf"}},{"refId":12,"pii":"S0925231218303266","filesize":"2MB","pdf":{"urlType":"download","url":"/science/article/pii/S0925231218303266/pdfft?md5=7ded741b2ce5b7c49cfbee8eecffca81&pid=1-s2.0-S0925231218303266-main.pdf"}},{"refId":25,"pii":"S0262885611000515","filesize":"2MB","pdf":{"urlType":"download","url":"/science/article/pii/S0262885611000515/pdfft?md5=9117a88e2958ec35b47c9caa69169926&pid=1-s2.0-S0262885611000515-main.pdf"}},{"refId":30,"pii":"S0925231219306137","filesize":"4MB","pdf":{"urlType":"download","url":"/science/article/pii/S0925231219306137/pdfft?md5=b31bdcbb1e65c9378c37c8bc3bd861d0&pid=1-s2.0-S0925231219306137-main.pdf"}},{"refId":37,"pii":"S0022509616308845","filesize":"5MB","pdf":{"urlType":"download","url":"/science/article/pii/S0022509616308845/pdfft?md5=9a1ea4149cd6c5664d8820f505a6b262&pid=1-s2.0-S0022509616308845-main.pdf"}}]},"refersTo":{},"referredToBy":{},"relatedContent":{"isModal":false,"isOpenSpecialIssueArticles":false,"isOpenVirtualSpecialIssueLink":false,"isOpenRecommendations":true,"isOpenSubstances":true,"citingArticles":[false,false,false,false,false,false],"recommendations":[false,false,false,false,false,false]},"seamlessAccess":{},"specialIssueArticles":{},"substances":{},"supplementaryFilesData":[],"tableOfContents":{"outlineTitle":"Outline","outline":[{"#name":"entry","$":{"id":"ab005","type":"abstract","class":"author","depth":"1"},"$$":[{"#name":"title","$":{"id":"st005"},"_":"Abstract"}]},{"#name":"entry","$":{"id":"kg005","type":"keywords","class":"keyword","depth":"1"},"$$":[{"#name":"title","$":{"id":"st010"},"_":"Keywords"}]},{"#name":"entry","$":{"id":"s0005","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"1"},{"#name":"title","$":{"id":"st015"},"_":"Introduction"}]},{"#name":"entry","$":{"id":"s0010","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"2"},{"#name":"title","$":{"id":"st020"},"_":"Related works"}]},{"#name":"entry","$":{"id":"s0015","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"3"},{"#name":"title","$":{"id":"st025"},"_":"The proposed method"},{"#name":"entry","$":{"id":"s0020","depth":"2"},"$$":[{"#name":"label","_":"3.1"},{"#name":"title","$":{"id":"st030"},"_":"Network architecture"}]},{"#name":"entry","$":{"id":"s0025","depth":"2"},"$$":[{"#name":"label","_":"3.2"},{"#name":"title","$":{"id":"st035"},"_":"Attention mechanism"}]},{"#name":"entry","$":{"id":"s0030","depth":"2"},"$$":[{"#name":"label","_":"3.3"},{"#name":"title","$":{"id":"st040"},"_":"Local binary patterns"}]},{"#name":"entry","$":{"id":"s0035","depth":"2"},"$$":[{"#name":"label","_":"3.4"},{"#name":"title","$":{"id":"st045"},"_":"Data augmentation"}]}]},{"#name":"entry","$":{"id":"s0040","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"4"},{"#name":"title","$":{"id":"st050"},"_":"Experimental results"},{"#name":"entry","$":{"id":"s0045","depth":"2"},"$$":[{"#name":"label","_":"4.1"},{"#name":"title","$":{"id":"st055"},"_":"Ablations on FER2013"}]},{"#name":"entry","$":{"id":"s0050","depth":"2"},"$$":[{"#name":"label","_":"4.2"},{"#name":"title","$":{"id":"st060"},"_":"Evaluation and comparison"},{"#name":"entry","$":{"id":"s0055","depth":"3"},"$$":[{"#name":"label","_":"4.2.1"},{"#name":"title","$":{"id":"st065"},"_":"FER2013 dataset"}]},{"#name":"entry","$":{"id":"s0060","depth":"3"},"$$":[{"#name":"label","_":"4.2.2"},{"#name":"title","$":{"id":"st070"},"_":"CK+ dataset"}]},{"#name":"entry","$":{"id":"s0065","depth":"3"},"$$":[{"#name":"label","_":"4.2.3"},{"#name":"title","$":{"id":"st075"},"_":"Oulu-CASIA dataset"}]},{"#name":"entry","$":{"id":"s0070","depth":"3"},"$$":[{"#name":"label","_":"4.2.4"},{"#name":"title","$":{"id":"st080"},"_":"JAFFE dataset"}]},{"#name":"entry","$":{"id":"s0075","depth":"3"},"$$":[{"#name":"label","_":"4.2.5"},{"#name":"title","$":{"id":"st085"},"_":"NCUFE dataset"}]}]}]},{"#name":"entry","$":{"id":"s0080","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"5"},{"#name":"title","$":{"id":"st090"},"_":"Conclusions and future work"}]},{"#name":"entry","$":{"id":"s0090","type":"sections","depth":"1"},"$$":[{"#name":"title","$":{"id":"st100"},"_":"CRediT authorship contribution statement"}]},{"#name":"entry","$":{"id":"coi005","type":"conflict-of-interest","depth":"1"},"$$":[{"#name":"title","$":{"id":"st105"},"_":"Declaration of Competing Interest"}]},{"#name":"entry","$":{"id":"ak005","type":"acknowledgment","depth":"1"},"$$":[{"#name":"title","$":{"id":"st110"},"_":"Acknowledgements"}]},{"#name":"entry","$":{"id":"bi005","type":"bibliography","depth":"1"},"$$":[{"#name":"title","$":{"id":"st115"},"_":"References"}]},{"#name":"entry","$":{"id":"bg005","type":"biography","depth":"1"},"$$":[{"#name":"title","_":"Vitae"}]}],"figures":[],"tables":[{"#name":"entry","$":{"id":"t0005","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 1"},{"#name":"caption","$":{"truncated":"false"},"_":"Comparison of different LBPs on FER2013 dataset."}]},{"#name":"entry","$":{"id":"t0010","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 2"},{"#name":"caption","$":{"truncated":"false"},"_":"Comparison of different architectures on the FER2013 dataset."}]},{"#name":"entry","$":{"id":"t0015","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 3"},{"#name":"caption","$":{"truncated":"false"},"_":"Comparison of different dilation rates of the reconstruction module on the FER2013 dataset."}]},{"#name":"entry","$":{"id":"t0020","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 4"},{"#name":"caption","$":{"truncated":"false"},"_":"Comparison of different methods on the FER2013 dataset."}]},{"#name":"entry","$":{"id":"t0025","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 5"},{"#name":"caption","$":{"truncated":"false"},"_":"Comparison of different methods on the CK+ dataset."}]},{"#name":"entry","$":{"id":"t0030","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 6"},{"#name":"caption","$":{"truncated":"false"},"_":"Comparison of different methods on the Oulu-CASIA dataset."}]},{"#name":"entry","$":{"id":"t0035","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 7"},{"#name":"caption","$":{"truncated":"false"},"_":"Comparison of different methods on the JAFFE dataset."}]},{"#name":"entry","$":{"id":"t0040","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 8"},{"#name":"caption","$":{"truncated":"false"},"_":"Comparison of different methods on NCUFE dataset."}]}],"extras":[],"attachments":[],"showEntitledTocLinks":false},"tail":{},"transientError":{"isOpen":false},"sidePanel":{"openState":1},"viewConfig":{"articleFeature":{"rightsAndContentLink":true,"sdAnswersButton":false},"pathPrefix":""},"virtualSpecialIssue":{"showVirtualSpecialIssueLink":false},"usageProps":{"itemStage":"S300","isAip":false,"tombAip":"0","sample":false},"userCookiePreferences":{"STRICTLY_NECESSARY":true,"PERFORMANCE":false,"FUNCTIONAL":false,"TARGETING":false}};
      </script>
      <noscript>
      JavaScript is disabled on your browser.
      Please enable JavaScript to use all the features on this page.
      <img src=https://smetrics.elsevier.com/b/ss/elsevier-sd-prod/1/G.4--NS/1734891642373?pageName=sd%3Aproduct%3Ajournal%3Aarticle&c16=els%3Arp%3Ast&c2=sd&v185=img&v33=ae%3AANON_GUEST&c1=ae%3A228598&c12=ae%3A12975512 />
    </noscript>
      <div id="elementForFocusReset" tabindex="-1"></div><a class="anchor sr-only sr-only-focusable u-display-inline anchor-primary" href="#screen-reader-main-content"><span class="anchor-text-container"><span class="anchor-text">Skip to main content</span></span></a><a class="anchor sr-only sr-only-focusable u-display-inline anchor-primary" href="#screen-reader-main-title"><span class="anchor-text-container"><span class="anchor-text">Skip to article</span></span></a>
      <div id="root"><div class="App" id="app" data-aa-name="root"><div class="page"><div class="sd-flex-container"><div class="sd-flex-content"><header id="gh-cnt"><div id="gh-main-cnt" class="u-flex-center-ver u-position-relative u-padding-s-hor u-padding-l-hor-from-xl"><a id="gh-branding" class="u-flex-center-ver" href="/" aria-label="ScienceDirect home page" data-aa-region="header" data-aa-name="ScienceDirect"><img class="gh-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/24/images/elsevier-non-solus-new-grey.svg" alt="Elsevier logo" height="48" width="54"><svg xmlns="http://www.w3.org/2000/svg" version="1.1" height="15" viewBox="0 0 190 23" role="img" class="gh-wordmark u-margin-s-left" aria-labelledby="gh-wm-science-direct" focusable="false" aria-hidden="true" alt="ScienceDirect Wordmark"><title id="gh-wm-science-direct">ScienceDirect</title><g><path fill="#EB6500" d="M3.81 6.9c0-1.48 0.86-3.04 3.7-3.04 1.42 0 3.1 0.43 4.65 1.32l0.13-2.64c-1.42-0.63-2.97-0.96-4.78-0.96 -4.62 0-6.6 2.44-6.6 5.45 0 5.61 8.78 6.14 8.78 9.93 0 1.48-1.15 3.04-3.86 3.04 -1.72 0-3.4-0.56-4.72-1.39l-0.36 2.64c1.55 0.76 3.57 1.06 5.15 1.06 4.26 0 6.7-2.48 6.7-5.51C12.59 11.49 3.81 10.76 3.81 6.9M20.27 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.14 0-4.55-1.71-4.55-5.91C17.93 10.2 20.01 9.18 20.27 9.01"></path><rect x="29.42" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M30.67 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.68-0.96 1.68-1.88C32.35 1.55 31.56 0.7 30.67 0.7M48.06 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H48.06M39.91 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C38.56 10.27 39.71 9.37 39.91 9.18zM58.82 6.57c-2.24 0-3.63 1.12-4.85 2.61l-0.4-2.21h-2.34l0.13 1.19c0.1 0.76 0.13 1.78 0.13 2.97v10.79h2.54V11.88c0.69-0.96 2.15-2.48 2.48-2.64 0.23-0.13 1.29-0.4 2.08-0.4 2.28 0 2.48 1.15 2.54 3.43 0.03 1.19 0.03 3.17 0.03 3.17 0.03 3-0.1 6.47-0.1 6.47h2.54c0 0 0.07-4.49 0.07-6.96 0-1.48 0.03-2.97-0.1-4.46C63.31 7.43 61.49 6.57 58.82 6.57M72.12 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C69.77 10.2 71.85 9.18 72.12 9.01M92.74 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H92.74M84.59 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C83.24 10.27 84.39 9.37 84.59 9.18zM103.9 1.98h-7.13v19.93h6.83c7.26 0 9.77-5.68 9.77-10.03C113.37 7.33 110.93 1.98 103.9 1.98M103.14 19.8h-3.76V4.1h4.09c5.38 0 6.96 4.39 6.96 7.79C110.43 16.87 108.19 19.8 103.14 19.8zM118.38 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.69-0.96 1.69-1.88C120.07 1.55 119.28 0.7 118.38 0.7"></path><rect x="117.13" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M130.2 6.6c-1.62 0-2.87 1.45-3.4 2.74l-0.43-2.37h-2.34l0.13 1.19c0.1 0.76 0.13 1.75 0.13 2.9v10.86h2.54v-9.51c0.53-1.29 1.72-3.7 3.17-3.7 0.96 0 1.06 0.99 1.06 1.22l2.08-0.6V9.18c0-0.03-0.03-0.17-0.06-0.4C132.8 7.36 131.91 6.6 130.2 6.6M145.87 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.89-1.95-4.89-5.51v-0.49H145.87M137.72 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C136.37 10.27 137.52 9.37 137.72 9.18zM153.23 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.14-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.69 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C150.89 10.2 152.97 9.18 153.23 9.01M170 19.44c-0.92 0.36-1.72 0.69-2.51 0.69 -1.16 0-1.58-0.66-1.58-2.34V8.95h3.93V6.97h-3.93V2.97h-2.48v3.99h-2.71v1.98h2.71v9.67c0 2.64 1.39 3.73 3.33 3.73 1.15 0 2.54-0.39 3.43-0.79L170 19.44M173.68 5.96c-1.09 0-2-0.87-2-1.97 0-1.1 0.91-1.97 2-1.97s1.98 0.88 1.98 1.98C175.66 5.09 174.77 5.96 173.68 5.96zM173.67 2.46c-0.85 0-1.54 0.67-1.54 1.52 0 0.85 0.69 1.54 1.54 1.54 0.85 0 1.54-0.69 1.54-1.54C175.21 3.13 174.52 2.46 173.67 2.46zM174.17 5.05c-0.09-0.09-0.17-0.19-0.25-0.3l-0.41-0.56h-0.16v0.87h-0.39V2.92c0.22-0.01 0.47-0.03 0.66-0.03 0.41 0 0.82 0.16 0.82 0.64 0 0.29-0.21 0.55-0.49 0.63 0.23 0.32 0.45 0.62 0.73 0.91H174.17zM173.56 3.22l-0.22 0.01v0.63h0.22c0.26 0 0.43-0.05 0.43-0.34C174 3.28 173.83 3.21 173.56 3.22z"></path></g></svg></a><div class="gh-nav-cnt u-hide-from-print"><div class="gh-nav-links-container gh-nav-links-container-h u-hide-from-print gh-nav-content-container"><nav aria-label="links" class="gh-nav gh-nav-links gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-item gh-move-to-spine"><a class="anchor gh-nav-action text-s anchor-secondary anchor-medium" href="/browse/journals-and-books" id="gh-journals-books-link" data-aa-region="header" data-aa-name="Journals &amp; Books"><span class="anchor-text-container"><span class="anchor-text">Journals &amp; Books</span></span></a></li></ul></nav><nav aria-label="utilities" class="gh-nav gh-nav-utilities gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-help text-s u-flex-center-ver u-gap-6 gh-nav-action"><div class="gh-move-to-spine gh-help-button gh-help-icon gh-nav-item"><div class="popover" id="gh-help-icon-popover"><div id="popover-trigger-gh-help-icon-popover"><input type="hidden"><button class="button-link button-link-secondary gh-icon-btn button-link-medium button-link-icon-left" title="Help" aria-expanded="false" type="button"><svg focusable="false" viewBox="0 0 114 128" height="20" width="20" class="icon icon-help gh-icon"><path d="M57 8C35.69 7.69 15.11 21.17 6.68 40.71c-8.81 19.38-4.91 43.67 9.63 59.25 13.81 15.59 36.85 21.93 56.71 15.68 21.49-6.26 37.84-26.81 38.88-49.21 1.59-21.15-10.47-42.41-29.29-52.1C74.76 10.17 65.88 7.99 57 8zm0 10c20.38-.37 39.57 14.94 43.85 34.85 4.59 18.53-4.25 39.23-20.76 48.79-17.05 10.59-40.96 7.62-54.9-6.83-14.45-13.94-17.42-37.85-6.83-54.9C26.28 26.5 41.39 17.83 57 18zm-.14 14C45.31 32.26 40 40.43 40 50v2h10v-2c0-4.22 2.22-9.66 8-9.24 5.5.4 6.32 5.14 5.78 8.14C62.68 55.06 52 58.4 52 69.4V76h10v-5.56c0-8.16 11.22-11.52 12-21.7.74-9.86-5.56-16.52-16-16.74-.39-.01-.76-.01-1.14 0zM52 82v10h10V82H52z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Help</span></span></button></div></div></div></li><li class="gh-nav-search text-s u-flex-center-ver u-gap-6 gh-nav-action"><div class="gh-search-toggle gh-nav-item search-button-link"><a class="anchor button-link-secondary anchor-secondary u-margin-l-left gh-nav-action gh-icon-btn anchor-medium anchor-icon-left anchor-with-icon" href="/search" id="gh-search-link" title="Search" data-aa-button="search-in-header-opened-from-article" role="button"><svg focusable="false" viewBox="0 0 100 128" height="20" class="icon icon-search gh-icon"><path d="M19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6L73.23 80.19c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96S19.9 18.47 12.19 26.18C4.47 33.89.22 44.15.22 55.06s4.25 21.17 11.97 28.88C19.9 91.65 30.16 95.9 41.07 95.9c9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg><span class="anchor-text-container"><span class="anchor-text">Search</span></span></a></div></li></ul></nav></div></div><div class="gh-profile-container gh-move-to-spine u-hide-from-print"><a class="anchor text-s u-clr-grey8 u-margin-l-left gh-icon-btn anchor-primary anchor-medium anchor-icon-left anchor-with-icon" href="/user/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0925231220309838&amp;from=globalheader" id="gh-myaccount-btn" data-aa-region="header" data-aa-name="personalsignin"><svg focusable="false" viewBox="0 0 106 128" height="20" aria-hidden="true" class="icon icon-person gh-cta-btn-icon"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><span class="anchor-text-container"><span class="anchor-text">My account</span></span></a></div><a class="anchor text-s u-clr-grey8 gh-move-to-spine u-hide-from-print u-margin-l-left anchor-secondary gh-icon-btn anchor-medium anchor-icon-left anchor-with-icon" href="/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0925231220309838" id="gh-institutionalsignin-btn" data-aa-region="header" data-aa-name="institutionalsignin"><svg focusable="false" viewBox="0 0 106 128" height="20" aria-hidden="true" class="icon icon-institution gh-cta-btn-icon"><path d="M84 98h10v10H12V98h10V52h14v46h10V52h14v46h10V52h14v46zM12 36.86l41-20.84 41 20.84V42H12v-5.14zM104 52V30.74L53 4.8 2 30.74V52h10v36H2v30h102V88H94V52h10z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Sign in</span></span></a><div id="gh-mobile-menu" class="mobile-menu u-hide-from-print"><div class="gh-hamburger u-fill-grey7"><button class="button-link u-flex-center-ver button-link-primary button-link-icon-left" aria-label="Toggle mobile menu" aria-expanded="false" type="button"><svg class="gh-hamburger-svg-el gh-hamburger-closed" role="img" aria-hidden="true" height="20" width="20"><path d="M0 14h40v2H0zm0-7h40v2H0zm0-7h40v2H0z"></path></svg></button></div><div id="gh-overlay" class="mobile-menu-overlay u-overlay u-display-none" role="button" tabindex="-1"></div><div id="gh-drawer" aria-label="Mobile menu" class="" role="navigation"></div></div></div></header><div class="Article Preview" id="mathjax-container" role="main"><div class="accessbar-sticky"><div id="screen-reader-main-content"></div><div role="region" aria-label="Download options and search"><div class="accessbar"><div class="accessbar-label"></div><ul aria-label="PDF Options"><li class="RemoteAccess"><a class="link-button RemoteAccessButton accessbar-utility-component accessbar-utility-link link-button-primary link-button-icon-left" href="/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0925231220309838" aria-label="Access through your organization"><svg focusable="false" viewBox="0 0 106 128" height="20" aria-label="Seamless access" role="img" class="icon icon-institution"><path d="M84 98h10v10H12V98h10V52h14v46h10V52h14v46h10V52h14v46zM12 36.86l41-20.84 41 20.84V42H12v-5.14zM104 52V30.74L53 4.8 2 30.74V52h10v36H2v30h102V88H94V52h10z"></path></svg><span class="link-button-text-container"><span class="link-button-text"><span>Access through&nbsp;<strong>your organization</strong></span></span></span></a></li><li class="PurchasePDF"><a class="anchor accessbar-utility-component accessbar-utility-link anchor-primary" href="/getaccess/pii/S0925231220309838/purchase" target="_blank" aria-label="Purchase PDF" rel="noreferrer noopener"><span class="anchor-text-container"><span class="anchor-text"><span>Purchase PDF</span></span></span></a></li></ul><form class="QuickSearch" action="/search#submit" method="get" aria-label="form"><div class="search-input"><div class="search-input-container search-input-container-no-label"><label class="search-input-label u-hide-visually" for="article-quick-search">Search ScienceDirect</label><input type="text" id="article-quick-search" name="qs" class="search-input-field" aria-describedby="article-quick-search-description-message" aria-invalid="false" aria-label="Search ScienceDirect" placeholder="Search ScienceDirect" value=""></div><div class="search-input-message-container"><div class="search-input-validation-error" aria-live="polite"></div><div id="article-quick-search-description-message"></div></div></div><button type="submit" class="button u-margin-xs-left button-primary small button-icon-only" aria-disabled="false" aria-label="Submit search"><svg focusable="false" viewBox="0 0 100 128" height="20" class="icon icon-search"><path d="M19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6L73.23 80.19c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96S19.9 18.47 12.19 26.18C4.47 33.89.22 44.15.22 55.06s4.25 21.17 11.97 28.88C19.9 91.65 30.16 95.9 41.07 95.9c9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></button><input type="hidden" name="origin" value="article"><input type="hidden" name="zone" value="qSearch"></form></div></div></div><div class="article-wrapper u-padding-s-top grid row"><div role="navigation" aria-label="Table of Contents" class="preview-sidebar u-display-block-from-lg col-lg-6"><div class="PreviewTableOfContents"><h2 class="u-h4 preview-table-of-contents-title">Article preview</h2><ul class="preview-table-of-contents-list"><li id="preview-section-abstract-item" class=""><a class="anchor anchor-primary" href="#preview-section-abstract"><span class="anchor-text-container"><span class="anchor-text">Abstract</span></span></a></li><li id="preview-section-introduction-item" class=""><a class="anchor anchor-primary" href="#preview-section-introduction"><span class="anchor-text-container"><span class="anchor-text">Introduction</span></span></a></li><li id="preview-section-snippets-item" class=""><a class="anchor anchor-primary" href="#preview-section-snippets"><span class="anchor-text-container"><span class="anchor-text">Section snippets</span></span></a></li><li id="preview-section-references-item" class=""><a class="anchor anchor-primary" href="#preview-section-references"><span class="anchor-text-container"><span class="anchor-text">References (44)</span></span></a></li><li id="preview-section-cited-by-item" class=""><a class="anchor anchor-primary" href="#preview-section-cited-by"><span class="anchor-text-container"><span class="anchor-text">Cited by (263)</span></span></a></li></ul></div></div><article class="col-lg-12 col-md-16 pad-left pad-right" lang="en"><div class="Publication" id="publication"><div class="publication-brand u-display-block-from-sm"><a class="anchor u-display-flex anchor-primary" href="/journal/neurocomputing" title="Go to Neurocomputing on ScienceDirect"><span class="anchor-text-container"><span class="anchor-text"><img class="publication-brand-image" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1/image/elsevier-non-solus.png" alt="Elsevier"></span></span></a></div><div class="publication-volume u-text-center"><h2 class="publication-title u-h3" id="publication-title"><a class="anchor anchor-secondary publication-title-link" href="/journal/neurocomputing" title="Go to Neurocomputing on ScienceDirect"><span class="anchor-text-container"><span class="anchor-text">Neurocomputing</span></span></a></h2><div class="text-xs"><a class="anchor anchor-primary" href="/journal/neurocomputing/vol/411/suppl/C" title="Go to table of contents for this volume/issue"><span class="anchor-text-container"><span class="anchor-text">Volume 411</span></span></a>, <!-- -->21 October 2020<!-- -->, Pages 340-350</div></div><div class="publication-cover u-display-block-from-sm"><a class="anchor u-display-flex anchor-primary" href="/journal/neurocomputing/vol/411/suppl/C"><span class="anchor-text-container"><span class="anchor-text"><img class="publication-cover-image" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00336-cov150h.gif" alt="Neurocomputing"></span></span></a></div></div><div class="PageDivider"></div><h1 id="screen-reader-main-title" class="Head u-font-serif u-h2 u-margin-s-ver"><span class="title-text">Attention mechanism-based CNN for facial expression recognition</span></h1><div class="Banner" id="banner"><div class="wrapper truncated"><div aria-live="polite"></div><div class="AuthorGroups"><div class="author-group" id="author-group"><span class="sr-only">Author links open overlay panel</span><button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au005" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Jing</span> <span class="text surname">Li</span> </span><span class="author-ref" id="baf005"><sup>a</sup></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au010" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Kan</span> <span class="text surname">Jin</span> </span><span class="author-ref" id="baf005"><sup>a</sup></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au015" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Dalin</span> <span class="text surname">Zhou</span> </span><span class="author-ref" id="baf010"><sup>b</sup></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au020" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Naoyuki</span> <span class="text surname">Kubota</span> </span><span class="author-ref" id="baf015"><sup>c</sup></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au025" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Zhaojie</span> <span class="text surname">Ju</span> </span><span class="author-ref" id="baf010"><sup>b</sup></span><svg focusable="false" viewBox="0 0 106 128" height="20" title="Correspondence author icon" class="icon icon-person react-xocs-author-icon u-fill-grey8"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><svg focusable="false" viewBox="0 0 102 128" height="20" title="Author email or social media contact details icon" class="icon icon-envelope react-xocs-author-icon u-fill-grey8"><path d="M55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0L17.58 34h69.54L55.8 57.19zM0 32.42l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-.98 9.42-2.93L102 34.34V24H0zM92 88.9L73.94 66.16l-8.04 5.95L83.28 94H18.74l18.38-23.12-8.04-5.96L10 88.94V51.36L0 42.9V104h102V44.82l-10 8.46V88.9"></path></svg></span></span></button></div></div></div><button class="button-link u-margin-s-ver button-link-primary button-link-icon-right" id="show-more-btn" type="button" data-aa-button="icon-expand"><span class="button-link-text-container"><span class="button-link-text">Show more</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="banner-options u-padding-xs-bottom"><button class="button-link AddToMendeley button-link-secondary u-margin-s-right u-display-inline-flex-from-md button-link-icon-left button-link-has-colored-icon" type="button"><svg focusable="false" viewBox="0 0 86 128" height="20" class="icon icon-plus"><path d="M48 58V20H38v38H0v10h38v38h10V68h38V58z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Add to Mendeley</span></span></button><div class="Social u-display-inline-block" id="social"><div class="popover social-popover" id="social-popover"><div id="popover-trigger-social-popover"><button class="button-link button-link-secondary u-margin-s-right button-link-icon-left button-link-has-colored-icon" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 114 128" height="20" class="icon icon-share"><path d="M90 112c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zM24 76c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zm66-60c6.62 0 12 5.38 12 12s-5.38 12-12 12-12-5.38-12-12 5.38-12 12-12zm0 62c-6.56 0-12.44 2.9-16.48 7.48L45.1 70.2c.58-1.98.9-4.04.9-6.2s-.32-4.22-.9-6.2l28.42-15.28C77.56 47.1 83.44 50 90 50c12.14 0 22-9.86 22-22S102.14 6 90 6s-22 9.86-22 22c0 1.98.28 3.9.78 5.72L40.14 49.1C36.12 44.76 30.38 42 24 42 11.86 42 2 51.86 2 64s9.86 22 22 22c6.38 0 12.12-2.76 16.14-7.12l28.64 15.38c-.5 1.84-.78 3.76-.78 5.74 0 12.14 9.86 22 22 22s22-9.86 22-22-9.86-22-22-22z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Share</span></span></button></div></div></div><div class="ExportCitation u-display-inline-block" id="export-citation"><div class="popover export-citation-popover" id="export-citation-popover"><div id="popover-trigger-export-citation-popover"><button class="button-link button-link-secondary button-link-icon-left button-link-has-colored-icon" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 104 128" height="20" class="icon icon-cited-by-66"><path d="M2 58.78V106h44V64H12v-5.22C12 40.28 29.08 32 46 32V22C20.1 22 2 37.12 2 58.78zM102 32V22c-25.9 0-44 15.12-44 36.78V106h44V64H68v-5.22C68 40.28 85.08 32 102 32z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Cite</span></span></button></div></div></div></div></div><div class="ArticleIdentifierLinks u-margin-xs-bottom text-xs" id="article-identifier-links"><a class="anchor doi anchor-primary" href="https://doi.org/10.1016/j.neucom.2020.06.014" target="_blank" rel="noreferrer noopener" aria-label="Persistent link using digital object identifier" title="Persistent link using digital object identifier"><span class="anchor-text-container"><span class="anchor-text">https://doi.org/10.1016/j.neucom.2020.06.014</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor rights-and-content anchor-primary" href="https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S0925231220309838&amp;orderBeanReset=true" target="_blank" rel="noreferrer noopener"><span class="anchor-text-container"><span class="anchor-text">Get rights and content</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><section class="ReferencedArticles"></section><section class="ReferencedArticles"></section><div id="preview-section-abstract"><div class="PageDivider"></div><div class="Abstracts u-font-serif" id="abstracts"><div class="abstract author" id="ab005" lang="en"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Abstract</h2><div id="as005"><div class="u-margin-s-bottom" id="sp0005"><span><span><a href="/topics/biochemistry-genetics-and-molecular-biology/facial-recognition" title="Learn more about Facial expression recognition from ScienceDirect's AI-generated Topic Pages" class="topic-link">Facial expression recognition</a> is a hot </span><a href="/topics/computer-science/research-topic" title="Learn more about research topic from ScienceDirect's AI-generated Topic Pages" class="topic-link">research topic</a><span><span> and can be applied in many <a href="/topics/engineering/computervision" title="Learn more about computer vision from ScienceDirect's AI-generated Topic Pages" class="topic-link">computer vision</a><span> fields, such as human–computer interaction, <a href="/topics/computer-science/affective-computing" title="Learn more about affective computing from ScienceDirect's AI-generated Topic Pages" class="topic-link">affective computing</a> and so on. In this paper, we propose a novel end-to-end network with </span></span><a href="/topics/computer-science/attention-machine-learning" title="Learn more about attention mechanism from ScienceDirect's AI-generated Topic Pages" class="topic-link">attention mechanism</a><span> for automatic facial expression recognition. The new <a href="/topics/computer-science/network-architecture" title="Learn more about network architecture from ScienceDirect's AI-generated Topic Pages" class="topic-link">network architecture</a> consists of four parts, i.e., the feature extraction module, the attention module, the reconstruction module and the classification module. The </span></span></span><a href="/topics/engineering/local-binary-pattern" title="Learn more about LBP from ScienceDirect's AI-generated Topic Pages" class="topic-link">LBP</a><span><span> features extract image <a href="/topics/computer-science/texture-information" title="Learn more about texture information from ScienceDirect's AI-generated Topic Pages" class="topic-link">texture information</a> and then catch the small movements of the faces, which can improve the network performance. Attention mechanism can make the </span><a href="/topics/computer-science/neural-network" title="Learn more about neural network from ScienceDirect's AI-generated Topic Pages" class="topic-link">neural network</a><span><span><span> pay more attention to useful features. We combine <a href="/topics/engineering/local-binary-pattern" title="Learn more about LBP from ScienceDirect's AI-generated Topic Pages" class="topic-link">LBP</a><span> features and <a href="/topics/computer-science/attention-machine-learning" title="Learn more about attention mechanism from ScienceDirect's AI-generated Topic Pages" class="topic-link">attention mechanism</a> to enhance the attention model to obtain better results. In addition, we collected and labelled a new facial expression dataset of seven expressions from 35 subjects aged from 20 to 25. For each subject, we captured both </span></span><a href="/topics/engineering/rgb-image" title="Learn more about RGB images from ScienceDirect's AI-generated Topic Pages" class="topic-link">RGB images</a> and depth images with a </span><a href="/topics/computer-science/microsoft-kinect-sensor" title="Learn more about Microsoft Kinect sensor from ScienceDirect's AI-generated Topic Pages" class="topic-link">Microsoft Kinect sensor</a>. For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. We apply the newly proposed method to our own dataset and four representative expression datasets, i.e., JAFFE, CK+, FER2013 and Oulu-CASIA. The experimental results demonstrate the feasibility and effectiveness of the proposed method.</span></span></div></div></div></div></div><div id="preview-section-introduction"><div class="PageDivider"></div><div class="Introduction u-font-serif u-margin-l-ver"><h2 class="u-h4 u-margin-s-bottom">Introduction</h2><section id="s0005"><div class="u-margin-s-bottom" id="p0005">Facial expression is one of the most direct signals to express inner feelings in people's daily communication. The physical or mental state of a person at one time can be obtained by analyzing facial expressions. Therefore, facial expression recognition is of great significance in autopilot, human–computer interaction, medical treatment and other fields related to facial expression, and has gradually become a more and more important research direction. In machine learning, a variety of facial expression recognition algorithms have been proposed. Due to the complexity, diversity, occlusion, lighting and other challenges in facial expression recognition, the recognition accuracy in practical applications is still unsatisfactory.</div><div class="u-margin-s-bottom" id="p0010">In this paper, our goal is to design a recognition model that can automatically and accurately recognize different expressions in various types of images. Generally, the process of facial expression recognition consists of the following steps: i) pre-processing of the facial expression data; ii) feature extraction of facial expressions; and iii) classification of facial expressions. The process is depicted in Fig. 1. We usually consider two kinds of features, namely, facial features and face model features. The facial features are specific points on the face, like eyes, mouth, and eyebrows; the face model features are the features used to model the face. Therefore, there are several ways for facial representation, like using the whole face to get the holistic representation, using specific points for local representation, and combining different points to get a hybrid approach. The final step is to define some set of categories to which the expression belongs.</div><div class="u-margin-s-bottom" id="p0015">When dealing with expression recognition as a classification problem, traditional methods often use hand-crafted features such as Local Binary Patterns (LBP) and traditional machine learning algorithms such as Support Vector Machine (SVM) to classify. These methods may work well on datasets collected under laboratory conditions, but with the introduction of more challenging expression datasets in uncontrollable environments (e.g., FER2013), they cannot effectively achieve this task. Fortunately, deep learning has made a breakthrough in convenience and effectiveness since it has been used to deal with the image classification problem.</div><div class="u-margin-s-bottom" id="p0020">The attention mechanism has been widely used in various computer vision tasks such as saliency detection [15], crowd counting [16] and facial expression recognition [38]. The operation can select the most useful features for classification by learning an intermediate attention map and then applying element-wise product on attention maps and source feature maps to weight the importance of different features. For the task of facial expression recognition, the features that are useful for recognition are mainly in some key parts such as eyes, nose and mouth. The attention mechanism increases the weights of these key features and helps improve the expression recognition results.</div><div class="u-margin-s-bottom" id="p0025">In this paper, we design a novel Convolutional Neural Network with an attention model for recognizing facial expressions. In [43], it showed that using LBP features is better than using HOG and Gabor features because LBP can achieve rotation invariance and grey-scale invariance and thus is suitable for extracting texture features at different scales and can solve the imbalance of displacement, rotation angles and illumination conditions in facial images. In addition, LBP features can reflect fine facial changes in skin textures like wrinkles and furrows, which shows the changes of expressions. In [38], an end-to-end network with an attention model was presented for facial expression recognition. The attention module makes the network focus more on useful features which are vital for expression recognition by increasing the weights of these features. This makes the network recognize expressions more efficiently. Inspired by [38], [43], we combine LBP features with an attention model for facial expression recognition. Embedding the attention model into the network allows the network to pay different attention and weight to different parts of the input data. This can make the neural network pay more attention to useful features, which is vital to expression recognition. Furthermore, we combine LBP features with convolution features to improve our recognition results. The proposed method has been tested on five facial expression datasets, which are CK+ [11], JAFFE [13], FER2013 [39], Oulu-CASIA [25], and our self-collected Nanchang University Facial Expression (NCUFE).</div><div class="u-margin-s-bottom" id="p0030">To verify the effectiveness of our algorithm, we collected a new facial expression dataset called NCUFE. The dataset consists of seven expressions (i.e., anger, disgust, fear, happiness, sadness, surprise and neutral). We collected these facial expression images from 35 graduate students (6 females and 29 males) by a Microsoft Kinect sensor for acquiring both RGB images and depth images. The sample images are shown in Fig. 2. For each student, the size of these two types of images is 1280*1024 and 512*424, respectively. For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. During the process of image capture, the students sat on a chair in front of the Kinect and faced the camera. The distance between the face and the Kinect was about 100&nbsp;cm. We asked each student to look the expression examples printed on some pieces of paper and then make seven expressions.</div><div class="u-margin-s-bottom" id="p0035">The main contributions of this paper are as follows:<ul class="list"><li class="react-xocs-list-item"><span class="list-label">1)</span><span><div class="u-margin-s-bottom" id="p0040">We introduce a novel facial expression recognition method with attention mechanism. Not only raw images, but also LBP features are added to the attention layers of the network. LBP features contain texture information and can reflect fine facial changes in skin textures, which can help distinguish expressions with subtle difference.</div></span></li><li class="react-xocs-list-item"><span class="list-label">2)</span><span><div class="u-margin-s-bottom" id="p0045">We collected and labelled a new dataset named Nanchang University Facial Expression (NCUFE) for facial expression recognition. The dataset includes 490 image sequence collected from 35 subjects labeled with seven facial expressions (i.e., anger, disgust, fear, happiness, sadness, surprise and neutral). For each subject, we captured both RGB images and depth images.</div></span></li><li class="react-xocs-list-item"><span class="list-label">3)</span><span><div class="u-margin-s-bottom" id="p0050">We implement substantial experiments on five different datasets, as shown in Fig. 3. There are not only datasets collected under laboratory conditions, such as CK+, JAFFE, Oulu-CASIA and NCUFE, but also those collected in real world like FER2013. We also compare the model performance with some state-of-the-art expression recognition algorithms, and the results show that our model is superior.</div></span></li></ul></div><div class="u-margin-s-bottom" id="p0055">The remainder of this paper is as follows. In Section 2, we introduce the related works in expression recognition and the existing algorithms. In Section 3, we describe the proposed method in detail. We describe our experimental process and results on different datasets and compare them with the results of the state-of-the-art algorithms in Section 4. We give a conclusion of the whole paper in Section 5.</div></section></div></div><div id="preview-section-snippets"><div class="PageDivider"></div><div class="Snippets u-font-serif"><h2 class="u-h4 u-margin-l-ver">Section snippets</h2><section><section id="s0010"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Related works</h2><div class="u-margin-s-bottom" id="p0060">Traditional facial feature extraction algorithms can be separated into two categories: 1) geometric-based methods, such as Active Appearance Models (AAM) [17]; and 2) appearance-based methods, such as LBP [9] and Gabor Wavelet Representation [21]. After feature description, the features are fed into a classifier, such as SVM [22] and K-nearest Neighbors (KNN) [24], for recognizing different facial expressions. Therefore, the performance of the classifier depends to a large extent on the quality </div></section></section><section><section id="s0015"><section id="s0020"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Network architecture</h2><div class="u-margin-s-bottom" id="p0090">In this section, we introduce our newly proposed convolutional neural network with attention mechanism for automatically recognizing facial expressions. The new network consists of four parts, i.e., the feature extraction module, the attention module, the reconstruction module and the classification module. The architecture starts from the feature extraction module composed of two separate CNN processing streams: one is for raw images and the other is for LBP feature maps. Our model uses pure</div></section></section></section><section><section id="s0040"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Experimental results</h2><div class="u-margin-s-bottom" id="p0150">In this work, we design a novel deep Convolutional Neural Network with an attention model to automatically recognizing facial expressions. Except for the famous facial expression datasets such as CK+ [11], JAFFE [13], Oulu-CASIA [25] and FER2013 [39], we also evaluate our proposed method on our self-collected dataset NCUFE. Because CK+, JAFFE, Oulu-CASIA and NCUFE do not provide specified training and testing sets, we employ 5-fold cross-validation protocol in these four datasets. The proposed</div></section></section><section><section id="s0080"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Conclusions and future work</h2><div class="u-margin-s-bottom" id="p0195">This paper presents a novel convolutional neural network with attention mechanism for facial expression recognition. The method fuses LBP features and convolution features, and then is combined with attention mechanism to improve the performance of the network. In order to prevent overfitting and ensure the generalization ability of the network, we apply data augmentation in the datasets we used in the experiments. In addition, we collected a new dataset called Nanchang University Facial</div></section></section><section><section id="s0090"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">CRediT authorship contribution statement</h2><div class="u-margin-s-bottom" id="p0210"><strong>Jing Li:</strong> Conceptualization, Methodology, Writing - original draft. <strong>Kan Jin:</strong> . <strong>Dalin Zhou:</strong> . <strong>Naoyuki Kubota:</strong> Writing - review &amp; editing. <strong>Zhaojie Ju:</strong> Conceptualization, Methodology, Writing - original draft.</div></section></section><section><section id="coi005"><h2 id="st105" class="u-h4 u-margin-l-top u-margin-xs-bottom">Declaration of Competing Interest</h2><div class="u-margin-s-bottom" id="p0215">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</div></section></section><section><section id="ak005"><h2 id="st110" class="u-h4 u-margin-l-top u-margin-xs-bottom">Acknowledgements</h2><div class="u-margin-s-bottom" id="p0220">This work is supported by <span id="gp005">National Natural Science Foundation of China</span> under Grant <span>61963027</span>, <span>61703198</span>, and <span>51575412</span>, Natural Science Foundation for Distinguished Young Scholars of Jiangxi Province under Grant <span>2018ACB21014</span>.</div></section></section><section><div class="article-biography article-biography-has-image" id="bg005"><div class="article-biography-image"></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0010">Jing Li received the B.E. degree in Electronic Information Engineering from Nanchang University, China, in 2005, and obtained her PhD degree in Electronic and Electrical Engineering from the University of Sheffield, UK, in 2011. From 2011 to 2012, she was a Research Associate with the Department of Computer Science at the University of Sheffield. Currently, she is an Associate Professor with the School of Information Engineering at Nanchang University. Her research interests include visual</div></div></div></section></div></div><div class="related-content-links u-display-none-from-md"><button class="button-link button-link-primary button-link-small" type="button"><span class="button-link-text-container"><span class="button-link-text">Recommended articles</span></span></button></div><div class="Tail"></div><div id="preview-section-references"><div class="paginatedReferences u-font-serif"><div class="PageDivider"></div><header><h2 class="u-h4 u-margin-l-ver"><span>References</span><span> (44)</span></h2></header><ul><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans">Sun</span><em> et al.</em></span><h3><a class="anchor title anchor-primary" href="/science/article/pii/S0925231217311785"><span class="anchor-text-container"><span class="anchor-text">An efficient unconstrained facial expression recognition algorithm based on stack binarized auto-encoders and binarized neural networks</span></span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Neurocomputing</h3></div><div class="series">(2017)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Z. </span>Yu</span><em> et al.</em></span><h3><a class="anchor title anchor-primary" href="/science/article/pii/S0925231218308634"><span class="anchor-text-container"><span class="anchor-text">Spatio-temporal convolutional features with nested LSTM for facial expression recognition[J]</span></span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Neurocomputing</h3></div><div class="series">(2018)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>T. </span>Ojala</span><em> et al.</em></span><h3><a class="anchor title anchor-primary" href="/science/article/pii/0031320395000674"><span class="anchor-text-container"><span class="anchor-text">A comparative study of texture measures with classification based on feature distributions</span></span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Pattern Recogn.</h3></div><div class="series">(1996)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>W. </span>Sun</span><em> et al.</em></span><h3><a class="anchor title anchor-primary" href="/science/article/pii/S0925231218303266"><span class="anchor-text-container"><span class="anchor-text">A visual attention based ROI detection method for facial expression recognition</span></span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Neurocomputing</h3></div><div class="series">(2018)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>G. </span>Zhao</span><em> et al.</em></span><h3><a class="anchor title anchor-primary" href="/science/article/pii/S0262885611000515"><span class="anchor-text-container"><span class="anchor-text">Facial expression recognition from near-infrared videos</span></span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Image Vision Comput.</h3></div><div class="series">(2011)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>J. </span>Shao</span><em> et al.</em></span><h3><a class="anchor title anchor-primary" href="/science/article/pii/S0925231219306137"><span class="anchor-text-container"><span class="anchor-text">Three convolutional neural network models for facial expression recognition in the wild</span></span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Neurocomputing</h3></div><div class="series">(2019)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Z. </span>Zhang</span><em> et al.</em></span><h3><a class="anchor title anchor-primary" href="/science/article/pii/S0022509616308845"><span class="anchor-text-container"><span class="anchor-text">From facial expression recognition to interpersonal relation prediction</span></span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Int. J. Comput. Vis.</h3></div><div class="series">(2018)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>Y.-H. Lai, S.-H. Lai, Emotion-preserving representation learning via generative adversarial network for multi-view...</span></li><li class="bib-reference u-margin-s-bottom"><span>A. Mollahosseini, D. Chan, M.H. Mahoor, Going deeper in facial expression recognition using deep neural networks,...</span></li><li class="bib-reference u-margin-s-bottom"><span>C. Szegedy, W. Liu, Y. Jia, et al., Going deeper with convolutions, IEEE Conference on Computer Vision and Pattern...</span></li></ul><div class="u-display-none"><li class="bib-reference u-margin-s-bottom"><span>K. He, X. Zhang, S. Ren, et al., Deep residual learning for image recognition, (2015)...</span></li><li class="bib-reference u-margin-s-bottom"><span>C. Szegedy, S. Ioffe, V. Vanhoucke, et al., Inception-v4, Inception-ResNet and the Impact of Residual Connections on...</span></li><li class="bib-reference u-margin-s-bottom"><span>B. Hasani, M.H. Mahoor, Spatio-temporal facial expression recognition using convolutional neural networks and...</span></li><li class="bib-reference u-margin-s-bottom"><span>T. Ojala, M. Pietikinen, T. Menp, Multiresolution grayscale and rotation invariant texture classification with local...</span></li><li class="bib-reference u-margin-s-bottom"><span>P. Lucey, J.F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, I. Matthews, The extended cohn-kanade dataset (ck+): a complete...</span></li><li class="bib-reference u-margin-s-bottom"><span>M. Lyons, S. Akamatsu, M. Kamachi, J. Gyoba, Coding facial expressions with Gabor wavelets, in: Proceedings Third IEEE...</span></li><li class="bib-reference u-margin-s-bottom"><span>G. Huang, Z. Liu, K. Q. Weinberger, L. van der Maaten, Densely connected convolutional networks. arXiv preprint...</span></li><li class="bib-reference u-margin-s-bottom"><span>T. Zhao, X. Wu, Pyramid feature attention network for saliency detection, Proceedings of the IEEE Conference on...</span></li><li class="bib-reference u-margin-s-bottom"><span>R.R. Varior, B. Shuai, J. Tighe, et al., Scale-Aware Attention Network for Crowd Counting. arXiv preprint...</span></li><li class="bib-reference u-margin-s-bottom"><span>T.F. Cootes, G.J. Edwards, C.J. Taylor, Active appearance models, IEEE Trans. Pattern Anal. Mach. Intell. 23 (6) (2011)...</span></li><li class="bib-reference u-margin-s-bottom"><span>W. Wang, Q. Sun, T. Chen, et al., A Fine-Grained Facial Expression Database for End-to-End Multi-Pose Facial Expression...</span></li><li class="bib-reference u-margin-s-bottom"><span>C.M. Kuo, S.H. Lai, M. Sarkis, A compact deep learning model for robust facial expression recognition, Proceedings of...</span></li></div><button class="button-alternative button-alternative-secondary u-font-sans u-margin-l-bottom large-alternative button-alternative-icon-left" type="button" id="show-more-refs-btn"><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">View more references</span></span></button></div></div><div id="preview-section-cited-by"><section aria-label="Cited by" class="ListArticles preview"><div class="PageDivider"></div><header id="citing-articles-header"><h2 class="u-h4 u-margin-l-ver u-font-serif">Cited by (263)</h2></header><div aria-describedby="citing-articles-header"><div class="citing-articles u-margin-l-bottom"><ul><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-0-title"><a class="anchor anchor-primary" href="/science/article/pii/S1566253523003354"><span class="anchor-text-container"><span class="anchor-text">Emotion recognition and artificial intelligence: A systematic review (2014–2023) and research recommendations</span></span></a></h3><div>2024, Information Fusion</div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-0-title" aria-controls="citing-articles-article-0" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="d1e11286">Emotion recognition is the ability to precisely infer human emotions from numerous sources and modalities using questionnaires, physical signals, and physiological signals. Recently, emotion recognition has gained attention because of its diverse application areas, like affective computing, healthcare, human–robot interactions, and market research. This paper provides a comprehensive and systematic review of emotion recognition techniques of the current decade. The paper includes emotion recognition using physical and physiological signals. Physical signals involve speech and facial expression, while physiological signals include electroencephalogram, electrocardiogram, galvanic skin response, and eye tracking. The paper provides an introduction to various emotion models, stimuli used for emotion elicitation, and the background of existing automated emotion recognition systems. This paper covers comprehensive searching and scanning of well-known datasets followed by design criteria for review. After a thorough analysis and discussion, we selected 142 journal articles using PRISMA guidelines. The review provides a detailed analysis of existing studies and available datasets of emotion recognition. Our review analysis also presented potential challenges in the existing literature and directions for future research.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-1-title"><a class="anchor anchor-primary" href="/science/article/pii/S1568494621009832"><span class="anchor-text-container"><span class="anchor-text">A hybrid approach for forecasting ship motion using CNN–GRU–AM and GCWOA</span></span></a></h3><div>2022, Applied Soft Computing</div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-1-title" aria-controls="citing-articles-article-1" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="d1e1277">The motion of a ship, which has six degrees of freedom, is a complex nonlinear dynamic process with variable periodicity and chaotic characteristics. With the development of smart ships, modern high-precision equipment needs the help from high accuracy of ship motion (SHM) forecasting. Existing models will not easily be able to satisfy future accuracy requirements. Therefore, to improve the accuracy of SHM forecasts, by firstly determining the sequence features of SHM time series, a convolutional neural network (CNN) was used herein to extract automatically spatial feature vectors. Considering the variable-period characteristics of SHM time series, a gated recurrent unit (GRU) was used to learn the inherent time characteristics and to extract temporal feature vectors. The attention mechanism (AM) was developed to control the effect of feature vectors on the output to solve the problem of the contribution of feature vectors. Integrating the above methods, an SHM hybrid forecasting model, the SHM CNN–GRU–AM (SHM-C&amp;G&amp;A) model, was established. Secondly, in view of the difficulty of selecting the hyperparameters of a hybrid model, on account of the defects of the whale optimization algorithm (WOA), a normal cloud local search (NCLS) algorithm was developed. Exploiting the advantages of the normal cloud search (NCS) and the genetic algorithm (GA), a genetic random global search (GRGS) algorithm was developed. Then, a hybrid genetic cloud whale optimization algorithm (GCWOA) was developed and used to optimize the hyperparameters of the SHM-C&amp;G&amp;A model. Accordingly, a hybrid forecasting approach that integrates SHM-C&amp;G&amp;A and GCWOA was proposed; it is referred to as GCWOA-SHM-C&amp;G&amp;A. Finally, ship heave and pitch time series data are used to analyze an example to test the forecasting effectiveness of SHM-C&amp;G&amp;A and the optimization performance of GCWOA. The experimental results reveal that the proposed SHM-C&amp;G&amp;A model is more robust that the other models that are considered in this paper, and exhibits better nonlinear characteristics. The proposed GCWOA yields a better combination of hyperparameters than contrast algorithms in the forecasting process.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-2-title"><a class="anchor anchor-primary" href="https://doi.org/10.3390/biomimetics8020199" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Distract Your Attention: Multi-Head Cross Attention Network for Facial Expression Recognition</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2023, Biomimetics</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-3-title"><a class="anchor anchor-primary" href="https://doi.org/10.3390/s23115204" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Deep Learning-Based IoT System for Remote Monitoring and Early Detection of Health Issues in Real-Time</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2023, Sensors</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-4-title"><a class="anchor anchor-primary" href="https://doi.org/10.1109/TAFFC.2021.3122146" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Facial Expression Recognition With Visual Transformers and Attentional Selective Fusion</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2023, IEEE Transactions on Affective Computing</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-5-title"><a class="anchor anchor-primary" href="https://doi.org/10.1155/2020/4065207" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Emotion Recognition of Students Based on Facial Expressions in Online Education Based on the Perspective of Computer Simulation</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2020, Complexity</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li></ul><a class="button-alternative button-alternative-secondary large-alternative button-alternative-icon-left" href="http://www.scopus.com/scopus/inward/citedby.url?partnerID=10&amp;rel=3.0.0&amp;eid=2-s2.0-85087331607&amp;md5=ba6a1756cbf7d149f11ac631079ec6a" target="_blank" id="citing-articles-view-all-btn"><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-right"><path d="M1 99l38-38L1 23l7-7 45 45-45 45z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">View all citing articles on Scopus</span></span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></a></div></div></section></div><div class="PageDivider"></div><div class="article-biography article-biography-has-image" id="bg005"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-fx1.jpg" height="155" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0010">Jing Li received the B.E. degree in Electronic Information Engineering from Nanchang University, China, in 2005, and obtained her PhD degree in Electronic and Electrical Engineering from the University of Sheffield, UK, in 2011. From 2011 to 2012, she was a Research Associate with the Department of Computer Science at the University of Sheffield. Currently, she is an Associate Professor with the School of Information Engineering at Nanchang University. Her research interests include visual tracking, behavior recognition, and crowd scene analysis. She has authored or coauthored in various journals, such as IEEE Transactions on Industrial Informatics, IEEE Transactions on Image Processing, Information Sciences (Elsevier), etc.</div></div></div><div class="article-biography article-biography-has-image" id="bg010"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-fx2.jpg" height="155" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0015">Kan Jin received the B.E. degree in Mechatronic Engineering from Hubei Polytechnic University, China, in 2017. He is currently pursuing the M.S. degree in the School of Information Engineering at Nanchang University, China. His research interests include facial expression recognition and crowd counting.</div></div></div><div class="article-biography article-biography-has-image" id="bg015"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-fx3.jpg" height="155" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0020">Dalin Zhou received the B.S. degree in automation from the University of Science and Technology of China, Hefei, China, in 2012, the Ph.D. degree in computing from the University of Portsmouth, UK, in 2018 and is currently a Lecturer in Computer Science with the School of Computing, the University of Portsmouth, UK. His current research interests include signal processing, machine learning, computational intelligence, biomedical robotics and multimodal sensor fusion. His current research contributes to the monitoring and rehabilitation of limb motor function improving the daily life activity and working capability for both the disadvantaged group of limb-impaired patients and the aging community.</div></div></div><div class="article-biography article-biography-has-image" id="bg020"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-fx4.jpg" height="155" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0025">Naoyuki Kubota,<!-- -->&nbsp;<!-- -->Faculty of Systems Design, Tokyo Metropolitan University, Tokyo, Japan Naoyuki Kubota received the B.Sc. degree from Osaka Kyoiku University, Kashiwara, Japan, in 1992, the M.Eng. degree from Hokkaido University, Hokkaido, Japan, in 1994, and the D.E. degree from Nagoya University, Nagoya, Japan, in 1997. He joined the Osaka Institute of Technology, Osaka, Japan, in 1997. He joined the Department of Human and Artificial Intelligence Systems, University of Fukui, Fukui, Japan, as an Associate Professor in 2000. He joined the Department of Mechanical Engineering, Tokyo Metropolitan University, Tokyo, Japan, in 2004. He was an Associate Professor from 2005 to 2012, and has been a Professor since 2012 at the Department of System Design, Tokyo Metropolitan University.</div></div></div><div class="article-biography article-biography-has-image" id="bg025"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-fx5.jpg" height="155" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0030">Zhaojie Ju received the B.S. in automatic control and the M.S. in intelligent robotics both from Huazhong University of Science and Technology, China, and the Ph.D. degree in intelligent robotics at the University of Portsmouth, UK. He held a research appointment at the University College London, London, U.K., before he started his independent academic position at the University of Portsmouth, U.K., in 2012. His research interests include machine intelligence, pattern recognition, and their applications on human motion analysis, multi-fingered robotic hand control, human–robot interaction and collaboration, and robot skill learning. He has authored or co-authored over 180 publications in journals, book chapters, and conference proceedings and received four best paper awards and one Best AE Award in ICRA2018.</div></div></div><a class="anchor full-text-link anchor-primary" href="/science/article/pii/S0925231220309838" aria-disabled="true" tabindex="-1"><span class="anchor-text-container"><span class="anchor-text">View full text</span></span></a><div class="Copyright"><span class="copyright-line">© 2020 Elsevier B.V. All rights reserved.</span></div></article><div class="u-display-block-from-md col-lg-6 col-md-8 pad-right u-padding-s-top"><aside class="RelatedContent u-clr-grey8" aria-label="Related content"><section class="RelatedContentPanel u-margin-s-bottom"><header id="recommended-articles-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" data-aa-button="sd:product:journal:article:location=recommended-articles:type=close" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Recommended articles</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="recommended-articles-header"><div id="recommended-articles" class="text-xs"><ul><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article0-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0925231215001605" title="AU-inspired Deep Networks for Facial Expression Feature Learning"><span class="anchor-text-container"><span class="anchor-text"><span>AU-inspired Deep Networks for Facial Expression Feature Learning</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Neurocomputing, Volume 159, 2015, pp. 126-136</div></div><div class="authors"><span>Mengyi</span> <span>Liu</span>, …, <span>Xilin</span> <span>Chen</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article1-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0925231218303266" title="A visual attention based ROI detection method for facial expression recognition"><span class="anchor-text-container"><span class="anchor-text"><span>A visual attention based ROI detection method for facial expression recognition</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Neurocomputing, Volume 296, 2018, pp. 12-22</div></div><div class="authors"><span>Wenyun</span> <span>Sun</span>, …, <span>Zhong</span> <span>Jin</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article2-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0167865517303902" title="Deep spatial-temporal feature fusion for facial expression recognition in static images"><span class="anchor-text-container"><span class="anchor-text"><span>Deep spatial-temporal feature fusion for facial expression recognition in static images</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Pattern Recognition Letters, Volume 119, 2019, pp. 49-61</div></div><div class="authors"><span>Ning</span> <span>Sun</span>, …, <span>Guang</span> <span>Han</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article3-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0925231218311342" title="Salient object detection via multi-scale attention CNN"><span class="anchor-text-container"><span class="anchor-text"><span>Salient object detection via multi-scale attention CNN</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Neurocomputing, Volume 322, 2018, pp. 130-140</div></div><div class="authors"><span>Yuzhu</span> <span>Ji</span>, …, <span>Q.M.</span> <span>Jonathan Wu</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article4-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0167865521000489" title="Landmark guidance independent spatio-channel attention and complementary context information based facial expression recognition"><span class="anchor-text-container"><span class="anchor-text"><span>Landmark guidance independent spatio-channel attention and complementary context information based facial expression recognition</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Pattern Recognition Letters, Volume 145, 2021, pp. 58-66</div></div><div class="authors"><span>Darshan</span> <span>Gera</span>, <span>S</span> <span>Balasubramanian</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article5-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S1568494619307008" title="A novel deep learning method based on attention mechanism for bearing remaining useful life prediction"><span class="anchor-text-container"><span class="anchor-text"><span>A novel deep learning method based on attention mechanism for bearing remaining useful life prediction</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Applied Soft Computing, Volume 86, 2020, Article 105919</div></div><div class="authors"><span>Yuanhang</span> <span>Chen</span>, …, <span>Sijue</span> <span>Li</span></div></div><div class="buttons"></div></li></ul></div><button class="button-link more-recommendations-button u-margin-s-bottom button-link-primary button-link-icon-right" type="button"><span class="button-link-text-container"><span class="button-link-text">Show 3 more articles</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div></section><section class="RelatedContentPanel u-margin-s-bottom"><header id="metrics-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Article Metrics</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="metrics-header"><div class="plumX-metrics"><h3 class="text-s metric-title metric-title-citations">Citations</h3><ul><li class="text-xs metrics"><span>Citation Indexes</span><span>259</span></li></ul><h3 class="text-s metric-title metric-title-captures">Captures</h3><ul><li class="text-xs metrics"><span>Readers</span><span>205</span></li></ul><div class="metrics u-margin-m-top u-margin-s-bottom"><img src="https://cdn.plu.mx/3ba727faf225e19d2c759f6ebffc511d/plumx-logo.png" class="plumX-logo" alt="PlumX Metrics Logo"><a class="anchor text-xs anchor-primary" href="https://plu.mx/plum/a/?doi=10.1016%2Fj.neucom.2020.06.014&amp;theme=plum-sciencedirect-theme&amp;hideUsage=true" target="_blank"><span class="anchor-text-container"><span class="anchor-text">View details</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></div></div></section></aside></div></div></div></div><footer role="contentinfo" class="els-footer u-bg-white text-xs u-padding-s-hor u-padding-m-hor-from-sm u-padding-l-hor-from-md u-padding-l-ver u-margin-l-top u-margin-xl-top-from-sm u-margin-l-top-from-md"><div class="els-footer-elsevier u-margin-m-bottom u-margin-0-bottom-from-md u-margin-s-right u-margin-m-right-from-md u-margin-l-right-from-lg"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="https://www.elsevier.com/" target="_blank" aria-label="Elsevier home page (opens in a new tab)" rel="nofollow"><img class="footer-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/47/images/elsevier-non-solus-new-with-wordmark.svg" alt="Elsevier logo with wordmark" height="64" width="58" loading="lazy"></a></div><div class="els-footer-content"><div class="u-remove-if-print"><ul class="els-footer-links u-margin-xs-bottom" style="list-style:none"><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/solutions/sciencedirect" target="_blank" id="els-footer-about-science-direct" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">About ScienceDirect</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0925231220309838" id="els-footer-remote-access" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Remote access</span></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://sd-cart.elsevier.com/?" target="_blank" id="els-footer-shopping-cart" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Shopping cart</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsmediakits.com" target="_blank" id="els-footer-advertise" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Advertise</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://service.elsevier.com/app/contact/supporthub/sciencedirect/" target="_blank" id="els-footer-contact-support" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Contact and support</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/legal/elsevier-website-terms-and-conditions" target="_blank" id="els-footer-terms-condition" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Terms and conditions</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/legal/privacy-policy" target="_blank" id="els-footer-privacy-policy" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Privacy policy</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li></ul></div><p id="els-footer-cookie-message" class="u-remove-if-print">Cookies are used by this site. <!-- --> <button class="button-link ot-sdk-show-settings cookie-btn button-link-primary button-link-small" id="ot-sdk-btn" type="button">Cookie Settings</button></p><p id="els-footer-copyright">All content on this site: Copyright © <!-- -->2024<!-- --> Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.</p></div><div class="els-footer-relx u-margin-0-top u-margin-m-top-from-xs u-margin-0-top-from-md"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="https://www.relx.com/" target="_blank" aria-label="RELX home page (opens in a new tab)" id="els-footer-relx" rel="nofollow"><img loading="lazy" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/60/images/logo-relx-tm.svg" width="93" height="20" alt="RELX group home page"></a></div></footer></div></div></div></div>
      <div id="floating-ui-node" class="floating-ui-node" data-sd-ui-floating-ui="true"></div>
      <iframe style="display: none" src="//acw.clinicalkey.com/SSOCore/update?acw=fdf9c8642b80a043f9996e064f67fbe1b665gxrqb%7C%24%7C1F993354FDC4636854CA051B2E6645FBD3B3E6BEC8842AEFCFFADCF3DC776483EEA08326AB2B6239563D972C978BBA0685832BCFD11735920E9169905BBD791CB0469A67597464825D387A21AFA2E514&amp;utt=79d2580046fe3912678df967d40ea758362f47c" tabindex="-1"></iframe><iframe style="display: none" src="//acw.scopus.com/SSOCore/update?acw=fdf9c8642b80a043f9996e064f67fbe1b665gxrqb%7C%24%7C1F993354FDC4636854CA051B2E6645FBD3B3E6BEC8842AEFCFFADCF3DC776483EEA08326AB2B6239563D972C978BBA0685832BCFD11735920E9169905BBD791CB0469A67597464825D387A21AFA2E514&amp;utt=79d2580046fe3912678df967d40ea758362f47c" tabindex="-1"></iframe><iframe style="display: none" src="//acw.sciencedirect.com/SSOCore/update?acw=fdf9c8642b80a043f9996e064f67fbe1b665gxrqb%7C%24%7C1F993354FDC4636854CA051B2E6645FBD3B3E6BEC8842AEFCFFADCF3DC776483EEA08326AB2B6239563D972C978BBA0685832BCFD11735920E9169905BBD791CB0469A67597464825D387A21AFA2E514&amp;utt=79d2580046fe3912678df967d40ea758362f47c" tabindex="-1"></iframe><iframe style="display: none" src="//acw.elsevier.com/SSOCore/update?acw=fdf9c8642b80a043f9996e064f67fbe1b665gxrqb%7C%24%7C1F993354FDC4636854CA051B2E6645FBD3B3E6BEC8842AEFCFFADCF3DC776483EEA08326AB2B6239563D972C978BBA0685832BCFD11735920E9169905BBD791CB0469A67597464825D387A21AFA2E514&amp;utt=79d2580046fe3912678df967d40ea758362f47c" tabindex="-1"></iframe>
      <script src="https://assets.adobedtm.com/4a848ae9611a/032db4f73473/launch-a6263b31083f.min.js" type="image/ot-performance" async=""></script>
      
<script type="text/javascript">
    window.pageData = {"content":[{"contentType":"JL","format":"MIME-XHTML","id":"sd:article:pii:S0925231220309838","type":"sd:article:JL:scope-abstract","detail":"sd:article:subtype:fla","publicationType":"journal","issn":"0925-2312","volumeNumber":"411","suppl":"C","provider":"elsevier","entitlementType":"unsubscribed"}],"page":{"businessUnit":"ELS:RP:ST","language":"en","name":"product:journal:article","noTracking":"false","productAppVersion":"abstract-direct","productName":"SD","type":"CP-CA","environment":"prod","loadTimestamp":1734891641804,"loadTime":"","testId":"sd:qna-article-page:beta-test"},"visitor":{"accessType":"ae:ANON_GUEST","accountId":"ae:228598","accountName":"ae:ScienceDirect Guests","loginStatus":"anonymous","userId":"ae:12975512","ipAddress":"77.165.246.201","appSessionId":"7e7f2e46-8645-4693-866b-b7ad2764d028"}};
    window.pageData.page.loadTime = performance ? Math.round(performance.now()).toString() : '';

    try {
      appData.push({
      event: 'pageLoad',
      page: pageData.page,
      visitor: pageData.visitor,
      content: pageData.content
      })
    } catch(e) {
        console.warn("There was an error loading or running Adobe DTM: ", e);
    }
</script>
      <script nomodule="" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/73/js/core-js/3.20.2/core-js.es.minified.js" type="text/javascript"></script>
      <script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/108/js/react/18.3.1/react.production.min.js" type="text/javascript"></script>
      <script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/108/js/react-dom/18.3.1/react-dom.production.min.js" type="text/javascript"></script>
      <script async="" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/b64013ec63c69e3d916174cbebae89d65b2419e1/arp.js" type="text/javascript"></script>
      <script type="text/javascript">
    const pendoData = {"visitor":{"pageName":"SD:product:journal:article","pageType":"CP-CA","pageProduct":"SD","pageLanguage":"en","pageEnvironment":"prod","accessType":"ae:ANON_GUEST","countryCode":"NL"},"account":{"id":"ae:228598","name":"ae:ScienceDirect Guests"},"events":{}};;
    pendoData.events = {
      ready: function () {
        pendo.addAltText();
      },
    };
    function runPendo(data, options) {
  const {
    firstDelay,
    maxRetries,
    urlPrefix,
    urlSuffix,
    apiKey
  } = options;
  (function (apiKey) {
    (function (p, e, n, d, o) {
      var v, w, x, y, z;
      o = p[d] = p[d] || {};
      o._q = [];
      v = ['initialize', 'identify', 'updateOptions', 'pageLoad'];
      for (w = 0, x = v.length; w < x; ++w) (function (m) {
        o[m] = o[m] || function () {
          o._q[m === v[0] ? 'unshift' : 'push']([m].concat([].slice.call(arguments, 0)));
        };
      })(v[w]);
      y = e.createElement(n);
      y.async = !0;
      y.src = urlPrefix + apiKey + urlSuffix;
      z = e.getElementsByTagName(n)[0];
      z.parentNode.insertBefore(y, z);
    })(window, document, 'script', 'pendo');
    pendo.addAltText = function () {
      var target = document.querySelector('body');
      var observer = new MutationObserver(function (mutations) {
        mutations.forEach(function (mutation) {
          if (mutation?.addedNodes?.length) {
            if (mutation.addedNodes[0]?.className?.includes("_pendo-badge")) {
              const badge = mutation.addedNodes[0];
              const altText = badge?.attributes['aria-label'].value ? badge?.attributes['aria-label'].value : 'Feedback';
              const pendoBadgeImage = pendo.dom(`#${badge?.attributes?.id.value} img`);
              if (pendoBadgeImage.length) {
                pendoBadgeImage[0]?.setAttribute('alt', altText);
              }
            }
          }
        });
      });
      var config = {
        attributeFilter: ['data-layout'],
        attributes: true,
        childList: true,
        characterData: true,
        subtree: false
      };
      observer.observe(target, config);
    };
  })(apiKey);
  (function watchAndSetPendo(nextDelay, retryAttempt) {
    if (typeof pageDataTracker === 'object' && typeof pageDataTracker.getVisitorId === 'function' && pageDataTracker.getVisitorId()) {
      data.visitor.id = pageDataTracker.getVisitorId();
      console.debug(`initializing pendo`);
      pendo.initialize(data);
    } else {
      if (retryAttempt > 0) {
        return setTimeout(function () {
          watchAndSetPendo(nextDelay * 2, retryAttempt - 1);
        }, nextDelay);
      }
      pendo.initialize(data);
      console.debug(`gave up ... pendo initialized`);
    }
  })(firstDelay, maxRetries);
}
    runPendo(pendoData, {
      firstDelay: 100,
      maxRetries: 5,
      urlPrefix: 'https://cdn.pendo.io/agent/static/',
      urlSuffix: '/pendo.js',
      apiKey: 'd6c1d995-bc7e-4e53-77f1-2ea4ecbb9565',
    });
  </script>
      <span id="pendo-answer-rating"></span>
      <script type="text/x-mathjax-config;executed=true">
        MathJax.Hub.Config({
          displayAlign: 'left',
          "fast-preview": {
            disabled: true
          },
          CommonHTML: { linebreaks: { automatic: true } },
          PreviewHTML: { linebreaks: { automatic: true } },
          'HTML-CSS': { linebreaks: { automatic: true } },
          SVG: {
            scale: 90,
            linebreaks: { automatic: true }
          }
        });
      </script>
      <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=MML_SVG" type="text/javascript"></script>
      <script async="" src="https://www.googletagservices.com/tag/js/gpt.js" type="text/javascript"></script>
      <script async="" src="https://scholar.google.com/scholar_js/casa.js" type="text/javascript"></script>
      <script data-cfasync="false">
      (function initOneTrust()  {
        const monitor = {
  init: () => {},
  loaded: () => {},
};
        function enableGroup(group) {
  document.querySelectorAll(`script[type*="ot-${group}"]`).forEach(script => {
    script.type = 'text/javascript';
    document.head.appendChild(script);
  });
}
        function runOneTrustCookies(doClear, monitor) {
  const oneTrustConsentSdkId = 'onetrust-consent-sdk';
  const emptyNodeSelectors = 'h3.ot-host-name, h4.ot-host-desc, button.ot-host-box';
  const ariaLabelledByButtonNodes = 'div.ot-accordion-layout > button';
  const ariaAttribute = 'aria-labelledby';
  function adjustOneTrustDOM() {
    const oneTrustRoot = document.getElementById('onetrust-consent-sdk');

    /* remove empty nodes */
    [...(oneTrustRoot?.querySelectorAll(emptyNodeSelectors) ?? [])].filter(e => e.textContent === '').forEach(e => e.remove());

    /* remove invalid aria-labelledby values */
    oneTrustRoot?.querySelectorAll(ariaLabelledByButtonNodes).forEach(e => {
      const presentIdValue = e.getAttribute(ariaAttribute)?.split(' ').filter(label => document.getElementById(label)).join(' ');
      if (presentIdValue) {
        e.setAttribute(ariaAttribute, presentIdValue);
      }
    });
  }
  function observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent) {
    const cb = (mutationList, observer) => {
      const oneTrustRoot = mutationList.filter(mutationRecord => mutationRecord.type === 'childList' && mutationRecord.addedNodes.length).map(mutationRecord => [...mutationRecord.addedNodes]).flat().find(e => e.id === oneTrustConsentSdkId);
      if (oneTrustRoot && typeof OneTrust !== 'undefined') {
        monitor.loaded(true);
        OneTrust.OnConsentChanged(() => {
          const perfAllowed = decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1]?.match('2:([0|1])')[1] === '1';
          if (perfAllowed) {
            enableGroup('performance');
          }
        });
        if (!isConsentPresent && (shouldSetOTDefaults || OneTrust.GetDomainData().ConsentModel.Name === 'implied consent')) {
          OneTrust.AllowAll();
        }
        document.dispatchEvent(new CustomEvent('@sdtech/onetrust/loaded', {}));
        observer.disconnect();
        adjustOneTrustDOM();
      }
    };
    const observer = new MutationObserver(cb);
    observer.observe(document.querySelector('body'), {
      childList: true
    });
  }
  if (doClear) {
    document.cookie = 'OptanonAlertBoxClosed=; expires=Thu, 01 Jan 1970 00:00:00 UTC; samesite=lax; path=/';
  }
  const isConsentPresent = !!decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1];
  const shouldSetOTDefaults = 'true' === 'false' && !document.cookie?.match('OptanonAlertBoxClosed=');
  if (shouldSetOTDefaults) {
    const date = new Date();
    date.setFullYear(date.getFullYear() + 1);
    document.cookie = `OptanonAlertBoxClosed=${new Date().toISOString()}; expires=${date.toUTCString()}; samesite=lax; path=/; domain=sciencedirect.com`;
  }
  observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent, monitor);
  window.addOTScript = () => {
    const otSDK = document.createElement('script');
    otSDK.setAttribute('data-cfasync', 'false');
    otSDK.setAttribute('src', 'https://cdn.cookielaw.org/scripttemplates/otSDKStub.js');
    otSDK.setAttribute('data-document-language', 'true');
    otSDK.setAttribute('data-domain-script', '865ea198-88cc-4e41-8952-1df75d554d02');
    window.addOTScript = () => {};
    document.head.appendChild(otSDK);
    monitor.init();
  };
  window.addEventListener('load', () => window.addOTScript());
}
        if (document.location.host.match(/.sciencedirect.com$/)) {
          runOneTrustCookies(true, monitor);
        }
        else {
          window.addEventListener('load', (event) => {
            enableGroup('performance');
          });
        }
      }());
    </script>
    <script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML="window.__CF$cv$params={r:'8f622097dfd0fb9d',t:'MTczNDg5MTY0Mi4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script><iframe height="1" width="1" style="position: absolute; top: 0px; left: 0px; border: none; visibility: hidden;"></iframe>
  <iframe id="ps_llctnwc" src="https://service.seamlessaccess.org/ps/" style="display: none; position: absolute; top: -999px; left: -999px;"></iframe><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div id="onetrust-consent-sdk"><div class="onetrust-pc-dark-filter ot-fade-in" style="z-index:2147483645;"></div><div id="onetrust-banner-sdk" class="otFlat bottom ot-wo-title ot-buttons-fw" tabindex="0" role="region" aria-label="Cookie banner"><div role="alertdialog" aria-describedby="onetrust-policy-text" aria-modal="true" aria-label="Privacy"><div class="ot-sdk-container"><div class="ot-sdk-row"><div id="onetrust-group-container" class="ot-sdk-eight ot-sdk-columns"><div class="banner_logo"></div><div id="onetrust-policy"><div id="onetrust-policy-text">We use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. For more information, see our<a class="ot-cookie-policy-link" href="https://www.elsevier.com/legal/cookienotice" target="_blank" aria-label=", opens in a new tab" rel="noopener">Cookie Policy</a></div></div></div><div id="onetrust-button-group-parent" class="ot-sdk-three ot-sdk-columns"><div id="onetrust-button-group"><button id="onetrust-pc-btn-handler" class="cookie-setting-link">Cookie Settings</button>  <button id="onetrust-accept-btn-handler">Accept all cookies</button></div></div></div></div><!-- Close Button --><div id="onetrust-close-btn-container"></div><!-- Close Button END--></div></div><div id="onetrust-pc-sdk" class="otPcCenter ot-hide ot-fade-in" lang="en" aria-label="Preference center" role="region"><div role="alertdialog" aria-modal="true" aria-describedby="ot-pc-desc" style="height: 100%;" aria-label="Cookie Preference Center"><!-- Close Button --><div class="ot-pc-header"><!-- Logo Tag --><div class="ot-pc-logo" role="img" aria-label="Company Logo"><img alt="Company Logo" src="https://cdn.cookielaw.org/logos/static/ot_company_logo.png"></div></div><!-- Close Button --><div id="ot-pc-content" class="ot-pc-scrollbar"><div class="ot-optout-signal ot-hide"><div class="ot-optout-icon"><svg xmlns="http://www.w3.org/2000/svg"><path class="ot-floating-button__svg-fill" d="M14.588 0l.445.328c1.807 1.303 3.961 2.533 6.461 3.688 2.015.93 4.576 1.746 7.682 2.446 0 14.178-4.73 24.133-14.19 29.864l-.398.236C4.863 30.87 0 20.837 0 6.462c3.107-.7 5.668-1.516 7.682-2.446 2.709-1.251 5.01-2.59 6.906-4.016zm5.87 13.88a.75.75 0 00-.974.159l-5.475 6.625-3.005-2.997-.077-.067a.75.75 0 00-.983 1.13l4.172 4.16 6.525-7.895.06-.083a.75.75 0 00-.16-.973z" fill="#FFF" fill-rule="evenodd"></path></svg></div><span></span></div><h2 id="ot-pc-title">Cookie Preference Center</h2><div id="ot-pc-desc">We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our <a href="https://www.elsevier.com/legal/cookienotice/_nocache" target="_blank">Cookie Policy</a> and the list of <a href="https://support.google.com/admanager/answer/9012903" target="_blank">Google Ad-Tech Vendors</a>.
<br>
<br>
You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.
<br>
</div><button id="accept-recommended-btn-handler">Allow all</button><section class="ot-sdk-row ot-cat-grp"><h3 id="ot-category-title"> Manage Consent Preferences</h3><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="1"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-1" aria-labelledby="ot-header-id-1 ot-status-id-1"></button><!-- Accordion header --><div class="ot-acc-hdr ot-always-active-group"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-1">Strictly Necessary Cookies</h4><div id="ot-status-id-1" class="ot-always-active">Always active</div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-1">These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.
<br><br></p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="1">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="3"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-3" aria-labelledby="ot-header-id-3"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-3">Functional Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-3" id="ot-group-id-3" role="switch" class="category-switch-handler" data-optanongroupid="3" aria-labelledby="ot-header-id-3"> <label class="ot-switch" for="ot-group-id-3"><span class="ot-switch-nob" aria-checked="false" role="switch" aria-label="Functional Cookies"></span> <span class="ot-label-txt">Functional Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-3">These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="3">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="2"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-2" aria-labelledby="ot-header-id-2"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-2">Performance Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-2" id="ot-group-id-2" role="switch" class="category-switch-handler" data-optanongroupid="2" aria-labelledby="ot-header-id-2"> <label class="ot-switch" for="ot-group-id-2"><span class="ot-switch-nob" aria-checked="false" role="switch" aria-label="Performance Cookies"></span> <span class="ot-label-txt">Performance Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-2">These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="2">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="4"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-4" aria-labelledby="ot-header-id-4"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-4">Targeting Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-4" id="ot-group-id-4" role="switch" class="category-switch-handler" data-optanongroupid="4" aria-labelledby="ot-header-id-4"> <label class="ot-switch" for="ot-group-id-4"><span class="ot-switch-nob" aria-checked="false" role="switch" aria-label="Targeting Cookies"></span> <span class="ot-label-txt">Targeting Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-4">These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. If you do not allow these cookies, you will experience less targeted advertising.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="4">Cookie Details List‎</button></div></div></div><!-- Groups sections starts --><!-- Group section ends --><!-- Accordion Group section starts --><!-- Accordion Group section ends --></section></div><section id="ot-pc-lst" class="ot-hide ot-hosts-ui ot-pc-scrollbar"><div id="ot-pc-hdr"><div id="ot-lst-title"><button class="ot-link-btn back-btn-handler" aria-label="Back"><svg id="ot-back-arw" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 444.531 444.531" xml:space="preserve"><title>Back Button</title><g><path fill="#656565" d="M213.13,222.409L351.88,83.653c7.05-7.043,10.567-15.657,10.567-25.841c0-10.183-3.518-18.793-10.567-25.835
                    l-21.409-21.416C323.432,3.521,314.817,0,304.637,0s-18.791,3.521-25.841,10.561L92.649,196.425
                    c-7.044,7.043-10.566,15.656-10.566,25.841s3.521,18.791,10.566,25.837l186.146,185.864c7.05,7.043,15.66,10.564,25.841,10.564
                    s18.795-3.521,25.834-10.564l21.409-21.412c7.05-7.039,10.567-15.604,10.567-25.697c0-10.085-3.518-18.746-10.567-25.978
                    L213.13,222.409z"></path></g></svg></button><h3>Cookie List</h3></div><div class="ot-lst-subhdr"><div class="ot-search-cntr"><p role="status" class="ot-scrn-rdr"></p><input id="vendor-search-handler" type="text" name="vendor-search-handler" placeholder="Search…" aria-label="Cookie list search"> <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 -30 110 110" aria-hidden="true"><title>Search Icon</title><path fill="#2e3644" d="M55.146,51.887L41.588,37.786c3.486-4.144,5.396-9.358,5.396-14.786c0-12.682-10.318-23-23-23s-23,10.318-23,23
            s10.318,23,23,23c4.761,0,9.298-1.436,13.177-4.162l13.661,14.208c0.571,0.593,1.339,0.92,2.162,0.92
            c0.779,0,1.518-0.297,2.079-0.837C56.255,54.982,56.293,53.08,55.146,51.887z M23.984,6c9.374,0,17,7.626,17,17s-7.626,17-17,17
            s-17-7.626-17-17S14.61,6,23.984,6z"></path></svg></div><div class="ot-fltr-cntr"><button id="filter-btn-handler" aria-label="Filter" aria-haspopup="true"><svg role="presentation" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 402.577 402.577" xml:space="preserve"><title>Filter Icon</title><g><path fill="#fff" d="M400.858,11.427c-3.241-7.421-8.85-11.132-16.854-11.136H18.564c-7.993,0-13.61,3.715-16.846,11.136
      c-3.234,7.801-1.903,14.467,3.999,19.985l140.757,140.753v138.755c0,4.955,1.809,9.232,5.424,12.854l73.085,73.083
      c3.429,3.614,7.71,5.428,12.851,5.428c2.282,0,4.66-0.479,7.135-1.43c7.426-3.238,11.14-8.851,11.14-16.845V172.166L396.861,31.413
      C402.765,25.895,404.093,19.231,400.858,11.427z"></path></g></svg></button></div><div id="ot-anchor"></div><section id="ot-fltr-modal"><div id="ot-fltr-cnt"><button id="clear-filters-handler">Clear</button><div class="ot-fltr-scrlcnt ot-pc-scrollbar"><div class="ot-fltr-opts"><div class="ot-fltr-opt"><div class="ot-chkbox"><input id="chkbox-id" type="checkbox" class="category-filter-handler"> <label for="chkbox-id"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div></div></div><div class="ot-fltr-btns"><button id="filter-apply-handler">Apply</button> <button id="filter-cancel-handler">Cancel</button></div></div></div></section></div></div><section id="ot-lst-cnt" class="ot-host-cnt ot-pc-scrollbar"><div id="ot-sel-blk"><div class="ot-sel-all"><div class="ot-sel-all-hdr"><span class="ot-consent-hdr">Consent</span> <span class="ot-li-hdr">Leg.Interest</span></div><div class="ot-sel-all-chkbox"><div class="ot-chkbox" id="ot-selall-hostcntr"><input id="select-all-hosts-groups-handler" type="checkbox"> <label for="select-all-hosts-groups-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div><div class="ot-chkbox" id="ot-selall-vencntr"><input id="select-all-vendor-groups-handler" type="checkbox"> <label for="select-all-vendor-groups-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div><div class="ot-chkbox" id="ot-selall-licntr"><input id="select-all-vendor-leg-handler" type="checkbox"> <label for="select-all-vendor-leg-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div></div></div></div><div class="ot-sdk-row"><div class="ot-sdk-column"><ul id="ot-host-lst"></ul></div></div></section></section><div class="ot-pc-footer ot-pc-scrollbar"><div class="ot-btn-container"> <button class="save-preference-btn-handler onetrust-close-btn-handler">Confirm my choices</button></div><!-- Footer logo --><div class="ot-pc-footer-logo"><a href="https://www.onetrust.com/products/cookie-consent/" target="_blank" rel="noopener noreferrer" aria-label="Powered by OneTrust Opens in a new Tab"><img alt="Powered by Onetrust" src="https://cdn.cookielaw.org/logos/static/powered_by_logo.svg" title="Powered by OneTrust Opens in a new Tab"></a></div></div><!-- Cookie subgroup container --><!-- Vendor list link --><!-- Cookie lost link --><!-- Toggle HTML element --><!-- Checkbox HTML --><!-- plus minus--><!-- Arrow SVG element --><!-- Accordion basic element --><span class="ot-scrn-rdr" aria-atomic="true" aria-live="polite"></span><!-- Vendor Service container and item template --></div><iframe class="ot-text-resize" sandbox="allow-same-origin" title="onetrust-text-resize" style="position: absolute; top: -50000px; width: 100em;" aria-hidden="true"></iframe></div></div></body></html>