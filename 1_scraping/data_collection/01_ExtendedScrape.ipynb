{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a467da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from scholarly import scholarly\n",
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed0b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fer_datasets_LONG = [\n",
    "    \"Extended Cohn-Kanade\", \n",
    "    'MMI Facial Expression',\n",
    "    \"Japanese Female Facial Expression\", \n",
    "    \"Toronto Face Database\",\n",
    "    \"Binghamton University 3D Facial Expression\",\n",
    "    \"Oulu-CASIA\",\n",
    "    \"Radboud Faces Database\",\n",
    "    \"Karolinska Directed Emotional Faces\",\n",
    "    \"Acted Facial Expressions In The Wild\",\n",
    "    \"Static Facial Expression in the Wild\",\n",
    "    \"CMU Multi-PIE\",\n",
    "    \"Affective Faces Database\",\n",
    "    \"Expression in-the-Wild\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66bfbd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"facial expression recognition\", \"FER\", \"deep learning\", \"machine learning\", \"classification\", \"classifier\", \"neural network\", \"CNN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def75269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for combination: Extended Cohn-Kanade facial expression recognition\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to search scholarly papers and collect extended information\n",
    "def search_scholarly(query, save_file):\n",
    "    search_query = scholarly.search_pubs(query)\n",
    "    papers = []\n",
    "    \n",
    "    # Define common metrics and synonyms for bias\n",
    "    metrics_to_check = [\n",
    "        'accuracy', 'f1', 'precision', 'recall', 'auc', 'roc', \n",
    "        'sensitivity', 'specificity', 'confusion matrix', \n",
    "        'loss function', 'cross-entropy', 'mean squared error', \n",
    "        'overfitting', 'underfitting', 'cross-validation', \n",
    "        'training time', 'inference time', 'statistical significance', \n",
    "        'p-value', 't-test', 'anova', 'correlation', 'regression', \n",
    "        'baseline comparison', \n",
    "        'mae', 'rmse'\n",
    "    ]\n",
    "    \n",
    "    bias_synonyms = [\n",
    "        'bias', 'biasness', 'fairness', 'unfairness', 'equity', \n",
    "        'inequality', 'prejudice', 'discrimination', 'impartiality', \n",
    "        'skewness', 'systematic error'\n",
    "    ]\n",
    "    \n",
    "    for _ in range(30):  # Adjust this number as needed (e.g., 35)\n",
    "        try:\n",
    "            paper = next(search_query)\n",
    "            # Collecting only papers with more than a certain citation threshold (e.g., 100)\n",
    "            if 'num_citations' in paper and paper['num_citations'] >= 100:\n",
    "                paper_info = {\n",
    "                    'Title': paper['bib'].get('title', 'No Title'),\n",
    "                    'Authors': paper['bib'].get('author', 'No Author'),\n",
    "                    'Year': paper['bib'].get('pub_year', None),\n",
    "                    'Cited By': paper['num_citations'],\n",
    "                    'Dataset': query,\n",
    "                    'Abstract': paper['bib'].get('abstract', ''),  # Extract abstract if available\n",
    "                    'DOI': paper['bib'].get('doi', 'No DOI'),      # Extract DOI if available\n",
    "                    'Journal': paper['bib'].get('venue', 'No Journal'),\n",
    "                    'URL': None  # Initialize URL as None\n",
    "                }\n",
    "\n",
    "                # Check for mentions of metrics and bias-related terms in the abstract\n",
    "                abstract = paper_info['Abstract'].lower() if paper_info['Abstract'] else ''\n",
    "                \n",
    "                # Include flags for whether specific metrics are mentioned\n",
    "                for metric in metrics_to_check:\n",
    "                    paper_info[f'Mentions_{metric.capitalize().replace(\" \", \"_\")}'] = metric in abstract\n",
    "                \n",
    "                # Include a separate flag for bias-related terms\n",
    "                paper_info['Mentions_Bias'] = any(bias_term in abstract for bias_term in bias_synonyms)\n",
    "                \n",
    "                # Perform a Google search to find the paper's URL\n",
    "                try:\n",
    "                    search_results = search(paper_info['Title'], num_results=1)  # Get the top search result\n",
    "                    for url in search_results:\n",
    "                        paper_info['URL'] = url\n",
    "                        break  # Only take the first result\n",
    "                except Exception as e:\n",
    "                    print(f\"Error finding URL for {paper_info['Title']}: {e}\")\n",
    "                    paper_info['URL'] = None\n",
    "                \n",
    "                papers.append(paper_info)\n",
    "\n",
    "                # Save to CSV after processing each paper\n",
    "                temp_df = pd.DataFrame(papers)\n",
    "                temp_df.to_csv(save_file, mode='a', header=not pd.io.common.file_exists(save_file), index=False)\n",
    "\n",
    "                # If we've collected 10 highly cited papers, break out of the loop\n",
    "                if len(papers) >= 20:\n",
    "                    break\n",
    "\n",
    "            # Random delay between 30 and 60 seconds to avoid detection\n",
    "            time.sleep(random.uniform(30, 60))\n",
    "        except StopIteration:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "\n",
    "    return papers\n",
    "\n",
    "# Collect data from Scholarly for each combination of dataset and topic\n",
    "def collect_data(fer_datasets_LONG, topics, save_file):\n",
    "    scholarly_results = []\n",
    "\n",
    "    for dataset in fer_datasets_LONG:\n",
    "        for topic in topics:\n",
    "            combined_query = f\"{dataset} {topic}\"\n",
    "            print(f\"Searching for combination: {combined_query}\")\n",
    "            scholarly_results.extend(search_scholarly(combined_query, save_file))\n",
    "\n",
    "# Save results to a CSV file\n",
    "save_file = 'scholarly_papers_combined_extended.csv'\n",
    "\n",
    "# Start collecting data\n",
    "collect_data(fer_datasets_LONG, topics, save_file)\n",
    "\n",
    "print(\"Data collection completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b1bd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
