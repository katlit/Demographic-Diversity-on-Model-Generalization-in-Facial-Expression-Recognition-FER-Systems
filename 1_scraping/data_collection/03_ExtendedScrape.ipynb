{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a467da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from scholarly import scholarly\n",
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed0b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fer_datasets_LONG = [\n",
    "    #\"Extended Cohn-Kanade\", \n",
    "    #'MMI Facial Expression',\n",
    "    #\"Japanese Female Facial Expression\", \n",
    "    #\"Toronto Face Database\",\n",
    "    #\"Binghamton University 3D Facial Expression\",\n",
    "    #\"Oulu-CASIA\",\n",
    "    #\"Radboud Faces Database\",\n",
    "    #\"Karolinska Directed Emotional Faces\",\n",
    "    \"Acted Facial Expressions In The Wild\",\n",
    "    \"Static Facial Expression in the Wild\",\n",
    "    \"CMU Multi-PIE\",\n",
    "    \"Affective Faces Database\",\n",
    "    \"Expression in-the-Wild\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66bfbd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"facial expression recognition\", \"FER\", \"deep learning\", \"machine learning\", \"classification\", \"classifier\", \"neural network\", \"CNN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def75269",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for combination: Acted Facial Expressions In The Wild facial expression recognition\n",
      "Searching for combination: Acted Facial Expressions In The Wild FER\n",
      "Searching for combination: Acted Facial Expressions In The Wild deep learning\n",
      "Searching for combination: Acted Facial Expressions In The Wild machine learning\n",
      "Searching for combination: Acted Facial Expressions In The Wild classification\n",
      "Searching for combination: Acted Facial Expressions In The Wild classifier\n",
      "Searching for combination: Acted Facial Expressions In The Wild neural network\n",
      "Searching for combination: Acted Facial Expressions In The Wild CNN\n",
      "Searching for combination: Static Facial Expression in the Wild facial expression recognition\n",
      "Searching for combination: Static Facial Expression in the Wild FER\n",
      "Searching for combination: Static Facial Expression in the Wild deep learning\n",
      "Searching for combination: Static Facial Expression in the Wild machine learning\n",
      "Searching for combination: Static Facial Expression in the Wild classification\n",
      "Searching for combination: Static Facial Expression in the Wild classifier\n",
      "Searching for combination: Static Facial Expression in the Wild neural network\n",
      "Searching for combination: Static Facial Expression in the Wild CNN\n",
      "Searching for combination: CMU Multi-PIE facial expression recognition\n",
      "Searching for combination: CMU Multi-PIE FER\n",
      "Searching for combination: CMU Multi-PIE deep learning\n",
      "Searching for combination: CMU Multi-PIE machine learning\n",
      "Searching for combination: CMU Multi-PIE classification\n",
      "Searching for combination: CMU Multi-PIE classifier\n",
      "Searching for combination: CMU Multi-PIE neural network\n",
      "Searching for combination: CMU Multi-PIE CNN\n",
      "Searching for combination: Affective Faces Database facial expression recognition\n",
      "Searching for combination: Affective Faces Database FER\n",
      "Searching for combination: Affective Faces Database deep learning\n",
      "Searching for combination: Affective Faces Database machine learning\n",
      "Searching for combination: Affective Faces Database classification\n",
      "Searching for combination: Affective Faces Database classifier\n",
      "Searching for combination: Affective Faces Database neural network\n",
      "An error occurred: Cannot Fetch from Google Scholar.\n",
      "An error occurred: Cannot Fetch from Google Scholar.\n",
      "An error occurred: Cannot Fetch from Google Scholar.\n",
      "An error occurred: Cannot Fetch from Google Scholar.\n",
      "An error occurred: Cannot Fetch from Google Scholar.\n",
      "An error occurred: Cannot Fetch from Google Scholar.\n",
      "An error occurred: Cannot Fetch from Google Scholar.\n",
      "An error occurred: Cannot Fetch from Google Scholar.\n",
      "An error occurred: Cannot Fetch from Google Scholar.\n",
      "An error occurred: Cannot Fetch from Google Scholar.\n",
      "Searching for combination: Affective Faces Database CNN\n"
     ]
    },
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMaxTriesExceededException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m save_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscholarly_papers_combined_extended.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Start collecting data\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[43mcollect_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfer_datasets_LONG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData collection completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 89\u001b[0m, in \u001b[0;36mcollect_data\u001b[1;34m(fer_datasets_LONG, topics, save_file)\u001b[0m\n\u001b[0;32m     87\u001b[0m combined_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearching for combination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 89\u001b[0m scholarly_results\u001b[38;5;241m.\u001b[39mextend(\u001b[43msearch_scholarly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_file\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36msearch_scholarly\u001b[1;34m(query, save_file)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_scholarly\u001b[39m(query, save_file):\n\u001b[1;32m----> 3\u001b[0m     search_query \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_pubs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     papers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Define common metrics and synonyms for bias\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scholarly\\_scholarly.py:160\u001b[0m, in \u001b[0;36m_Scholarly.search_pubs\u001b[1;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m:param query: terms to be searched\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_url(_PUBSEARCH\u001b[38;5;241m.\u001b[39mformat(requests\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mquote(query)), patents\u001b[38;5;241m=\u001b[39mpatents,\n\u001b[0;32m    158\u001b[0m                           citations\u001b[38;5;241m=\u001b[39mcitations, year_low\u001b[38;5;241m=\u001b[39myear_low, year_high\u001b[38;5;241m=\u001b[39myear_high,\n\u001b[0;32m    159\u001b[0m                           sort_by\u001b[38;5;241m=\u001b[39msort_by, include_last_year\u001b[38;5;241m=\u001b[39minclude_last_year, start_index\u001b[38;5;241m=\u001b[39mstart_index)\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_publications\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scholarly\\_navigator.py:296\u001b[0m, in \u001b[0;36mNavigator.search_publications\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_publications\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _SearchScholarIterator:\n\u001b[0;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    :param url: the url where publications can be found.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_SearchScholarIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scholarly\\publication_parser.py:53\u001b[0m, in \u001b[0;36m_SearchScholarIterator.__init__\u001b[1;34m(self, nav, url)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pubtype \u001b[38;5;241m=\u001b[39m PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scholar?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m url \u001b[38;5;28;01melse\u001b[39;00m PublicationSource\u001b[38;5;241m.\u001b[39mJOURNAL_CITATION_LIST\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav \u001b[38;5;241m=\u001b[39m nav\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_total_results()\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nav)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scholarly\\publication_parser.py:59\u001b[0m, in \u001b[0;36m_SearchScholarIterator._load_url\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_url\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# this is temporary until setup json file\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_r gs_or gs_scl\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_mpat_ttl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scholarly\\_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[0;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scholarly\\_navigator.py:190\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[1;34m(self, pagerequest, premium)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_page(pagerequest, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTriesExceededException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot Fetch from Google Scholar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mMaxTriesExceededException\u001b[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to search scholarly papers and collect extended information\n",
    "def search_scholarly(query, save_file):\n",
    "    search_query = scholarly.search_pubs(query)\n",
    "    papers = []\n",
    "    \n",
    "    # Define common metrics and synonyms for bias\n",
    "    metrics_to_check = [\n",
    "        'accuracy', 'f1', 'precision', 'recall', 'auc', 'roc', \n",
    "        'sensitivity', 'specificity', 'confusion matrix', \n",
    "        'loss function', 'cross-entropy', 'mean squared error', \n",
    "        'overfitting', 'underfitting', 'cross-validation', \n",
    "        'training time', 'inference time', 'statistical significance', \n",
    "        'p-value', 't-test', 'anova', 'correlation', 'regression', \n",
    "        'baseline comparison', \n",
    "        'mae', 'rmse'\n",
    "    ]\n",
    "    \n",
    "    bias_synonyms = [\n",
    "        'bias', 'biasness', 'fairness', 'unfairness', 'equity', \n",
    "        'inequality', 'prejudice', 'discrimination', 'impartiality', \n",
    "        'skewness', 'systematic error'\n",
    "    ]\n",
    "    \n",
    "    for _ in range(30):  # Adjust this number as needed (e.g., 35)\n",
    "        try:\n",
    "            paper = next(search_query)\n",
    "            # Collecting only papers with more than a certain citation threshold (e.g., 100)\n",
    "            if 'num_citations' in paper and paper['num_citations'] >= 100:\n",
    "                paper_info = {\n",
    "                    'Title': paper['bib'].get('title', 'No Title'),\n",
    "                    'Authors': paper['bib'].get('author', 'No Author'),\n",
    "                    'Year': paper['bib'].get('pub_year', None),\n",
    "                    'Cited By': paper['num_citations'],\n",
    "                    'Dataset': query,\n",
    "                    'Abstract': paper['bib'].get('abstract', ''),  # Extract abstract if available\n",
    "                    'DOI': paper['bib'].get('doi', 'No DOI'),      # Extract DOI if available\n",
    "                    'Journal': paper['bib'].get('venue', 'No Journal'),\n",
    "                    'URL': None  # Initialize URL as None\n",
    "                }\n",
    "\n",
    "                # Check for mentions of metrics and bias-related terms in the abstract\n",
    "                abstract = paper_info['Abstract'].lower() if paper_info['Abstract'] else ''\n",
    "                \n",
    "                # Include flags for whether specific metrics are mentioned\n",
    "                for metric in metrics_to_check:\n",
    "                    paper_info[f'Mentions_{metric.capitalize().replace(\" \", \"_\")}'] = metric in abstract\n",
    "                \n",
    "                # Include a separate flag for bias-related terms\n",
    "                paper_info['Mentions_Bias'] = any(bias_term in abstract for bias_term in bias_synonyms)\n",
    "                \n",
    "                # Perform a Google search to find the paper's URL\n",
    "                try:\n",
    "                    search_results = search(paper_info['Title'], num_results=1)  # Get the top search result\n",
    "                    for url in search_results:\n",
    "                        paper_info['URL'] = url\n",
    "                        break  # Only take the first result\n",
    "                except Exception as e:\n",
    "                    print(f\"Error finding URL for {paper_info['Title']}: {e}\")\n",
    "                    paper_info['URL'] = None\n",
    "                \n",
    "                papers.append(paper_info)\n",
    "\n",
    "                # Save to CSV after processing each paper\n",
    "                temp_df = pd.DataFrame(papers)\n",
    "                temp_df.to_csv(save_file, mode='a', header=not pd.io.common.file_exists(save_file), index=False)\n",
    "\n",
    "                # If we've collected 10 highly cited papers, break out of the loop\n",
    "                if len(papers) >= 20:\n",
    "                    break\n",
    "\n",
    "            # Random delay between 30 and 60 seconds to avoid detection\n",
    "            time.sleep(random.uniform(30, 60))\n",
    "        except StopIteration:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "\n",
    "    return papers\n",
    "\n",
    "# Collect data from Scholarly for each combination of dataset and topic\n",
    "def collect_data(fer_datasets_LONG, topics, save_file):\n",
    "    scholarly_results = []\n",
    "\n",
    "    for dataset in fer_datasets_LONG:\n",
    "        for topic in topics:\n",
    "            combined_query = f\"{dataset} {topic}\"\n",
    "            print(f\"Searching for combination: {combined_query}\")\n",
    "            scholarly_results.extend(search_scholarly(combined_query, save_file))\n",
    "\n",
    "# Save results to a CSV file\n",
    "save_file = 'scholarly_papers_combined_extended.csv'\n",
    "\n",
    "# Start collecting data\n",
    "collect_data(fer_datasets_LONG, topics, save_file)\n",
    "\n",
    "print(\"Data collection completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b1bd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
